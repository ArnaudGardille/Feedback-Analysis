{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_url = \"https://azureainame2554289873.openai.azure.com/\"\n",
    "\n",
    "\n",
    "curl https://azureainame2554289873.openai.azure.com/openai/deployments/YOUR_DEPLOYMENT_NAME/completions?api-version=2023-05-15\\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -H \"api-key: YOUR_API_KEY\" \\\n",
    "  -d \"{\n",
    "  \\\"prompt\\\": \\\"Once upon a time\\\",\n",
    "  \\\"max_tokens\\\": 5\n",
    "}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:8000/v1\"\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion result: Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\" I. Introduction\\n\\nJason is a name that is commonly used for both males and females. In this context, we will assume that the person referred to is a male. Jason's age is given as 25 years old.\\n\\nII. Age\\n\\nJason's age is 25 years old. This means that he has been alive for 25 years. Age is a measure of the length of time that a person has existed. In this case, Jason has existed for 25 years.\\n\\nIII. Birth Year\\n\\nTo find Jason's birth year, we can subtract his age from the current year. Assuming the current year is 2023, we can calculate Jason's birth year as follows:\\n\\nBirth year = Current year - Age\\nBirth year = 2023 - 25\\nBirth year = 1998\\n\\nIV. Conclusion\\n\\nSo, Jason was born in the year 1998. He is currently 25 years old. Age is an important factor in many aspects of life, including eligibility for certain privileges, social expectations, and personal development. In Jason's case, being 25 years old puts him in a stage of life where he may be focusing on establishing a career, starting a family, or pursuing further education. Regardless of what specific path Jason is on, his age is an essential part of his identity and will continue to shape his experiences as he grows older.\", role='assistant', function_call=None, tool_calls=None))\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(model=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "                                      messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Extract Jason is 25 years old\"},\n",
    "    ],)\n",
    "print(\"Completion result:\", completion.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT = \"dechiktorren-9187-oqsni\"\n",
    "DEPLOYMENT = \"mistralai-mixtral-8x7b-instru-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://dechiktorren-9187-oqsni.westeurope.inference.ml.azure.com/score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The public registry name contains Llama 2 models\n",
    "registry_name = \"azureml-meta\"\n",
    "model_name = \"mistralai-Mixtral-8x7B-v01\"\n",
    "\n",
    "endpoint_name = f\"{model_name}-test-ep\"  # Replace with your endpoint name\n",
    "deployment_name = \"mixtral\"  # Replace with your deployment name, lower case only!!!\n",
    "sku_name = \"Standard_NC24s_v3\"  # Name of the sku(instance type) Check the model-list(can be found in the parent folder(inference)) to get the most optimal sku for your model (Default: Standard_DS2_v2)\n",
    "\n",
    "# The severity level that will trigger response be blocked\n",
    "# Please reference Azure AI content documentation for more details\n",
    "# https://learn.microsoft.com/en-us/azure/cognitive-services/content-safety/concepts/harm-categories\n",
    "content_severity_threshold = \"2\"\n",
    "\n",
    "# UAI to be used for endpoint if you choose to use UAI as authentication method\n",
    "uai_name = \"\"  # default to \"aacs-uai\" in prepare uai notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'azure'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01midentity\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DefaultAzureCredential, InteractiveBrowserCredential\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m     credential \u001b[38;5;241m=\u001b[39m DefaultAzureCredential()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'azure'"
     ]
    }
   ],
   "source": [
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2788449138.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    import OllamaFunctions from \"langchain/experimental/chat_models/ollama_functions\";\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import OllamaFunctions from \"langchain/experimental/chat_models/ollama_functions\";\n",
    "\n",
    "const model = new OllamaFunctions({\n",
    "  temperature: 0.1,\n",
    "  model: \"mistral\",\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\"{\\\\\"error\\\\\": \\\\\"Error in processing request\\\\\", \\\\\"exception\\\\\": \\\\\"{\\\\\\\\\\\\\"error\\\\\\\\\\\\\": \\\\\\\\\\\\\"Expected input format: \\\\\\\\\\\\\\\\n{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"input_data\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"input_string\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"<query>\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"parameters\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"k1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"v1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"k2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"v2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"}}}.\\\\\\\\\\\\\\\\n <query> should be in below format:\\\\\\\\\\\\\\\\n For text-generation: [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"str1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"str2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", ...]\\\\\\\\\\\\\\\\nFor chat-completion: [{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"role\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"user\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"str1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"role\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"assistant\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"str2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"} ....]\\\\\\\\\\\\\", \\\\\\\\\\\\\"exception\\\\\\\\\\\\\": \\\\\\\\\\\\\"Invalid input data\\\\\\\\\\\\\"}\\\\\"}\"'\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "def allowSelfSignedHttps(allowed):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
    "\n",
    "# Request data goes here\n",
    "# The example below assumes JSON formatting which may be updated\n",
    "# depending on the format your endpoint expects.\n",
    "# More information can be found here:\n",
    "# https://docs.microsoft.com/azure/machine-learning/how-to-deploy-advanced-entry-script\n",
    "data = {}\n",
    "\n",
    "body = str.encode(json.dumps(data))\n",
    "\n",
    "url = 'https://dechiktorren-9187-oqsni.westeurope.inference.ml.azure.com/score'\n",
    "# Replace this with the primary/secondary key or AMLToken for the endpoint\n",
    "api_key = 'wgPBeyPI2DZxJhdyWbCHCGzEWvoxfybX'\n",
    "if not api_key:\n",
    "    raise Exception(\"A key should be provided to invoke the endpoint\")\n",
    "\n",
    "# The azureml-model-deployment header will force the request to go to a specific deployment.\n",
    "# Remove this header to have the request observe the endpoint traffic rules\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key), 'azureml-model-deployment': 'mistralai-mixtral-8x7b-instru-1' }\n",
    "\n",
    "req = urllib.request.Request(url, body, headers)\n",
    "\n",
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "\n",
    "    result = response.read()\n",
    "    print(result)\n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"The request failed with status code: \" + str(error.code))\n",
    "\n",
    "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
    "    print(error.info())\n",
    "    print(error.read().decode(\"utf8\", 'ignore'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\"{\\\\\"error\\\\\": \\\\\"Error in processing request\\\\\", \\\\\"exception\\\\\": \\\\\"{\\\\\\\\\\\\\"error\\\\\\\\\\\\\": \\\\\\\\\\\\\"Expected input format: \\\\\\\\\\\\\\\\n{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"input_data\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"input_string\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"<query>\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"parameters\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"k1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"v1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"k2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"v2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"}}}.\\\\\\\\\\\\\\\\n <query> should be in below format:\\\\\\\\\\\\\\\\n For text-generation: [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"str1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"str2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", ...]\\\\\\\\\\\\\\\\nFor chat-completion: [{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"role\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"user\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"str1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"role\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"assistant\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"str2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"} ....]\\\\\\\\\\\\\", \\\\\\\\\\\\\"exception\\\\\\\\\\\\\": \\\\\\\\\\\\\"Invalid input data\\\\\\\\\\\\\"}\\\\\"}\"'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'object',\n",
       " 'properties': {'title': {'type': 'string'},\n",
       "  'summary': {'type': 'string'},\n",
       "  'author': {'type': 'string'},\n",
       "  'published_year': {'type': 'integer'}},\n",
       " 'required': ['title', 'summary', 'author', 'published_year']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llm_core.schema import to_json_schema\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Book:\n",
    "    title: str\n",
    "    summary: str\n",
    "    author: str\n",
    "    published_year: int\n",
    "\n",
    "schema = to_json_schema(Book)\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import argparse\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# whitespace is constrained to a single space char to prevent model \"running away\" in\n",
    "# whitespace. Also maybe improves generation quality?\n",
    "SPACE_RULE = '\" \"?'\n",
    "\n",
    "PRIMITIVE_RULES = {\n",
    "    'boolean': '(\"true\" | \"false\") space',\n",
    "    'number': '(\"-\"? ([0-9] | [1-9] [0-9]*)) (\".\" [0-9]+)? ([eE] [-+]? [0-9]+)? space',\n",
    "    'integer': '(\"-\"? ([0-9] | [1-9] [0-9]*)) space',\n",
    "    'string': r''' \"\\\"\" (\n",
    "        [^\"\\\\] |\n",
    "        \"\\\\\" ([\"\\\\/bfnrt] | \"u\" [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F])\n",
    "      )* \"\\\"\" space ''',\n",
    "    'null': '\"null\" space',\n",
    "}\n",
    "\n",
    "INVALID_RULE_CHARS_RE = re.compile(r'[^a-zA-Z0-9-]+')\n",
    "GRAMMAR_LITERAL_ESCAPE_RE = re.compile(r'[\\r\\n\"]')\n",
    "GRAMMAR_LITERAL_ESCAPES = {'\\r': '\\\\r', '\\n': '\\\\n', '\"': '\\\\\"'}\n",
    "\n",
    "\n",
    "class SchemaConverter:\n",
    "    def __init__(self, prop_order):\n",
    "        self._prop_order = prop_order\n",
    "        self._rules = {'space': SPACE_RULE}\n",
    "\n",
    "    def _format_literal(self, literal):\n",
    "        escaped = GRAMMAR_LITERAL_ESCAPE_RE.sub(\n",
    "            lambda m: GRAMMAR_LITERAL_ESCAPES.get(m.group(0)), json.dumps(literal)\n",
    "        )\n",
    "        return f'\"{escaped}\"'\n",
    "\n",
    "    def _add_rule(self, name, rule):\n",
    "        esc_name = INVALID_RULE_CHARS_RE.sub('-', name)\n",
    "        if esc_name not in self._rules or self._rules[esc_name] == rule:\n",
    "            key = esc_name\n",
    "        else:\n",
    "            i = 0\n",
    "            while f'{esc_name}{i}' in self._rules:\n",
    "                i += 1\n",
    "            key = f'{esc_name}{i}'\n",
    "        self._rules[key] = rule\n",
    "        return key\n",
    "\n",
    "    def visit(self, schema, name):\n",
    "        schema_type = schema.get('type')\n",
    "        rule_name = name or 'root'\n",
    "\n",
    "        if 'oneOf' in schema or 'anyOf' in schema:\n",
    "            rule = ' | '.join((\n",
    "                self.visit(alt_schema, f'{name}{\"-\" if name else \"\"}{i}')\n",
    "                for i, alt_schema in enumerate(schema.get('oneOf') or schema['anyOf'])\n",
    "            ))\n",
    "            return self._add_rule(rule_name, rule)\n",
    "\n",
    "        elif 'const' in schema:\n",
    "            return self._add_rule(rule_name, self._format_literal(schema['const']))\n",
    "\n",
    "        elif 'enum' in schema:\n",
    "            rule = ' | '.join((self._format_literal(v) for v in schema['enum']))\n",
    "            return self._add_rule(rule_name, rule)\n",
    "\n",
    "        elif schema_type == 'object' and 'properties' in schema:\n",
    "            # TODO: `required` keyword\n",
    "            prop_order = self._prop_order\n",
    "            prop_pairs = sorted(\n",
    "                schema['properties'].items(),\n",
    "                # sort by position in prop_order (if specified) then by key\n",
    "                key=lambda kv: (prop_order.get(kv[0], len(prop_order)), kv[0]),\n",
    "            )\n",
    "\n",
    "            rule = '\"{\" space'\n",
    "            for i, (prop_name, prop_schema) in enumerate(prop_pairs):\n",
    "                prop_rule_name = self.visit(prop_schema, f'{name}{\"-\" if name else \"\"}{prop_name}')\n",
    "                if i > 0:\n",
    "                    rule += ' \",\" space'\n",
    "                rule += fr' {self._format_literal(prop_name)} space \":\" space {prop_rule_name}'\n",
    "            rule += ' \"}\" space'\n",
    "\n",
    "            return self._add_rule(rule_name, rule)\n",
    "\n",
    "        elif schema_type == 'array' and 'items' in schema:\n",
    "            # TODO `prefixItems` keyword\n",
    "            item_rule_name = self.visit(schema['items'], f'{name}{\"-\" if name else \"\"}item')\n",
    "            rule = f'\"[\" space ({item_rule_name} (\",\" space {item_rule_name})*)? \"]\" space'\n",
    "            return self._add_rule(rule_name, rule)\n",
    "\n",
    "        else:\n",
    "            assert schema_type in PRIMITIVE_RULES, f'Unrecognized schema: {schema}'\n",
    "            return self._add_rule(\n",
    "                'root' if rule_name == 'root' else schema_type,\n",
    "                PRIMITIVE_RULES[schema_type]\n",
    "            )\n",
    "\n",
    "    def format_grammar(self):\n",
    "        return '\\n'.join((f'{name} ::= {rule}' for name, rule in self._rules.items()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_grammar(schema):\n",
    "    converter = SchemaConverter({})\n",
    "    converter.visit(schema, '')\n",
    "    return converter.format_grammar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'space ::= \" \"?\\nstring ::=  \"\\\\\"\" (\\n        [^\"\\\\\\\\] |\\n        \"\\\\\\\\\" ([\"\\\\\\\\/bfnrt] | \"u\" [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F])\\n      )* \"\\\\\"\" space \\ninteger ::= (\"-\"? ([0-9] | [1-9] [0-9]*)) space\\nroot ::= \"{\" space \"\\\\\"author\\\\\"\" space \":\" space string \",\" space \"\\\\\"published_year\\\\\"\" space \":\" space integer \",\" space \"\\\\\"summary\\\\\"\" space \":\" space string \",\" space \"\\\\\"title\\\\\"\" space \":\" space string \"}\" space'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_grammar(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def parse(text, schema):\n",
    "    url = \"http://localhost:8080/completion\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    grammar = generate_grammar(schema)\n",
    "\n",
    "    prompt = f\"\"\"<s>[INST]\n",
    "    {text}\n",
    "    [/INST]\n",
    "    \"\"\"\n",
    "\n",
    "    data = {\n",
    "        \"prompt\": prompt,\n",
    "        \"n_predict\": 512,\n",
    "        \"temperature\": 0.1,\n",
    "        \"grammar\": grammar,\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    return json.loads(response.json()[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author': 'Isaac Asimov', 'published_year': 1951, 'summary': 'Foundation is a science fiction novel by American writer Isaac Asimov. It is the first published in his Foundation Trilogy (later expanded into the Foundation series). Foundation is a cycle of five interrelated short stories, first published as a single book by Gnome Press in 1951. Collectively they tell the early story of the Foundation, an institute founded by psychohistorian Hari Seldon to preserve the best of galactic civilization after the collapse of the Galactic Empire.', 'title': 'Foundation'}\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Foundation is a science fiction novel by American writer\n",
    "Isaac Asimov. It is the first published in his Foundation Trilogy (later\n",
    "expanded into the Foundation series). Foundation is a cycle of five\n",
    "interrelated short stories, first published as a single book by Gnome Press\n",
    "in 1951. Collectively they tell the early story of the Foundation,\n",
    "an institute founded by psychohistorian Hari Seldon to preserve the best\n",
    "of galactic civilization after the collapse of the Galactic Empire.\n",
    "\"\"\"\n",
    "from pydantic import BaseModel\n",
    "\n",
    "@dataclass\n",
    "class Book(BaseModel):\n",
    "    title: str\n",
    "    summary: str\n",
    "    author: str\n",
    "    published_year: int\n",
    "\n",
    "    @classmethod\n",
    "    def schema(cls):\n",
    "        return to_json_schema(cls)\n",
    "\n",
    "\n",
    "data = parse(text, Book.schema())\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Book(title='Foundation', summary='Foundation is a science fiction novel by American writer Isaac Asimov. It is the first published in his Foundation Trilogy (later expanded into the Foundation series). Foundation is a cycle of five interrelated short stories, first published as a single book by Gnome Press in 1951. Collectively they tell the early story of the Foundation, an institute founded by psychohistorian Hari Seldon to preserve the best of galactic civilization after the collapse of the Galactic Empire.', author='Isaac Asimov', published_year=1951)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Book(**data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'categories': ['NLP', 'Summarization'], 'main_topic': 'Summary Generation', 'summary_in_50_words': 'This study investigates the tradeoff between informativeness and readability in summary generation. GPT-4 generates increasingly dense summaries using a Chain of Density (CoD) prompt, which leads to more abstractive, fused summaries with less lead bias. Human preference studies show that GPT-4 summaries generated by CoD are preferred over vanilla prompts and almost as dense as human-written summaries.', 'title': 'Understanding the Tradeoff between Informativeness and Readability in Summary Generation using GPT-4'}\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class Publication(BaseModel):\n",
    "    title: str\n",
    "    main_topic: str\n",
    "    summary_in_50_words: str\n",
    "    categories: List[str]\n",
    "\n",
    "    @classmethod\n",
    "    def schema(cls):\n",
    "        return to_json_schema(cls)\n",
    "\n",
    "text = \"\"\"\n",
    "Abstract\n",
    "\n",
    "Selecting the “right” amount of information to include in a summary is\n",
    "a difficult task. A good summary should be detailed and entity-centric\n",
    "without being overly dense and hard to follow.\n",
    "\n",
    "To better understand this tradeoff, we solicit increasingly dense GPT-4\n",
    "summaries with what we refer to as a “Chain of Density” (CoD) prompt.\n",
    "\n",
    "Specifically, GPT-4 generates an initial entity- sparse summary before\n",
    "iteratively incorporating missing salient entities without increasing the\n",
    "length. Summaries generated by CoD are more abstractive, exhibit more\n",
    "fusion, and have less of a lead bias than GPT-4 summaries generated by\n",
    "a vanilla prompt.\n",
    "\n",
    "We conduct a human preference study on 100 CNN DailyMail articles and\n",
    "find that that humans prefer GPT-4 summaries that are more dense than\n",
    "those generated by a vanilla prompt and almost as dense as human\n",
    "written summaries.\n",
    "\n",
    "Qualitative analysis supports the notion that there exists a tradeoff between\n",
    "informativeness and readability. 500 annotated CoD summaries, as well as\n",
    "an extra 5,000 unannotated summaries, are freely available on HuggingFace.\n",
    "\"\"\"\n",
    "\n",
    "data = parse(text, Publication.schema())\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Publication(title='Understanding the Tradeoff between Informativeness and Readability in Summary Generation using GPT-4', main_topic='Summary Generation', summary_in_50_words='This study investigates the tradeoff between informativeness and readability in summary generation. GPT-4 generates increasingly dense summaries using a Chain of Density (CoD) prompt, which leads to more abstractive, fused summaries with less lead bias. Human preference studies show that GPT-4 summaries generated by CoD are preferred over vanilla prompts and almost as dense as human-written summaries.', categories=['NLP', 'Summarization'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Publication(**data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feedback_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
