{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjPRVXra8lVZ"
      },
      "source": [
        "# Dependancies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKSREXZg85yy"
      },
      "source": [
        "## Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMSukVZh29HK"
      },
      "outputs": [],
      "source": [
        "#!pip install sentence_transformers langchain openai tqdm datasets asyncio scikit-learn cohere tiktoken umap altair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Md3DNHlV22Ai"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from datasets import load_dataset\n",
        "import umap\n",
        "import altair as alt\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from typing import List\n",
        "import enum\n",
        "\n",
        "from langchain_community.llms import Ollama\n",
        "from langchain.output_parsers.regex_dict import RegexDictParser\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, ChatMessage\n",
        "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from pydantic import BaseModel, Field, validator, create_model\n",
        "from openai import AsyncOpenAI, OpenAI\n",
        "import asyncio\n",
        "import os\n",
        "\n",
        "import requests\n",
        "import json\n",
        "\n",
        "import itertools\n",
        "from copy import deepcopy\n",
        "from tqdm.notebook import tqdm, trange\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import umap.umap_ as umap\n",
        "#import umap\n",
        "import hdbscan\n",
        "\n",
        "from typing import Literal, Union, Optional\n",
        "from pydantic.config import ConfigDict\n",
        "\n",
        "import openai\n",
        "import instructor\n",
        "\n",
        "from src.bubble import *\n",
        "from src.models import *\n",
        "from src.utilities import *\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiENBWdi22Al"
      },
      "outputs": [],
      "source": [
        "#PROJECT =  \"Metro\" #\"Cheerz\"\n",
        "#project_path = 'Results/'+PROJECT\n",
        "#os.makedirs(project_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "aspects_df = get(\"Aspect\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "aspects_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Insights extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TYPES_LIST = ['Point positif', 'Nouvelle fonctionnalité', 'Point de douleur', 'Bug']\n",
        "\n",
        "tags_df = get(\"Tag\", constraints=[])\n",
        "#types_df = get(\"Type\", constraints=[])\n",
        "categories_df = get(\"Category\")\n",
        "subcategories_df = get(\"SubCategory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "company_infos = bubble_client.get(\n",
        "    \"Company\",\n",
        "    bubble_id=COMPANY_ID,\n",
        ")\n",
        "project_infos = bubble_client.get(\n",
        "    \"Project\",\n",
        "    bubble_id=PROJECT_ID,\n",
        ")\n",
        "\n",
        "feedback_context = {\n",
        "    \"entreprise\": company_infos[\"Name\"],\n",
        "    \"context\": company_infos['Context'],\n",
        "    \"role\": company_infos['Role'],\n",
        "    \"cible\": project_infos['Target'],\n",
        "    \"types\": '- '+' \\n- '.join(TYPES_LIST),\n",
        "    \"tags\": '- '+' \\n- '.join([row[\"Name\"]+' : '+row[\"Description\"] for _,row in tags_df.iterrows()]),\n",
        "    #\"types\": '- '+' \\n- '.join([row[\"Name\"]+' : '+row[\"Description\"] for _,row in types_df.iterrows()]),\n",
        "    #\"insight_types\": types_descr,\n",
        "    #\"insight_categories\": tags_descr,\n",
        "    #\"question\": project_infos['Study_question'],\n",
        "    #\"exemple_commentaire\": exemple_commentaire,\n",
        "    #\"example_insights\": '\\n- '.join(list(examples_insights_df['Insights qui devraient en découler'])),\n",
        "}\n",
        "\n",
        "feedback_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ID_CATEG_NONE = categories_df[categories_df[\"Name\"].isna()].iloc[0][\"_id\"]\n",
        "SUBCATEG_NONE = subcategories_df[subcategories_df[\"Name\"].isna()]\n",
        "ID_CATEG_NONE, SUBCATEG_NONE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TypeInsight = enum.Enum(\"Type de l'insight\", [(convert_text_to_constants(t), t) for t in TYPES_LIST])\n",
        "#types_to_id = {convert_text_to_constants(row.Name): row._id for _, row in types_df.iterrows()}\n",
        "\n",
        "#TypeInsight = enum.Enum(\"Type de l'insight\", [(convert_text_to_constants(row.Name), row.Name) for _, row in types_df.iterrows()])\n",
        "TagInsight = enum.Enum(\"Tag de l'insight\", [(convert_text_to_constants(row.Name), row.Name) for _, row in tags_df.iterrows()])\n",
        "tags_to_id = {convert_text_to_constants(row.Name): row._id for _, row in tags_df.iterrows()}\n",
        "#type_to_id = {convert_text_to_constants(row.Name): row._id for _, row in types_df.iterrows()}\n",
        "#type_to_id[convert_text_to_constants('Point de douleur')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list(TypeInsight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#FeedbackIndex = enum.Enum(\"Indice du retour associé\", [(str(i), i) for i in range(BATCH_SIZE)])\n",
        "\n",
        "class Insight(BaseModel):\n",
        "    insight: str = Field(description=\"Insight, c'est a dire infirmation importante que révèle cette étude à l'entreprise, et lui permettera d'améliorer son experience utilisateur, sa stratégie ou son produit.\") \n",
        "    insight_type: TypeInsight = Field(description=\"Type de l'insight, parmis \"+', '.join(TYPES_LIST)) \n",
        "    insight_tags: List[TagInsight] = Field(description=\"Tags de l'insight. Peut eventuellement être une liste vide.\")\n",
        "    associated_indexes: List[int] = Field(description=\"Indices des retours associés.\")\n",
        "    details: List[str] = Field(description=\"Détails de l'insights. Peut eventuellement être une liste vide.\") \n",
        "    consequences: List[str] = Field(description=\"Conséquences pour l'entrerpise. Peut eventuellement être une liste vide.\")\n",
        "    recommandations: List[str] = Field(description=\"Recommandations pour l'entrerpise. Peut eventuellement être une liste vide.\")\n",
        "    def __str__(self):\n",
        "        return \"\"\"{0}\n",
        "\n",
        "Détails:\n",
        "    - {1}\n",
        "Conséquences:\n",
        "    - {2}\n",
        "Recommandations:\n",
        "    - {3}\n",
        "Retours: \n",
        "    - {4}\n",
        "Type: \n",
        "    {5}\n",
        "Tags: \n",
        "    {6}\n",
        "        \"\"\".format(self.insight, '\\n    - '.join(self.details), '\\n    - '.join(self.consequences), '\\n    - '.join(self.recommandations), '\\n    - '.join([str(x) for x in self.associated_indexes]), self.insight_type._value_, \", \".join([x._value_ for x in self.insight_tags]))\n",
        "\n",
        "class ListInsights(BaseModel):\n",
        "    insights: List[Insight] = Field(description=\"Liste des insights qui ont été déduits.\")\n",
        "    def __str__(self):\n",
        "        return '\\n\\n'.join([str(x) for x in self.insights])\n",
        "\n",
        "#ListInsights.model_json_schema() \n",
        "    \n",
        "test = ListInsights(insights=[Insight(insight='Accueil chaleureux et personnel serviable', insight_type=TypeInsight.POINT_POSITIF, insight_tags=[TagInsight.MAGASIN, TagInsight.SERVICE_CLIENT], associated_indexes=[96, 123, 475, 1249, 1267, 1372, 1695, 1965], details=[], consequences=[], recommandations=[]), Insight(insight='Ecoute attentive et conseils pertinents', insight_type=TypeInsight.POINT_POSITIF, insight_tags=[TagInsight.MAGASIN, TagInsight.SERVICE_CLIENT], associated_indexes=[20, 891, 1372], details=[], consequences=[], recommandations=[])])\n",
        "print(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('Prompts/fr/prompt_regroupement.txt') as f:\n",
        "    prompt_regroupement = PromptTemplate.from_template(f.read())\n",
        "\n",
        "\n",
        "print(prompt_regroupement.template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "with open('Prompts/fr/prompt_regroupement_create_example.txt') as f:\n",
        "    prompt_regroupement_create_example = PromptTemplate.from_template(f.read())\n",
        "\n",
        "example = apply_async_analysis([prompt_regroupement_create_example], ListInsights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "example_clustering_json = example[0].json()\n",
        "from pprint import pprint\n",
        "pprint(example_clustering_json)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompts = []\n",
        "subcat_ids = []\n",
        "for subcat_id, df in aspects_df[aspects_df['Explanation'].notna()].groupby('SubCategory'):\n",
        "    subcat = subcategories_df[subcategories_df['_id'] == subcat_id].iloc[0]\n",
        "    cat = categories_df[categories_df['_id'] == subcat['Category']].iloc[0]\n",
        "\n",
        "    feedbacks = '\\n'.join([str(index)+' : '+content for (index, content) in df['Explanation'].items()])\n",
        "    \n",
        "    prompts.append(prompt_regroupement.invoke({\"feedbacks\": feedbacks, \"category\": cat[\"Name\"]+\" : \"+subcat['Name'], \"example\":example_clustering_json, **feedback_context}).text)\n",
        "    subcat_ids.append(subcat_id)\n",
        "\n",
        "#print(prompts[0])\n",
        "print(\"Traitement synchronisé de\", len(prompts), \"prompts.\")\n",
        "list_insights = apply_async_analysis(prompts, ListSubCategory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def send_insights(insights_group, cat_id, subcat_id):\n",
        "\n",
        "    if len(insights_group.insights)>0:\n",
        "      res = bubble_client.create(\"Insight\",\n",
        "        [{\n",
        "          \"Company\": COMPANY_ID,\n",
        "          \"Project\": PROJECT_ID,\n",
        "          \"Name\": insight.insight,\n",
        "          \"Category\": cat_id,\n",
        "          \"SubCategory\": subcat_id,\n",
        "          \"Type\": insight.insight_type._value_,\n",
        "          \"Tags\": [tags_to_id[convert_text_to_constants(tag._name_)] for tag in insight.insight_tags],\n",
        "          \"Aspects\": list(aspects_df.iloc[insight.associated_indexes]._id),\n",
        "          \"Feedbacks\": list(aspects_df.iloc[insight.associated_indexes].Associated_feedback),\n",
        "          \"Nb Feedbacks\": len(list(aspects_df.iloc[insight.associated_indexes].Associated_feedback)),\n",
        "          }  for insight in insights_group.insights]                     \n",
        "        )\n",
        "      insights_id = [x['id'] for x in res]\n",
        "    else:\n",
        "      insights_id = []\n",
        "\n",
        "    if len(insights_group.consequences)>0:\n",
        "      res = bubble_client.create(\"Consequence\",\n",
        "        [{\n",
        "          \"Company\": COMPANY_ID,\n",
        "          \"Project\": PROJECT_ID,\n",
        "          \"Description\": conseq.detail,\n",
        "          \"Name\": conseq.title,\n",
        "          }  for conseq in insights_group.consequences]                     \n",
        "        )\n",
        "      consequences_id = [x['id'] for x in res] \n",
        "    else:\n",
        "      consequences_id = []\n",
        "\n",
        "\n",
        "    bubble_id = bubble_client.create(\"Insights Group\", {\n",
        "      \"Company\": COMPANY_ID,\n",
        "      \"Project\": PROJECT_ID,\n",
        "      \"Name\": insights_group.title,\n",
        "      \"Category\": cat_id,\n",
        "      \"SubCategory\": subcat_id,\n",
        "      \"Insights\": insights_id,\n",
        "      \"Consequences\": consequences_id,\n",
        "      #\"Tags\": [tags_to_id[tag._name_] for tag in insight.insight_tags],\n",
        "      })\n",
        "\n",
        "    \n",
        "\n",
        "for (list_insight_groups, subcat_id) in tqdm(zip(list_insights, subcat_ids)):\n",
        "  cat_id = subcategories_df[subcategories_df['_id'] == subcat_id].iloc[0].Category\n",
        "  for insights_group in list_insight_groups.sub_categories_list:\n",
        "    send_insights(insights_group, cat_id, subcat_id)\n",
        "\n",
        "    empty_subcat = SUBCATEG_NONE[SUBCATEG_NONE[\"Category\"] ==cat_id].iloc[0]._id\n",
        "    send_insights(insights_group, cat_id, empty_subcat)\n",
        "\n",
        "    empty_subcat = SUBCATEG_NONE[SUBCATEG_NONE[\"Category\"] ==ID_CATEG_NONE].iloc[0]._id\n",
        "    send_insights(insights_group, ID_CATEG_NONE, empty_subcat)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "collapsed_sections": [
        "pKSREXZg85yy",
        "iiOlJz-d9AsB"
      ],
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
