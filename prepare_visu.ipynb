{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved company Darty : 1707313014508x102198350946437700\n",
      "Retrieved project Darty_trustpilot : 1707329196900x870734705097005300\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_cpp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbubble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minstructor\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_cpp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Llama\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llama_cpp'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset\n",
    "import umap\n",
    "import altair as alt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List\n",
    "import enum\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.output_parsers.regex_dict import RegexDictParser\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, ChatMessage\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from pydantic import BaseModel, Field, validator, create_model\n",
    "from openai import AsyncOpenAI, OpenAI\n",
    "import asyncio\n",
    "import os\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import umap.umap_ as umap\n",
    "#import umap\n",
    "import hdbscan\n",
    "\n",
    "from typing import Literal, Union\n",
    "from pydantic.config import ConfigDict\n",
    "\n",
    "from src.context import context\n",
    "\n",
    "from src.utilities import *\n",
    "from src.bubble import *\n",
    "\n",
    "import instructor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get(\"Fee\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feedback_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
