{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHJUBPlcX789"
      },
      "source": [
        "# **Topic Modeling with Quantized LLMs**\n",
        "*Create easily interpretable topics with BERTopic and LLMs*\n",
        "<br>\n",
        "\n",
        "<img src=\"https://pbs.twimg.com/media/GDA2JQoX0AElWoq?format=jpg&name=large\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mQjwWu4XzgG"
      },
      "source": [
        "---\n",
        "        \n",
        "ðŸ’¡ **NOTE**: We will want to use a GPU to run both 7B LLMs as well as BERTopic for this use case. In Google Colab, go to\n",
        "**Runtime > Change runtime type > Hardware accelerator > GPU > GPU type > T4**.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJe5rT-ChHWe"
      },
      "source": [
        "We will start by installing a number of packages that we are going to use throughout this example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zyGnibwAXJFb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n%%capture\\n# BERTopic + llama-cpp-python\\n!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python\\n!pip install bertopic datasets\\n\\n# DataMapPlot\\n!git clone https://github.com/TutteInstitute/datamapplot.git\\n!pip install datamapplot/.\\n\\n# GPU-accelerated HDBSCAN + UMAP\\n!pip install cudf-cu12 dask-cudf-cu12 --extra-index-url=https://pypi.nvidia.com\\n!pip install cuml-cu12 --extra-index-url=https://pypi.nvidia.com\\n!pip install cugraph-cu12 --extra-index-url=https://pypi.nvidia.com\\n!pip install cupy-cuda12x -f https://pip.cupy.dev/aarch64\\n'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "%%capture\n",
        "# BERTopic + llama-cpp-python\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python\n",
        "!pip install bertopic datasets\n",
        "\n",
        "# DataMapPlot\n",
        "!git clone https://github.com/TutteInstitute/datamapplot.git\n",
        "!pip install datamapplot/.\n",
        "\n",
        "# GPU-accelerated HDBSCAN + UMAP\n",
        "!pip install cudf-cu12 dask-cudf-cu12 --extra-index-url=https://pypi.nvidia.com\n",
        "!pip install cuml-cu12 --extra-index-url=https://pypi.nvidia.com\n",
        "!pip install cugraph-cu12 --extra-index-url=https://pypi.nvidia.com\n",
        "!pip install cupy-cuda12x -f https://pip.cupy.dev/aarch64\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAxVj9cGYWX1"
      },
      "source": [
        "# ðŸ“„ **Data**\n",
        "\n",
        "We are going to apply topic modeling on a number of ArXiv abstracts. They are a great source for topic modeling since they contain a wide variety of topics and are generally well-written."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341,
          "referenced_widgets": [
            "4bda87d74e3c4144965a8378f6ecd55d",
            "e5a14432201a4555aeafcab05cde85da",
            "ce8273bae8f44c09aaa6d20ed9733320",
            "0e5dd6cd23634bebace06350f7261dd9",
            "4bdd30f0b2064c09a75be73e9f3693f9",
            "ad2f32462e0549e6bc86caf9669fef64",
            "3b609a78031542ec9ad23639bea6fbd8",
            "d8ab72a750044bcb89138176f97bfb87",
            "32a918340856453489397cd396aa74ef",
            "767239d6be1f4e61812154e9307f8cd4",
            "929629791d604f08afdee6b7c812c4e6",
            "0656dc8d4d4f4b2987e41da798c1cc2b",
            "6d1c63a7a7574ff08330faf410b38a9b",
            "64371ae184bc42d89017e9d426ce71da",
            "c8cb15a80ab5442b9725bcd3d4df3cca",
            "274e55c30b554a7c8a0d3b140c6e164e",
            "3d375f52b5d84b38825d11bafafcfc9f",
            "bfd2099a75744919bbabc28db878ecb1",
            "2caedd07b84a4c2e83948e7d36ffce13",
            "8de0aa4ddfa240e1b55dcb966f02651b",
            "32c56102732245f7b1c0980e2b32343d",
            "53527a64fdba4ee0a322b32867f473b9",
            "8bfb23759e14494bb4ab56b92e8c1611",
            "51b13d2bc9f14949bdae2d926ae94a68",
            "43796a96b6bc4fa49f793cf10e9753ac",
            "86844c08bc1c4286a43167a9a50d95ff",
            "2747796f87d348afa909fe11e7a0672d",
            "565feae099e74cbb9f702a5836e672f6",
            "c4d1958113544a5cb5eb8beb3384f0c3",
            "51f7538f4fc54c04bf5cf54c0d1db01c",
            "4ee0283e32ca45b0aed5ae1baf48cea6",
            "4902c16cf7fc41258572e9e77da6e785",
            "e7bd4ae907124c638850fd340c95c9ab"
          ]
        },
        "id": "rbwHbJc_YXi8",
        "outputId": "40503655-c99a-48bb-fad2-0506dcfb91ba"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# ArXiv ML Documents\n",
        "docs = load_dataset(\"CShorten/ML-ArXiv-Papers\")[\"train\"][\"abstract\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['  The problem of statistical learning is to construct a predictor of a random\\nvariable $Y$ as a function of a related random variable $X$ on the basis of an\\ni.i.d. training sample from the joint distribution of $(X,Y)$. Allowable\\npredictors are drawn from some specified class, and the goal is to approach\\nasymptotically the performance (expected loss) of the best predictor in the\\nclass. We consider the setting in which one has perfect observation of the\\n$X$-part of the sample, while the $Y$-part has to be communicated at some\\nfinite bit rate. The encoding of the $Y$-values is allowed to depend on the\\n$X$-values. Under suitable regularity conditions on the admissible predictors,\\nthe underlying family of probability distributions and the loss function, we\\ngive an information-theoretic characterization of achievable predictor\\nperformance in terms of conditional distortion-rate functions. The ideas are\\nillustrated on the example of nonparametric regression in Gaussian noise.\\n',\n",
              " '  In a sensor network, in practice, the communication among sensors is subject\\nto:(1) errors or failures at random times; (3) costs; and(2) constraints since\\nsensors and networks operate under scarce resources, such as power, data rate,\\nor communication. The signal-to-noise ratio (SNR) is usually a main factor in\\ndetermining the probability of error (or of communication failure) in a link.\\nThese probabilities are then a proxy for the SNR under which the links operate.\\nThe paper studies the problem of designing the topology, i.e., assigning the\\nprobabilities of reliable communication among sensors (or of link failures) to\\nmaximize the rate of convergence of average consensus, when the link\\ncommunication costs are taken into account, and there is an overall\\ncommunication budget constraint. To consider this problem, we address a number\\nof preliminary issues: (1) model the network as a random topology; (2)\\nestablish necessary and sufficient conditions for mean square sense (mss) and\\nalmost sure (a.s.) convergence of average consensus when network links fail;\\nand, in particular, (3) show that a necessary and sufficient condition for both\\nmss and a.s. convergence is for the algebraic connectivity of the mean graph\\ndescribing the network topology to be strictly positive. With these results, we\\nformulate topology design, subject to random link failures and to a\\ncommunication cost constraint, as a constrained convex optimization problem to\\nwhich we apply semidefinite programming techniques. We show by an extensive\\nnumerical study that the optimal design improves significantly the convergence\\nspeed of the consensus algorithm and can achieve the asymptotic performance of\\na non-random network at a fraction of the communication cost.\\n',\n",
              " '  The on-line shortest path problem is considered under various models of\\npartial monitoring. Given a weighted directed acyclic graph whose edge weights\\ncan change in an arbitrary (adversarial) way, a decision maker has to choose in\\neach round of a game a path between two distinguished vertices such that the\\nloss of the chosen path (defined as the sum of the weights of its composing\\nedges) be as small as possible. In a setting generalizing the multi-armed\\nbandit problem, after choosing a path, the decision maker learns only the\\nweights of those edges that belong to the chosen path. For this problem, an\\nalgorithm is given whose average cumulative loss in n rounds exceeds that of\\nthe best path, matched off-line to the entire sequence of the edge weights, by\\na quantity that is proportional to 1/\\\\sqrt{n} and depends only polynomially on\\nthe number of edges of the graph. The algorithm can be implemented with linear\\ncomplexity in the number of rounds n and in the number of edges. An extension\\nto the so-called label efficient setting is also given, in which the decision\\nmaker is informed about the weights of the edges corresponding to the chosen\\npath at a total of m << n time instances. Another extension is shown where the\\ndecision maker competes against a time-varying path, a generalization of the\\nproblem of tracking the best expert. A version of the multi-armed bandit\\nsetting for shortest path is also discussed where the decision maker learns\\nonly the total weight of the chosen path but not the weights of the individual\\nedges on the path. Applications to routing in packet switched networks along\\nwith simulation results are also presented.\\n',\n",
              " '  Ordinal regression is an important type of learning, which has properties of\\nboth classification and regression. Here we describe a simple and effective\\napproach to adapt a traditional neural network to learn ordinal categories. Our\\napproach is a generalization of the perceptron method for ordinal regression.\\nOn several benchmark datasets, our method (NNRank) outperforms a neural network\\nclassification method. Compared with the ordinal regression methods using\\nGaussian processes and support vector machines, NNRank achieves comparable\\nperformance. Moreover, NNRank has the advantages of traditional neural\\nnetworks: learning in both online and batch modes, handling very large training\\ndatasets, and making rapid predictions. These features make NNRank a useful and\\ncomplementary tool for large-scale data processing tasks such as information\\nretrieval, web page ranking, collaborative filtering, and protein ranking in\\nBioinformatics.\\n',\n",
              " \"  This paper uncovers and explores the close relationship between Monte Carlo\\nOptimization of a parametrized integral (MCO), Parametric machine-Learning\\n(PL), and `blackbox' or `oracle'-based optimization (BO). We make four\\ncontributions. First, we prove that MCO is mathematically identical to a broad\\nclass of PL problems. This identity potentially provides a new application\\ndomain for all broadly applicable PL techniques: MCO. Second, we introduce\\nimmediate sampling, a new version of the Probability Collectives (PC) algorithm\\nfor blackbox optimization. Immediate sampling transforms the original BO\\nproblem into an MCO problem. Accordingly, by combining these first two\\ncontributions, we can apply all PL techniques to BO. In our third contribution\\nwe validate this way of improving BO by demonstrating that cross-validation and\\nbagging improve immediate sampling. Finally, conventional MC and MCO procedures\\nignore the relationship between the sample point locations and the associated\\nvalues of the integrand; only the values of the integrand at those locations\\nare considered. We demonstrate that one can exploit the sample location\\ninformation using PL techniques, for example by forming a fit of the sample\\nlocations to the associated values of the integrand. This provides an\\nadditional way to apply PL techniques to improve MCO.\\n\",\n",
              " '  This paper has been withdrawn by the author. This draft is withdrawn for its\\npoor quality in english, unfortunately produced by the author when he was just\\nstarting his science route. Look at the ICML version instead:\\nhttp://icml2008.cs.helsinki.fi/papers/111.pdf\\n',\n",
              " '  We consider inapproximability of the correlation clustering problem defined\\nas follows: Given a graph $G = (V,E)$ where each edge is labeled either \"+\"\\n(similar) or \"-\" (dissimilar), correlation clustering seeks to partition the\\nvertices into clusters so that the number of pairs correctly (resp.\\nincorrectly) classified with respect to the labels is maximized (resp.\\nminimized). The two complementary problems are called MaxAgree and MinDisagree,\\nrespectively, and have been studied on complete graphs, where every edge is\\nlabeled, and general graphs, where some edge might not have been labeled.\\nNatural edge-weighted versions of both problems have been studied as well. Let\\nS-MaxAgree denote the weighted problem where all weights are taken from set S,\\nwe show that S-MaxAgree with weights bounded by $O(|V|^{1/2-\\\\delta})$\\nessentially belongs to the same hardness class in the following sense: if there\\nis a polynomial time algorithm that approximates S-MaxAgree within a factor of\\n$\\\\lambda = O(\\\\log{|V|})$ with high probability, then for any choice of S\\',\\nS\\'-MaxAgree can be approximated in polynomial time within a factor of $(\\\\lambda\\n+ \\\\epsilon)$, where $\\\\epsilon > 0$ can be arbitrarily small, with high\\nprobability. A similar statement also holds for $S-MinDisagree. This result\\nimplies it is hard (assuming $NP \\\\neq RP$) to approximate unweighted MaxAgree\\nwithin a factor of $80/79-\\\\epsilon$, improving upon a previous known factor of\\n$116/115-\\\\epsilon$ by Charikar et. al. \\\\cite{Chari05}.\\n',\n",
              " '  The problem of joint universal source coding and modeling, treated in the\\ncontext of lossless codes by Rissanen, was recently generalized to fixed-rate\\nlossy coding of finitely parametrized continuous-alphabet i.i.d. sources. We\\nextend these results to variable-rate lossy block coding of stationary ergodic\\nsources and show that, for bounded metric distortion measures, any finitely\\nparametrized family of stationary sources satisfying suitable mixing,\\nsmoothness and Vapnik-Chervonenkis learnability conditions admits universal\\nschemes for joint lossy source coding and identification. We also give several\\nexplicit examples of parametric sources satisfying the regularity conditions.\\n',\n",
              " '  We introduce a framework for filtering features that employs the\\nHilbert-Schmidt Independence Criterion (HSIC) as a measure of dependence\\nbetween the features and the labels. The key idea is that good features should\\nmaximise such dependence. Feature selection for various supervised learning\\nproblems (including classification and regression) is unified under this\\nframework, and the solutions can be approximated using a backward-elimination\\nalgorithm. We demonstrate the usefulness of our method on both artificial and\\nreal world datasets.\\n',\n",
              " \"  Max-product belief propagation is a local, iterative algorithm to find the\\nmode/MAP estimate of a probability distribution. While it has been successfully\\nemployed in a wide variety of applications, there are relatively few\\ntheoretical guarantees of convergence and correctness for general loopy graphs\\nthat may have many short cycles. Of these, even fewer provide exact ``necessary\\nand sufficient'' characterizations.\\n  In this paper we investigate the problem of using max-product to find the\\nmaximum weight matching in an arbitrary graph with edge weights. This is done\\nby first constructing a probability distribution whose mode corresponds to the\\noptimal matching, and then running max-product. Weighted matching can also be\\nposed as an integer program, for which there is an LP relaxation. This\\nrelaxation is not always tight. In this paper we show that \\\\begin{enumerate}\\n\\\\item If the LP relaxation is tight, then max-product always converges, and\\nthat too to the correct answer. \\\\item If the LP relaxation is loose, then\\nmax-product does not converge. \\\\end{enumerate} This provides an exact,\\ndata-dependent characterization of max-product performance, and a precise\\nconnection to LP relaxation, which is a well-studied optimization technique.\\nAlso, since LP relaxation is known to be tight for bipartite graphs, our\\nresults generalize other recent results on using max-product to find weighted\\nmatchings in bipartite graphs.\\n\",\n",
              " '  Speaker identification is a powerful, non-invasive and in-expensive biometric\\ntechnique. The recognition accuracy, however, deteriorates when noise levels\\naffect a specific band of frequency. In this paper, we present a sub-band based\\nspeaker identification that intends to improve the live testing performance.\\nEach frequency sub-band is processed and classified independently. We also\\ncompare the linear and non-linear merging techniques for the sub-bands\\nrecognizer. Support vector machines and Gaussian Mixture models are the\\nnon-linear merging techniques that are investigated. Results showed that the\\nsub-band based method used with linear merging techniques enormously improved\\nthe performance of the speaker identification over the performance of wide-band\\nrecognizers when tested live. A live testing improvement of 9.78% was achieved\\n',\n",
              " '  We analyze the generalization performance of a student in a model composed of\\nnonlinear perceptrons: a true teacher, ensemble teachers, and the student. We\\ncalculate the generalization error of the student analytically or numerically\\nusing statistical mechanics in the framework of on-line learning. We treat two\\nwell-known learning rules: Hebbian learning and perceptron learning. As a\\nresult, it is proven that the nonlinear model shows qualitatively different\\nbehaviors from the linear model. Moreover, it is clarified that Hebbian\\nlearning and perceptron learning show qualitatively different behaviors from\\neach other. In Hebbian learning, we can analytically obtain the solutions. In\\nthis case, the generalization error monotonically decreases. The steady value\\nof the generalization error is independent of the learning rate. The larger the\\nnumber of teachers is and the more variety the ensemble teachers have, the\\nsmaller the generalization error is. In perceptron learning, we have to\\nnumerically obtain the solutions. In this case, the dynamical behaviors of the\\ngeneralization error are non-monotonic. The smaller the learning rate is, the\\nlarger the number of teachers is; and the more variety the ensemble teachers\\nhave, the smaller the minimum value of the generalization error is.\\n',\n",
              " '  We consider the problem of minimal correction of the training set to make it\\nconsistent with monotonic constraints. This problem arises during analysis of\\ndata sets via techniques that require monotone data. We show that this problem\\nis NP-hard in general and is equivalent to finding a maximal independent set in\\nspecial orgraphs. Practically important cases of that problem considered in\\ndetail. These are the cases when a partial order given on the replies set is a\\ntotal order or has a dimension 2. We show that the second case can be reduced\\nto maximization of a quadratic convex function on a convex set. For this case\\nwe construct an approximate polynomial algorithm based on convex optimization.\\n',\n",
              " '  Observations consisting of measurements on relationships for pairs of objects\\narise in many settings, such as protein interaction and gene regulatory\\nnetworks, collections of author-recipient email, and social networks. Analyzing\\nsuch data with probabilisic models can be delicate because the simple\\nexchangeability assumptions underlying many boilerplate models no longer hold.\\nIn this paper, we describe a latent variable model of such data called the\\nmixed membership stochastic blockmodel. This model extends blockmodels for\\nrelational data to ones which capture mixed membership latent relational\\nstructure, thus providing an object-specific low-dimensional representation. We\\ndevelop a general variational inference algorithm for fast approximate\\nposterior inference. We explore applications to social and protein interaction\\nnetworks.\\n',\n",
              " '  In this paper we derive the equations for Loop Corrected Belief Propagation\\non a continuous variable Gaussian model. Using the exactness of the averages\\nfor belief propagation for Gaussian models, a different way of obtaining the\\ncovariances is found, based on Belief Propagation on cavity graphs. We discuss\\nthe relation of this loop correction algorithm to Expectation Propagation\\nalgorithms for the case in which the model is no longer Gaussian, but slightly\\nperturbed by nonlinear terms.\\n',\n",
              " '  In the process of training Support Vector Machines (SVMs) by decomposition\\nmethods, working set selection is an important technique, and some exciting\\nschemes were employed into this field. To improve working set selection, we\\npropose a new model for working set selection in sequential minimal\\noptimization (SMO) decomposition methods. In this model, it selects B as\\nworking set without reselection. Some properties are given by simple proof, and\\nexperiments demonstrate that the proposed method is in general faster than\\nexisting methods.\\n',\n",
              " '  Probabilistic graphical models (PGMs) have become a popular tool for\\ncomputational analysis of biological data in a variety of domains. But, what\\nexactly are they and how do they work? How can we use PGMs to discover patterns\\nthat are biologically relevant? And to what extent can PGMs help us formulate\\nnew hypotheses that are testable at the bench? This note sketches out some\\nanswers and illustrates the main ideas behind the statistical approach to\\nbiological pattern discovery.\\n',\n",
              " '  Conformal prediction uses past experience to determine precise levels of\\nconfidence in new predictions. Given an error probability $\\\\epsilon$, together\\nwith a method that makes a prediction $\\\\hat{y}$ of a label $y$, it produces a\\nset of labels, typically containing $\\\\hat{y}$, that also contains $y$ with\\nprobability $1-\\\\epsilon$. Conformal prediction can be applied to any method for\\nproducing $\\\\hat{y}$: a nearest-neighbor method, a support-vector machine, ridge\\nregression, etc.\\n  Conformal prediction is designed for an on-line setting in which labels are\\npredicted successively, each one being revealed before the next is predicted.\\nThe most novel and valuable feature of conformal prediction is that if the\\nsuccessive examples are sampled independently from the same distribution, then\\nthe successive predictions will be right $1-\\\\epsilon$ of the time, even though\\nthey are based on an accumulating dataset rather than on independent datasets.\\n  In addition to the model under which successive examples are sampled\\nindependently, other on-line compression models can also use conformal\\nprediction. The widely used Gaussian linear model is one of these.\\n  This tutorial presents a self-contained account of the theory of conformal\\nprediction and works through several numerical examples. A more comprehensive\\ntreatment of the topic is provided in \"Algorithmic Learning in a Random World\",\\nby Vladimir Vovk, Alex Gammerman, and Glenn Shafer (Springer, 2005).\\n',\n",
              " '  Bounds on the risk play a crucial role in statistical learning theory. They\\nusually involve as capacity measure of the model studied the VC dimension or\\none of its extensions. In classification, such \"VC dimensions\" exist for models\\ntaking values in {0, 1}, {1,..., Q} and R. We introduce the generalizations\\nappropriate for the missing case, the one of models with values in R^Q. This\\nprovides us with a new guaranteed risk for M-SVMs which appears superior to the\\nexisting one.\\n',\n",
              " \"  This paper I assume that in humans the creation of knowledge depends on a\\ndiscrete time, or stage, sequential decision-making process subjected to a\\nstochastic, information transmitting environment. For each time-stage, this\\nenvironment randomly transmits Shannon type information-packets to the\\ndecision-maker, who examines each of them for relevancy and then determines his\\noptimal choices. Using this set of relevant information-packets, the\\ndecision-maker adapts, over time, to the stochastic nature of his environment,\\nand optimizes the subjective expected rate-of-growth of knowledge. The\\ndecision-maker's optimal actions, lead to a decision function that involves,\\nover time, his view of the subjective entropy of the environmental process and\\nother important parameters at each time-stage of the process. Using this model\\nof human behavior, one could create psychometric experiments using computer\\nsimulation and real decision-makers, to play programmed games to measure the\\nresulting human performance.\\n\",\n",
              " \"  In this paper, we study the application of sparse principal component\\nanalysis (PCA) to clustering and feature selection problems. Sparse PCA seeks\\nsparse factors, or linear combinations of the data variables, explaining a\\nmaximum amount of variance in the data while having only a limited number of\\nnonzero coefficients. PCA is often used as a simple clustering technique and\\nsparse factors allow us here to interpret the clusters in terms of a reduced\\nset of variables. We begin with a brief introduction and motivation on sparse\\nPCA and detail our implementation of the algorithm in d'Aspremont et al.\\n(2005). We then apply these results to some classic clustering and feature\\nselection problems arising in biology.\\n\",\n",
              " \"  We consider the problem of estimating the parameters of a Gaussian or binary\\ndistribution in such a way that the resulting undirected graphical model is\\nsparse. Our approach is to solve a maximum likelihood problem with an added\\nl_1-norm penalty term. The problem as formulated is convex but the memory\\nrequirements and complexity of existing interior point methods are prohibitive\\nfor problems with more than tens of nodes. We present two new algorithms for\\nsolving problems with at least a thousand nodes in the Gaussian case. Our first\\nalgorithm uses block coordinate descent, and can be interpreted as recursive\\nl_1-norm penalized regression. Our second algorithm, based on Nesterov's first\\norder method, yields a complexity estimate with a better dependence on problem\\nsize than existing interior point methods. Using a log determinant relaxation\\nof the log partition function (Wainwright & Jordan (2006)), we show that these\\nsame algorithms can be used to solve an approximate sparse maximum likelihood\\nproblem for the binary case. We test our algorithms on synthetic data, as well\\nas on gene expression and senate voting records data.\\n\",\n",
              " '  Given a sample covariance matrix, we examine the problem of maximizing the\\nvariance explained by a linear combination of the input variables while\\nconstraining the number of nonzero coefficients in this combination. This is\\nknown as sparse principal component analysis and has a wide array of\\napplications in machine learning and engineering. We formulate a new\\nsemidefinite relaxation to this problem and derive a greedy algorithm that\\ncomputes a full set of good solutions for all target numbers of non zero\\ncoefficients, with total complexity O(n^3), where n is the number of variables.\\nWe then use the same relaxation to derive sufficient conditions for global\\noptimality of a solution, which can be tested in O(n^3) per pattern. We discuss\\napplications in subset selection and sparse recovery and show on artificial\\nexamples and biological data that our algorithm does provide globally optimal\\nsolutions in many cases.\\n',\n",
              " '  In this article, we derive a new generalization of Chebyshev inequality for\\nrandom vectors. We demonstrate that the new generalization is much less\\nconservative than the classical generalization.\\n',\n",
              " '  The proposal is to use clusters, graphs and networks as models in order to\\nanalyse the Web structure. Clusters, graphs and networks provide knowledge\\nrepresentation and organization. Clusters were generated by co-site analysis.\\nThe sample is a set of academic Web sites from the countries belonging to the\\nEuropean Union. These clusters are here revisited from the point of view of\\ngraph theory and social network analysis. This is a quantitative and structural\\nanalysis. In fact, the Internet is a computer network that connects people and\\norganizations. Thus we may consider it to be a social network. The set of Web\\nacademic sites represents an empirical social network, and is viewed as a\\nvirtual community. The network structural properties are here analysed applying\\ntogether cluster analysis, graph theory and social network analysis.\\n',\n",
              " '  We consider an agent interacting with an unmodeled environment. At each time,\\nthe agent makes an observation, takes an action, and incurs a cost. Its actions\\ncan influence future observations and costs. The goal is to minimize the\\nlong-term average cost. We propose a novel algorithm, known as the active LZ\\nalgorithm, for optimal control based on ideas from the Lempel-Ziv scheme for\\nuniversal data compression and prediction. We establish that, under the active\\nLZ algorithm, if there exists an integer $K$ such that the future is\\nconditionally independent of the past given a window of $K$ consecutive actions\\nand observations, then the average cost converges to the optimum. Experimental\\nresults involving the game of Rock-Paper-Scissors illustrate merits of the\\nalgorithm.\\n',\n",
              " '  We consider the least-square regression problem with regularization by a\\nblock 1-norm, i.e., a sum of Euclidean norms over spaces of dimensions larger\\nthan one. This problem, referred to as the group Lasso, extends the usual\\nregularization by the 1-norm where all spaces have dimension one, where it is\\ncommonly referred to as the Lasso. In this paper, we study the asymptotic model\\nconsistency of the group Lasso. We derive necessary and sufficient conditions\\nfor the consistency of group Lasso under practical assumptions, such as model\\nmisspecification. When the linear predictors and Euclidean norms are replaced\\nby functions and reproducing kernel Hilbert norms, the problem is usually\\nreferred to as multiple kernel learning and is commonly used for learning from\\nheterogeneous data sources and for non linear variable selection. Using tools\\nfrom functional analysis, and in particular covariance operators, we extend the\\nconsistency results to this infinite dimensional case and also propose an\\nadaptive scheme to obtain a consistent model estimate, even when the necessary\\ncondition required for the non adaptive scheme is not satisfied.\\n',\n",
              " '  In this article we develop quantum algorithms for learning and testing\\njuntas, i.e. Boolean functions which depend only on an unknown set of k out of\\nn input variables. Our aim is to develop efficient algorithms:\\n  - whose sample complexity has no dependence on n, the dimension of the domain\\nthe Boolean functions are defined over;\\n  - with no access to any classical or quantum membership (\"black-box\")\\nqueries. Instead, our algorithms use only classical examples generated\\nuniformly at random and fixed quantum superpositions of such classical\\nexamples;\\n  - which require only a few quantum examples but possibly many classical\\nrandom examples (which are considered quite \"cheap\" relative to quantum\\nexamples).\\n  Our quantum algorithms are based on a subroutine FS which enables sampling\\naccording to the Fourier spectrum of f; the FS subroutine was used in earlier\\nwork of Bshouty and Jackson on quantum learning. Our results are as follows:\\n  - We give an algorithm for testing k-juntas to accuracy $\\\\epsilon$ that uses\\n$O(k/\\\\epsilon)$ quantum examples. This improves on the number of examples used\\nby the best known classical algorithm.\\n  - We establish the following lower bound: any FS-based k-junta testing\\nalgorithm requires $\\\\Omega(\\\\sqrt{k})$ queries.\\n  - We give an algorithm for learning $k$-juntas to accuracy $\\\\epsilon$ that\\nuses $O(\\\\epsilon^{-1} k\\\\log k)$ quantum examples and $O(2^k \\\\log(1/\\\\epsilon))$\\nrandom examples. We show that this learning algorithms is close to optimal by\\ngiving a related lower bound.\\n',\n",
              " '  Support vector machines and kernel methods have recently gained considerable\\nattention in chemoinformatics. They offer generally good performance for\\nproblems of supervised classification or regression, and provide a flexible and\\ncomputationally efficient framework to include relevant information and prior\\nknowledge about the data and problems to be handled. In particular, with kernel\\nmethods molecules do not need to be represented and stored explicitly as\\nvectors or fingerprints, but only to be compared to each other through a\\ncomparison function technically called a kernel. While classical kernels can be\\nused to compare vector or fingerprint representations of molecules, completely\\nnew kernels were developed in the recent years to directly compare the 2D or 3D\\nstructures of molecules, without the need for an explicit vectorization step\\nthrough the extraction of molecular descriptors. While still in their infancy,\\nthese approaches have already demonstrated their relevance on several toxicity\\nprediction and structure-activity relationship problems.\\n',\n",
              " \"  We show how rate-distortion theory provides a mechanism for automated theory\\nbuilding by naturally distinguishing between regularity and randomness. We\\nstart from the simple principle that model variables should, as much as\\npossible, render the future and past conditionally independent. From this, we\\nconstruct an objective function for model making whose extrema embody the\\ntrade-off between a model's structural complexity and its predictive power. The\\nsolutions correspond to a hierarchy of models that, at each level of\\ncomplexity, achieve optimal predictive power at minimal cost. In the limit of\\nmaximal prediction the resulting optimal model identifies a process's intrinsic\\norganization by extracting the underlying causal states. In this limit, the\\nmodel's complexity is given by the statistical complexity, which is known to be\\nminimal for achieving maximum prediction. Examples show how theory building can\\nprofit from analyzing a process's causal compressibility, which is reflected in\\nthe optimal models' rate-distortion curve--the process's characteristic for\\noptimally balancing structure and noise at different levels of representation.\\n\",\n",
              " '  Supervised learning deals with the inference of a distribution over an output\\nor label space $\\\\CY$ conditioned on points in an observation space $\\\\CX$, given\\na training dataset $D$ of pairs in $\\\\CX \\\\times \\\\CY$. However, in a lot of\\napplications of interest, acquisition of large amounts of observations is easy,\\nwhile the process of generating labels is time-consuming or costly. One way to\\ndeal with this problem is {\\\\em active} learning, where points to be labelled\\nare selected with the aim of creating a model with better performance than that\\nof an model trained on an equal number of randomly sampled points. In this\\npaper, we instead propose to deal with the labelling cost directly: The\\nlearning goal is defined as the minimisation of a cost which is a function of\\nthe expected model performance and the total cost of the labels used. This\\nallows the development of general strategies and specific algorithms for (a)\\noptimal stopping, where the expected cost dictates whether label acquisition\\nshould continue (b) empirical evaluation, where the cost is used as a\\nperformance metric for a given combination of inference, stopping and sampling\\nmethods. Though the main focus of the paper is optimal stopping, we also aim to\\nprovide the background for further developments and discussion in the related\\nfield of active learning.\\n',\n",
              " '  The method of defensive forecasting is applied to the problem of prediction\\nwith expert advice for binary outcomes. It turns out that defensive forecasting\\nis not only competitive with the Aggregating Algorithm but also handles the\\ncase of \"second-guessing\" experts, whose advice depends on the learner\\'s\\nprediction; this paper assumes that the dependence on the learner\\'s prediction\\nis continuous.\\n',\n",
              " \"  We introduce an approach to inferring the causal architecture of stochastic\\ndynamical systems that extends rate distortion theory to use causal\\nshielding---a natural principle of learning. We study two distinct cases of\\ncausal inference: optimal causal filtering and optimal causal estimation.\\n  Filtering corresponds to the ideal case in which the probability distribution\\nof measurement sequences is known, giving a principled method to approximate a\\nsystem's causal structure at a desired level of representation. We show that,\\nin the limit in which a model complexity constraint is relaxed, filtering finds\\nthe exact causal architecture of a stochastic dynamical system, known as the\\ncausal-state partition. From this, one can estimate the amount of historical\\ninformation the process stores. More generally, causal filtering finds a graded\\nmodel-complexity hierarchy of approximations to the causal architecture. Abrupt\\nchanges in the hierarchy, as a function of approximation, capture distinct\\nscales of structural organization.\\n  For nonideal cases with finite data, we show how the correct number of\\nunderlying causal states can be found by optimal causal estimation. A\\npreviously derived model complexity control term allows us to correct for the\\neffect of statistical fluctuations in probability estimates and thereby avoid\\nover-fitting.\\n\",\n",
              " \"  Solomonoff's central result on induction is that the posterior of a universal\\nsemimeasure M converges rapidly and with probability 1 to the true sequence\\ngenerating posterior mu, if the latter is computable. Hence, M is eligible as a\\nuniversal sequence predictor in case of unknown mu. Despite some nearby results\\nand proofs in the literature, the stronger result of convergence for all\\n(Martin-Loef) random sequences remained open. Such a convergence result would\\nbe particularly interesting and natural, since randomness can be defined in\\nterms of M itself. We show that there are universal semimeasures M which do not\\nconverge for all random sequences, i.e. we give a partial negative answer to\\nthe open problem. We also provide a positive answer for some non-universal\\nsemimeasures. We define the incomputable measure D as a mixture over all\\ncomputable measures and the enumerable semimeasure W as a mixture over all\\nenumerable nearly-measures. We show that W converges to D and D to mu on all\\nrandom sequences. The Hellinger distance measuring closeness of two\\ndistributions plays a central role.\\n\",\n",
              " '  Defensive forecasting is a method of transforming laws of probability (stated\\nin game-theoretic terms as strategies for Sceptic) into forecasting algorithms.\\nThere are two known varieties of defensive forecasting: \"continuous\", in which\\nSceptic\\'s moves are assumed to depend on the forecasts in a (semi)continuous\\nmanner and which produces deterministic forecasts, and \"randomized\", in which\\nthe dependence of Sceptic\\'s moves on the forecasts is arbitrary and\\nForecaster\\'s moves are allowed to be randomized. This note shows that the\\nrandomized variety can be obtained from the continuous variety by smearing\\nSceptic\\'s moves to make them continuous.\\n',\n",
              " '  In the constraint satisfaction problem ($CSP$), the aim is to find an\\nassignment of values to a set of variables subject to specified constraints. In\\nthe minimum cost homomorphism problem ($MinHom$), one is additionally given\\nweights $c_{va}$ for every variable $v$ and value $a$, and the aim is to find\\nan assignment $f$ to the variables that minimizes $\\\\sum_{v} c_{vf(v)}$. Let\\n$MinHom(\\\\Gamma)$ denote the $MinHom$ problem parameterized by the set of\\npredicates allowed for constraints. $MinHom(\\\\Gamma)$ is related to many\\nwell-studied combinatorial optimization problems, and concrete applications can\\nbe found in, for instance, defence logistics and machine learning. We show that\\n$MinHom(\\\\Gamma)$ can be studied by using algebraic methods similar to those\\nused for CSPs. With the aid of algebraic techniques, we classify the\\ncomputational complexity of $MinHom(\\\\Gamma)$ for all choices of $\\\\Gamma$. Our\\nresult settles a general dichotomy conjecture previously resolved only for\\ncertain classes of directed graphs, [Gutin, Hell, Rafiey, Yeo, European J. of\\nCombinatorics, 2008].\\n',\n",
              " '  The purpose of this note is to show how the method of maximum entropy in the\\nmean (MEM) may be used to improve parametric estimation when the measurements\\nare corrupted by large level of noise. The method is developed in the context\\non a concrete example: that of estimation of the parameter in an exponential\\ndistribution. We compare the performance of our method with the bayesian and\\nmaximum likelihood approaches.\\n',\n",
              " \"  The Bayesian framework is a well-studied and successful framework for\\ninductive reasoning, which includes hypothesis testing and confirmation,\\nparameter estimation, sequence prediction, classification, and regression. But\\nstandard statistical guidelines for choosing the model class and prior are not\\nalways available or fail, in particular in complex situations. Solomonoff\\ncompleted the Bayesian framework by providing a rigorous, unique, formal, and\\nuniversal choice for the model class and the prior. We discuss in breadth how\\nand in which sense universal (non-i.i.d.) sequence prediction solves various\\n(philosophical) problems of traditional Bayesian sequence prediction. We show\\nthat Solomonoff's model possesses many desirable properties: Strong total and\\nweak instantaneous bounds, and in contrast to most classical continuous prior\\ndensities has no zero p(oste)rior problem, i.e. can confirm universal\\nhypotheses, is reparametrization and regrouping invariant, and avoids the\\nold-evidence and updating problem. It even performs well (actually better) in\\nnon-computable environments.\\n\",\n",
              " '  In this paper, we model the various wireless users in a cognitive radio\\nnetwork as a collection of selfish, autonomous agents that strategically\\ninteract in order to acquire the dynamically available spectrum opportunities.\\nOur main focus is on developing solutions for wireless users to successfully\\ncompete with each other for the limited and time-varying spectrum\\nopportunities, given the experienced dynamics in the wireless network. We\\ncategorize these dynamics into two types: one is the disturbance due to the\\nenvironment (e.g. wireless channel conditions, source traffic characteristics,\\netc.) and the other is the impact caused by competing users. To analyze the\\ninteractions among users given the environment disturbance, we propose a\\ngeneral stochastic framework for modeling how the competition among users for\\nspectrum opportunities evolves over time. At each stage of the dynamic resource\\nallocation, a central spectrum moderator auctions the available resources and\\nthe users strategically bid for the required resources. The joint bid actions\\naffect the resource allocation and hence, the rewards and future strategies of\\nall users. Based on the observed resource allocation and corresponding rewards\\nfrom previous allocations, we propose a best response learning algorithm that\\ncan be deployed by wireless users to improve their bidding policy at each\\nstage. The simulation results show that by deploying the proposed best response\\nlearning algorithm, the wireless users can significantly improve their own\\nperformance in terms of both the packet loss rate and the incurred cost for the\\nused resources.\\n',\n",
              " '  Data from spectrophotometers form vectors of a large number of exploitable\\nvariables. Building quantitative models using these variables most often\\nrequires using a smaller set of variables than the initial one. Indeed, a too\\nlarge number of input variables to a model results in a too large number of\\nparameters, leading to overfitting and poor generalization abilities. In this\\npaper, we suggest the use of the mutual information measure to select variables\\nfrom the initial set. The mutual information measures the information content\\nin input variables with respect to the model output, without making any\\nassumption on the model that will be used; it is thus suitable for nonlinear\\nmodelling. In addition, it leads to the selection of variables among the\\ninitial set, and not to linear or nonlinear combinations of them. Without\\ndecreasing the model performances compared to other variable projection\\nmethods, it allows therefore a greater interpretability of the results.\\n',\n",
              " \"  In many real world applications, data cannot be accurately represented by\\nvectors. In those situations, one possible solution is to rely on dissimilarity\\nmeasures that enable sensible comparison between observations. Kohonen's\\nSelf-Organizing Map (SOM) has been adapted to data described only through their\\ndissimilarity matrix. This algorithm provides both non linear projection and\\nclustering of non vector data. Unfortunately, the algorithm suffers from a high\\ncost that makes it quite difficult to use with voluminous data sets. In this\\npaper, we propose a new algorithm that provides an important reduction of the\\ntheoretical cost of the dissimilarity SOM without changing its outcome (the\\nresults are exactly the same as the ones obtained with the original algorithm).\\nMoreover, we introduce implementation methods that result in very short running\\ntimes. Improvements deduced from the theoretical cost model are validated on\\nsimulated and real world data (a word list clustering problem). We also\\ndemonstrate that the proposed implementation methods reduce by a factor up to 3\\nthe running time of the fast algorithm over a standard implementation.\\n\",\n",
              " \"  Many data analysis methods cannot be applied to data that are not represented\\nby a fixed number of real values, whereas most of real world observations are\\nnot readily available in such a format. Vector based data analysis methods have\\ntherefore to be adapted in order to be used with non standard complex data. A\\nflexible and general solution for this adaptation is to use a (dis)similarity\\nmeasure. Indeed, thanks to expert knowledge on the studied data, it is\\ngenerally possible to define a measure that can be used to make pairwise\\ncomparison between observations. General data analysis methods are then\\nobtained by adapting existing methods to (dis)similarity matrices. In this\\narticle, we propose an adaptation of Kohonen's Self Organizing Map (SOM) to\\n(dis)similarity data. The proposed algorithm is an adapted version of the\\nvector based batch SOM. The method is validated on real world data: we provide\\nan analysis of the usage patterns of the web site of the Institut National de\\nRecherche en Informatique et Automatique, constructed thanks to web log mining\\nmethod.\\n\",\n",
              " '  In data analysis new forms of complex data have to be considered like for\\nexample (symbolic data, functional data, web data, trees, SQL query and\\nmultimedia data, ...). In this context classical data analysis for knowledge\\ndiscovery based on calculating the center of gravity can not be used because\\ninput are not $\\\\mathbb{R}^p$ vectors. In this paper, we present an application\\non real world symbolic data using the self-organizing map. To this end, we\\npropose an extension of the self-organizing map that can handle symbolic data.\\n',\n",
              " '  The large number of spectral variables in most data sets encountered in\\nspectral chemometrics often renders the prediction of a dependent variable\\nuneasy. The number of variables hopefully can be reduced, by using either\\nprojection techniques or selection methods; the latter allow for the\\ninterpretation of the selected variables. Since the optimal approach of testing\\nall possible subsets of variables with the prediction model is intractable, an\\nincremental selection approach using a nonparametric statistics is a good\\noption, as it avoids the computationally intensive use of the model itself. It\\nhas two drawbacks however: the number of groups of variables to test is still\\nhuge, and colinearities can make the results unstable. To overcome these\\nlimitations, this paper presents a method to select groups of spectral\\nvariables. It consists in a forward-backward procedure applied to the\\ncoefficients of a B-Spline representation of the spectra. The criterion used in\\nthe forward-backward procedure is the mutual information, allowing to find\\nnonlinear dependencies between variables, on the contrary of the generally used\\ncorrelation. The spline representation is used to get interpretability of the\\nresults, as groups of consecutive spectral variables will be selected. The\\nexperiments conducted on NIR spectra from fescue grass and diesel fuels show\\nthat the method provides clearly identified groups of selected variables,\\nmaking interpretation easy, while keeping a low computational load. The\\nprediction performances obtained using the selected coefficients are higher\\nthan those obtained by the same method applied directly to the original\\nvariables and similar to those obtained using traditional models, although\\nusing significantly less spectral variables.\\n',\n",
              " '  Combining the mutual information criterion with a forward feature selection\\nstrategy offers a good trade-off between optimality of the selected feature\\nsubset and computation time. However, it requires to set the parameter(s) of\\nthe mutual information estimator and to determine when to halt the forward\\nprocedure. These two choices are difficult to make because, as the\\ndimensionality of the subset increases, the estimation of the mutual\\ninformation becomes less and less reliable. This paper proposes to use\\nresampling methods, a K-fold cross-validation and the permutation test, to\\naddress both issues. The resampling methods bring information about the\\nvariance of the estimator, information which can then be used to automatically\\nset the parameter and to calculate a threshold to stop the forward procedure.\\nThe procedure is illustrated on a synthetic dataset as well as on real-world\\nexamples.\\n',\n",
              " '  The ability of a classifier to take on new information and classes by\\nevolving the classifier without it having to be fully retrained is known as\\nincremental learning. Incremental learning has been successfully applied to\\nmany classification problems, where the data is changing and is not all\\navailable at once. In this paper there is a comparison between Learn++, which\\nis one of the most recent incremental learning algorithms, and the new proposed\\nmethod of Incremental Learning Using Genetic Algorithm (ILUGA). Learn++ has\\nshown good incremental learning capabilities on benchmark datasets on which the\\nnew ILUGA method has been tested. ILUGA has also shown good incremental\\nlearning ability using only a few classifiers and does not suffer from\\ncatastrophic forgetting. The results obtained for ILUGA on the Optical\\nCharacter Recognition (OCR) and Wine datasets are good, with an overall\\naccuracy of 93% and 94% respectively showing a 4% improvement over Learn++.MT\\nfor the difficult multi-class OCR dataset.\\n',\n",
              " '  Support Vector Machines (SVMs) are a relatively new supervised classification\\ntechnique to the land cover mapping community. They have their roots in\\nStatistical Learning Theory and have gained prominence because they are robust,\\naccurate and are effective even when using a small training sample. By their\\nnature SVMs are essentially binary classifiers, however, they can be adopted to\\nhandle the multiple classification tasks common in remote sensing studies. The\\ntwo approaches commonly used are the One-Against-One (1A1) and One-Against-All\\n(1AA) techniques. In this paper, these approaches are evaluated in as far as\\ntheir impact and implication for land cover mapping. The main finding from this\\nresearch is that whereas the 1AA technique is more predisposed to yielding\\nunclassified and mixed pixels, the resulting classification accuracy is not\\nsignificantly different from 1A1 approach. It is the authors conclusions that\\nultimately the choice of technique adopted boils down to personal preference\\nand the uniqueness of the dataset at hand.\\n',\n",
              " '  We show that the Brier game of prediction is mixable and find the optimal\\nlearning rate and substitution function for it. The resulting prediction\\nalgorithm is applied to predict results of football and tennis matches. The\\ntheoretical performance guarantee turns out to be rather tight on these data\\nsets, especially in the case of the more extensive tennis data.\\n',\n",
              " '  One of the most utilized data mining tasks is the search for association\\nrules. Association rules represent significant relationships between items in\\ntransactions. We extend the concept of association rule to represent a much\\nbroader class of associations, which we refer to as \\\\emph{entity-relationship\\nrules.} Semantically, entity-relationship rules express associations between\\nproperties of related objects. Syntactically, these rules are based on a broad\\nsubclass of safe domain relational calculus queries. We propose a new\\ndefinition of support and confidence for entity-relationship rules and for the\\nfrequency of entity-relationship queries. We prove that the definition of\\nfrequency satisfies standard probability axioms and the Apriori property.\\n',\n",
              " '  Data mining allows the exploration of sequences of phenomena, whereas one\\nusually tends to focus on isolated phenomena or on the relation between two\\nphenomena. It offers invaluable tools for theoretical analyses and exploration\\nof the structure of sentences, texts, dialogues, and speech. We report here the\\nresults of an attempt at using it for inspecting sequences of verbs from French\\naccounts of road accidents. This analysis comes from an original approach of\\nunsupervised training allowing the discovery of the structure of sequential\\ndata. The entries of the analyzer were only made of the verbs appearing in the\\nsentences. It provided a classification of the links between two successive\\nverbs into four distinct clusters, allowing thus text segmentation. We give\\nhere an interpretation of these clusters by applying a statistical analysis to\\nindependent semantic annotations.\\n',\n",
              " '  Regularization by the sum of singular values, also referred to as the trace\\nnorm, is a popular technique for estimating low rank rectangular matrices. In\\nthis paper, we extend some of the consistency results of the Lasso to provide\\nnecessary and sufficient conditions for rank consistency of trace norm\\nminimization with the square loss. We also provide an adaptive version that is\\nrank consistent even when the necessary condition for the non adaptive version\\nis not fulfilled.\\n',\n",
              " '  This paper describes an efficient reduction of the learning problem of\\nranking to binary classification. The reduction guarantees an average pairwise\\nmisranking regret of at most that of the binary classifier regret, improving a\\nrecent result of Balcan et al which only guarantees a factor of 2. Moreover,\\nour reduction applies to a broader class of ranking loss functions, admits a\\nsimpler proof, and the expected running time complexity of our algorithm in\\nterms of number of calls to a classifier or preference function is improved\\nfrom $\\\\Omega(n^2)$ to $O(n \\\\log n)$. In addition, when the top $k$ ranked\\nelements only are required ($k \\\\ll n$), as in many applications in information\\nextraction or search engines, the time complexity of our algorithm can be\\nfurther reduced to $O(k \\\\log k + n)$. Our reduction and algorithm are thus\\npractical for realistic applications where the number of points to rank exceeds\\nseveral thousands. Much of our results also extend beyond the bipartite case\\npreviously studied.\\n  Our rediction is a randomized one. To complement our result, we also derive\\nlower bounds on any deterministic reduction from binary (preference)\\nclassification to ranking, implying that our use of a randomized reduction is\\nessentially necessary for the guarantees we provide.\\n',\n",
              " '  Statistically resolving the underlying haplotype pair for a genotype\\nmeasurement is an important intermediate step in gene mapping studies, and has\\nreceived much attention recently. Consequently, a variety of methods for this\\nproblem have been developed. Different methods employ different statistical\\nmodels, and thus implicitly encode different assumptions about the nature of\\nthe underlying haplotype structure. Depending on the population sample in\\nquestion, their relative performance can vary greatly, and it is unclear which\\nmethod to choose for a particular sample. Instead of choosing a single method,\\nwe explore combining predictions returned by different methods in a principled\\nway, and thereby circumvent the problem of method selection.\\n  We propose several techniques for combining haplotype reconstructions and\\nanalyze their computational properties. In an experimental study on real-world\\nhaplotype data we show that such techniques can provide more accurate and\\nrobust reconstructions, and are useful for outlier detection. Typically, the\\ncombined prediction is at least as accurate as or even more accurate than the\\nbest individual method, effectively circumventing the method selection problem.\\n',\n",
              " '  In recent years, spectral clustering has become one of the most popular\\nmodern clustering algorithms. It is simple to implement, can be solved\\nefficiently by standard linear algebra software, and very often outperforms\\ntraditional clustering algorithms such as the k-means algorithm. On the first\\nglance spectral clustering appears slightly mysterious, and it is not obvious\\nto see why it works at all and what it really does. The goal of this tutorial\\nis to give some intuition on those questions. We describe different graph\\nLaplacians and their basic properties, present the most common spectral\\nclustering algorithms, and derive those algorithms from scratch by several\\ndifferent approaches. Advantages and disadvantages of the different spectral\\nclustering algorithms are discussed.\\n',\n",
              " '  Building rules on top of ontologies is the ultimate goal of the logical layer\\nof the Semantic Web. To this aim an ad-hoc mark-up language for this layer is\\ncurrently under discussion. It is intended to follow the tradition of hybrid\\nknowledge representation and reasoning systems such as $\\\\mathcal{AL}$-log that\\nintegrates the description logic $\\\\mathcal{ALC}$ and the function-free Horn\\nclausal language \\\\textsc{Datalog}. In this paper we consider the problem of\\nautomating the acquisition of these rules for the Semantic Web. We propose a\\ngeneral framework for rule induction that adopts the methodological apparatus\\nof Inductive Logic Programming and relies on the expressive and deductive power\\nof $\\\\mathcal{AL}$-log. The framework is valid whatever the scope of induction\\n(description vs. prediction) is. Yet, for illustrative purposes, we also\\ndiscuss an instantiation of the framework which aims at description and turns\\nout to be useful in Ontology Refinement.\\n  Keywords: Inductive Logic Programming, Hybrid Knowledge Representation and\\nReasoning Systems, Ontologies, Semantic Web.\\n  Note: To appear in Theory and Practice of Logic Programming (TPLP)\\n',\n",
              " '  Higher-order tensor decompositions are analogous to the familiar Singular\\nValue Decomposition (SVD), but they transcend the limitations of matrices\\n(second-order tensors). SVD is a powerful tool that has achieved impressive\\nresults in information retrieval, collaborative filtering, computational\\nlinguistics, computational vision, and other fields. However, SVD is limited to\\ntwo-dimensional arrays of data (two modes), and many potential applications\\nhave three or more modes, which require higher-order tensor decompositions.\\nThis paper evaluates four algorithms for higher-order tensor decomposition:\\nHigher-Order Singular Value Decomposition (HO-SVD), Higher-Order Orthogonal\\nIteration (HOOI), Slice Projection (SP), and Multislice Projection (MP). We\\nmeasure the time (elapsed run time), space (RAM and disk space requirements),\\nand fit (tensor reconstruction accuracy) of the four algorithms, under a\\nvariety of conditions. We find that standard implementations of HO-SVD and HOOI\\ndo not scale up to larger tensors, due to increasing RAM requirements. We\\nrecommend HOOI for tensors that are small enough for the available RAM and MP\\nfor larger tensors.\\n',\n",
              " '  In this paper, we consider the nonasymptotic sequential estimation of means\\nof random variables bounded in between zero and one. We have rigorously\\ndemonstrated that, in order to guarantee prescribed relative precision and\\nconfidence level, it suffices to continue sampling until the sample sum is no\\nless than a certain bound and then take the average of samples as an estimate\\nfor the mean of the bounded random variable. We have developed an explicit\\nformula and a bisection search method for the determination of such bound of\\nsample sum, without any knowledge of the bounded variable. Moreover, we have\\nderived bounds for the distribution of sample size. In the special case of\\nBernoulli random variables, we have established analytical and numerical\\nmethods to further reduce the bound of sample sum and thus improve the\\nefficiency of sampling. Furthermore, the fallacy of existing results are\\ndetected and analyzed.\\n',\n",
              " '  Support Vector Machines (SVMs) are a relatively new supervised classification\\ntechnique to the land cover mapping community. They have their roots in\\nStatistical Learning Theory and have gained prominence because they are robust,\\naccurate and are effective even when using a small training sample. By their\\nnature SVMs are essentially binary classifiers, however, they can be adopted to\\nhandle the multiple classification tasks common in remote sensing studies. The\\ntwo approaches commonly used are the One-Against-One (1A1) and One-Against-All\\n(1AA) techniques. In this paper, these approaches are evaluated in as far as\\ntheir impact and implication for land cover mapping. The main finding from this\\nresearch is that whereas the 1AA technique is more predisposed to yielding\\nunclassified and mixed pixels, the resulting classification accuracy is not\\nsignificantly different from 1A1 approach. It is the authors conclusion\\ntherefore that ultimately the choice of technique adopted boils down to\\npersonal preference and the uniqueness of the dataset at hand.\\n',\n",
              " '  Recent spectral clustering methods are a propular and powerful technique for\\ndata clustering. These methods need to solve the eigenproblem whose\\ncomputational complexity is $O(n^3)$, where $n$ is the number of data samples.\\nIn this paper, a non-eigenproblem based clustering method is proposed to deal\\nwith the clustering problem. Its performance is comparable to the spectral\\nclustering algorithms but it is more efficient with computational complexity\\n$O(n^2)$. We show that with a transitive distance and an observed property,\\ncalled K-means duality, our algorithm can be used to handle data sets with\\ncomplex cluster shapes, multi-scale clusters, and noise. Moreover, no\\nparameters except the number of clusters need to be set in our algorithm.\\n',\n",
              " '  This correspondence studies the basic problem of classifications - how to\\nevaluate different classifiers. Although the conventional performance indexes,\\nsuch as accuracy, are commonly used in classifier selection or evaluation,\\ninformation-based criteria, such as mutual information, are becoming popular in\\nfeature/model selections. In this work, we propose to assess classifiers in\\nterms of normalized mutual information (NI), which is novel and well defined in\\na compact range for classifier evaluation. We derive close-form relations of\\nnormalized mutual information with respect to accuracy, precision, and recall\\nin binary classifications. By exploring the relations among them, we reveal\\nthat NI is actually a set of nonlinear functions, with a concordant\\npower-exponent form, to each performance index. The relations can also be\\nexpressed with respect to precision and recall, or to false alarm and hitting\\nrate (recall).\\n',\n",
              " '  Covariances from categorical variables are defined using a regular simplex\\nexpression for categories. The method follows the variance definition by Gini,\\nand it gives the covariance as a solution of simultaneous equations. The\\ncalculated results give reasonable values for test data. A method of principal\\ncomponent analysis (RS-PCA) is also proposed using regular simplex expressions,\\nwhich allows easy interpretation of the principal components. The proposed\\nmethods apply to variable selection problem of categorical data USCensus1990\\ndata. The proposed methods give appropriate criterion for the variable\\nselection problem of categorical\\n',\n",
              " \"  For a classification problem described by the joint density $P(\\\\omega,x)$,\\nmodels of $P(\\\\omega\\\\eq\\\\omega'|x,x')$ (the ``Bayesian similarity measure'') have\\nbeen shown to be an optimal similarity measure for nearest neighbor\\nclassification. This paper analyzes demonstrates several additional properties\\nof that conditional distribution. The paper first shows that we can\\nreconstruct, up to class labels, the class posterior distribution $P(\\\\omega|x)$\\ngiven $P(\\\\omega\\\\eq\\\\omega'|x,x')$, gives a procedure for recovering the class\\nlabels, and gives an asymptotically Bayes-optimal classification procedure. It\\nalso shows, given such an optimal similarity measure, how to construct a\\nclassifier that outperforms the nearest neighbor classifier and achieves\\nBayes-optimal classification rates. The paper then analyzes Bayesian similarity\\nin a framework where a classifier faces a number of related classification\\ntasks (multitask learning) and illustrates that reconstruction of the class\\nposterior distribution is not possible in general. Finally, the paper\\nidentifies a distinct class of classification problems using\\n$P(\\\\omega\\\\eq\\\\omega'|x,x')$ and shows that using $P(\\\\omega\\\\eq\\\\omega'|x,x')$ to\\nsolve those problems is the Bayes optimal solution.\\n\",\n",
              " '  The generation of meaningless \"words\" matching certain statistical and/or\\nlinguistic criteria is frequently needed for experimental purposes in\\nPsycholinguistics. Such stimuli receive the name of pseudowords or nonwords in\\nthe Cognitive Neuroscience literatue. The process for building nonwords\\nsometimes has to be based on linguistic units such as syllables or morphemes,\\nresulting in a numerical explosion of combinations when the size of the\\nnonwords is increased. In this paper, a reactive tabu search scheme is proposed\\nto generate nonwords of variables size. The approach builds pseudowords by\\nusing a modified Metaheuristic algorithm based on a local search procedure\\nenhanced by a feedback-based scheme. Experimental results show that the new\\nalgorithm is a practical and effective tool for nonword generation.\\n',\n",
              " '  Learning machines which have hierarchical structures or hidden variables are\\nsingular statistical models because they are nonidentifiable and their Fisher\\ninformation matrices are singular. In singular statistical models, neither the\\nBayes a posteriori distribution converges to the normal distribution nor the\\nmaximum likelihood estimator satisfies asymptotic normality. This is the main\\nreason why it has been difficult to predict their generalization performances\\nfrom trained states. In this paper, we study four errors, (1) Bayes\\ngeneralization error, (2) Bayes training error, (3) Gibbs generalization error,\\nand (4) Gibbs training error, and prove that there are mathematical relations\\namong these errors. The formulas proved in this paper are equations of states\\nin statistical estimation because they hold for any true distribution, any\\nparametric model, and any a priori distribution. Also we show that Bayes and\\nGibbs generalization errors are estimated by Bayes and Gibbs training errors,\\nand propose widely applicable information criteria which can be applied to both\\nregular and singular statistical models.\\n',\n",
              " '  We give a universal kernel that renders all the regular languages linearly\\nseparable. We are not able to compute this kernel efficiently and conjecture\\nthat it is intractable, but we do have an efficient $\\\\eps$-approximation.\\n',\n",
              " \"  This paper proposes an unsupervised learning technique by using Multi-layer\\nMirroring Neural Network and Forgy's clustering algorithm. Multi-layer\\nMirroring Neural Network is a neural network that can be trained with\\ngeneralized data inputs (different categories of image patterns) to perform\\nnon-linear dimensionality reduction and the resultant low-dimensional code is\\nused for unsupervised pattern classification using Forgy's algorithm. By\\nadapting the non-linear activation function (modified sigmoidal function) and\\ninitializing the weights and bias terms to small random values, mirroring of\\nthe input pattern is initiated. In training, the weights and bias terms are\\nchanged in such a way that the input presented is reproduced at the output by\\nback propagating the error. The mirroring neural network is capable of reducing\\nthe input vector to a great degree (approximately 1/30th the original size) and\\nalso able to reconstruct the input pattern at the output layer from this\\nreduced code units. The feature set (output of central hidden layer) extracted\\nfrom this network is fed to Forgy's algorithm, which classify input data\\npatterns into distinguishable classes. In the implementation of Forgy's\\nalgorithm, initial seed points are selected in such a way that they are distant\\nenough to be perfectly grouped into different categories. Thus a new method of\\nunsupervised learning is formulated and demonstrated in this paper. This method\\ngave impressive results when applied to classification of different image\\npatterns.\\n\",\n",
              " '  Markov random fields are used to model high dimensional distributions in a\\nnumber of applied areas. Much recent interest has been devoted to the\\nreconstruction of the dependency structure from independent samples from the\\nMarkov random fields. We analyze a simple algorithm for reconstructing the\\nunderlying graph defining a Markov random field on $n$ nodes and maximum degree\\n$d$ given observations. We show that under mild non-degeneracy conditions it\\nreconstructs the generating graph with high probability using $\\\\Theta(d\\n\\\\epsilon^{-2}\\\\delta^{-4} \\\\log n)$ samples where $\\\\epsilon,\\\\delta$ depend on the\\nlocal interactions. For most local interaction $\\\\eps,\\\\delta$ are of order\\n$\\\\exp(-O(d))$.\\n  Our results are optimal as a function of $n$ up to a multiplicative constant\\ndepending on $d$ and the strength of the local interactions. Our results seem\\nto be the first results for general models that guarantee that {\\\\em the}\\ngenerating model is reconstructed. Furthermore, we provide explicit $O(n^{d+2}\\n\\\\epsilon^{-2}\\\\delta^{-4} \\\\log n)$ running time bound. In cases where the\\nmeasure on the graph has correlation decay, the running time is $O(n^2 \\\\log n)$\\nfor all fixed $d$. We also discuss the effect of observing noisy samples and\\nshow that as long as the noise level is low, our algorithm is effective. On the\\nother hand, we construct an example where large noise implies\\nnon-identifiability even for generic noise and interactions. Finally, we\\nbriefly show that in some simple cases, models with hidden nodes can also be\\nrecovered.\\n',\n",
              " '  Cross-layer optimization solutions have been proposed in recent years to\\nimprove the performance of network users operating in a time-varying,\\nerror-prone wireless environment. However, these solutions often rely on ad-hoc\\noptimization approaches, which ignore the different environmental dynamics\\nexperienced at various layers by a user and violate the layered network\\narchitecture of the protocol stack by requiring layers to provide access to\\ntheir internal protocol parameters to other layers. This paper presents a new\\ntheoretic foundation for cross-layer optimization, which allows each layer to\\nmake autonomous decisions individually, while maximizing the utility of the\\nwireless user by optimally determining what information needs to be exchanged\\namong layers. Hence, this cross-layer framework does not change the current\\nlayered architecture. Specifically, because the wireless user interacts with\\nthe environment at various layers of the protocol stack, the cross-layer\\noptimization problem is formulated as a layered Markov decision process (MDP)\\nin which each layer adapts its own protocol parameters and exchanges\\ninformation (messages) with other layers in order to cooperatively maximize the\\nperformance of the wireless user. The message exchange mechanism for\\ndetermining the optimal cross-layer transmission strategies has been designed\\nfor both off-line optimization and on-line dynamic adaptation. We also show\\nthat many existing cross-layer optimization algorithms can be formulated as\\nsimplified, sub-optimal, versions of our layered MDP framework.\\n',\n",
              " \"  We consider the problem of choosing a density estimate from a set of\\ndistributions F, minimizing the L1-distance to an unknown distribution\\n(Devroye, Lugosi 2001). Devroye and Lugosi analyze two algorithms for the\\nproblem: Scheffe tournament winner and minimum distance estimate. The Scheffe\\ntournament estimate requires fewer computations than the minimum distance\\nestimate, but has strictly weaker guarantees than the latter.\\n  We focus on the computational aspect of density estimation. We present two\\nalgorithms, both with the same guarantee as the minimum distance estimate. The\\nfirst one, a modification of the minimum distance estimate, uses the same\\nnumber (quadratic in |F|) of computations as the Scheffe tournament. The second\\none, called ``efficient minimum loss-weight estimate,'' uses only a linear\\nnumber of computations, assuming that F is preprocessed.\\n  We also give examples showing that the guarantees of the algorithms cannot be\\nimproved and explore randomized algorithms for density estimation.\\n\",\n",
              " '  Point clouds are sets of points in two or three dimensions. Most kernel\\nmethods for learning on sets of points have not yet dealt with the specific\\ngeometrical invariances and practical constraints associated with point clouds\\nin computer vision and graphics. In this paper, we present extensions of graph\\nkernels for point clouds, which allow to use kernel methods for such ob jects\\nas shapes, line drawings, or any three-dimensional point clouds. In order to\\ndesign rich and numerically efficient kernels with as few free parameters as\\npossible, we use kernels between covariance matrices and their factorizations\\non graphical models. We derive polynomial time dynamic programming recursions\\nand present applications to recognition of handwritten digits and Chinese\\ncharacters from few training examples.\\n',\n",
              " '  In this paper we shall review the common problems associated with Piecewise\\nLinear Separation incremental algorithms. This kind of neural models yield poor\\nperformances when dealing with some classification problems, due to the\\nevolving schemes used to construct the resulting networks. So as to avoid this\\nundesirable behavior we shall propose a modification criterion. It is based\\nupon the definition of a function which will provide information about the\\nquality of the network growth process during the learning phase. This function\\nis evaluated periodically as the network structure evolves, and will permit, as\\nwe shall show through exhaustive benchmarks, to considerably improve the\\nperformance(measured in terms of network complexity and generalization\\ncapabilities) offered by the networks generated by these incremental models.\\n',\n",
              " '  In this paper, we propose a spreading activation approach for collaborative\\nfiltering (SA-CF). By using the opinion spreading process, the similarity\\nbetween any users can be obtained. The algorithm has remarkably higher accuracy\\nthan the standard collaborative filtering (CF) using Pearson correlation.\\nFurthermore, we introduce a free parameter $\\\\beta$ to regulate the\\ncontributions of objects to user-user correlations. The numerical results\\nindicate that decreasing the influence of popular objects can further improve\\nthe algorithmic accuracy and personality. We argue that a better algorithm\\nshould simultaneously require less computation and generate higher accuracy.\\nAccordingly, we further propose an algorithm involving only the top-$N$ similar\\nneighbors for each target user, which has both less computational complexity\\nand higher algorithmic accuracy.\\n',\n",
              " '  In this contribution, we propose a generic online (also sometimes called\\nadaptive or recursive) version of the Expectation-Maximisation (EM) algorithm\\napplicable to latent variable models of independent observations. Compared to\\nthe algorithm of Titterington (1984), this approach is more directly connected\\nto the usual EM algorithm and does not rely on integration with respect to the\\ncomplete data distribution. The resulting algorithm is usually simpler and is\\nshown to achieve convergence to the stationary points of the Kullback-Leibler\\ndivergence between the marginal distribution of the observation and the model\\ndistribution at the optimal rate, i.e., that of the maximum likelihood\\nestimator. In addition, the proposed approach is also suitable for conditional\\n(or regression) models, as illustrated in the case of the mixture of linear\\nregressions model.\\n',\n",
              " \"  It is hard to exaggerate the role of economic aggregators -- functions that\\nsummarize numerous and / or heterogeneous data -- in economic models since the\\nearly XX$^{th}$ century. In many cases, as witnessed by the pioneering works of\\nCobb and Douglas, these functions were information quantities tailored to\\neconomic theories, i.e. they were built to fit economic phenomena. In this\\npaper, we look at these functions from the complementary side: information. We\\nuse a recent toolbox built on top of a vast class of distortions coined by\\nBregman, whose application field rivals metrics' in various subfields of\\nmathematics. This toolbox makes it possible to find the quality of an\\naggregator (for consumptions, prices, labor, capital, wages, etc.), from the\\nstandpoint of the information it carries. We prove a rather striking result.\\n  From the informational standpoint, well-known economic aggregators do belong\\nto the \\\\textit{optimal} set. As common economic assumptions enter the analysis,\\nthis large set shrinks, and it essentially ends up \\\\textit{exactly fitting}\\neither CES, or Cobb-Douglas, or both. To summarize, in the relevant economic\\ncontexts, one could not have crafted better some aggregator from the\\ninformation standpoint. We also discuss global economic behaviors of optimal\\ninformation aggregators in general, and present a brief panorama of the links\\nbetween economic and information aggregators.\\n  Keywords: Economic Aggregators, CES, Cobb-Douglas, Bregman divergences\\n\",\n",
              " '  The cross-entropy method is a simple but efficient method for global\\noptimization. In this paper we provide two online variants of the basic CEM,\\ntogether with a proof of convergence.\\n',\n",
              " '  In this paper we propose a novel algorithm, factored value iteration (FVI),\\nfor the approximate solution of factored Markov decision processes (fMDPs). The\\ntraditional approximate value iteration algorithm is modified in two ways. For\\none, the least-squares projection operator is modified so that it does not\\nincrease max-norm, and thus preserves convergence. The other modification is\\nthat we uniformly sample polynomially many samples from the (exponentially\\nlarge) state space. This way, the complexity of our algorithm becomes\\npolynomial in the size of the fMDP description length. We prove that the\\nalgorithm is convergent. We also derive an upper bound on the difference\\nbetween our approximate solution and the optimal one, and also on the error\\nintroduced by sampling. We analyze various projection operators with respect to\\ntheir computation complexity and their convergence when combined with\\napproximate value iteration.\\n',\n",
              " '  We prove that the optimal assignment kernel, proposed recently as an attempt\\nto embed labeled graphs and more generally tuples of basic data to a Hilbert\\nspace, is in fact not always positive definite.\\n',\n",
              " \"  Kolmogorov argued that the concept of information exists also in problems\\nwith no underlying stochastic model (as Shannon's information representation)\\nfor instance, the information contained in an algorithm or in the genome. He\\nintroduced a combinatorial notion of entropy and information $I(x:\\\\sy)$\\nconveyed by a binary string $x$ about the unknown value of a variable $\\\\sy$.\\nThe current paper poses the following questions: what is the relationship\\nbetween the information conveyed by $x$ about $\\\\sy$ to the description\\ncomplexity of $x$ ? is there a notion of cost of information ? are there limits\\non how efficient $x$ conveys information ?\\n  To answer these questions Kolmogorov's definition is extended and a new\\nconcept termed {\\\\em information width} which is similar to $n$-widths in\\napproximation theory is introduced. Information of any input source, e.g.,\\nsample-based, general side-information or a hybrid of both can be evaluated by\\na single common formula. An application to the space of binary functions is\\nconsidered.\\n\",\n",
              " '  Consider a class $\\\\mH$ of binary functions $h: X\\\\to\\\\{-1, +1\\\\}$ on a finite\\ninterval $X=[0, B]\\\\subset \\\\Real$. Define the {\\\\em sample width} of $h$ on a\\nfinite subset (a sample) $S\\\\subset X$ as $\\\\w_S(h) \\\\equiv \\\\min_{x\\\\in S}\\n|\\\\w_h(x)|$, where $\\\\w_h(x) = h(x) \\\\max\\\\{a\\\\geq 0: h(z)=h(x), x-a\\\\leq z\\\\leq\\nx+a\\\\}$. Let $\\\\mathbb{S}_\\\\ell$ be the space of all samples in $X$ of cardinality\\n$\\\\ell$ and consider sets of wide samples, i.e., {\\\\em hypersets} which are\\ndefined as $A_{\\\\beta, h} = \\\\{S\\\\in \\\\mathbb{S}_\\\\ell: \\\\w_{S}(h) \\\\geq \\\\beta\\\\}$.\\nThrough an application of the Sauer-Shelah result on the density of sets an\\nupper estimate is obtained on the growth function (or trace) of the class\\n$\\\\{A_{\\\\beta, h}: h\\\\in\\\\mH\\\\}$, $\\\\beta>0$, i.e., on the number of possible\\ndichotomies obtained by intersecting all hypersets with a fixed collection of\\nsamples $S\\\\in\\\\mathbb{S}_\\\\ell$ of cardinality $m$. The estimate is\\n$2\\\\sum_{i=0}^{2\\\\lfloor B/(2\\\\beta)\\\\rfloor}{m-\\\\ell\\\\choose i}$.\\n',\n",
              " '  Given R groups of numerical variables X1, ... XR, we assume that each group\\nis the result of one underlying latent variable, and that all latent variables\\nare bound together through a linear equation system. Moreover, we assume that\\nsome explanatory latent variables may interact pairwise in one or more\\nequations. We basically consider PLS Path Modelling\\'s algorithm to estimate\\nboth latent variables and the model\\'s coefficients. New \"external\" estimation\\nschemes are proposed that draw latent variables towards strong group structures\\nin a more flexible way. New \"internal\" estimation schemes are proposed to\\nenable PLSPM to make good use of variable group complementarity and to deal\\nwith interactions. Application examples are given.\\n',\n",
              " '  We study the problem of partitioning a small sample of $n$ individuals from a\\nmixture of $k$ product distributions over a Boolean cube $\\\\{0, 1\\\\}^K$ according\\nto their distributions. Each distribution is described by a vector of allele\\nfrequencies in $\\\\R^K$. Given two distributions, we use $\\\\gamma$ to denote the\\naverage $\\\\ell_2^2$ distance in frequencies across $K$ dimensions, which\\nmeasures the statistical divergence between them. We study the case assuming\\nthat bits are independently distributed across $K$ dimensions. This work\\ndemonstrates that, for a balanced input instance for $k = 2$, a certain\\ngraph-based optimization function returns the correct partition with high\\nprobability, where a weighted graph $G$ is formed over $n$ individuals, whose\\npairwise hamming distances between their corresponding bit vectors define the\\nedge weights, so long as $K = \\\\Omega(\\\\ln n/\\\\gamma)$ and $Kn = \\\\tilde\\\\Omega(\\\\ln\\nn/\\\\gamma^2)$. The function computes a maximum-weight balanced cut of $G$, where\\nthe weight of a cut is the sum of the weights across all edges in the cut. This\\nresult demonstrates a nice property in the high-dimensional feature space: one\\ncan trade off the number of features that are required with the size of the\\nsample to accomplish certain tasks like clustering.\\n',\n",
              " '  We propose a novel model for nonlinear dimension reduction motivated by the\\nprobabilistic formulation of principal component analysis. Nonlinearity is\\nachieved by specifying different transformation matrices at different locations\\nof the latent space and smoothing the transformation using a Markov random\\nfield type prior. The computation is made feasible by the recent advances in\\nsampling from von Mises-Fisher distributions.\\n',\n",
              " '  We present a general approach for collaborative filtering (CF) using spectral\\nregularization to learn linear operators from \"users\" to the \"objects\" they\\nrate. Recent low-rank type matrix completion approaches to CF are shown to be\\nspecial cases. However, unlike existing regularization based CF methods, our\\napproach can be used to also incorporate information such as attributes of the\\nusers or the objects -- a limitation of existing regularization based CF\\nmethods. We then provide novel representer theorems that we use to develop new\\nestimation methods. We provide learning algorithms based on low-rank\\ndecompositions, and test them on a standard CF dataset. The experiments\\nindicate the advantages of generalizing the existing regularization based CF\\nmethods to incorporate related information about users and objects. Finally, we\\nshow that certain multi-task learning methods can be also seen as special cases\\nof our proposed approach.\\n',\n",
              " '  We show how models for prediction with expert advice can be defined concisely\\nand clearly using hidden Markov models (HMMs); standard HMM algorithms can then\\nbe used to efficiently calculate, among other things, how the expert\\npredictions should be weighted according to the model. We cast many existing\\nmodels as HMMs and recover the best known running times in each case. We also\\ndescribe two new models: the switch distribution, which was recently developed\\nto improve Bayesian/Minimum Description Length model selection, and a new\\ngeneralisation of the fixed share algorithm based on run-length coding. We give\\nloss bounds for all models and shed new light on their relationships.\\n',\n",
              " '  In the study of computer codes, filling space as uniformly as possible is\\nimportant to describe the complexity of the investigated phenomenon. However,\\nthis property is not conserved by reducing the dimension. Some numeric\\nexperiment designs are conceived in this sense as Latin hypercubes or\\northogonal arrays, but they consider only the projections onto the axes or the\\ncoordinate planes. In this article we introduce a statistic which allows\\nstudying the good distribution of points according to all 1-dimensional\\nprojections. By angularly scanning the domain, we obtain a radar type\\nrepresentation, allowing the uniformity defects of a design to be identified\\nwith respect to its projections onto straight lines. The advantages of this new\\ntool are demonstrated on usual examples of space-filling designs (SFD) and a\\nglobal statistic independent of the angle of rotation is studied.\\n',\n",
              " '  Counting is among the most fundamental operations in computing. For example,\\ncounting the pth frequency moment has been a very active area of research, in\\ntheoretical computer science, databases, and data mining. When p=1, the task\\n(i.e., counting the sum) can be accomplished using a simple counter.\\n  Compressed Counting (CC) is proposed for efficiently computing the pth\\nfrequency moment of a data stream signal A_t, where 0<p<=2. CC is applicable if\\nthe streaming data follow the Turnstile model, with the restriction that at the\\ntime t for the evaluation, A_t[i]>= 0, which includes the strict Turnstile\\nmodel as a special case. For natural data streams encountered in practice, this\\nrestriction is minor.\\n  The underly technique for CC is what we call skewed stable random\\nprojections, which captures the intuition that, when p=1 a simple counter\\nsuffices, and when p = 1+/\\\\Delta with small \\\\Delta, the sample complexity of a\\ncounter system should be low (continuously as a function of \\\\Delta). We show at\\nsmall \\\\Delta the sample complexity (number of projections) k = O(1/\\\\epsilon)\\ninstead of O(1/\\\\epsilon^2).\\n  Compressed Counting can serve a basic building block for other tasks in\\nstatistics and computing, for example, estimation entropies of data streams,\\nparameter estimations using the method of moments and maximum likelihood.\\n  Finally, another contribution is an algorithm for approximating the\\nlogarithmic norm, \\\\sum_{i=1}^D\\\\log A_t[i], and logarithmic distance. The\\nlogarithmic distance is useful in machine learning practice with heavy-tailed\\ndata.\\n',\n",
              " \"  In this project, we have developed a sign language tutor that lets users\\nlearn isolated signs by watching recorded videos and by trying the same signs.\\nThe system records the user's video and analyses it. If the sign is recognized,\\nboth verbal and animated feedback is given to the user. The system is able to\\nrecognize complex signs that involve both hand gestures and head movements and\\nexpressions. Our performance tests yield a 99% recognition rate on signs\\ninvolving only manual gestures and 85% recognition rate on signs that involve\\nboth manual and non manual components, such as head movement and facial\\nexpressions.\\n\",\n",
              " '  We consider the framework of stochastic multi-armed bandit problems and study\\nthe possibilities and limitations of forecasters that perform an on-line\\nexploration of the arms. These forecasters are assessed in terms of their\\nsimple regret, a regret notion that captures the fact that exploration is only\\nconstrained by the number of available rounds (not necessarily known in\\nadvance), in contrast to the case when the cumulative regret is considered and\\nwhen exploitation needs to be performed at the same time. We believe that this\\nperformance criterion is suited to situations when the cost of pulling an arm\\nis expressed in terms of resources rather than rewards. We discuss the links\\nbetween the simple and the cumulative regret. One of the main results in the\\ncase of a finite number of arms is a general lower bound on the simple regret\\nof a forecaster in terms of its cumulative regret: the smaller the latter, the\\nlarger the former. Keeping this result in mind, we then exhibit upper bounds on\\nthe simple regret of some forecasters. The paper ends with a study devoted to\\ncontinuous-armed bandit problems; we show that the simple regret can be\\nminimized with respect to a family of probability distributions if and only if\\nthe cumulative regret can be minimized for it. Based on this equivalence, we\\nare able to prove that the separable metric spaces are exactly the metric\\nspaces on which these regrets can be minimized with respect to the family of\\nall probability distributions with continuous mean-payoff functions.\\n',\n",
              " '  Several technologies are emerging that provide new ways to capture, store,\\npresent and use knowledge. This book is the first to provide a comprehensive\\nintroduction to five of the most important of these technologies: Knowledge\\nEngineering, Knowledge Based Engineering, Knowledge Webs, Ontologies and\\nSemantic Webs. For each of these, answers are given to a number of key\\nquestions (What is it? How does it operate? How is a system developed? What can\\nit be used for? What tools are available? What are the main issues?). The book\\nis aimed at students, researchers and practitioners interested in Knowledge\\nManagement, Artificial Intelligence, Design Engineering and Web Technologies.\\n  During the 1990s, Nick worked at the University of Nottingham on the\\napplication of AI techniques to knowledge management and on various knowledge\\nacquisition projects to develop expert systems for military applications. In\\n1999, he joined Epistemics where he worked on numerous knowledge projects and\\nhelped establish knowledge management programmes at large organisations in the\\nengineering, technology and legal sectors. He is author of the book \"Knowledge\\nAcquisition in Practice\", which describes a step-by-step procedure for\\nacquiring and implementing expertise. He maintains strong links with leading\\nresearch organisations working on knowledge technologies, such as\\nknowledge-based engineering, ontologies and semantic technologies.\\n',\n",
              " '  Learning problems form an important category of computational tasks that\\ngeneralizes many of the computations researchers apply to large real-life data\\nsets. We ask: what concept classes can be learned privately, namely, by an\\nalgorithm whose output does not depend too heavily on any one input or specific\\ntraining example? More precisely, we investigate learning algorithms that\\nsatisfy differential privacy, a notion that provides strong confidentiality\\nguarantees in contexts where aggregate information is released about a database\\ncontaining sensitive information about individuals. We demonstrate that,\\nignoring computational constraints, it is possible to privately agnostically\\nlearn any concept class using a sample size approximately logarithmic in the\\ncardinality of the concept class. Therefore, almost anything learnable is\\nlearnable privately: specifically, if a concept class is learnable by a\\n(non-private) algorithm with polynomial sample complexity and output size, then\\nit can be learned privately using a polynomial number of samples. We also\\npresent a computationally efficient private PAC learner for the class of parity\\nfunctions. Local (or randomized response) algorithms are a practical class of\\nprivate algorithms that have received extensive investigation. We provide a\\nprecise characterization of local private learning algorithms. We show that a\\nconcept class is learnable by a local algorithm if and only if it is learnable\\nin the statistical query (SQ) model. Finally, we present a separation between\\nthe power of interactive and noninteractive local learning algorithms.\\n',\n",
              " '  We consider privacy preserving decision tree induction via ID3 in the case\\nwhere the training data is horizontally or vertically distributed. Furthermore,\\nwe consider the same problem in the case where the data is both horizontally\\nand vertically distributed, a situation we refer to as grid partitioned data.\\nWe give an algorithm for privacy preserving ID3 over horizontally partitioned\\ndata involving more than two parties. For grid partitioned data, we discuss two\\ndifferent evaluation methods for preserving privacy ID3, namely, first merging\\nhorizontally and developing vertically or first merging vertically and next\\ndeveloping horizontally. Next to introducing privacy preserving data mining\\nover grid-partitioned data, the main contribution of this paper is that we\\nshow, by means of a complexity analysis that the former evaluation method is\\nthe more efficient.\\n',\n",
              " \"  The recognition, involvement, and description of main actors influences the\\nstory line of the whole text. This is of higher importance as the text per se\\nrepresents a flow of words and expressions that once it is read it is lost. In\\nthis respect, the understanding of a text and moreover on how the actor exactly\\nbehaves is not only a major concern: as human beings try to store a given input\\non short-term memory while associating diverse aspects and actors with\\nincidents, the following approach represents a virtual architecture, where\\ncollocations are concerned and taken as the associative completion of the\\nactors' acting. Once that collocations are discovered, they become managed in\\nseparated memory blocks broken down by the actors. As for human beings, the\\nmemory blocks refer to associative mind-maps. We then present several priority\\nfunctions to represent the actual temporal situation inside a mind-map to\\nenable the user to reconstruct the recent events from the discovered temporal\\nresults.\\n\",\n",
              " '  We consider regularized support vector machines (SVMs) and show that they are\\nprecisely equivalent to a new robust optimization formulation. We show that\\nthis equivalence of robust optimization and regularization has implications for\\nboth algorithms, and analysis. In terms of algorithms, the equivalence suggests\\nmore general SVM-like algorithms for classification that explicitly build in\\nprotection to noise, and at the same time control overfitting. On the analysis\\nfront, the equivalence of robustness and regularization, provides a robust\\noptimization interpretation for the success of regularized SVMs. We use the\\nthis new robustness interpretation of SVMs to give a new proof of consistency\\nof (kernelized) SVMs, thus establishing robustness as the reason regularized\\nSVMs generalize well.\\n',\n",
              " '  Two meta-evolutionary optimization strategies described in this paper\\naccelerate the convergence of evolutionary programming algorithms while still\\nretaining much of their ability to deal with multi-modal problems. The\\nstrategies, called directional mutation and recorded step in this paper, can\\noperate independently but together they greatly enhance the ability of\\nevolutionary programming algorithms to deal with fitness landscapes\\ncharacterized by long narrow valleys. The directional mutation aspect of this\\ncombined method uses correlated meta-mutation but does not introduce a full\\ncovariance matrix. These new methods are thus much more economical in terms of\\nstorage for problems with high dimensionality. Additionally, directional\\nmutation is rotationally invariant which is a substantial advantage over\\nself-adaptive methods which use a single variance per coordinate for problems\\nwhere the natural orientation of the problem is not oriented along the axes.\\n',\n",
              " '  We propose a method for support vector machine classification using\\nindefinite kernels. Instead of directly minimizing or stabilizing a nonconvex\\nloss function, our algorithm simultaneously computes support vectors and a\\nproxy kernel matrix used in forming the loss. This can be interpreted as a\\npenalized kernel learning problem where indefinite kernel matrices are treated\\nas a noisy observations of a true Mercer kernel. Our formulation keeps the\\nproblem convex and relatively large problems can be solved efficiently using\\nthe projected gradient or analytic center cutting plane methods. We compare the\\nperformance of our technique with other methods on several classic data sets.\\n',\n",
              " \"  We present a general framework of semi-supervised dimensionality reduction\\nfor manifold learning which naturally generalizes existing supervised and\\nunsupervised learning frameworks which apply the spectral decomposition.\\nAlgorithms derived under our framework are able to employ both labeled and\\nunlabeled examples and are able to handle complex problems where data form\\nseparate clusters of manifolds. Our framework offers simple views, explains\\nrelationships among existing frameworks and provides further extensions which\\ncan improve existing algorithms. Furthermore, a new semi-supervised\\nkernelization framework called ``KPCA trick'' is proposed to handle non-linear\\nproblems.\\n\",\n",
              " '  We consider the least-square linear regression problem with regularization by\\nthe l1-norm, a problem usually referred to as the Lasso. In this paper, we\\npresent a detailed asymptotic analysis of model consistency of the Lasso. For\\nvarious decays of the regularization parameter, we compute asymptotic\\nequivalents of the probability of correct model selection (i.e., variable\\nselection). For a specific rate decay, we show that the Lasso selects all the\\nvariables that should enter the model with probability tending to one\\nexponentially fast, while it selects all other variables with strictly positive\\nprobability. We show that this property implies that if we run the Lasso for\\nseveral bootstrapped replications of a given sample, then intersecting the\\nsupports of the Lasso bootstrap estimates leads to consistent model selection.\\nThis novel variable selection algorithm, referred to as the Bolasso, is\\ncompared favorably to other linear regression methods on synthetic data and\\ndatasets from the UCI machine learning repository.\\n',\n",
              " '  This paper focuses on the problem of kernelizing an existing supervised\\nMahalanobis distance learner. The following features are included in the paper.\\nFirstly, three popular learners, namely, \"neighborhood component analysis\",\\n\"large margin nearest neighbors\" and \"discriminant neighborhood embedding\",\\nwhich do not have kernel versions are kernelized in order to improve their\\nclassification performances. Secondly, an alternative kernelization framework\\ncalled \"KPCA trick\" is presented. Implementing a learner in the new framework\\ngains several advantages over the standard framework, e.g. no mathematical\\nformulas and no reprogramming are required for a kernel implementation, the\\nframework avoids troublesome problems such as singularity, etc. Thirdly, while\\nthe truths of representer theorems are just assumptions in previous papers\\nrelated to ours, here, representer theorems are formally proven. The proofs\\nvalidate both the kernel trick and the KPCA trick in the context of Mahalanobis\\ndistance learning. Fourthly, unlike previous works which always apply brute\\nforce methods to select a kernel, we investigate two approaches which can be\\nefficiently adopted to construct an appropriate kernel for a given dataset.\\nFinally, numerical results on various real-world datasets are presented.\\n',\n",
              " '  We present a new algorithm for clustering points in R^n. The key property of\\nthe algorithm is that it is affine-invariant, i.e., it produces the same\\npartition for any affine transformation of the input. It has strong guarantees\\nwhen the input is drawn from a mixture model. For a mixture of two arbitrary\\nGaussians, the algorithm correctly classifies the sample assuming only that the\\ntwo components are separable by a hyperplane, i.e., there exists a halfspace\\nthat contains most of one Gaussian and almost none of the other in probability\\nmass. This is nearly the best possible, improving known results substantially.\\nFor k > 2 components, the algorithm requires only that there be some\\n(k-1)-dimensional subspace in which the emoverlap in every direction is small.\\nHere we define overlap to be the ratio of the following two quantities: 1) the\\naverage squared distance between a point and the mean of its component, and 2)\\nthe average squared distance between a point and the mean of the mixture. The\\nmain result may also be stated in the language of linear discriminant analysis:\\nif the standard Fisher discriminant is small enough, labels are not needed to\\nestimate the optimal subspace for projection. Our main tools are isotropic\\ntransformation, spectral projection and a simple reweighting technique. We call\\nthis combination isotropic PCA.\\n',\n",
              " \"  We study the problem of learning k-juntas given access to examples drawn from\\na number of different product distributions. Thus we wish to learn a function f\\n: {-1,1}^n -> {-1,1} that depends on k (unknown) coordinates. While the best\\nknown algorithms for the general problem of learning a k-junta require running\\ntime of n^k * poly(n,2^k), we show that given access to k different product\\ndistributions with biases separated by \\\\gamma>0, the functions may be learned\\nin time poly(n,2^k,\\\\gamma^{-k}). More generally, given access to t <= k\\ndifferent product distributions, the functions may be learned in time n^{k/t} *\\npoly(n,2^k,\\\\gamma^{-k}). Our techniques involve novel results in Fourier\\nanalysis relating Fourier expansions with respect to different biases and a\\ngeneralization of Russo's formula.\\n\",\n",
              " '  Dependence strucuture estimation is one of the important problems in machine\\nlearning domain and has many applications in different scientific areas. In\\nthis paper, a theoretical framework for such estimation based on copula and\\ncopula entropy -- the probabilistic theory of representation and measurement of\\nstatistical dependence, is proposed. Graphical models are considered as a\\nspecial case of the copula framework. A method of the framework for estimating\\nmaximum spanning copula is proposed. Due to copula, the method is irrelevant to\\nthe properties of individual variables, insensitive to outlier and able to deal\\nwith non-Gaussianity. Experiments on both simulated data and real dataset\\ndemonstrated the effectiveness of the proposed method.\\n',\n",
              " '  The use of computational intelligence techniques for classification has been\\nused in numerous applications. This paper compares the use of a Multi Layer\\nPerceptron Neural Network and a new Relational Network on classifying the HIV\\nstatus of women at ante-natal clinics. The paper discusses the architecture of\\nthe relational network and its merits compared to a neural network and most\\nother computational intelligence classifiers. Results gathered from the study\\nindicate comparable classification accuracies as well as revealed relationships\\nbetween data features in the classification data. Much higher classification\\naccuracies are recommended for future research in the area of HIV\\nclassification as well as missing data estimation.\\n',\n",
              " '  This paper aims to showcase the measure of structural diversity of an\\nensemble of 9 classifiers and then map a relationship between this structural\\ndiversity and accuracy. The structural diversity was induced by having\\ndifferent architectures or structures of the classifiers The Genetical\\nAlgorithms (GA) were used to derive the relationship between diversity and the\\nclassification accuracy by evolving the classifiers and then picking 9\\nclassifiers out on an ensemble of 60 classifiers. It was found that as the\\nensemble became diverse the accuracy improved. However at a certain diversity\\nmeasure the accuracy began to drop. The Kohavi-Wolpert variance method is used\\nto measure the diversity of the ensemble. A method of voting is used to\\naggregate the results from each classifier. The lowest error was observed at a\\ndiversity measure of 0.16 with a mean square error of 0.274, when taking 0.2024\\nas maximum diversity measured. The parameters that were varied were: the number\\nof hidden nodes, learning rate and the activation function.\\n',\n",
              " '  Using a support vector machine requires to set two types of hyperparameters:\\nthe soft margin parameter C and the parameters of the kernel. To perform this\\nmodel selection task, the method of choice is cross-validation. Its\\nleave-one-out variant is known to produce an estimator of the generalization\\nerror which is almost unbiased. Its major drawback rests in its time\\nrequirement. To overcome this difficulty, several upper bounds on the\\nleave-one-out error of the pattern recognition SVM have been derived. Among\\nthose bounds, the most popular one is probably the radius-margin bound. It\\napplies to the hard margin pattern recognition SVM, and by extension to the\\n2-norm SVM. In this report, we introduce a quadratic loss M-SVM, the M-SVM^2,\\nas a direct extension of the 2-norm SVM to the multi-class case. For this\\nmachine, a generalized radius-margin bound is then established.\\n',\n",
              " '  This article considers constrained $\\\\ell_1$ minimization methods for the\\nrecovery of high dimensional sparse signals in three settings: noiseless,\\nbounded error and Gaussian noise. A unified and elementary treatment is given\\nin these noise settings for two $\\\\ell_1$ minimization methods: the Dantzig\\nselector and $\\\\ell_1$ minimization with an $\\\\ell_2$ constraint. The results of\\nthis paper improve the existing results in the literature by weakening the\\nconditions and tightening the error bounds. The improvement on the conditions\\nshows that signals with larger support can be recovered accurately. This paper\\nalso establishes connections between restricted isometry property and the\\nmutual incoherence property. Some results of Candes, Romberg and Tao (2006) and\\nDonoho, Elad, and Temlyakov (2006) are extended.\\n',\n",
              " '  On-line learning of a hierarchical learning model is studied by a method from\\nstatistical mechanics. In our model a student of a simple perceptron learns\\nfrom not a true teacher directly, but ensemble teachers who learn from the true\\nteacher with a perceptron learning rule. Since the true teacher and the\\nensemble teachers are expressed as non-monotonic perceptron and simple ones,\\nrespectively, the ensemble teachers go around the unlearnable true teacher with\\nthe distance between them fixed in an asymptotic steady state. The\\ngeneralization performance of the student is shown to exceed that of the\\nensemble teachers in a transient state, as was shown in similar\\nensemble-teachers models. Further, it is found that moving the ensemble\\nteachers even in the steady state, in contrast to the fixed ensemble teachers,\\nis efficient for the performance of the student.\\n',\n",
              " '  Several researchers have recently investigated the connection between\\nreinforcement learning and classification. We are motivated by proposals of\\napproximate policy iteration schemes without value functions which focus on\\npolicy representation using classifiers and address policy learning as a\\nsupervised learning problem. This paper proposes variants of an improved policy\\niteration scheme which addresses the core sampling problem in evaluating a\\npolicy through simulation as a multi-armed bandit machine. The resulting\\nalgorithm offers comparable performance to the previous algorithm achieved,\\nhowever, with significantly less computational effort. An order of magnitude\\nimprovement is demonstrated experimentally in two standard reinforcement\\nlearning domains: inverted pendulum and mountain-car.\\n',\n",
              " '  We prove existence and uniqueness of the minimizer for the average geodesic\\ndistance to the points of a geodesically convex set on the sphere. This implies\\na corresponding existence and uniqueness result for an optimal algorithm for\\nhalfspace learning, when data and target functions are drawn from the uniform\\ndistribution.\\n',\n",
              " '  We propose a framework for analyzing and comparing distributions, allowing us\\nto design statistical tests to determine if two samples are drawn from\\ndifferent distributions. Our test statistic is the largest difference in\\nexpectations over functions in the unit ball of a reproducing kernel Hilbert\\nspace (RKHS). We present two tests based on large deviation bounds for the test\\nstatistic, while a third is based on the asymptotic distribution of this\\nstatistic. The test statistic can be computed in quadratic time, although\\nefficient linear time approximations are available. Several classical metrics\\non distributions are recovered when the function space used to compute the\\ndifference in expectations is allowed to be more general (eg. a Banach space).\\nWe apply our two-sample tests to a variety of problems, including attribute\\nmatching for databases using the Hungarian marriage method, where they perform\\nstrongly. Excellent performance is also obtained when comparing distributions\\nover graphs, for which these are the first such tests.\\n',\n",
              " '  We identify the classical Perceptron algorithm with margin as a member of a\\nbroader family of large margin classifiers which we collectively call the\\nMargitron. The Margitron, (despite its) sharing the same update rule with the\\nPerceptron, is shown in an incremental setting to converge in a finite number\\nof updates to solutions possessing any desirable fraction of the maximum\\nmargin. Experiments comparing the Margitron with decomposition SVMs on tasks\\ninvolving linear kernels and 2-norm soft margin are also reported.\\n',\n",
              " '  This paper presents a theoretical analysis of sample selection bias\\ncorrection. The sample bias correction technique commonly used in machine\\nlearning consists of reweighting the cost of an error on each training point of\\na biased sample to more closely reflect the unbiased distribution. This relies\\non weights derived by various estimation techniques based on finite samples. We\\nanalyze the effect of an error in that estimation on the accuracy of the\\nhypothesis returned by the learning algorithm for two estimation techniques: a\\ncluster-based estimation technique and kernel mean matching. We also report the\\nresults of sample bias correction experiments with several data sets using\\nthese techniques. Our analysis is based on the novel concept of distributional\\nstability which generalizes the existing concept of point-based stability. Much\\nof our work and proof techniques can be used to analyze other importance\\nweighting techniques and their effect on accuracy when using a distributionally\\nstable algorithm.\\n',\n",
              " '  We define a novel, basic, unsupervised learning problem - learning the lowest\\ndensity homogeneous hyperplane separator of an unknown probability\\ndistribution. This task is relevant to several problems in machine learning,\\nsuch as semi-supervised learning and clustering stability. We investigate the\\nquestion of existence of a universally consistent algorithm for this problem.\\nWe propose two natural learning paradigms and prove that, on input unlabeled\\nrandom samples generated by any member of a rich family of distributions, they\\nare guaranteed to converge to the optimal separator for that distribution. We\\ncomplement this result by showing that no learning algorithm for our task can\\nachieve uniform learning rates (that are independent of the data generating\\ndistribution).\\n',\n",
              " '  This article describes an approach to designing a distributed and modular\\nneural classifier. This approach introduces a new hierarchical clustering that\\nenables one to determine reliable regions in the representation space by\\nexploiting supervised information. A multilayer perceptron is then associated\\nwith each of these detected clusters and charged with recognizing elements of\\nthe associated cluster while rejecting all others. The obtained global\\nclassifier is comprised of a set of cooperating neural networks and completed\\nby a K-nearest neighbor classifier charged with treating elements rejected by\\nall the neural networks. Experimental results for the handwritten digit\\nrecognition problem and comparison with neural and statistical nonmodular\\nclassifiers are given.\\n',\n",
              " \"  Nous pr\\\\'esentons dans cette contribution une approche \\\\`a la fois symbolique\\net probabiliste permettant d'extraire l'information sur la segmentation du\\nsignal de parole \\\\`a partir d'information prosodique. Nous utilisons pour ce\\nfaire des grammaires probabilistes poss\\\\'edant une structure hi\\\\'erarchique\\nminimale. La phase de construction des grammaires ainsi que leur pouvoir de\\npr\\\\'ediction sont \\\\'evalu\\\\'es qualitativement ainsi que quantitativement.\\n  -----\\n  Methodologically oriented, the present work sketches an approach for prosodic\\ninformation retrieval and speech segmentation, based on both symbolic and\\nprobabilistic information. We have recourse to probabilistic grammars, within\\nwhich we implement a minimal hierarchical structure. Both the stages of\\nprobabilistic grammar building and its testing in prediction are explored and\\nquantitatively and qualitatively evaluated.\\n\",\n",
              " '  We describe a novel approach to statistical learning from particles tracked\\nwhile moving in a random environment. The problem consists in inferring\\nproperties of the environment from recorded snapshots. We consider here the\\ncase of a fluid seeded with identical passive particles that diffuse and are\\nadvected by a flow. Our approach rests on efficient algorithms to estimate the\\nweighted number of possible matchings among particles in two consecutive\\nsnapshots, the partition function of the underlying graphical model. The\\npartition function is then maximized over the model parameters, namely\\ndiffusivity and velocity gradient. A Belief Propagation (BP) scheme is the\\nbackbone of our algorithm, providing accurate results for the flow parameters\\nwe want to learn. The BP estimate is additionally improved by incorporating\\nLoop Series (LS) contributions. For the weighted matching problem, LS is\\ncompactly expressed as a Cauchy integral, accurately estimated by a saddle\\npoint approximation. Numerical experiments show that the quality of our\\nimproved BP algorithm is comparable to the one of a fully polynomial randomized\\napproximation scheme, based on the Markov Chain Monte Carlo (MCMC) method,\\nwhile the BP-based scheme is substantially faster than the MCMC scheme.\\n',\n",
              " '  Statistical modeling of nuclear data provides a novel approach to nuclear\\nsystematics complementary to established theoretical and phenomenological\\napproaches based on quantum theory. Continuing previous studies in which global\\nstatistical modeling is pursued within the general framework of machine\\nlearning theory, we implement advances in training algorithms designed to\\nimproved generalization, in application to the problem of reproducing and\\npredicting the halflives of nuclear ground states that decay 100% by the beta^-\\nmode. More specifically, fully-connected, multilayer feedforward artificial\\nneural network models are developed using the Levenberg-Marquardt optimization\\nalgorithm together with Bayesian regularization and cross-validation. The\\npredictive performance of models emerging from extensive computer experiments\\nis compared with that of traditional microscopic and phenomenological models as\\nwell as with the performance of other learning systems, including earlier\\nneural network models as well as the support vector machines recently applied\\nto the same problem. In discussing the results, emphasis is placed on\\npredictions for nuclei that are far from the stability line, and especially\\nthose involved in the r-process nucleosynthesis. It is found that the new\\nstatistical models can match or even surpass the predictive performance of\\nconventional models for beta-decay systematics and accordingly should provide a\\nvaluable additional tool for exploring the expanding nuclear landscape.\\n',\n",
              " \"  As a fundamental problem in pattern recognition, graph matching has\\napplications in a variety of fields, from computer vision to computational\\nbiology. In graph matching, patterns are modeled as graphs and pattern\\nrecognition amounts to finding a correspondence between the nodes of different\\ngraphs. Many formulations of this problem can be cast in general as a quadratic\\nassignment problem, where a linear term in the objective function encodes node\\ncompatibility and a quadratic term encodes edge compatibility. The main\\nresearch focus in this theme is about designing efficient algorithms for\\napproximately solving the quadratic assignment problem, since it is NP-hard. In\\nthis paper we turn our attention to a different question: how to estimate\\ncompatibility functions such that the solution of the resulting graph matching\\nproblem best matches the expected solution that a human would manually provide.\\nWe present a method for learning graph matching: the training examples are\\npairs of graphs and the `labels' are matches between them. Our experimental\\nresults reveal that learning can substantially improve the performance of\\nstandard graph matching algorithms. In particular, we find that simple linear\\nassignment with such a learning scheme outperforms Graduated Assignment with\\nbistochastic normalisation, a state-of-the-art quadratic assignment relaxation\\nalgorithm.\\n\",\n",
              " '  Statistical learning theory chiefly studies restricted hypothesis classes,\\nparticularly those with finite Vapnik-Chervonenkis (VC) dimension. The\\nfundamental quantity of interest is the sample complexity: the number of\\nsamples required to learn to a specified level of accuracy. Here we consider\\nlearning over the set of all computable labeling functions. Since the\\nVC-dimension is infinite and a priori (uniform) bounds on the number of samples\\nare impossible, we let the learning algorithm decide when it has seen\\nsufficient samples to have learned. We first show that learning in this setting\\nis indeed possible, and develop a learning algorithm. We then show, however,\\nthat bounding sample complexity independently of the distribution is\\nimpossible. Notably, this impossibility is entirely due to the requirement that\\nthe learning algorithm be computable, and not due to the statistical nature of\\nthe problem.\\n',\n",
              " '  We prove that the class of functions g:{-1,+1}^n -> {-1,+1} that only depend\\non an unknown subset of k<<n variables (so-called k-juntas) is agnostically\\nlearnable from a random walk in time polynomial in n, 2^{k^2}, epsilon^{-k},\\nand log(1/delta). In other words, there is an algorithm with the claimed\\nrunning time that, given epsilon, delta > 0 and access to a random walk on\\n{-1,+1}^n labeled by an arbitrary function f:{-1,+1}^n -> {-1,+1}, finds with\\nprobability at least 1-delta a k-junta that is (opt(f)+epsilon)-close to f,\\nwhere opt(f) denotes the distance of a closest k-junta to f.\\n',\n",
              " \"  The remarkable results of Foster and Vohra was a starting point for a series\\nof papers which show that any sequence of outcomes can be learned (with no\\nprior knowledge) using some universal randomized forecasting algorithm and\\nforecast-dependent checking rules. We show that for the class of all\\ncomputationally efficient outcome-forecast-based checking rules, this property\\nis violated. Moreover, we present a probabilistic algorithm generating with\\nprobability close to one a sequence with a subsequence which simultaneously\\nmiscalibrates all partially weakly computable randomized forecasting\\nalgorithms. %subsequences non-learnable by each randomized algorithm.\\n  According to the Dawid's prequential framework we consider partial recursive\\nrandomized algorithms.\\n\",\n",
              " \"  The games of prediction with expert advice are considered in this paper. We\\npresent some modification of Kalai and Vempala algorithm of following the\\nperturbed leader for the case of unrestrictedly large one-step gains. We show\\nthat in general case the cumulative gain of any probabilistic prediction\\nalgorithm can be much worse than the gain of some expert of the pool.\\nNevertheless, we give the lower bound for this cumulative gain in general case\\nand construct a universal algorithm which has the optimal performance; we also\\nprove that in case when one-step gains of experts of the pool have ``limited\\ndeviations'' the performance of our algorithm is close to the performance of\\nthe best expert.\\n\",\n",
              " '  The method of stable random projections is a tool for efficiently computing\\nthe $l_\\\\alpha$ distances using low memory, where $0<\\\\alpha \\\\leq 2$ is a tuning\\nparameter. The method boils down to a statistical estimation task and various\\nestimators have been proposed, based on the geometric mean, the harmonic mean,\\nand the fractional power etc.\\n  This study proposes the optimal quantile estimator, whose main operation is\\nselecting, which is considerably less expensive than taking fractional power,\\nthe main operation in previous estimators. Our experiments report that the\\noptimal quantile estimator is nearly one order of magnitude more\\ncomputationally efficient than previous estimators. For large-scale learning\\ntasks in which storing and computing pairwise distances is a serious\\nbottleneck, this estimator should be desirable.\\n  In addition to its computational advantages, the optimal quantile estimator\\nexhibits nice theoretical properties. It is more accurate than previous\\nestimators when $\\\\alpha>1$. We derive its theoretical error bounds and\\nestablish the explicit (i.e., no hidden constants) sample complexity bound.\\n',\n",
              " \"  Applications in machine learning and data mining require computing pairwise\\nLp distances in a data matrix A. For massive high-dimensional data, computing\\nall pairwise distances of A can be infeasible. In fact, even storing A or all\\npairwise distances of A in the memory may be also infeasible. This paper\\nproposes a simple method for p = 2, 4, 6, ... We first decompose the l_p (where\\np is even) distances into a sum of 2 marginal norms and p-1 ``inner products''\\nat different orders. Then we apply normal or sub-Gaussian random projections to\\napproximate the resultant ``inner products,'' assuming that the marginal norms\\ncan be computed exactly by a linear scan. We propose two strategies for\\napplying random projections. The basic projection strategy requires only one\\nprojection matrix but it is more difficult to analyze, while the alternative\\nprojection strategy requires p-1 projection matrices but its theoretical\\nanalysis is much easier. In terms of the accuracy, at least for p=4, the basic\\nstrategy is always more accurate than the alternative strategy if the data are\\nnon-negative, which is common in reality.\\n\",\n",
              " \"  We study the empirical meaning of randomness with respect to a family of\\nprobability distributions $P_\\\\theta$, where $\\\\theta$ is a real parameter, using\\nalgorithmic randomness theory. In the case when for a computable probability\\ndistribution $P_\\\\theta$ an effectively strongly consistent estimate exists, we\\nshow that the Levin's a priory semicomputable semimeasure of the set of all\\n$P_\\\\theta$-random sequences is positive if and only if the parameter $\\\\theta$\\nis a computable real number. The different methods for generating\\n``meaningful'' $P_\\\\theta$-random sequences with noncomputable $\\\\theta$ are\\ndiscussed.\\n\",\n",
              " '  We propose a general method called truncated gradient to induce sparsity in\\nthe weights of online learning algorithms with convex loss functions. This\\nmethod has several essential properties: The degree of sparsity is continuous\\n-- a parameter controls the rate of sparsification from no sparsification to\\ntotal sparsification. The approach is theoretically motivated, and an instance\\nof it can be regarded as an online counterpart of the popular\\n$L_1$-regularization method in the batch setting. We prove that small rates of\\nsparsification result in only small additional regret with respect to typical\\nonline learning guarantees. The approach works well empirically. We apply the\\napproach to several datasets and find that for datasets with large numbers of\\nfeatures, substantial sparsity is discoverable.\\n',\n",
              " '  We present a unified framework to study graph kernels, special cases of which\\ninclude the random walk graph kernel \\\\citep{GaeFlaWro03,BorOngSchVisetal05},\\nmarginalized graph kernel \\\\citep{KasTsuIno03,KasTsuIno04,MahUedAkuPeretal04},\\nand geometric kernel on graphs \\\\citep{Gaertner02}. Through extensions of linear\\nalgebra to Reproducing Kernel Hilbert Spaces (RKHS) and reduction to a\\nSylvester equation, we construct an algorithm that improves the time complexity\\nof kernel computation from $O(n^6)$ to $O(n^3)$. When the graphs are sparse,\\nconjugate gradient solvers or fixed-point iterations bring our algorithm into\\nthe sub-cubic domain. Experiments on graphs from bioinformatics and other\\napplication domains show that it is often more than a thousand times faster\\nthan previous approaches. We then explore connections between diffusion kernels\\n\\\\citep{KonLaf02}, regularization on graphs \\\\citep{SmoKon03}, and graph kernels,\\nand use these connections to propose new graph kernels. Finally, we show that\\nrational kernels \\\\citep{CorHafMoh02,CorHafMoh03,CorHafMoh04} when specialized\\nto graphs reduce to the random walk graph kernel.\\n',\n",
              " '  Bayesian model averaging, model selection and its approximations such as BIC\\nare generally statistically consistent, but sometimes achieve slower rates og\\nconvergence than other methods such as AIC and leave-one-out cross-validation.\\nOn the other hand, these other methods can br inconsistent. We identify the\\n\"catch-up phenomenon\" as a novel explanation for the slow convergence of\\nBayesian methods. Based on this analysis we define the switch distribution, a\\nmodification of the Bayesian marginal distribution. We show that, under broad\\nconditions,model selection and prediction based on the switch distribution is\\nboth consistent and achieves optimal convergence rates, thereby resolving the\\nAIC-BIC dilemma. The method is practical; we give an efficient implementation.\\nThe switch distribution has a data compression interpretation, and can thus be\\nviewed as a \"prequential\" or MDL method; yet it is different from the MDL\\nmethods that are usually considered in the literature. We compare the switch\\ndistribution to Bayes factor model selection and leave-one-out\\ncross-validation.\\n',\n",
              " '  Algorithm selection is typically based on models of algorithm performance,\\nlearned during a separate offline training sequence, which can be prohibitively\\nexpensive. In recent work, we adopted an online approach, in which a\\nperformance model is iteratively updated and used to guide selection on a\\nsequence of problem instances. The resulting exploration-exploitation trade-off\\nwas represented as a bandit problem with expert advice, using an existing\\nsolver for this game, but this required the setting of an arbitrary bound on\\nalgorithm runtimes, thus invalidating the optimal regret of the solver. In this\\npaper, we propose a simpler framework for representing algorithm selection as a\\nbandit problem, with partial information, and an unknown bound on losses. We\\nadapt an existing solver to this game, proving a bound on its expected regret,\\nwhich holds also for the resulting algorithm selection technique. We present\\npreliminary experiments with a set of SAT solvers on a mixed SAT-UNSAT\\nbenchmark.\\n',\n",
              " '  Multi-instance learning attempts to learn from a training set consisting of\\nlabeled bags each containing many unlabeled instances. Previous studies\\ntypically treat the instances in the bags as independently and identically\\ndistributed. However, the instances in a bag are rarely independent, and\\ntherefore a better performance can be expected if the instances are treated in\\nan non-i.i.d. way that exploits the relations among instances. In this paper,\\nwe propose a simple yet effective multi-instance learning method, which regards\\neach bag as a graph and uses a specific kernel to distinguish the graphs by\\nconsidering the features of the nodes as well as the features of the edges that\\nconvey some relations among instances. The effectiveness of the proposed method\\nis validated by experiments.\\n',\n",
              " '  We study the problem of dynamic spectrum sensing and access in cognitive\\nradio systems as a partially observed Markov decision process (POMDP). A group\\nof cognitive users cooperatively tries to exploit vacancies in primary\\n(licensed) channels whose occupancies follow a Markovian evolution. We first\\nconsider the scenario where the cognitive users have perfect knowledge of the\\ndistribution of the signals they receive from the primary users. For this\\nproblem, we obtain a greedy channel selection and access policy that maximizes\\nthe instantaneous reward, while satisfying a constraint on the probability of\\ninterfering with licensed transmissions. We also derive an analytical universal\\nupper bound on the performance of the optimal policy. Through simulation, we\\nshow that our scheme achieves good performance relative to the upper bound and\\nimproved performance relative to an existing scheme.\\n  We then consider the more practical scenario where the exact distribution of\\nthe signal from the primary is unknown. We assume a parametric model for the\\ndistribution and develop an algorithm that can learn the true distribution,\\nstill guaranteeing the constraint on the interference probability. We show that\\nthis algorithm outperforms the naive design that assumes a worst case value for\\nthe parameter. We also provide a proof for the convergence of the learning\\nalgorithm.\\n',\n",
              " '  We study probability distributions over free algebras of trees. Probability\\ndistributions can be seen as particular (formal power) tree series [Berstel et\\nal 82, Esik et al 03], i.e. mappings from trees to a semiring K . A widely\\nstudied class of tree series is the class of rational (or recognizable) tree\\nseries which can be defined either in an algebraic way or by means of\\nmultiplicity tree automata. We argue that the algebraic representation is very\\nconvenient to model probability distributions over a free algebra of trees.\\nFirst, as in the string case, the algebraic representation allows to design\\nlearning algorithms for the whole class of probability distributions defined by\\nrational tree series. Note that learning algorithms for rational tree series\\ncorrespond to learning algorithms for weighted tree automata where both the\\nstructure and the weights are learned. Second, the algebraic representation can\\nbe easily extended to deal with unranked trees (like XML trees where a symbol\\nmay have an unbounded number of children). Both properties are particularly\\nrelevant for applications: nondeterministic automata are required for the\\ninference problem to be relevant (recall that Hidden Markov Models are\\nequivalent to nondeterministic string automata); nowadays applications for Web\\nInformation Extraction, Web Services and document processing consider unranked\\ntrees.\\n',\n",
              " \"  We consider the problem of reconstructing a discrete-time signal (sequence)\\nwith continuous-valued components corrupted by a known memoryless channel. When\\nperformance is measured using a per-symbol loss function satisfying mild\\nregularity conditions, we develop a sequence of denoisers that, although\\nindependent of the distribution of the underlying `clean' sequence, is\\nuniversally optimal in the limit of large sequence length. This sequence of\\ndenoisers is universal in the sense of performing as well as any sliding window\\ndenoising scheme which may be optimized for the underlying clean signal. Our\\nresults are initially developed in a ``semi-stochastic'' setting, where the\\nnoiseless signal is an unknown individual sequence, and the only source of\\nrandomness is due to the channel noise. It is subsequently shown that in the\\nfully stochastic setting, where the noiseless sequence is a stationary\\nstochastic process, our schemes universally attain optimum performance. The\\nproposed schemes draw from nonparametric density estimation techniques and are\\npractically implementable. We demonstrate efficacy of the proposed schemes in\\ndenoising gray-scale images in the conventional additive white Gaussian noise\\nsetting, with additional promising results for less conventional noise\\ndistributions.\\n\",\n",
              " '  We present a novel graphical framework for modeling non-negative sequential\\ndata with hierarchical structure. Our model corresponds to a network of coupled\\nnon-negative matrix factorization (NMF) modules, which we refer to as a\\npositive factor network (PFN). The data model is linear, subject to\\nnon-negativity constraints, so that observation data consisting of an additive\\ncombination of individually representable observations is also representable by\\nthe network. This is a desirable property for modeling problems in\\ncomputational auditory scene analysis, since distinct sound sources in the\\nenvironment are often well-modeled as combining additively in the corresponding\\nmagnitude spectrogram. We propose inference and learning algorithms that\\nleverage existing NMF algorithms and that are straightforward to implement. We\\npresent a target tracking example and provide results for synthetic observation\\ndata which serve to illustrate the interesting properties of PFNs and motivate\\ntheir potential usefulness in applications such as music transcription, source\\nseparation, and speech recognition. We show how a target process characterized\\nby a hierarchical state transition model can be represented as a PFN. Our\\nresults illustrate that a PFN which is defined in terms of a single target\\nobservation can then be used to effectively track the states of multiple\\nsimultaneous targets. Our results show that the quality of the inferred target\\nstates degrades gradually as the observation noise is increased. We also\\npresent results for an example in which meaningful hierarchical features are\\nextracted from a spectrogram. Such a hierarchical representation could be\\nuseful for music transcription and source separation applications. We also\\npropose a network for language modeling.\\n',\n",
              " '  We prove that mutual information is actually negative copula entropy, based\\non which a method for mutual information estimation is proposed.\\n',\n",
              " '  In many fields where human understanding plays a crucial role, such as\\nbioprocesses, the capacity of extracting knowledge from data is of critical\\nimportance. Within this framework, fuzzy learning methods, if properly used,\\ncan greatly help human experts. Amongst these methods, the aim of orthogonal\\ntransformations, which have been proven to be mathematically robust, is to\\nbuild rules from a set of training data and to select the most important ones\\nby linear regression or rank revealing techniques. The OLS algorithm is a good\\nrepresentative of those methods. However, it was originally designed so that it\\nonly cared about numerical performance. Thus, we propose some modifications of\\nthe original method to take interpretability into account. After recalling the\\noriginal algorithm, this paper presents the changes made to the original\\nmethod, then discusses some results obtained from benchmark problems. Finally,\\nthe algorithm is applied to a real-world fault detection depollution problem.\\n',\n",
              " '  In this paper, we propose the MIML (Multi-Instance Multi-Label learning)\\nframework where an example is described by multiple instances and associated\\nwith multiple class labels. Compared to traditional learning frameworks, the\\nMIML framework is more convenient and natural for representing complicated\\nobjects which have multiple semantic meanings. To learn from MIML examples, we\\npropose the MimlBoost and MimlSvm algorithms based on a simple degeneration\\nstrategy, and experiments show that solving problems involving complicated\\nobjects with multiple semantic meanings in the MIML framework can lead to good\\nperformance. Considering that the degeneration process may lose information, we\\npropose the D-MimlSvm algorithm which tackles MIML problems directly in a\\nregularization framework. Moreover, we show that even when we do not have\\naccess to the real objects and thus cannot capture more information from real\\nobjects by using the MIML representation, MIML is still useful. We propose the\\nInsDif and SubCod algorithms. InsDif works by transforming single-instances\\ninto the MIML representation for learning, while SubCod works by transforming\\nsingle-label examples into the MIML representation for learning. Experiments\\nshow that in some tasks they are able to achieve better performance than\\nlearning the single-instances or single-label examples directly.\\n',\n",
              " \"  Using the game-theoretic framework for probability, Vovk and Shafer. have\\nshown that it is always possible, using randomization, to make sequential\\nprobability forecasts that pass any countable set of well-behaved statistical\\ntests. This result generalizes work by other authors, who consider only tests\\nof calbration.\\n  We complement this result with a lower bound. We show that Vovk and Shafer's\\nresult is valid only when the forecasts are computed with unrestrictedly\\nincreasing degree of accuracy.\\n  When some level of discreteness is fixed, we present a game-theoretic\\ngeneralization of Oakes' example for randomized forecasting that is a test\\nfailing any given method of deferministic forecasting; originally, this example\\nwas presented for deterministic calibration.\\n\",\n",
              " '  We propose a unified framework for deriving and studying soft-in-soft-out\\n(SISO) detection in interference channels using the concept of variational\\ninference. The proposed framework may be used in multiple-access interference\\n(MAI), inter-symbol interference (ISI), and multiple-input multiple-outpu\\n(MIMO) channels. Without loss of generality, we will focus our attention on\\nturbo multiuser detection, to facilitate a more concrete discussion. It is\\nshown that, with some loss of optimality, variational inference avoids the\\nexponential complexity of a posteriori probability (APP) detection by\\noptimizing a closely-related, but much more manageable, objective function\\ncalled variational free energy. In addition to its systematic appeal, there are\\nseveral other advantages to this viewpoint. First of all, it provides unified\\nand rigorous justifications for numerous detectors that were proposed on\\nradically different grounds, and facilitates convenient joint detection and\\ndecoding (utilizing the turbo principle) when error-control codes are\\nincorporated. Secondly, efficient joint parameter estimation and data detection\\nis possible via the variational expectation maximization (EM) algorithm, such\\nthat the detrimental effect of inaccurate channel knowledge at the receiver may\\nbe dealt with systematically. We are also able to extend BPSK-based SISO\\ndetection schemes to arbitrary square QAM constellations in a rigorous manner\\nusing a variational argument.\\n',\n",
              " '  Recognizing analogies, synonyms, antonyms, and associations appear to be four\\ndistinct tasks, requiring distinct NLP algorithms. In the past, the four tasks\\nhave been treated independently, using a wide variety of algorithms. These four\\nsemantic classes, however, are a tiny sample of the full range of semantic\\nphenomena, and we cannot afford to create ad hoc algorithms for each semantic\\nphenomenon; we need to seek a unified approach. We propose to subsume a broad\\nrange of phenomena under analogies. To limit the scope of this paper, we\\nrestrict our attention to the subsumption of synonyms, antonyms, and\\nassociations. We introduce a supervised corpus-based machine learning algorithm\\nfor classifying analogous word pairs, and we show that it can solve\\nmultiple-choice SAT analogy questions, TOEFL synonym questions, ESL\\nsynonym-antonym questions, and similar-associated-both questions from cognitive\\npsychology.\\n',\n",
              " '  Quantum classification is defined as the task of predicting the associated\\nclass of an unknown quantum state drawn from an ensemble of pure states given a\\nfinite number of copies of this state. By recasting the state discrimination\\nproblem within the framework of Machine Learning (ML), we can use the notion of\\nlearning reduction coming from classical ML to solve different variants of the\\nclassification task, such as the weighted binary and the multiclass versions.\\n',\n",
              " \"  In many physical, statistical, biological and other investigations it is\\ndesirable to approximate a system of points by objects of lower dimension\\nand/or complexity. For this purpose, Karl Pearson invented principal component\\nanalysis in 1901 and found 'lines and planes of closest fit to system of\\npoints'. The famous k-means algorithm solves the approximation problem too, but\\nby finite sets instead of lines and planes. This chapter gives a brief\\npractical introduction into the methods of construction of general principal\\nobjects, i.e. objects embedded in the 'middle' of the multidimensional data\\nset. As a basis, the unifying framework of mean squared distance approximation\\nof finite datasets is selected. Principal graphs and manifolds are constructed\\nas generalisations of principal components and k-means principal points. For\\nthis purpose, the family of expectation/maximisation algorithms with nearest\\ngeneralisations is presented. Construction of principal graphs with controlled\\ncomplexity is based on the graph grammar approach.\\n\",\n",
              " \"  We give a characterization of Maximum Entropy/Minimum Relative Entropy\\ninference by providing two `strong entropy concentration' theorems. These\\ntheorems unify and generalize Jaynes' `concentration phenomenon' and Van\\nCampenhout and Cover's `conditional limit theorem'. The theorems characterize\\nexactly in what sense a prior distribution Q conditioned on a given constraint,\\nand the distribution P, minimizing the relative entropy D(P ||Q) over all\\ndistributions satisfying the constraint, are `close' to each other. We then\\napply our theorems to establish the relationship between entropy concentration\\nand a game-theoretic characterization of Maximum Entropy Inference due to\\nTopsoe and others.\\n\",\n",
              " '  In this paper, we have established a unified framework of multistage\\nparameter estimation. We demonstrate that a wide variety of statistical\\nproblems such as fixed-sample-size interval estimation, point estimation with\\nerror control, bounded-width confidence intervals, interval estimation\\nfollowing hypothesis testing, construction of confidence sequences, can be cast\\ninto the general framework of constructing sequential random intervals with\\nprescribed coverage probabilities. We have developed exact methods for the\\nconstruction of such sequential random intervals in the context of multistage\\nsampling. In particular, we have established inclusion principle and coverage\\ntuning techniques to control and adjust the coverage probabilities of\\nsequential random intervals. We have obtained concrete sampling schemes which\\nare unprecedentedly efficient in terms of sampling effort as compared to\\nexisting procedures.\\n',\n",
              " '  While statistics focusses on hypothesis testing and on estimating (properties\\nof) the true sampling distribution, in machine learning the performance of\\nlearning algorithms on future data is the primary issue. In this paper we\\nbridge the gap with a general principle (PHI) that identifies hypotheses with\\nbest predictive performance. This includes predictive point and interval\\nestimation, simple and composite hypothesis testing, (mixture) model selection,\\nand others as special cases. For concrete instantiations we will recover\\nwell-known methods, variations thereof, and new ones. PHI nicely justifies,\\nreconciles, and blends (a reparametrization invariant variation of) MAP, ML,\\nMDL, and moment estimation. One particular feature of PHI is that it can\\ngenuinely deal with nested hypotheses.\\n',\n",
              " '  For supervised and unsupervised learning, positive definite kernels allow to\\nuse large and potentially infinite dimensional feature spaces with a\\ncomputational cost that only depends on the number of observations. This is\\nusually done through the penalization of predictor functions by Euclidean or\\nHilbertian norms. In this paper, we explore penalizing by sparsity-inducing\\nnorms such as the l1-norm or the block l1-norm. We assume that the kernel\\ndecomposes into a large sum of individual basis kernels which can be embedded\\nin a directed acyclic graph; we show that it is then possible to perform kernel\\nselection through a hierarchical multiple kernel learning framework, in\\npolynomial time in the number of selected kernels. This framework is naturally\\napplied to non linear variable selection; our extensive simulations on\\nsynthetic datasets and datasets from the UCI repository show that efficiently\\nexploring the large feature space through sparsity-inducing norms leads to\\nstate-of-the-art predictive performance.\\n',\n",
              " '  We consider a general class of regularization methods which learn a vector of\\nparameters on the basis of linear measurements. It is well known that if the\\nregularizer is a nondecreasing function of the inner product then the learned\\nvector is a linear combination of the input data. This result, known as the\\n{\\\\em representer theorem}, is at the basis of kernel-based methods in machine\\nlearning. In this paper, we prove the necessity of the above condition, thereby\\ncompleting the characterization of kernel methods based on regularization. We\\nfurther extend our analysis to regularization methods which learn a matrix, a\\nproblem which is motivated by the application to multi-task learning. In this\\ncontext, we study a more general representer theorem, which holds for a larger\\nclass of regularizers. We provide a necessary and sufficient condition for\\nthese class of matrix regularizers and highlight them with some concrete\\nexamples of practical importance. Our analysis uses basic principles from\\nmatrix theory, especially the useful notion of matrix nondecreasing function.\\n',\n",
              " '  In this paper, we show a connection between a certain online low-congestion\\nrouting problem and an online prediction of graph labeling. More specifically,\\nwe prove that if there exists a routing scheme that guarantees a congestion of\\n$\\\\alpha$ on any edge, there exists an online prediction algorithm with mistake\\nbound $\\\\alpha$ times the cut size, which is the size of the cut induced by the\\nlabel partitioning of graph vertices. With previous known bound of $O(\\\\log n)$\\nfor $\\\\alpha$ for the routing problem on trees with $n$ vertices, we obtain an\\nimproved prediction algorithm for graphs with high effective resistance.\\n  In contrast to previous approaches that move the graph problem into problems\\nin vector space using graph Laplacian and rely on the analysis of the\\nperceptron algorithm, our proof are purely combinatorial. Further more, our\\napproach directly generalizes to the case where labels are not binary.\\n',\n",
              " '  In multi-task learning several related tasks are considered simultaneously,\\nwith the hope that by an appropriate sharing of information across tasks, each\\ntask may benefit from the others. In the context of learning linear functions\\nfor supervised classification or regression, this can be achieved by including\\na priori information about the weight vectors associated with the tasks, and\\nhow they are expected to be related to each other. In this paper, we assume\\nthat tasks are clustered into groups, which are unknown beforehand, and that\\ntasks within a group have similar weight vectors. We design a new spectral norm\\nthat encodes this a priori assumption, without the prior knowledge of the\\npartition of tasks into groups, resulting in a new convex optimization\\nformulation for multi-task learning. We show in simulations on synthetic\\nexamples and on the IEDB MHC-I binding dataset, that our approach outperforms\\nwell-known convex methods for multi-task learning, as well as related non\\nconvex methods dedicated to the same problem.\\n',\n",
              " \"  We introduce algorithmic information theory, also known as the theory of\\nKolmogorov complexity. We explain the main concepts of this quantitative\\napproach to defining `information'. We discuss the extent to which Kolmogorov's\\nand Shannon's information theory have a common purpose, and where they are\\nfundamentally different. We indicate how recent developments within the theory\\nallow one to formally distinguish between `structural' (meaningful) and\\n`random' information as measured by the Kolmogorov structure function, which\\nleads to a mathematical formalization of Occam's razor in inductive inference.\\nWe end by discussing some of the philosophical implications of the theory.\\n\",\n",
              " '  We show how text from news articles can be used to predict intraday price\\nmovements of financial assets using support vector machines. Multiple kernel\\nlearning is used to combine equity returns with text as predictive features to\\nincrease classification performance and we develop an analytic center cutting\\nplane method to solve the kernel learning problem efficiently. We observe that\\nwhile the direction of returns is not predictable using either text or returns,\\ntheir size is, with text features producing significantly better performance\\nthan historical returns alone.\\n',\n",
              " '  In this paper, we have established a general framework of multistage\\nhypothesis tests which applies to arbitrarily many mutually exclusive and\\nexhaustive composite hypotheses. Within the new framework, we have constructed\\nspecific multistage tests which rigorously control the risk of committing\\ndecision errors and are more efficient than previous tests in terms of average\\nsample number and the number of sampling operations. Without truncation, the\\nsample numbers of our testing plans are absolutely bounded.\\n',\n",
              " '  This paper generalizes the traditional statistical concept of prediction\\nintervals for arbitrary probability density functions in high-dimensional\\nfeature spaces by introducing significance level distributions, which provides\\ninterval-independent probabilities for continuous random variables. The\\nadvantage of the transformation of a probability density function into a\\nsignificance level distribution is that it enables one-class classification or\\noutlier detection in a direct manner.\\n',\n",
              " '  Models for near-rigid shape matching are typically based on distance-related\\nfeatures, in order to infer matches that are consistent with the isometric\\nassumption. However, real shapes from image datasets, even when expected to be\\nrelated by \"almost isometric\" transformations, are actually subject not only to\\nnoise but also, to some limited degree, to variations in appearance and scale.\\nIn this paper, we introduce a graphical model that parameterises appearance,\\ndistance, and angle features and we learn all of the involved parameters via\\nstructured prediction. The outcome is a model for near-rigid shape matching\\nwhich is robust in the sense that it is able to capture the possibly limited\\nbut still important scale and appearance variations. Our experimental results\\nreveal substantial improvements upon recent successful models, while\\nmaintaining similar running times.\\n',\n",
              " '  The Baum-Welsh algorithm together with its derivatives and variations has\\nbeen the main technique for learning Hidden Markov Models (HMM) from\\nobservational data. We present an HMM learning algorithm based on the\\nnon-negative matrix factorization (NMF) of higher order Markovian statistics\\nthat is structurally different from the Baum-Welsh and its associated\\napproaches. The described algorithm supports estimation of the number of\\nrecurrent states of an HMM and iterates the non-negative matrix factorization\\n(NMF) algorithm to improve the learned HMM parameters. Numerical examples are\\nprovided as well.\\n',\n",
              " '  We consider the task of learning a classifier from the feature space\\n$\\\\mathcal{X}$ to the set of classes $\\\\mathcal{Y} = \\\\{0, 1\\\\}$, when the features\\ncan be partitioned into class-conditionally independent feature sets\\n$\\\\mathcal{X}_1$ and $\\\\mathcal{X}_2$. We show the surprising fact that the\\nclass-conditional independence can be used to represent the original learning\\ntask in terms of 1) learning a classifier from $\\\\mathcal{X}_2$ to\\n$\\\\mathcal{X}_1$ and 2) learning the class-conditional distribution of the\\nfeature set $\\\\mathcal{X}_1$. This fact can be exploited for semi-supervised\\nlearning because the former task can be accomplished purely from unlabeled\\nsamples. We present experimental evaluation of the idea in two real world\\napplications.\\n',\n",
              " '  In a multi-armed bandit problem, an online algorithm chooses from a set of\\nstrategies in a sequence of trials so as to maximize the total payoff of the\\nchosen strategies. While the performance of bandit algorithms with a small\\nfinite strategy set is quite well understood, bandit problems with large\\nstrategy sets are still a topic of very active investigation, motivated by\\npractical applications such as online auctions and web advertisement. The goal\\nof such research is to identify broad and natural classes of strategy sets and\\npayoff functions which enable the design of efficient solutions. In this work\\nwe study a very general setting for the multi-armed bandit problem in which the\\nstrategies form a metric space, and the payoff function satisfies a Lipschitz\\ncondition with respect to the metric. We refer to this problem as the\\n\"Lipschitz MAB problem\". We present a complete solution for the multi-armed\\nproblem in this setting. That is, for every metric space (L,X) we define an\\nisometry invariant which bounds from below the performance of Lipschitz MAB\\nalgorithms for X, and we present an algorithm which comes arbitrarily close to\\nmeeting this bound. Furthermore, our technique gives even better results for\\nbenign payoff functions.\\n',\n",
              " '  In this paper we present a linear programming solution for sign pattern\\nrecovery of a sparse signal from noisy random projections of the signal. We\\nconsider two types of noise models, input noise, where noise enters before the\\nrandom projection; and output noise, where noise enters after the random\\nprojection. Sign pattern recovery involves the estimation of sign pattern of a\\nsparse signal. Our idea is to pretend that no noise exists and solve the\\nnoiseless $\\\\ell_1$ problem, namely, $\\\\min \\\\|\\\\beta\\\\|_1 ~ s.t. ~ y=G \\\\beta$ and\\nquantizing the resulting solution. We show that the quantized solution\\nperfectly reconstructs the sign pattern of a sufficiently sparse signal.\\nSpecifically, we show that the sign pattern of an arbitrary k-sparse,\\nn-dimensional signal $x$ can be recovered with $SNR=\\\\Omega(\\\\log n)$ and\\nmeasurements scaling as $m= \\\\Omega(k \\\\log{n/k})$ for all sparsity levels $k$\\nsatisfying $0< k \\\\leq \\\\alpha n$, where $\\\\alpha$ is a sufficiently small\\npositive constant. Surprisingly, this bound matches the optimal\\n\\\\emph{Max-Likelihood} performance bounds in terms of $SNR$, required number of\\nmeasurements, and admissible sparsity level in an order-wise sense. In contrast\\nto our results, previous results based on LASSO and Max-Correlation techniques\\neither assume significantly larger $SNR$, sublinear sparsity levels or\\nrestrictive assumptions on signal sets. Our proof technique is based on noisy\\nperturbation of the noiseless $\\\\ell_1$ problem, in that, we estimate the\\nmaximum admissible noise level before sign pattern recovery fails.\\n',\n",
              " '  In this paper, we examine the CE method in the broad context of Monte Carlo\\nOptimization (MCO) and Parametric Learning (PL), a type of machine learning. A\\nwell-known overarching principle used to improve the performance of many PL\\nalgorithms is the bias-variance tradeoff. This tradeoff has been used to\\nimprove PL algorithms ranging from Monte Carlo estimation of integrals, to\\nlinear estimation, to general statistical estimation. Moreover, as described\\nby, MCO is very closely related to PL. Owing to this similarity, the\\nbias-variance tradeoff affects MCO performance, just as it does PL performance.\\n  In this article, we exploit the bias-variance tradeoff to enhance the\\nperformance of MCO algorithms. We use the technique of cross-validation, a\\ntechnique based on the bias-variance tradeoff, to significantly improve the\\nperformance of the Cross Entropy (CE) method, which is an MCO algorithm. In\\nprevious work we have confirmed that other PL techniques improve the perfomance\\nof other MCO algorithms. We conclude that the many techniques pioneered in PL\\ncould be investigated as ways to improve MCO algorithms in general, and the CE\\nmethod in particular.\\n',\n",
              " '  We consider the design of cognitive Medium Access Control (MAC) protocols\\nenabling an unlicensed (secondary) transmitter-receiver pair to communicate\\nover the idle periods of a set of licensed channels, i.e., the primary network.\\nThe objective is to maximize data throughput while maintaining the\\nsynchronization between secondary users and avoiding interference with licensed\\n(primary) users. No statistical information about the primary traffic is\\nassumed to be available a-priori to the secondary user. We investigate two\\ndistinct sensing scenarios. In the first, the secondary transmitter is capable\\nof sensing all the primary channels, whereas it senses one channel only in the\\nsecond scenario. In both cases, we propose MAC protocols that efficiently learn\\nthe statistics of the primary traffic online. Our simulation results\\ndemonstrate that the proposed blind protocols asymptotically achieve the\\nthroughput obtained when prior knowledge of primary traffic statistics is\\navailable.\\n',\n",
              " '  Support vector machines (SVMs) are an extremely successful type of\\nclassification and regression algorithms. Building an SVM entails solving a\\nconstrained convex quadratic programming problem, which is quadratic in the\\nnumber of training samples. We introduce an efficient parallel implementation\\nof an support vector regression solver, based on the Gaussian Belief\\nPropagation algorithm (GaBP).\\n  In this paper, we demonstrate that methods from the complex system domain\\ncould be utilized for performing efficient distributed computation. We compare\\nthe proposed algorithm to previously proposed distributed and single-node SVM\\nsolvers. Our comparison shows that the proposed algorithm is just as accurate\\nas these solvers, while being significantly faster, especially for large\\ndatasets. We demonstrate scalability of the proposed algorithm to up to 1,024\\ncomputing nodes and hundreds of thousands of data points using an IBM Blue Gene\\nsupercomputer. As far as we know, our work is the largest parallel\\nimplementation of belief propagation ever done, demonstrating the applicability\\nof this algorithm for large scale distributed computing systems.\\n',\n",
              " '  The repeatability and efficiency of a corner detector determines how likely\\nit is to be useful in a real-world application. The repeatability is importand\\nbecause the same scene viewed from different positions should yield features\\nwhich correspond to the same real-world 3D locations [Schmid et al 2000]. The\\nefficiency is important because this determines whether the detector combined\\nwith further processing can operate at frame rate.\\n  Three advances are described in this paper. First, we present a new heuristic\\nfor feature detection, and using machine learning we derive a feature detector\\nfrom this which can fully process live PAL video using less than 5% of the\\navailable processing time. By comparison, most other detectors cannot even\\noperate at frame rate (Harris detector 115%, SIFT 195%). Second, we generalize\\nthe detector, allowing it to be optimized for repeatability, with little loss\\nof efficiency. Third, we carry out a rigorous comparison of corner detectors\\nbased on the above repeatability criterion applied to 3D scenes. We show that\\ndespite being principally constructed for speed, on these stringent tests, our\\nheuristic detector significantly outperforms existing feature detectors.\\nFinally, the comparison demonstrates that using machine learning produces\\nsignificant improvements in repeatability, yielding a detector that is both\\nvery fast and very high quality.\\n',\n",
              " '  The LETOR website contains three information retrieval datasets used as a\\nbenchmark for testing machine learning ideas for ranking. Algorithms\\nparticipating in the challenge are required to assign score values to search\\nresults for a collection of queries, and are measured using standard IR ranking\\nmeasures (NDCG, precision, MAP) that depend only the relative score-induced\\norder of the results. Similarly to many of the ideas proposed in the\\nparticipating algorithms, we train a linear classifier. In contrast with other\\nparticipating algorithms, we define an additional free variable (intercept, or\\nbenchmark) for each query. This allows expressing the fact that results for\\ndifferent queries are incomparable for the purpose of determining relevance.\\nThe cost of this idea is the addition of relatively few nuisance parameters.\\nOur approach is simple, and we used a standard logistic regression library to\\ntest it. The results beat the reported participating algorithms. Hence, it\\nseems promising to combine our approach with other more complex ideas.\\n',\n",
              " '  The exploration-exploitation dilemma has been an intriguing and unsolved\\nproblem within the framework of reinforcement learning. \"Optimism in the face\\nof uncertainty\" and model building play central roles in advanced exploration\\nmethods. Here, we integrate several concepts and obtain a fast and simple\\nalgorithm. We show that the proposed algorithm finds a near-optimal policy in\\npolynomial time, and give experimental evidence that it is robust and efficient\\ncompared to its ascendants.\\n',\n",
              " '  In this paper entropy based methods are compared and used to measure\\nstructural diversity of an ensemble of 21 classifiers. This measure is mostly\\napplied in ecology, whereby species counts are used as a measure of diversity.\\nThe measures used were Shannon entropy, Simpsons and the Berger Parker\\ndiversity indexes. As the diversity indexes increased so did the accuracy of\\nthe ensemble. An ensemble dominated by classifiers with the same structure\\nproduced poor accuracy. Uncertainty rule from information theory was also used\\nto further define diversity. Genetic algorithms were used to find the optimal\\nensemble by using the diversity indices as the cost function. The method of\\nvoting was used to aggregate the decisions.\\n',\n",
              " '  This paper proposes a method to construct an adaptive agent that is universal\\nwith respect to a given class of experts, where each expert is an agent that\\nhas been designed specifically for a particular environment. This adaptive\\ncontrol problem is formalized as the problem of minimizing the relative entropy\\nof the adaptive agent from the expert that is most suitable for the unknown\\nenvironment. If the agent is a passive observer, then the optimal solution is\\nthe well-known Bayesian predictor. However, if the agent is active, then its\\npast actions need to be treated as causal interventions on the I/O stream\\nrather than normal probability conditions. Here it is shown that the solution\\nto this new variational problem is given by a stochastic controller called the\\nBayesian control rule, which implements adaptive behavior as a mixture of\\nexperts. Furthermore, it is shown that under mild assumptions, the Bayesian\\ncontrol rule converges to the control law of the most suitable expert.\\n',\n",
              " '  The key approaches for machine learning, especially learning in unknown\\nprobabilistic environments are new representations and computation mechanisms.\\nIn this paper, a novel quantum reinforcement learning (QRL) method is proposed\\nby combining quantum theory and reinforcement learning (RL). Inspired by the\\nstate superposition principle and quantum parallelism, a framework of value\\nupdating algorithm is introduced. The state (action) in traditional RL is\\nidentified as the eigen state (eigen action) in QRL. The state (action) set can\\nbe represented with a quantum superposition state and the eigen state (eigen\\naction) can be obtained by randomly observing the simulated quantum state\\naccording to the collapse postulate of quantum measurement. The probability of\\nthe eigen action is determined by the probability amplitude, which is\\nparallelly updated according to rewards. Some related characteristics of QRL\\nsuch as convergence, optimality and balancing between exploration and\\nexploitation are also analyzed, which shows that this approach makes a good\\ntradeoff between exploration and exploitation using the probability amplitude\\nand can speed up learning through the quantum parallelism. To evaluate the\\nperformance and practicability of QRL, several simulated experiments are given\\nand the results demonstrate the effectiveness and superiority of QRL algorithm\\nfor some complex problems. The present work is also an effective exploration on\\nthe application of quantum computation to artificial intelligence.\\n',\n",
              " '  We give polynomial-time algorithms for the exact computation of lowest-energy\\n(ground) states, worst margin violators, log partition functions, and marginal\\nedge probabilities in certain binary undirected graphical models. Our approach\\nprovides an interesting alternative to the well-known graph cut paradigm in\\nthat it does not impose any submodularity constraints; instead we require\\nplanarity to establish a correspondence with perfect matchings (dimer\\ncoverings) in an expanded dual graph. We implement a unified framework while\\ndelegating complex but well-understood subproblems (planar embedding,\\nmaximum-weight perfect matching) to established algorithms for which efficient\\nimplementations are freely available. Unlike graph cut methods, we can perform\\npenalized maximum-likelihood as well as maximum-margin parameter estimation in\\nthe associated conditional random fields (CRFs), and employ marginal posterior\\nprobabilities as well as maximum a posteriori (MAP) states for prediction.\\nMaximum-margin CRF parameter estimation on image denoising and segmentation\\nproblems shows our approach to be efficient and effective. A C++ implementation\\nis available from http://nic.schraudolph.org/isinf/\\n',\n",
              " '  Maximum Variance Unfolding (MVU) and its variants have been very successful\\nin embedding data-manifolds in lower dimensional spaces, often revealing the\\ntrue intrinsic dimension. In this paper we show how to also incorporate\\nsupervised class information into an MVU-like method without breaking its\\nconvexity. We call this method the Isometric Separation Map and we show that\\nthe resulting kernel matrix can be used as a binary/multiclass Support Vector\\nMachine-like method in a semi-supervised (transductive) framework. We also show\\nthat the method always finds a kernel matrix that linearly separates the\\ntraining data exactly without projecting them in infinite dimensional spaces.\\nIn traditional SVMs we choose a kernel and hope that the data become linearly\\nseparable in the kernel space. In this paper we show how the hyperplane can be\\nchosen ad-hoc and the kernel is trained so that data are always linearly\\nseparable. Comparisons with Large Margin SVMs show comparable performance.\\n',\n",
              " '  We introduce a modified model of random walk, and then develop two novel\\nclustering algorithms based on it. In the algorithms, each data point in a\\ndataset is considered as a particle which can move at random in space according\\nto the preset rules in the modified model. Further, this data point may be also\\nviewed as a local control subsystem, in which the controller adjusts its\\ntransition probability vector in terms of the feedbacks of all data points, and\\nthen its transition direction is identified by an event-generating function.\\nFinally, the positions of all data points are updated. As they move in space,\\ndata points collect gradually and some separating parts emerge among them\\nautomatically. As a consequence, data points that belong to the same class are\\nlocated at a same position, whereas those that belong to different classes are\\naway from one another. Moreover, the experimental results have demonstrated\\nthat data points in the test datasets are clustered reasonably and efficiently,\\nand the comparison with other algorithms also provides an indication of the\\neffectiveness of the proposed algorithms.\\n',\n",
              " '  In this paper, we have established a new framework of truncated inverse\\nsampling for estimating mean values of non-negative random variables such as\\nbinomial, Poisson, hyper-geometrical, and bounded variables. We have derived\\nexplicit formulas and computational methods for designing sampling schemes to\\nensure prescribed levels of precision and confidence for point estimators.\\nMoreover, we have developed interval estimation methods.\\n',\n",
              " '  This paper presents the formulation of a combinatorial optimization problem\\nwith the following characteristics: i.the search space is the power set of a\\nfinite set structured as a Boolean lattice; ii.the cost function forms a\\nU-shaped curve when applied to any lattice chain. This formulation applies for\\nfeature selection in the context of pattern recognition. The known approaches\\nfor this problem are branch-and-bound algorithms and heuristics, that explore\\npartially the search space. Branch-and-bound algorithms are equivalent to the\\nfull search, while heuristics are not. This paper presents a branch-and-bound\\nalgorithm that differs from the others known by exploring the lattice structure\\nand the U-shaped chain curves of the search space. The main contribution of\\nthis paper is the architecture of this algorithm that is based on the\\nrepresentation and exploration of the search space by new lattice properties\\nproven here. Several experiments, with well known public data, indicate the\\nsuperiority of the proposed method to SFFS, which is a popular heuristic that\\ngives good results in very short computational time. In all experiments, the\\nproposed method got better or equal results in similar or even smaller\\ncomputational time.\\n',\n",
              " \"  We derive an equation for temporal difference learning from statistical\\nprinciples. Specifically, we start with the variational principle and then\\nbootstrap to produce an updating rule for discounted state value estimates. The\\nresulting equation is similar to the standard equation for temporal difference\\nlearning with eligibility traces, so called TD(lambda), however it lacks the\\nparameter alpha that specifies the learning rate. In the place of this free\\nparameter there is now an equation for the learning rate that is specific to\\neach state transition. We experimentally test this new learning rule against\\nTD(lambda) and find that it offers superior performance in various settings.\\nFinally, we make some preliminary investigations into how to extend our new\\ntemporal difference algorithm to reinforcement learning. To do this we combine\\nour update equation with both Watkins' Q(lambda) and Sarsa(lambda) and find\\nthat it again offers superior performance without a learning rate parameter.\\n\",\n",
              " '  We address the problem of reinforcement learning in which observations may\\nexhibit an arbitrary form of stochastic dependence on past observations and\\nactions, i.e. environments more general than (PO)MDPs. The task for an agent is\\nto attain the best possible asymptotic reward where the true generating\\nenvironment is unknown but belongs to a known countable family of environments.\\nWe find some sufficient conditions on the class of environments under which an\\nagent exists which attains the best asymptotic reward for any environment in\\nthe class. We analyze how tight these conditions are and how they relate to\\ndifferent probabilistic assumptions known in reinforcement learning and related\\nfields, such as Markov Decision Processes and mixing conditions.\\n',\n",
              " \"  In this paper, I expand Shannon's definition of entropy into a new form of\\nentropy that allows integration of information from different random events.\\nShannon's notion of entropy is a special case of my more general definition of\\nentropy. I define probability using a so-called performance function, which is\\nde facto an exponential distribution. Assuming that my general notion of\\nentropy reflects the true uncertainty about a probabilistic event, I understand\\nthat our perceived uncertainty differs. I claim that our perception is the\\nresult of two opposing forces similar to the two famous antagonists in Chinese\\nphilosophy: Yin and Yang. Based on this idea, I show that our perceived\\nuncertainty matches the true uncertainty in points determined by the golden\\nratio. I demonstrate that the well-known sigmoid function, which we typically\\nemploy in artificial neural networks as a non-linear threshold function,\\ndescribes the actual performance. Furthermore, I provide a motivation for the\\ntime dilation in Einstein's Special Relativity, basically claiming that\\nalthough time dilation conforms with our perception, it does not correspond to\\nreality. At the end of the paper, I show how to apply this theoretical\\nframework to practical applications. I present recognition rates for a pattern\\nrecognition problem, and also propose a network architecture that can take\\nadvantage of general entropy to solve complex decision problems.\\n\",\n",
              " \"  This paper presents the current state of a work in progress, whose objective\\nis to better understand the effects of factors that significantly influence the\\nperformance of Latent Semantic Analysis (LSA). A difficult task, which consists\\nin answering (French) biology Multiple Choice Questions, is used to test the\\nsemantic properties of the truncated singular space and to study the relative\\ninfluence of main parameters. A dedicated software has been designed to fine\\ntune the LSA semantic space for the Multiple Choice Questions task. With\\noptimal parameters, the performances of our simple model are quite surprisingly\\nequal or superior to those of 7th and 8th grades students. This indicates that\\nsemantic spaces were quite good despite their low dimensions and the small\\nsizes of training data sets. Besides, we present an original entropy global\\nweighting of answers' terms of each question of the Multiple Choice Questions\\nwhich was necessary to achieve the model's success.\\n\",\n",
              " '  We develop the concept of ABC-Boost (Adaptive Base Class Boost) for\\nmulti-class classification and present ABC-MART, a concrete implementation of\\nABC-Boost. The original MART (Multiple Additive Regression Trees) algorithm has\\nbeen very successful in large-scale applications. For binary classification,\\nABC-MART recovers MART. For multi-class classification, ABC-MART considerably\\nimproves MART, as evaluated on several public data sets.\\n',\n",
              " '  Most generalization bounds in learning theory are based on some measure of\\nthe complexity of the hypothesis class used, independently of any algorithm. In\\ncontrast, the notion of algorithmic stability can be used to derive tight\\ngeneralization bounds that are tailored to specific learning algorithms by\\nexploiting their particular properties. However, as in much of learning theory,\\nexisting stability analyses and bounds apply only in the scenario where the\\nsamples are independently and identically distributed. In many machine learning\\napplications, however, this assumption does not hold. The observations received\\nby the learning algorithm often have some inherent temporal dependence.\\n  This paper studies the scenario where the observations are drawn from a\\nstationary phi-mixing or beta-mixing sequence, a widely adopted assumption in\\nthe study of non-i.i.d. processes that implies a dependence between\\nobservations weakening over time. We prove novel and distinct stability-based\\ngeneralization bounds for stationary phi-mixing and beta-mixing sequences.\\nThese bounds strictly generalize the bounds given in the i.i.d. case and apply\\nto all stable learning algorithms, thereby extending the use of\\nstability-bounds to non-i.i.d. scenarios.\\n  We also illustrate the application of our phi-mixing generalization bounds to\\ngeneral classes of learning algorithms, including Support Vector Regression,\\nKernel Ridge Regression, and Support Vector Machines, and many other kernel\\nregularization-based and relative entropy-based regularization algorithms.\\nThese novel bounds can thus be viewed as the first theoretical basis for the\\nuse of these algorithms in non-i.i.d. scenarios.\\n',\n",
              " '  Lasso, or $\\\\ell^1$ regularized least squares, has been explored extensively\\nfor its remarkable sparsity properties. It is shown in this paper that the\\nsolution to Lasso, in addition to its sparsity, has robustness properties: it\\nis the solution to a robust optimization problem. This has two important\\nconsequences. First, robustness provides a connection of the regularizer to a\\nphysical property, namely, protection from noise. This allows a principled\\nselection of the regularizer, and in particular, generalizations of Lasso that\\nalso yield convex optimization problems are obtained by considering different\\nuncertainty sets.\\n  Secondly, robustness can itself be used as an avenue to exploring different\\nproperties of the solution. In particular, it is shown that robustness of the\\nsolution explains why the solution is sparse. The analysis as well as the\\nspecific results obtained differ from standard sparsity results, providing\\ndifferent geometric intuition. Furthermore, it is shown that the robust\\noptimization formulation is related to kernel density estimation, and based on\\nthis approach, a proof that Lasso is consistent is given using robustness\\ndirectly. Finally, a theorem saying that sparsity and algorithmic stability\\ncontradict each other, and hence Lasso is not stable, is presented.\\n',\n",
              " '  Ensemble classification is an emerging approach to land cover mapping whereby\\nthe final classification output is a result of a consensus of classifiers.\\nIntuitively, an ensemble system should consist of base classifiers which are\\ndiverse i.e. classifiers whose decision boundaries err differently. In this\\npaper ensemble feature selection is used to impose diversity in ensembles. The\\nfeatures of the constituent base classifiers for each ensemble were created\\nthrough an exhaustive search algorithm using different separability indices.\\nFor each ensemble, the classification accuracy was derived as well as a\\ndiversity measure purported to give a measure of the inensemble diversity. The\\ncorrelation between ensemble classification accuracy and diversity measure was\\ndetermined to establish the interplay between the two variables. From the\\nfindings of this paper, diversity measures as currently formulated do not\\nprovide an adequate means upon which to constitute ensembles for land cover\\nmapping.\\n',\n",
              " '  Hidden Markov Models (HMMs) are one of the most fundamental and widely used\\nstatistical tools for modeling discrete time series. In general, learning HMMs\\nfrom data is computationally hard (under cryptographic assumptions), and\\npractitioners typically resort to search heuristics which suffer from the usual\\nlocal optima issues. We prove that under a natural separation condition (bounds\\non the smallest singular value of the HMM parameters), there is an efficient\\nand provably correct algorithm for learning HMMs. The sample complexity of the\\nalgorithm does not explicitly depend on the number of distinct (discrete)\\nobservations---it implicitly depends on this quantity through spectral\\nproperties of the underlying HMM. This makes the algorithm particularly\\napplicable to settings with a large number of observations, such as those in\\nnatural language processing where the space of observation is sometimes the\\nwords in a language. The algorithm is also simple, employing only a singular\\nvalue decomposition and matrix multiplications.\\n',\n",
              " '  Many databases store data in relational format, with different types of\\nentities and information about links between the entities. The field of\\nstatistical-relational learning (SRL) has developed a number of new statistical\\nmodels for such data. In this paper we focus on learning class-level or\\nfirst-order dependencies, which model the general database statistics over\\nattributes of linked objects and links (e.g., the percentage of A grades given\\nin computer science classes). Class-level statistical relationships are\\nimportant in themselves, and they support applications like policy making,\\nstrategic planning, and query optimization. Most current SRL methods find\\nclass-level dependencies, but their main task is to support instance-level\\npredictions about the attributes or links of specific entities. We focus only\\non class-level prediction, and describe algorithms for learning class-level\\nmodels that are orders of magnitude faster for this task. Our algorithms learn\\nBayes nets with relational structure, leveraging the efficiency of single-table\\nnonrelational Bayes net learners. An evaluation of our methods on three data\\nsets shows that they are computationally feasible for realistic table sizes,\\nand that the learned structures represent the statistical information in the\\ndatabases well. After learning compiles the database statistics into a Bayes\\nnet, querying these statistics via Bayes net inference is faster than with SQL\\nqueries, and does not depend on the size of the database.\\n',\n",
              " '  The k-means algorithm is a well-known method for partitioning n points that\\nlie in the d-dimensional space into k clusters. Its main features are\\nsimplicity and speed in practice. Theoretically, however, the best known upper\\nbound on its running time (i.e. O(n^{kd})) can be exponential in the number of\\npoints. Recently, Arthur and Vassilvitskii [3] showed a super-polynomial\\nworst-case analysis, improving the best known lower bound from \\\\Omega(n) to\\n2^{\\\\Omega(\\\\sqrt{n})} with a construction in d=\\\\Omega(\\\\sqrt{n}) dimensions. In\\n[3] they also conjectured the existence of superpolynomial lower bounds for any\\nd >= 2.\\n  Our contribution is twofold: we prove this conjecture and we improve the\\nlower bound, by presenting a simple construction in the plane that leads to the\\nexponential lower bound 2^{\\\\Omega(n)}.\\n',\n",
              " '  In the past few years powerful generalizations to the Euclidean k-means\\nproblem have been made, such as Bregman clustering [7], co-clustering (i.e.,\\nsimultaneous clustering of rows and columns of an input matrix) [9,18], and\\ntensor clustering [8,34]. Like k-means, these more general problems also suffer\\nfrom the NP-hardness of the associated optimization. Researchers have developed\\napproximation algorithms of varying degrees of sophistication for k-means,\\nk-medians, and more recently also for Bregman clustering [2]. However, there\\nseem to be no approximation algorithms for Bregman co- and tensor clustering.\\nIn this paper we derive the first (to our knowledge) guaranteed methods for\\nthese increasingly important clustering settings. Going beyond Bregman\\ndivergences, we also prove an approximation factor for tensor clustering with\\narbitrary separable metrics. Through extensive experiments we evaluate the\\ncharacteristics of our method, and show that it also has practical impact.\\n',\n",
              " \"  Enormous successes have been made by quantum algorithms during the last\\ndecade. In this paper, we combine the quantum game with the problem of data\\nclustering, and then develop a quantum-game-based clustering algorithm, in\\nwhich data points in a dataset are considered as players who can make decisions\\nand implement quantum strategies in quantum games. After each round of a\\nquantum game, each player's expected payoff is calculated. Later, he uses a\\nlink-removing-and-rewiring (LRR) function to change his neighbors and adjust\\nthe strength of links connecting to them in order to maximize his payoff.\\nFurther, algorithms are discussed and analyzed in two cases of strategies, two\\npayoff matrixes and two LRR functions. Consequently, the simulation results\\nhave demonstrated that data points in datasets are clustered reasonably and\\nefficiently, and the clustering algorithms have fast rates of convergence.\\nMoreover, the comparison with other algorithms also provides an indication of\\nthe effectiveness of the proposed approach.\\n\",\n",
              " '  We consider the problem of PAC-learning decision trees, i.e., learning a\\ndecision tree over the n-dimensional hypercube from independent random labeled\\nexamples. Despite significant effort, no polynomial-time algorithm is known for\\nlearning polynomial-sized decision trees (even trees of any super-constant\\nsize), even when examples are assumed to be drawn from the uniform distribution\\non {0,1}^n. We give an algorithm that learns arbitrary polynomial-sized\\ndecision trees for {\\\\em most product distributions}. In particular, consider a\\nrandom product distribution where the bias of each bit is chosen independently\\nand uniformly from, say, [.49,.51]. Then with high probability over the\\nparameters of the product distribution and the random examples drawn from it,\\nthe algorithm will learn any tree. More generally, in the spirit of smoothed\\nanalysis, we consider an arbitrary product distribution whose parameters are\\nspecified only up to a [-c,c] accuracy (perturbation), for an arbitrarily small\\npositive constant c.\\n',\n",
              " '  We participated in three of the protein-protein interaction subtasks of the\\nSecond BioCreative Challenge: classification of abstracts relevant for\\nprotein-protein interaction (IAS), discovery of protein pairs (IPS) and text\\npassages characterizing protein interaction (ISS) in full text documents. We\\napproached the abstract classification task with a novel, lightweight linear\\nmodel inspired by spam-detection techniques, as well as an uncertainty-based\\nintegration scheme. We also used a Support Vector Machine and the Singular\\nValue Decomposition on the same features for comparison purposes. Our approach\\nto the full text subtasks (protein pair and passage identification) includes a\\nfeature expansion method based on word-proximity networks. Our approach to the\\nabstract classification task (IAS) was among the top submissions for this task\\nin terms of the measures of performance used in the challenge evaluation\\n(accuracy, F-score and AUC). We also report on a web-tool we produced using our\\napproach: the Protein Interaction Abstract Relevance Evaluator (PIARE). Our\\napproach to the full text tasks resulted in one of the highest recall rates as\\nwell as mean reciprocal rank of correct passages. Our approach to abstract\\nclassification shows that a simple linear model, using relatively few features,\\nis capable of generalizing and uncovering the conceptual nature of\\nprotein-protein interaction from the bibliome. Since the novel approach is\\nbased on a very lightweight linear model, it can be easily ported and applied\\nto similar problems. In full text problems, the expansion of word features with\\nword-proximity networks is shown to be useful, though the need for some\\nimprovements is discussed.\\n',\n",
              " '  In this paper, we propose a general cross-layer optimization framework in\\nwhich we explicitly consider both the heterogeneous and dynamically changing\\ncharacteristics of delay-sensitive applications and the underlying time-varying\\nnetwork conditions. We consider both the independently decodable data units\\n(DUs, e.g. packets) and the interdependent DUs whose dependencies are captured\\nby a directed acyclic graph (DAG). We first formulate the cross-layer design as\\na non-linear constrained optimization problem by assuming complete knowledge of\\nthe application characteristics and the underlying network conditions. The\\nconstrained cross-layer optimization is decomposed into several cross-layer\\noptimization subproblems for each DU and two master problems. The proposed\\ndecomposition method determines the necessary message exchanges between layers\\nfor achieving the optimal cross-layer solution. However, the attributes (e.g.\\ndistortion impact, delay deadline etc) of future DUs as well as the network\\nconditions are often unknown in the considered real-time applications. The\\nimpact of current cross-layer actions on the future DUs can be characterized by\\na state-value function in the Markov decision process (MDP) framework. Based on\\nthe dynamic programming solution to the MDP, we develop a low-complexity\\ncross-layer optimization algorithm using online learning for each DU\\ntransmission. This online algorithm can be implemented in real-time in order to\\ncope with unknown source characteristics, network dynamics and resource\\nconstraints. Our numerical results demonstrate the efficiency of the proposed\\nonline algorithm.\\n',\n",
              " '  The enormous successes have been made by quantum algorithms during the last\\ndecade. In this paper, we combine the quantum random walk (QRW) with the\\nproblem of data clustering, and develop two clustering algorithms based on the\\none dimensional QRW. Then, the probability distributions on the positions\\ninduced by QRW in these algorithms are investigated, which also indicates the\\npossibility of obtaining better results. Consequently, the experimental results\\nhave demonstrated that data points in datasets are clustered reasonably and\\nefficiently, and the clustering algorithms are of fast rates of convergence.\\nMoreover, the comparison with other algorithms also provides an indication of\\nthe effectiveness of the proposed approach.\\n',\n",
              " '  We present a convex formulation of dictionary learning for sparse signal\\ndecomposition. Convexity is obtained by replacing the usual explicit upper\\nbound on the dictionary size by a convex rank-reducing term similar to the\\ntrace norm. In particular, our formulation introduces an explicit trade-off\\nbetween size and sparsity of the decomposition of rectangular matrices. Using a\\nlarge set of synthetic examples, we compare the estimation abilities of the\\nconvex and non-convex approaches, showing that while the convex formulation has\\na single local minimum, this may lead in some cases to performance which is\\ninferior to the local minima of the non-convex formulation.\\n',\n",
              " '  We consider a multi-round auction setting motivated by pay-per-click auctions\\nfor Internet advertising. In each round the auctioneer selects an advertiser\\nand shows her ad, which is then either clicked or not. An advertiser derives\\nvalue from clicks; the value of a click is her private information. Initially,\\nneither the auctioneer nor the advertisers have any information about the\\nlikelihood of clicks on the advertisements. The auctioneer\\'s goal is to design\\na (dominant strategies) truthful mechanism that (approximately) maximizes the\\nsocial welfare.\\n  If the advertisers bid their true private values, our problem is equivalent\\nto the \"multi-armed bandit problem\", and thus can be viewed as a strategic\\nversion of the latter. In particular, for both problems the quality of an\\nalgorithm can be characterized by \"regret\", the difference in social welfare\\nbetween the algorithm and the benchmark which always selects the same \"best\"\\nadvertisement. We investigate how the design of multi-armed bandit algorithms\\nis affected by the restriction that the resulting mechanism must be truthful.\\nWe find that truthful mechanisms have certain strong structural properties --\\nessentially, they must separate exploration from exploitation -- and they incur\\nmuch higher regret than the optimal multi-armed bandit algorithms. Moreover, we\\nprovide a truthful mechanism which (essentially) matches our lower bound on\\nregret.\\n',\n",
              " '  Applications such as face recognition that deal with high-dimensional data\\nneed a mapping technique that introduces representation of low-dimensional\\nfeatures with enhanced discriminatory power and a proper classifier, able to\\nclassify those complex features. Most of traditional Linear Discriminant\\nAnalysis suffer from the disadvantage that their optimality criteria are not\\ndirectly related to the classification ability of the obtained feature\\nrepresentation. Moreover, their classification accuracy is affected by the\\n\"small sample size\" problem which is often encountered in FR tasks. In this\\nshort paper, we combine nonlinear kernel based mapping of data called KDDA with\\nSupport Vector machine classifier to deal with both of the shortcomings in an\\nefficient and cost effective manner. The proposed here method is compared, in\\nterms of classification accuracy, to other commonly used FR methods on UMIST\\nface database. Results indicate that the performance of the proposed method is\\noverall superior to those of traditional FR approaches, such as the Eigenfaces,\\nFisherfaces, and D-LDA methods and traditional linear classifiers.\\n',\n",
              " '  Recently, Adaboost has been widely used to improve the accuracy of any given\\nlearning algorithm. In this paper we focus on designing an algorithm to employ\\ncombination of Adaboost with Support Vector Machine as weak component\\nclassifiers to be used in Face Detection Task. To obtain a set of effective\\nSVM-weaklearner Classifier, this algorithm adaptively adjusts the kernel\\nparameter in SVM instead of using a fixed one. Proposed combination outperforms\\nin generalization in comparison with SVM on imbalanced classification problem.\\nThe proposed here method is compared, in terms of classification accuracy, to\\nother commonly used Adaboost methods, such as Decision Trees and Neural\\nNetworks, on CMU+MIT face database. Results indicate that the performance of\\nthe proposed method is overall superior to previous Adaboost approaches.\\n',\n",
              " '  We introduce a simple and computationally trivial method for binary\\nclassification based on the evaluation of potential functions. We demonstrate\\nthat despite the conceptual and computational simplicity of the method its\\nperformance can match or exceed that of standard Support Vector Machine\\nmethods.\\n',\n",
              " '  We investigate the performance of a simple signed distance function (SDF)\\nbased method by direct comparison with standard SVM packages, as well as\\nK-nearest neighbor and RBFN methods. We present experimental results comparing\\nthe SDF approach with other classifiers on both synthetic geometric problems\\nand five benchmark clinical microarray data sets. On both geometric problems\\nand microarray data sets, the non-optimized SDF based classifiers perform just\\nas well or slightly better than well-developed, standard SVM methods. These\\nresults demonstrate the potential accuracy of SDF-based methods on some types\\nof problems.\\n',\n",
              " '  We define a new model of quantum learning that we call Predictive Quantum\\n(PQ). This is a quantum analogue of PAC, where during the testing phase the\\nstudent is only required to answer a polynomial number of testing queries.\\n  We demonstrate a relational concept class that is efficiently learnable in\\nPQ, while in any \"reasonable\" classical model exponential amount of training\\ndata would be required. This is the first unconditional separation between\\nquantum and classical learning.\\n  We show that our separation is the best possible in several ways; in\\nparticular, there is no analogous result for a functional class, as well as for\\nseveral weaker versions of quantum learning. In order to demonstrate tightness\\nof our separation we consider a special case of one-way communication that we\\ncall single-input mode, where Bob receives no input. Somewhat surprisingly,\\nthis setting becomes nontrivial when relational communication tasks are\\nconsidered. In particular, any problem with two-sided input can be transformed\\ninto a single-input relational problem of equal classical one-way cost. We show\\nthat the situation is different in the quantum case, where the same\\ntransformation can make the communication complexity exponentially larger. This\\nhappens if and only if the original problem has exponential gap between quantum\\nand classical one-way communication costs. We believe that these auxiliary\\nresults might be of independent interest.\\n',\n",
              " '  We consider bandit problems involving a large (possibly infinite) collection\\nof arms, in which the expected reward of each arm is a linear function of an\\n$r$-dimensional random vector $\\\\mathbf{Z} \\\\in \\\\mathbb{R}^r$, where $r \\\\geq 2$.\\nThe objective is to minimize the cumulative regret and Bayes risk. When the set\\nof arms corresponds to the unit sphere, we prove that the regret and Bayes risk\\nis of order $\\\\Theta(r \\\\sqrt{T})$, by establishing a lower bound for an\\narbitrary policy, and showing that a matching upper bound is obtained through a\\npolicy that alternates between exploration and exploitation phases. The\\nphase-based policy is also shown to be effective if the set of arms satisfies a\\nstrong convexity condition. For the case of a general set of arms, we describe\\na near-optimal policy whose regret and Bayes risk admit upper bounds of the\\nform $O(r \\\\sqrt{T} \\\\log^{3/2} T)$.\\n',\n",
              " '  We present an algorithm, called the Offset Tree, for learning to make\\ndecisions in situations where the payoff of only one choice is observed, rather\\nthan all choices. The algorithm reduces this setting to binary classification,\\nallowing one to reuse of any existing, fully supervised binary classification\\nalgorithm in this partial information setting. We show that the Offset Tree is\\nan optimal reduction to binary classification. In particular, it has regret at\\nmost $(k-1)$ times the regret of the binary classifier it uses (where $k$ is\\nthe number of choices), and no reduction to binary classification can do\\nbetter. This reduction is also computationally optimal, both at training and\\ntest time, requiring just $O(\\\\log_2 k)$ work to train on an example or make a\\nprediction.\\n  Experiments with the Offset Tree show that it generally performs better than\\nseveral alternative approaches.\\n',\n",
              " '  A client-server architecture to simultaneously solve multiple learning tasks\\nfrom distributed datasets is described. In such architecture, each client is\\nassociated with an individual learning task and the associated dataset of\\nexamples. The goal of the architecture is to perform information fusion from\\nmultiple datasets while preserving privacy of individual data. The role of the\\nserver is to collect data in real-time from the clients and codify the\\ninformation in a common database. The information coded in this database can be\\nused by all the clients to solve their individual learning task, so that each\\nclient can exploit the informative content of all the datasets without actually\\nhaving access to private data of others. The proposed algorithmic framework,\\nbased on regularization theory and kernel methods, uses a suitable class of\\nmixed effect kernels. The new method is illustrated through a simulated music\\nrecommendation system.\\n',\n",
              " '  Many AI researchers and cognitive scientists have argued that analogy is the\\ncore of cognition. The most influential work on computational modeling of\\nanalogy-making is Structure Mapping Theory (SMT) and its implementation in the\\nStructure Mapping Engine (SME). A limitation of SME is the requirement for\\ncomplex hand-coded representations. We introduce the Latent Relation Mapping\\nEngine (LRME), which combines ideas from SME and Latent Relational Analysis\\n(LRA) in order to remove the requirement for hand-coded representations. LRME\\nbuilds analogical mappings between lists of words, using a large corpus of raw\\ntext to automatically discover the semantic relations among the words. We\\nevaluate LRME on a set of twenty analogical mapping problems, ten based on\\nscientific analogies and ten based on common metaphors. LRME achieves\\nhuman-level performance on the twenty problems. We compare LRME with a variety\\nof alternative approaches and find that they are not able to reach the same\\nlevel of performance.\\n',\n",
              " '  General purpose intelligent learning agents cycle through (complex,non-MDP)\\nsequences of observations, actions, and rewards. On the other hand,\\nreinforcement learning is well-developed for small finite state Markov Decision\\nProcesses (MDPs). So far it is an art performed by human designers to extract\\nthe right state representation out of the bare observations, i.e. to reduce the\\nagent setup to the MDP framework. Before we can think of mechanizing this\\nsearch for suitable MDPs, we need a formal objective criterion. The main\\ncontribution of this article is to develop such a criterion. I also integrate\\nthe various parts into one learning algorithm. Extensions to more realistic\\ndynamic Bayesian networks are developed in a companion article.\\n',\n",
              " '  Feature Markov Decision Processes (PhiMDPs) are well-suited for learning\\nagents in general environments. Nevertheless, unstructured (Phi)MDPs are\\nlimited to relatively simple environments. Structured MDPs like Dynamic\\nBayesian Networks (DBNs) are used for large-scale real-world problems. In this\\narticle I extend PhiMDP to PhiDBN. The primary contribution is to derive a cost\\ncriterion that allows to automatically extract the most relevant features from\\nthe environment, leading to the \"best\" DBN representation. I discuss all\\nbuilding blocks required for a complete general learning algorithm.\\n',\n",
              " '  We present a practical and statistically consistent scheme for actively\\nlearning binary classifiers under general loss functions. Our algorithm uses\\nimportance weighting to correct sampling bias, and by controlling the variance,\\nwe are able to give rigorous label complexity bounds for the learning process.\\nExperiments on passively labeled data show that this approach reduces the label\\ncomplexity required to achieve good predictive performance on many learning\\nproblems.\\n',\n",
              " '  We have proposed a model based upon flocking on a complex network, and then\\ndeveloped two clustering algorithms on the basis of it. In the algorithms,\\nfirstly a \\\\textit{k}-nearest neighbor (knn) graph as a weighted and directed\\ngraph is produced among all data points in a dataset each of which is regarded\\nas an agent who can move in space, and then a time-varying complex network is\\ncreated by adding long-range links for each data point. Furthermore, each data\\npoint is not only acted by its \\\\textit{k} nearest neighbors but also \\\\textit{r}\\nlong-range neighbors through fields established in space by them together, so\\nit will take a step along the direction of the vector sum of all fields. It is\\nmore important that these long-range links provides some hidden information for\\neach data point when it moves and at the same time accelerate its speed\\nconverging to a center. As they move in space according to the proposed model,\\ndata points that belong to the same class are located at a same position\\ngradually, whereas those that belong to different classes are away from one\\nanother. Consequently, the experimental results have demonstrated that data\\npoints in datasets are clustered reasonably and efficiently, and the rates of\\nconvergence of clustering algorithms are fast enough. Moreover, the comparison\\nwith other algorithms also provides an indication of the effectiveness of the\\nproposed approach.\\n',\n",
              " '  This paper introduces a model based upon games on an evolving network, and\\ndevelops three clustering algorithms according to it. In the clustering\\nalgorithms, data points for clustering are regarded as players who can make\\ndecisions in games. On the network describing relationships among data points,\\nan edge-removing-and-rewiring (ERR) function is employed to explore in a\\nneighborhood of a data point, which removes edges connecting to neighbors with\\nsmall payoffs, and creates new edges to neighbors with larger payoffs. As such,\\nthe connections among data points vary over time. During the evolution of\\nnetwork, some strategies are spread in the network. As a consequence, clusters\\nare formed automatically, in which data points with the same evolutionarily\\nstable strategy are collected as a cluster, so the number of evolutionarily\\nstable strategies indicates the number of clusters. Moreover, the experimental\\nresults have demonstrated that data points in datasets are clustered reasonably\\nand efficiently, and the comparison with other algorithms also provides an\\nindication of the effectiveness of the proposed algorithms.\\n',\n",
              " '  Least squares (LS) fitting is one of the most fundamental techniques in\\nscience and engineering. It is used to estimate parameters from multiple noisy\\nobservations. In many problems the parameters are known a-priori to be bounded\\ninteger valued, or they come from a finite set of values on an arbitrary finite\\nlattice. In this case finding the closest vector becomes NP-Hard problem. In\\nthis paper we propose a novel algorithm, the Tomographic Least Squares Decoder\\n(TLSD), that not only solves the ILS problem, better than other sub-optimal\\ntechniques, but also is capable of providing the a-posteriori probability\\ndistribution for each element in the solution vector. The algorithm is based on\\nreconstruction of the vector from multiple two-dimensional projections. The\\nprojections are carefully chosen to provide low computational complexity.\\nUnlike other iterative techniques, such as the belief propagation, the proposed\\nalgorithm has ensured convergence. We also provide simulated experiments\\ncomparing the algorithm to other sub-optimal algorithms.\\n',\n",
              " '  Cooperative decision making is a vision of future network management and\\ncontrol. Distributed connection preemption is an important example where nodes\\ncan make intelligent decisions on allocating resources and controlling traffic\\nflows for multi-class service networks. A challenge is that nodal decisions are\\nspatially dependent as traffic flows trespass multiple nodes in a network.\\nHence the performance-complexity trade-off becomes important, i.e., how\\naccurate decisions are versus how much information is exchanged among nodes.\\nConnection preemption is known to be NP-complete. Centralized preemption is\\noptimal but computationally intractable. Decentralized preemption is\\ncomputationally efficient but may result in a poor performance. This work\\ninvestigates distributed preemption where nodes decide whether and which flows\\nto preempt using only local information exchange with neighbors. We develop,\\nbased on the probabilistic graphical models, a near-optimal distributed\\nalgorithm. The algorithm is used by each node to make collectively near-optimal\\npreemption decisions. We study trade-offs between near-optimal performance and\\ncomplexity that corresponds to the amount of information-exchange of the\\ndistributed algorithm. The algorithm is validated by both analysis and\\nsimulation.\\n',\n",
              " '  The emergence of low-cost sensor architectures for diverse modalities has\\nmade it possible to deploy sensor arrays that capture a single event from a\\nlarge number of vantage points and using multiple modalities. In many\\nscenarios, these sensors acquire very high-dimensional data such as audio\\nsignals, images, and video. To cope with such high-dimensional data, we\\ntypically rely on low-dimensional models. Manifold models provide a\\nparticularly powerful model that captures the structure of high-dimensional\\ndata when it is governed by a low-dimensional set of parameters. However, these\\nmodels do not typically take into account dependencies among multiple sensors.\\nWe thus propose a new joint manifold framework for data ensembles that exploits\\nsuch dependencies. We show that simple algorithms can exploit the joint\\nmanifold structure to improve their performance on standard signal processing\\napplications. Additionally, recent results concerning dimensionality reduction\\nfor manifolds enable us to formulate a network-scalable data compression scheme\\nthat uses random projections of the sensed data. This scheme efficiently fuses\\nthe data from all sensors through the addition of such projections, regardless\\nof the data modalities and dimensions.\\n',\n",
              " '  We consider the problem of joint universal variable-rate lossy coding and\\nidentification for parametric classes of stationary $\\\\beta$-mixing sources with\\ngeneral (Polish) alphabets. Compression performance is measured in terms of\\nLagrangians, while identification performance is measured by the variational\\ndistance between the true source and the estimated source. Provided that the\\nsources are mixing at a sufficiently fast rate and satisfy certain smoothness\\nand Vapnik-Chervonenkis learnability conditions, it is shown that, for bounded\\nmetric distortions, there exist universal schemes for joint lossy compression\\nand identification whose Lagrangian redundancies converge to zero as $\\\\sqrt{V_n\\n\\\\log n /n}$ as the block length $n$ tends to infinity, where $V_n$ is the\\nVapnik-Chervonenkis dimension of a certain class of decision regions defined by\\nthe $n$-dimensional marginal distributions of the sources; furthermore, for\\neach $n$, the decoder can identify $n$-dimensional marginal of the active\\nsource up to a ball of radius $O(\\\\sqrt{V_n\\\\log n/n})$ in variational distance,\\neventually with probability one. The results are supplemented by several\\nexamples of parametric sources satisfying the regularity conditions.\\n',\n",
              " '  The problem of statistical learning is to construct an accurate predictor of\\na random variable as a function of a correlated random variable on the basis of\\nan i.i.d. training sample from their joint distribution. Allowable predictors\\nare constrained to lie in some specified class, and the goal is to approach\\nasymptotically the performance of the best predictor in the class. We consider\\ntwo settings in which the learning agent only has access to rate-limited\\ndescriptions of the training data, and present information-theoretic bounds on\\nthe predictor performance achievable in the presence of these communication\\nconstraints. Our proofs do not assume any separation structure between\\ncompression and learning and rely on a new class of operational criteria\\nspecifically tailored to joint design of encoders and learning algorithms in\\nrate-constrained settings.\\n',\n",
              " '  In statistical problems, a set of parameterized probability distributions is\\nused to estimate the true probability distribution. If Fisher information\\nmatrix at the true distribution is singular, then it has been left unknown what\\nwe can estimate about the true distribution from random samples. In this paper,\\nwe study a singular regression problem and prove a limit theorem which shows\\nthe relation between the singular regression problem and two birational\\ninvariants, a real log canonical threshold and a singular fluctuation. The\\nobtained theorem has an important application to statistics, because it enables\\nus to estimate the generalization error from the training error without any\\nknowledge of the true probability distribution.\\n',\n",
              " '  Let M be a random (alpha n) x n matrix of rank r<<n, and assume that a\\nuniformly random subset E of its entries is observed. We describe an efficient\\nalgorithm that reconstructs M from |E| = O(rn) observed entries with relative\\nroot mean square error RMSE <= C(rn/|E|)^0.5 . Further, if r=O(1), M can be\\nreconstructed exactly from |E| = O(n log(n)) entries. These results apply\\nbeyond random matrices to general low-rank incoherent matrices.\\n  This settles (in the case of bounded rank) a question left open by Candes and\\nRecht and improves over the guarantees for their reconstruction algorithm. The\\ncomplexity of our algorithm is O(|E|r log(n)), which opens the way to its use\\nfor massive data sets. In the process of proving these statements, we obtain a\\ngeneralization of a celebrated result by Friedman-Kahn-Szemeredi and Feige-Ofek\\non the spectrum of sparse random matrices.\\n',\n",
              " '  We consider the least-square linear regression problem with regularization by\\nthe $\\\\ell^1$-norm, a problem usually referred to as the Lasso. In this paper,\\nwe first present a detailed asymptotic analysis of model consistency of the\\nLasso in low-dimensional settings. For various decays of the regularization\\nparameter, we compute asymptotic equivalents of the probability of correct\\nmodel selection. For a specific rate decay, we show that the Lasso selects all\\nthe variables that should enter the model with probability tending to one\\nexponentially fast, while it selects all other variables with strictly positive\\nprobability. We show that this property implies that if we run the Lasso for\\nseveral bootstrapped replications of a given sample, then intersecting the\\nsupports of the Lasso bootstrap estimates leads to consistent model selection.\\nThis novel variable selection procedure, referred to as the Bolasso, is\\nextended to high-dimensional settings by a provably consistent two-step\\nprocedure.\\n',\n",
              " '  We study boosting algorithms from a new perspective. We show that the\\nLagrange dual problems of AdaBoost, LogitBoost and soft-margin LPBoost with\\ngeneralized hinge loss are all entropy maximization problems. By looking at the\\ndual problems of these boosting algorithms, we show that the success of\\nboosting algorithms can be understood in terms of maintaining a better margin\\ndistribution by maximizing margins and at the same time controlling the margin\\nvariance.We also theoretically prove that, approximately, AdaBoost maximizes\\nthe average margin, instead of the minimum margin. The duality formulation also\\nenables us to develop column generation based optimization algorithms, which\\nare totally corrective. We show that they exhibit almost identical\\nclassification results to that of standard stage-wise additive boosting\\nalgorithms but with much faster convergence rates. Therefore fewer weak\\nclassifiers are needed to build the ensemble using our proposed optimization\\ntechnique.\\n',\n",
              " '  Scenarios for the emergence or bootstrap of a lexicon involve the repeated\\ninteraction between at least two agents who must reach a consensus on how to\\nname N objects using H words. Here we consider minimal models of two types of\\nlearning algorithms: cross-situational learning, in which the individuals\\ndetermine the meaning of a word by looking for something in common across all\\nobserved uses of that word, and supervised operant conditioning learning, in\\nwhich there is strong feedback between individuals about the intended meaning\\nof the words. Despite the stark differences between these learning schemes, we\\nshow that they yield the same communication accuracy in the realistic limits of\\nlarge N and H, which coincides with the result of the classical occupancy\\nproblem of randomly assigning N objects to H words.\\n',\n",
              " \"  Walley's Imprecise Dirichlet Model (IDM) for categorical i.i.d. data extends\\nthe classical Dirichlet model to a set of priors. It overcomes several\\nfundamental problems which other approaches to uncertainty suffer from. Yet, to\\nbe useful in practice, one needs efficient ways for computing the\\nimprecise=robust sets or intervals. The main objective of this work is to\\nderive exact, conservative, and approximate, robust and credible interval\\nestimates under the IDM for a large class of statistical estimators, including\\nthe entropy and mutual information.\\n\",\n",
              " \"  Gaussian belief propagation (GaBP) is an iterative message-passing algorithm\\nfor inference in Gaussian graphical models. It is known that when GaBP\\nconverges it converges to the correct MAP estimate of the Gaussian random\\nvector and simple sufficient conditions for its convergence have been\\nestablished. In this paper we develop a double-loop algorithm for forcing\\nconvergence of GaBP. Our method computes the correct MAP estimate even in cases\\nwhere standard GaBP would not have converged. We further extend this\\nconstruction to compute least-squares solutions of over-constrained linear\\nsystems. We believe that our construction has numerous applications, since the\\nGaBP algorithm is linked to solution of linear systems of equations, which is a\\nfundamental problem in computer science and engineering. As a case study, we\\ndiscuss the linear detection problem. We show that using our new construction,\\nwe are able to force convergence of Montanari's linear detection algorithm, in\\ncases where it would originally fail. As a consequence, we are able to increase\\nsignificantly the number of users that can transmit concurrently.\\n\",\n",
              " \"  Grammar inference deals with determining (preferable simple) models/grammars\\nconsistent with a set of observations. There is a large body of research on\\ngrammar inference within the theory of formal languages. However, there is\\nsurprisingly little known on grammar inference for graph grammars. In this\\npaper we take a further step in this direction and work within the framework of\\nnode label controlled (NLC) graph grammars. Specifically, we characterize,\\ngiven a set of disjoint and isomorphic subgraphs of a graph $G$, whether or not\\nthere is a NLC graph grammar rule which can generate these subgraphs to obtain\\n$G$. This generalizes previous results by assuming that the set of isomorphic\\nsubgraphs is disjoint instead of non-touching. This leads naturally to consider\\nthe more involved ``non-confluent'' graph grammar rules.\\n\",\n",
              " '  Research in reinforcement learning has produced algorithms for optimal\\ndecision making under uncertainty that fall within two main types. The first\\nemploys a Bayesian framework, where optimality improves with increased\\ncomputational time. This is because the resulting planning task takes the form\\nof a dynamic programming problem on a belief tree with an infinite number of\\nstates. The second type employs relatively simple algorithm which are shown to\\nsuffer small regret within a distribution-free framework. This paper presents a\\nlower bound and a high probability upper bound on the optimal value function\\nfor the nodes in the Bayesian belief tree, which are analogous to similar\\nbounds in POMDPs. The bounds are then used to create more efficient strategies\\nfor exploring the tree. The resulting algorithms are compared with the\\ndistribution-free algorithm UCB1, as well as a simpler baseline algorithm on\\nmulti-armed bandit problems.\\n',\n",
              " '  Frequent episode discovery is a popular framework for pattern discovery in\\nevent streams. An episode is a partially ordered set of nodes with each node\\nassociated with an event type. Efficient (and separate) algorithms exist for\\nepisode discovery when the associated partial order is total (serial episode)\\nand trivial (parallel episode). In this paper, we propose efficient algorithms\\nfor discovering frequent episodes with general partial orders. These algorithms\\ncan be easily specialized to discover serial or parallel episodes. Also, the\\nalgorithms are flexible enough to be specialized for mining in the space of\\ncertain interesting subclasses of partial orders. We point out that there is an\\ninherent combinatorial explosion in frequent partial order mining and most\\nimportantly, frequency alone is not a sufficient measure of interestingness. We\\npropose a new interestingness measure for general partial order episodes and a\\ndiscovery method based on this measure, for filtering out uninteresting partial\\norders. Simulations demonstrate the effectiveness of our algorithms.\\n',\n",
              " '  In this paper, we propose a technique to extract constrained formal concepts.\\n',\n",
              " '  Recently, different works proposed a new way to mine patterns in databases\\nwith pathological size. For example, experiments in genome biology usually\\nprovide databases with thousands of attributes (genes) but only tens of objects\\n(experiments). In this case, mining the \"transposed\" database runs through a\\nsmaller search space, and the Galois connection allows to infer the closed\\npatterns of the original database. We focus here on constrained pattern mining\\nfor those unusual databases and give a theoretical framework for database and\\nconstraint transposition. We discuss the properties of constraint transposition\\nand look into classical constraints. We then address the problem of generating\\nthe closed patterns of the original database satisfying the constraint,\\nstarting from those mined in the \"transposed\" database. Finally, we show how to\\ngenerate all the patterns satisfying the constraint from the closed ones.\\n',\n",
              " '  We consider multi-label prediction problems with large output spaces under\\nthe assumption of output sparsity -- that the target (label) vectors have small\\nsupport. We develop a general theory for a variant of the popular error\\ncorrecting output code scheme, using ideas from compressed sensing for\\nexploiting this sparsity. The method can be regarded as a simple reduction from\\nmulti-label regression problems to binary regression problems. We show that the\\nnumber of subproblems need only be logarithmic in the total number of possible\\nlabels, making this approach radically more efficient than others. We also\\nstate and prove robustness guarantees for this method in the form of regret\\ntransform bounds (in general), and also provide a more detailed analysis for\\nthe linear prediction setting.\\n',\n",
              " \"  Classification of some objects in classes of concepts is an essential and\\neven breathtaking task in many applications. A solution is discussed here based\\non Multi-Agent systems. A kernel of some expert agents in several classes is to\\nconsult a central agent decide among the classification problem of a certain\\nobject. This kernel is moderated with the center agent, trying to manage the\\nquerying agents for any decision problem by means of a data-header like feature\\nset. Agents have cooperation among concepts related to the classes of this\\nclassification decision-making; and may affect on each others' results on a\\ncertain query object in a multi-agent learning approach. This leads to an\\nonline feature learning via the consulting trend. The performance is discussed\\nto be much better in comparison to some other prior trends while system's\\nmessage passing overload is decreased to less agents and the expertism helps\\nthe performance and operability of system win the comparison.\\n\",\n",
              " '  We present a family of pairwise tournaments reducing $k$-class classification\\nto binary classification. These reductions are provably robust against a\\nconstant fraction of binary errors. The results improve on the PECOC\\nconstruction \\\\cite{SECOC} with an exponential improvement in computation, from\\n$O(k)$ to $O(\\\\log_2 k)$, and the removal of a square root in the regret\\ndependence, matching the best possible computation and regret up to a constant.\\n',\n",
              " '  We report a new optimal resolution for the statistical stratification problem\\nunder proportional sampling allocation among strata. Consider a finite\\npopulation of N units, a random sample of n units selected from this population\\nand a number L of strata. Thus, we have to define which units belong to each\\nstratum so as to minimize the variance of a total estimator for one desired\\nvariable of interest in each stratum,and consequently reduce the overall\\nvariance for such quantity. In order to solve this problem, an exact algorithm\\nbased on the concept of minimal path in a graph is proposed and assessed.\\nComputational results using real data from IBGE (Brazilian Central Statistical\\nOffice) are provided.\\n',\n",
              " '  This paper formalises the concept of learning symbolic rules from multisource\\ndata in a cardiac monitoring context. Our sources, electrocardiograms and\\narterial blood pressure measures, describe cardiac behaviours from different\\nviewpoints. To learn interpretable rules, we use an Inductive Logic Programming\\n(ILP) method. We develop an original strategy to cope with the dimensionality\\nissues caused by using this ILP technique on a rich multisource language. The\\nresults show that our method greatly improves the feasibility and the\\nefficiency of the process while staying accurate. They also confirm the\\nbenefits of using multiple sources to improve the diagnosis of cardiac\\narrhythmias.\\n',\n",
              " '  This paper addresses the general problem of domain adaptation which arises in\\na variety of applications where the distribution of the labeled sample\\navailable somewhat differs from that of the test data. Building on previous\\nwork by Ben-David et al. (2007), we introduce a novel distance between\\ndistributions, discrepancy distance, that is tailored to adaptation problems\\nwith arbitrary loss functions. We give Rademacher complexity bounds for\\nestimating the discrepancy distance from finite samples for different loss\\nfunctions. Using this distance, we derive novel generalization bounds for\\ndomain adaptation for a wide family of loss functions. We also present a series\\nof novel adaptation bounds for large classes of regularization-based\\nalgorithms, including support vector machines and kernel ridge regression based\\non the empirical discrepancy. This motivates our analysis of the problem of\\nminimizing the empirical discrepancy for various loss functions for which we\\nalso give novel algorithms. We report the results of preliminary experiments\\nthat demonstrate the benefits of our discrepancy minimization algorithms for\\ndomain adaptation.\\n',\n",
              " '  We discuss multi-task online learning when a decision maker has to deal\\nsimultaneously with M tasks. The tasks are related, which is modeled by\\nimposing that the M-tuple of actions taken by the decision maker needs to\\nsatisfy certain constraints. We give natural examples of such restrictions and\\nthen discuss a general class of tractable constraints, for which we introduce\\ncomputationally efficient ways of selecting actions, essentially by reducing to\\nan on-line shortest path problem. We briefly discuss \"tracking\" and \"bandit\"\\nversions of the problem and extend the model in various ways, including\\nnon-additive global losses and uncountably infinite sets of tasks.\\n',\n",
              " '  The problem of completing a low-rank matrix from a subset of its entries is\\noften encountered in the analysis of incomplete data sets exhibiting an\\nunderlying factor model with applications in collaborative filtering, computer\\nvision and control. Most recent work had been focused on constructing efficient\\nalgorithms for exact or approximate recovery of the missing matrix entries and\\nproving lower bounds for the number of known entries that guarantee a\\nsuccessful recovery with high probability. A related problem from both the\\nmathematical and algorithmic point of view is the distance geometry problem of\\nrealizing points in a Euclidean space from a given subset of their pairwise\\ndistances. Rigidity theory answers basic questions regarding the uniqueness of\\nthe realization satisfying a given partial set of distances. We observe that\\nbasic ideas and tools of rigidity theory can be adapted to determine uniqueness\\nof low-rank matrix completion, where inner products play the role that\\ndistances play in rigidity theory. This observation leads to an efficient\\nrandomized algorithm for testing both local and global unique completion.\\nCrucial to our analysis is a new matrix, which we call the completion matrix,\\nthat serves as the analogue of the rigidity matrix.\\n',\n",
              " '  We introduce a new protocol for prediction with expert advice in which each\\nexpert evaluates the learner\\'s and his own performance using a loss function\\nthat may change over time and may be different from the loss functions used by\\nthe other experts. The learner\\'s goal is to perform better or not much worse\\nthan each expert, as evaluated by that expert, for all experts simultaneously.\\nIf the loss functions used by the experts are all proper scoring rules and all\\nmixable, we show that the defensive forecasting algorithm enjoys the same\\nperformance guarantee as that attainable by the Aggregating Algorithm in the\\nstandard setting and known to be optimal. This result is also applied to the\\ncase of \"specialist\" (or \"sleeping\") experts. In this case, the defensive\\nforecasting algorithm reduces to a simple modification of the Aggregating\\nAlgorithm.\\n',\n",
              " '  We present multiplicative updates for solving hard and soft margin support\\nvector machines (SVM) with non-negative kernels. They follow as a natural\\nextension of the updates for non-negative matrix factorization. No additional\\nparam- eter setting, such as choosing learning, rate is required. Ex- periments\\ndemonstrate rapid convergence to good classifiers. We analyze the rates of\\nasymptotic convergence of the up- dates and establish tight bounds. We test the\\nperformance on several datasets using various non-negative kernels and report\\nequivalent generalization errors to that of a standard SVM.\\n',\n",
              " '  A collaborative filtering system recommends to users products that similar\\nusers like. Collaborative filtering systems influence purchase decisions, and\\nhence have become targets of manipulation by unscrupulous vendors. We provide\\ntheoretical and empirical results demonstrating that while common nearest\\nneighbor algorithms, which are widely used in commercial systems, can be highly\\nsusceptible to manipulation, two classes of collaborative filtering algorithms\\nwhich we refer to as linear and asymptotically linear are relatively robust.\\nThese results provide guidance for the design of future collaborative filtering\\nsystems.\\n',\n",
              " '  Collecting large labeled data sets is a laborious and expensive task, whose\\nscaling up requires division of the labeling workload between many teachers.\\nWhen the number of classes is large, miscorrespondences between the labels\\ngiven by the different teachers are likely to occur, which, in the extreme\\ncase, may reach total inconsistency. In this paper we describe how globally\\nconsistent labels can be obtained, despite the absence of teacher coordination,\\nand discuss the possible efficiency of this process in terms of human labor. We\\ndefine a notion of label efficiency, measuring the ratio between the number of\\nglobally consistent labels obtained and the number of labels provided by\\ndistributed teachers. We show that the efficiency depends critically on the\\nratio alpha between the number of data instances seen by a single teacher, and\\nthe number of classes. We suggest several algorithms for the distributed\\nlabeling problem, and analyze their efficiency as a function of alpha. In\\naddition, we provide an upper bound on label efficiency for the case of\\ncompletely uncoordinated teachers, and show that efficiency approaches 0 as the\\nratio between the number of labels each teacher provides and the number of\\nclasses drops (i.e. alpha goes to 0).\\n',\n",
              " '  In large systems, it is important for agents to learn to act effectively, but\\nsophisticated multi-agent learning algorithms generally do not scale. An\\nalternative approach is to find restricted classes of games where simple,\\nefficient algorithms converge. It is shown that stage learning efficiently\\nconverges to Nash equilibria in large anonymous games if best-reply dynamics\\nconverge. Two features are identified that improve convergence. First, rather\\nthan making learning more difficult, more agents are actually beneficial in\\nmany settings. Second, providing agents with statistical information about the\\nbehavior of others can significantly reduce the number of observations needed.\\n',\n",
              " '  This paper has been retracted.\\n',\n",
              " '  We study the problem of decision-theoretic online learning (DTOL). Motivated\\nby practical applications, we focus on DTOL when the number of actions is very\\nlarge. Previous algorithms for learning in this framework have a tunable\\nlearning rate parameter, and a barrier to using online-learning in practical\\napplications is that it is not understood how to set this parameter optimally,\\nparticularly when the number of actions is large.\\n  In this paper, we offer a clean solution by proposing a novel and completely\\nparameter-free algorithm for DTOL. We introduce a new notion of regret, which\\nis more natural for applications with a large number of actions. We show that\\nour algorithm achieves good performance with respect to this new notion of\\nregret; in addition, it also achieves performance close to that of the best\\nbounds achieved by previous algorithms with optimally-tuned parameters,\\naccording to previous notions of regret.\\n',\n",
              " '  We study the tracking problem, namely, estimating the hidden state of an\\nobject over time, from unreliable and noisy measurements. The standard\\nframework for the tracking problem is the generative framework, which is the\\nbasis of solutions such as the Bayesian algorithm and its approximation, the\\nparticle filters. However, the problem with these solutions is that they are\\nvery sensitive to model mismatches. In this paper, motivated by online\\nlearning, we introduce a new framework -- an {\\\\em explanatory} framework -- for\\ntracking. We provide an efficient tracking algorithm for this framework. We\\nprovide experimental results comparing our algorithm to the Bayesian algorithm\\non simulated data. Our experiments show that when there are slight model\\nmismatches, our algorithm vastly outperforms the Bayesian algorithm.\\n',\n",
              " '  A $p$-adic modification of the split-LBG classification method is presented\\nin which first clusterings and then cluster centers are computed which locally\\nminimise an energy function. The outcome for a fixed dataset is independent of\\nthe prime number $p$ with finitely many exceptions. The methods are applied to\\nthe construction of $p$-adic classifiers in the context of learning.\\n',\n",
              " '  The paper studies the asymptotic behavior of Random Algebraic Riccati\\nEquations (RARE) arising in Kalman filtering when the arrival of the\\nobservations is described by a Bernoulli i.i.d. process. We model the RARE as\\nan order-preserving, strongly sublinear random dynamical system (RDS). Under a\\nsufficient condition, stochastic boundedness, and using a limit-set dichotomy\\nresult for order-preserving, strongly sublinear RDS, we establish the\\nasymptotic properties of the RARE: the sequence of random prediction error\\ncovariance matrices converges weakly to a unique invariant distribution, whose\\nsupport exhibits fractal behavior. In particular, this weak convergence holds\\nunder broad conditions and even when the observations arrival rate is below the\\ncritical probability for mean stability. We apply the weak-Feller property of\\nthe Markov process governing the RARE to characterize the support of the\\nlimiting invariant distribution as the topological closure of a countable set\\nof points, which, in general, is not dense in the set of positive semi-definite\\nmatrices. We use the explicit characterization of the support of the invariant\\ndistribution and the almost sure ergodicity of the sample paths to easily\\ncompute the moments of the invariant distribution. A one dimensional example\\nillustrates that the support is a fractured subset of the non-negative reals\\nwith self-similarity properties.\\n',\n",
              " '  Many reinforcement learning exploration techniques are overly optimistic and\\ntry to explore every state. Such exploration is impossible in environments with\\nthe unlimited number of states. I propose to use simulated exploration with an\\noptimistic model to discover promising paths for real exploration. This reduces\\nthe needs for the real exploration.\\n',\n",
              " '  In this work, we first show that feature selection methods other than\\nboosting can also be used for training an efficient object detector. In\\nparticular, we introduce Greedy Sparse Linear Discriminant Analysis (GSLDA)\\n\\\\cite{Moghaddam2007Fast} for its conceptual simplicity and computational\\nefficiency; and slightly better detection performance is achieved compared with\\n\\\\cite{Viola2004Robust}. Moreover, we propose a new technique, termed Boosted\\nGreedy Sparse Linear Discriminant Analysis (BGSLDA), to efficiently train a\\ndetection cascade. BGSLDA exploits the sample re-weighting property of boosting\\nand the class-separability criterion of GSLDA.\\n',\n",
              " '  Detecting outliers which are grossly different from or inconsistent with the\\nremaining dataset is a major challenge in real-world KDD applications. Existing\\noutlier detection methods are ineffective on scattered real-world datasets due\\nto implicit data patterns and parameter setting issues. We define a novel\\n\"Local Distance-based Outlier Factor\" (LDOF) to measure the {outlier-ness} of\\nobjects in scattered datasets which addresses these issues. LDOF uses the\\nrelative location of an object to its neighbours to determine the degree to\\nwhich the object deviates from its neighbourhood. Properties of LDOF are\\ntheoretically analysed including LDOF\\'s lower bound and its false-detection\\nprobability, as well as parameter settings. In order to facilitate parameter\\nsettings in real-world applications, we employ a top-n technique in our outlier\\ndetection approach, where only the objects with the highest LDOF values are\\nregarded as outliers. Compared to conventional approaches (such as top-n KNN\\nand top-n LOF), our method top-n LDOF is more effective at detecting outliers\\nin scattered data. It is also easier to set parameters, since its performance\\nis relatively stable over a large range of parameter values, as illustrated by\\nexperimental results on both real-world and synthetic datasets.\\n',\n",
              " '  This paper introduces a new approach to solve sensor management problems.\\nClassically sensor management problems can be well formalized as\\nPartially-Observed Markov Decision Processes (POMPD). The original approach\\ndevelopped here consists in deriving the optimal parameterized policy based on\\na stochastic gradient estimation. We assume in this work that it is possible to\\nlearn the optimal policy off-line (in simulation) using models of the\\nenvironement and of the sensor(s). The learned policy can then be used to\\nmanage the sensor(s). In order to approximate the gradient in a stochastic\\ncontext, we introduce a new method to approximate the gradient, based on\\nInfinitesimal Perturbation Approximation (IPA). The effectiveness of this\\ngeneral framework is illustrated by the managing of an Electronically Scanned\\nArray Radar. First simulations results are finally proposed.\\n',\n",
              " \"  Given a random binary sequence $X^{(n)}$ of random variables, $X_{t},$\\n$t=1,2,...,n$, for instance, one that is generated by a Markov source (teacher)\\nof order $k^{*}$ (each state represented by $k^{*}$ bits). Assume that the\\nprobability of the event $X_{t}=1$ is constant and denote it by $\\\\beta$.\\nConsider a learner which is based on a parametric model, for instance a Markov\\nmodel of order $k$, who trains on a sequence $x^{(m)}$ which is randomly drawn\\nby the teacher. Test the learner's performance by giving it a sequence\\n$x^{(n)}$ (generated by the teacher) and check its predictions on every bit of\\n$x^{(n)}.$ An error occurs at time $t$ if the learner's prediction $Y_{t}$\\ndiffers from the true bit value $X_{t}$. Denote by $\\\\xi^{(n)}$ the sequence of\\nerrors where the error bit $\\\\xi_{t}$ at time $t$ equals 1 or 0 according to\\nwhether the event of an error occurs or not, respectively. Consider the\\nsubsequence $\\\\xi^{(\\\\nu)}$ of $\\\\xi^{(n)}$ which corresponds to the errors of\\npredicting a 0, i.e., $\\\\xi^{(\\\\nu)}$ consists of the bits of $\\\\xi^{(n)}$ only at\\ntimes $t$ such that $Y_{t}=0.$ In this paper we compute an estimate on the\\ndeviation of the frequency of 1s of $\\\\xi^{(\\\\nu)}$ from $\\\\beta$. The result\\nshows that the level of randomness of $\\\\xi^{(\\\\nu)}$ decreases relative to an\\nincrease in the complexity of the learner.\\n\",\n",
              " '  We consider the problem of estimating the conditional probability of a label\\nin time $O(\\\\log n)$, where $n$ is the number of possible labels. We analyze a\\nnatural reduction of this problem to a set of binary regression problems\\norganized in a tree structure, proving a regret bound that scales with the\\ndepth of the tree. Motivated by this analysis, we propose the first online\\nalgorithm which provably constructs a logarithmic depth tree on the set of\\nlabels to solve this problem. We test the algorithm empirically, showing that\\nit works succesfully on a dataset with roughly $10^6$ labels.\\n',\n",
              " '  The Bethe approximation, or loopy belief propagation algorithm is a\\nsuccessful method for approximating partition functions of probabilistic models\\nassociated with a graph. Chertkov and Chernyak derived an interesting formula\\ncalled Loop Series Expansion, which is an expansion of the partition function.\\nThe main term of the series is the Bethe approximation while other terms are\\nlabeled by subgraphs called generalized loops. In our recent paper, we derive\\nthe loop series expansion in form of a polynomial with coefficients positive\\nintegers, and extend the result to the expansion of marginals. In this paper,\\nwe give more clear derivation for the results and discuss the properties of the\\npolynomial which is introduced in the paper.\\n',\n",
              " '  For a variety of regularized optimization problems in machine learning,\\nalgorithms computing the entire solution path have been developed recently.\\nMost of these methods are quadratic programs that are parameterized by a single\\nparameter, as for example the Support Vector Machine (SVM). Solution path\\nalgorithms do not only compute the solution for one particular value of the\\nregularization parameter but the entire path of solutions, making the selection\\nof an optimal parameter much easier.\\n  It has been assumed that these piecewise linear solution paths have only\\nlinear complexity, i.e. linearly many bends. We prove that for the support\\nvector machine this complexity can be exponential in the number of training\\npoints in the worst case. More strongly, we construct a single instance of n\\ninput points in d dimensions for an SVM such that at least \\\\Theta(2^{n/2}) =\\n\\\\Theta(2^d) many distinct subsets of support vectors occur as the\\nregularization parameter changes.\\n',\n",
              " '  For a wide variety of regularization methods, algorithms computing the entire\\nsolution path have been developed recently. Solution path algorithms do not\\nonly compute the solution for one particular value of the regularization\\nparameter but the entire path of solutions, making the selection of an optimal\\nparameter much easier. Most of the currently used algorithms are not robust in\\nthe sense that they cannot deal with general or degenerate input. Here we\\npresent a new robust, generic method for parametric quadratic programming. Our\\nalgorithm directly applies to nearly all machine learning applications, where\\nso far every application required its own different algorithm.\\n  We illustrate the usefulness of our method by applying it to a very low rank\\nproblem which could not be solved by existing path tracking methods, namely to\\ncompute part-worth values in choice based conjoint analysis, a popular\\ntechnique from market research to estimate consumers preferences on a class of\\nparameterized options.\\n',\n",
              " '  In the context of inference with expectation constraints, we propose an\\napproach based on the \"loopy belief propagation\" algorithm LBP, as a surrogate\\nto an exact Markov Random Field MRF modelling. A prior information composed of\\ncorrelations among a large set of N variables, is encoded into a graphical\\nmodel; this encoding is optimized with respect to an approximate decoding\\nprocedure LBP, which is used to infer hidden variables from an observed subset.\\nWe focus on the situation where the underlying data have many different\\nstatistical components, representing a variety of independent patterns.\\nConsidering a single parameter family of models we show how LBP may be used to\\nencode and decode efficiently such information, without solving the NP hard\\ninverse problem yielding the optimal MRF. Contrary to usual practice, we work\\nin the non-convex Bethe free energy minimization framework, and manage to\\nassociate a belief propagation fixed point to each component of the underlying\\nprobabilistic mixture. The mean field limit is considered and yields an exact\\nconnection with the Hopfield model at finite temperature and steady state, when\\nthe number of mixture components is proportional to the number of variables. In\\naddition, we provide an enhanced learning procedure, based on a straightforward\\nmulti-parameter extension of the model in conjunction with an effective\\ncontinuous optimization procedure. This is performed using the stochastic\\nsearch heuristic CMAES and yields a significant improvement with respect to the\\nsingle parameter basic model.\\n',\n",
              " '  A technique for speeding up reinforcement learning algorithms by using time\\nmanipulation is proposed. It is applicable to failure-avoidance control\\nproblems running in a computer simulation. Turning the time of the simulation\\nbackwards on failure events is shown to speed up the learning by 260% and\\nimprove the state space exploration by 12% on the cart-pole balancing task,\\ncompared to the conventional Q-learning and Actor-Critic algorithms.\\n',\n",
              " \"  We study the regret of optimal strategies for online convex optimization\\ngames. Using von Neumann's minimax theorem, we show that the optimal regret in\\nthis adversarial setting is closely related to the behavior of the empirical\\nminimization algorithm in a stochastic process setting: it is equal to the\\nmaximum, over joint distributions of the adversary's action sequence, of the\\ndifference between a sum of minimal expected losses and the minimal empirical\\nloss. We show that the optimal regret has a natural geometric interpretation,\\nsince it can be viewed as the gap in Jensen's inequality for a concave\\nfunctional--the minimizer over the player's actions of expected loss--defined\\non a set of probability distributions. We use this expression to obtain upper\\nand lower bounds on the regret of an optimal strategy for a variety of online\\nlearning problems. Our method provides upper bounds without the need to\\nconstruct a learning algorithm; the lower bounds provide explicit optimal\\nstrategies for the adversary.\\n\",\n",
              " '  Given i.i.d. data from an unknown distribution, we consider the problem of\\npredicting future items. An adaptive way to estimate the probability density is\\nto recursively subdivide the domain to an appropriate data-dependent\\ngranularity. A Bayesian would assign a data-independent prior probability to\\n\"subdivide\", which leads to a prior over infinite(ly many) trees. We derive an\\nexact, fast, and simple inference algorithm for such a prior, for the data\\nevidence, the predictive distribution, the effective model dimension, moments,\\nand other quantities. We prove asymptotic convergence and consistency results,\\nand illustrate the behavior of our model on some prototypical functions.\\n',\n",
              " '  This preprint has been withdrawn by the author for revision\\n',\n",
              " '  A mechanism called Eligibility Propagation is proposed to speed up the Time\\nHopping technique used for faster Reinforcement Learning in simulations.\\nEligibility Propagation provides for Time Hopping similar abilities to what\\neligibility traces provide for conventional Reinforcement Learning. It\\npropagates values from one state to all of its temporal predecessors using a\\nstate transitions graph. Experiments on a simulated biped crawling robot\\nconfirm that Eligibility Propagation accelerates the learning process more than\\n3 times.\\n',\n",
              " '  Given a time series of multicomponent measurements x(t), the usual objective\\nof nonlinear blind source separation (BSS) is to find a \"source\" time series\\ns(t), comprised of statistically independent combinations of the measured\\ncomponents. In this paper, the source time series is required to have a density\\nfunction in (s,ds/dt)-space that is equal to the product of density functions\\nof individual components. This formulation of the BSS problem has a solution\\nthat is unique, up to permutations and component-wise transformations.\\nSeparability is shown to impose constraints on certain locally invariant\\n(scalar) functions of x, which are derived from local higher-order correlations\\nof the data\\'s velocity dx/dt. The data are separable if and only if they\\nsatisfy these constraints, and, if the constraints are satisfied, the sources\\ncan be explicitly constructed from the data. The method is illustrated by using\\nit to separate two speech-like sounds recorded with a single microphone.\\n',\n",
              " '  We show that Boolean functions expressible as monotone disjunctive normal\\nforms are PAC-evolvable under a uniform distribution on the Boolean cube if the\\nhypothesis size is allowed to remain fixed. We further show that this result is\\ninsufficient to prove the PAC-learnability of monotone Boolean functions,\\nthereby demonstrating a counter-example to a recent claim to the contrary. We\\nfurther discuss scenarios wherein evolvability and learnability will coincide\\nas well as scenarios under which they differ. The implications of the latter\\ncase on the prospects of learning in complex hypothesis spaces is briefly\\nexamined.\\n',\n",
              " \"  This paper applies machine learning techniques to student modeling. It\\npresents a method for discovering high-level student behaviors from a very\\nlarge set of low-level traces corresponding to problem-solving actions in a\\nlearning environment. Basic actions are encoded into sets of domain-dependent\\nattribute-value patterns called cases. Then a domain-independent hierarchical\\nclustering identifies what we call general attitudes, yielding automatic\\ndiagnosis expressed in natural language, addressed in principle to teachers.\\nThe method can be applied to individual students or to entire groups, like a\\nclass. We exhibit examples of this system applied to thousands of students'\\nactions in the domain of algebraic transformations.\\n\",\n",
              " '  This paper uses the notion of algorithmic stability to derive novel\\ngeneralization bounds for several families of transductive regression\\nalgorithms, both by using convexity and closed-form solutions. Our analysis\\nhelps compare the stability of these algorithms. It also shows that a number of\\nwidely used transductive regression algorithms are in fact unstable. Finally,\\nit reports the results of experiments with local transductive regression\\ndemonstrating the benefit of our stability bounds for model selection, for one\\nof the algorithms, in particular for determining the radius of the local\\nneighborhood used by the algorithm.\\n',\n",
              " '  We show that learning a convex body in $\\\\RR^d$, given random samples from the\\nbody, requires $2^{\\\\Omega(\\\\sqrt{d/\\\\eps})}$ samples. By learning a convex body\\nwe mean finding a set having at most $\\\\eps$ relative symmetric difference with\\nthe input body. To prove the lower bound we construct a hard to learn family of\\nconvex bodies. Our construction of this family is very simple and based on\\nerror correcting codes.\\n',\n",
              " \"  In this paper we apply computer learning methods to diagnosing ovarian cancer\\nusing the level of the standard biomarker CA125 in conjunction with information\\nprovided by mass-spectrometry. We are working with a new data set collected\\nover a period of 7 years. Using the level of CA125 and mass-spectrometry peaks,\\nour algorithm gives probability predictions for the disease. To estimate\\nclassification accuracy we convert probability predictions into strict\\npredictions. Our algorithm makes fewer errors than almost any linear\\ncombination of the CA125 level and one peak's intensity (taken on the log\\nscale). To check the power of our algorithm we use it to test the hypothesis\\nthat CA125 and the peaks do not contain useful information for the prediction\\nof the disease at a particular time before the diagnosis. Our algorithm\\nproduces $p$-values that are better than those produced by the algorithm that\\nhas been previously applied to this data set. Our conclusion is that the\\nproposed algorithm is more reliable for prediction on new data.\\n\",\n",
              " '  Inferring the sequence of states from observations is one of the most\\nfundamental problems in Hidden Markov Models. In statistical physics language,\\nthis problem is equivalent to computing the marginals of a one-dimensional\\nmodel with a random external field. While this task can be accomplished through\\ntransfer matrix methods, it becomes quickly intractable when the underlying\\nstate space is large.\\n  This paper develops several low-complexity approximate algorithms to address\\nthis inference problem when the state space becomes large. The new algorithms\\nare based on various mean-field approximations of the transfer matrix. Their\\nperformances are studied in detail on a simple realistic model for DNA\\npyrosequencing.\\n',\n",
              " '  Jerry Fodor argues that Darwin was wrong about \"natural selection\" because\\n(1) it is only a tautology rather than a scientific law that can support\\ncounterfactuals (\"If X had happened, Y would have happened\") and because (2)\\nonly minds can select. Hence Darwin\\'s analogy with \"artificial selection\" by\\nanimal breeders was misleading and evolutionary explanation is nothing but\\npost-hoc historical narrative. I argue that Darwin was right on all counts.\\n',\n",
              " '  Boosting has attracted much research attention in the past decade. The\\nsuccess of boosting algorithms may be interpreted in terms of the margin\\ntheory. Recently it has been shown that generalization error of classifiers can\\nbe obtained by explicitly taking the margin distribution of the training data\\ninto account. Most of the current boosting algorithms in practice usually\\noptimizes a convex loss function and do not make use of the margin\\ndistribution. In this work we design a new boosting algorithm, termed\\nmargin-distribution boosting (MDBoost), which directly maximizes the average\\nmargin and minimizes the margin variance simultaneously. This way the margin\\ndistribution is optimized. A totally-corrective optimization algorithm based on\\ncolumn generation is proposed to implement MDBoost. Experiments on UCI datasets\\nshow that MDBoost outperforms AdaBoost and LPBoost in most cases.\\n',\n",
              " '  Motivation: Several different threads of research have been proposed for\\nmodeling and mining temporal data. On the one hand, approaches such as dynamic\\nBayesian networks (DBNs) provide a formal probabilistic basis to model\\nrelationships between time-indexed random variables but these models are\\nintractable to learn in the general case. On the other, algorithms such as\\nfrequent episode mining are scalable to large datasets but do not exhibit the\\nrigorous probabilistic interpretations that are the mainstay of the graphical\\nmodels literature.\\n  Results: We present a unification of these two seemingly diverse threads of\\nresearch, by demonstrating how dynamic (discrete) Bayesian networks can be\\ninferred from the results of frequent episode mining. This helps bridge the\\nmodeling emphasis of the former with the counting emphasis of the latter.\\nFirst, we show how, under reasonable assumptions on data characteristics and on\\ninfluences of random variables, the optimal DBN structure can be computed using\\na greedy, local, algorithm. Next, we connect the optimality of the DBN\\nstructure with the notion of fixed-delay episodes and their counts of distinct\\noccurrences. Finally, to demonstrate the practical feasibility of our approach,\\nwe focus on a specific (but broadly applicable) class of networks, called\\nexcitatory networks, and show how the search for the optimal DBN structure can\\nbe conducted using just information from frequent episodes. Application on\\ndatasets gathered from mathematical models of spiking neurons as well as real\\nneuroscience datasets are presented.\\n  Availability: Algorithmic implementations, simulator codebases, and datasets\\nare available from our website at http://neural-code.cs.vt.edu/dbn\\n',\n",
              " \"  Experimental verification has been the method of choice for verifying the\\nstability of a multi-agent reinforcement learning (MARL) algorithm as the\\nnumber of agents grows and theoretical analysis becomes prohibitively complex.\\nFor cooperative agents, where the ultimate goal is to optimize some global\\nmetric, the stability is usually verified by observing the evolution of the\\nglobal performance metric over time. If the global metric improves and\\neventually stabilizes, it is considered a reasonable verification of the\\nsystem's stability.\\n  The main contribution of this note is establishing the need for better\\nexperimental frameworks and measures to assess the stability of large-scale\\nadaptive cooperative systems. We show an experimental case study where the\\nstability of the global performance metric can be rather deceiving, hiding an\\nunderlying instability in the system that later leads to a significant drop in\\nperformance. We then propose an alternative metric that relies on agents' local\\npolicies and show, experimentally, that our proposed metric is more effective\\n(than the traditional global performance metric) in exposing the instability of\\nMARL algorithms.\\n\",\n",
              " \"  We describe a preliminary investigation into learning a Chess player's style\\nfrom game records. The method is based on attempting to learn features of a\\nplayer's individual evaluation function using the method of temporal\\ndifferences, with the aid of a conventional Chess engine architecture. Some\\nencouraging results were obtained in learning the styles of two recent Chess\\nworld champions, and we report on our attempt to use the learnt styles to\\ndiscriminate between the players from game records by trying to detect who was\\nplaying white and who was playing black. We also discuss some limitations of\\nour approach and propose possible directions for future research. The method we\\nhave presented may also be applicable to other strategic games, and may even be\\ngeneralisable to other domains where sequences of agents' actions are recorded.\\n\",\n",
              " '  We present a method for learning max-weight matching predictors in bipartite\\ngraphs. The method consists of performing maximum a posteriori estimation in\\nexponential families with sufficient statistics that encode permutations and\\ndata features. Although inference is in general hard, we show that for one very\\nrelevant application - web page ranking - exact inference is efficient. For\\ngeneral model instances, an appropriate sampler is readily available. Contrary\\nto existing max-margin matching models, our approach is statistically\\nconsistent and, in addition, experiments with increasing sample sizes indicate\\nsuperior improvement over such models. We apply the method to graph matching in\\ncomputer vision as well as to a standard benchmark dataset for learning web\\npage ranking, in which we obtain state-of-the-art results, in particular\\nimproving on max-margin variants. The drawback of this method with respect to\\nmax-margin alternatives is its runtime for large graphs, which is comparatively\\nhigh.\\n',\n",
              " '  Neighborhood graphs are gaining popularity as a concise data representation\\nin machine learning. However, naive graph construction by pairwise distance\\ncalculation takes $O(n^2)$ runtime for $n$ data points and this is\\nprohibitively slow for millions of data points. For strings of equal length,\\nthe multiple sorting method (Uno, 2008) can construct an $\\\\epsilon$-neighbor\\ngraph in $O(n+m)$ time, where $m$ is the number of $\\\\epsilon$-neighbor pairs in\\nthe data. To introduce this remarkably efficient algorithm to continuous\\ndomains such as images, signals and texts, we employ a random projection method\\nto convert vectors to strings. Theoretical results are presented to elucidate\\nthe trade-off between approximation quality and computation time. Empirical\\nresults show the efficiency of our method in comparison to fast nearest\\nneighbor alternatives.\\n',\n",
              " \"  In this paper we propose an algorithm for polynomial-time reinforcement\\nlearning in factored Markov decision processes (FMDPs). The factored optimistic\\ninitial model (FOIM) algorithm, maintains an empirical model of the FMDP in a\\nconventional way, and always follows a greedy policy with respect to its model.\\nThe only trick of the algorithm is that the model is initialized\\noptimistically. We prove that with suitable initialization (i) FOIM converges\\nto the fixed point of approximate value iteration (AVI); (ii) the number of\\nsteps when the agent makes non-near-optimal decisions (with respect to the\\nsolution of AVI) is polynomial in all relevant quantities; (iii) the per-step\\ncosts of the algorithm are also polynomial. To our best knowledge, FOIM is the\\nfirst algorithm with these properties. This extended version contains the\\nrigorous proofs of the main theorem. A version of this paper appeared in\\nICML'09.\\n\",\n",
              " '  Introduction to Machine learning covering Statistical Inference (Bayes, EM,\\nML/MaxEnt duality), algebraic and spectral methods (PCA, LDA, CCA, Clustering),\\nand PAC learning (the Formal model, VC dimension, Double Sampling theorem).\\n',\n",
              " '  Artificial intelligence offers superior techniques and methods by which\\nproblems from diverse domains may find an optimal solution. The Machine\\nLearning technologies refer to the domain of artificial intelligence aiming to\\ndevelop the techniques allowing the computers to \"learn\". Some systems based on\\nMachine Learning technologies tend to eliminate the necessity of the human\\nintelligence while the others adopt a man-machine collaborative approach.\\n',\n",
              " '  In this paper, we consider the coherent theory of (epistemic) uncertainty of\\nWalley, in which beliefs are represented through sets of probability\\ndistributions, and we focus on the problem of modeling prior ignorance about a\\ncategorical random variable. In this setting, it is a known result that a state\\nof prior ignorance is not compatible with learning. To overcome this problem,\\nanother state of beliefs, called \\\\emph{near-ignorance}, has been proposed.\\nNear-ignorance resembles ignorance very closely, by satisfying some principles\\nthat can arguably be regarded as necessary in a state of ignorance, and allows\\nlearning to take place. What this paper does, is to provide new and substantial\\nevidence that also near-ignorance cannot be really regarded as a way out of the\\nproblem of starting statistical inference in conditions of very weak beliefs.\\nThe key to this result is focusing on a setting characterized by a variable of\\ninterest that is \\\\emph{latent}. We argue that such a setting is by far the most\\ncommon case in practice, and we provide, for the case of categorical latent\\nvariables (and general \\\\emph{manifest} variables) a condition that, if\\nsatisfied, prevents learning to take place under prior near-ignorance. This\\ncondition is shown to be easily satisfied even in the most common statistical\\nproblems. We regard these results as a strong form of evidence against the\\npossibility to adopt a condition of prior near-ignorance in real statistical\\nproblems.\\n',\n",
              " '  Engine assembly is a complex and heavily automated distributed-control\\nprocess, with large amounts of faults data logged everyday. We describe an\\napplication of temporal data mining for analyzing fault logs in an engine\\nassembly plant. Frequent episode discovery framework is a model-free method\\nthat can be used to deduce (temporal) correlations among events from the logs\\nin an efficient manner. In addition to being theoretically elegant and\\ncomputationally efficient, frequent episodes are also easy to interpret in the\\nform actionable recommendations. Incorporation of domain-specific information\\nis critical to successful application of the method for analyzing fault logs in\\nthe manufacturing domain. We show how domain-specific knowledge can be\\nincorporated using heuristic rules that act as pre-filters and post-filters to\\nfrequent episode discovery. The system described here is currently being used\\nin one of the engine assembly plants of General Motors and is planned for\\nadaptation in other plants. To the best of our knowledge, this paper presents\\nthe first real, large-scale application of temporal data mining in the\\nmanufacturing domain. We believe that the ideas presented in this paper can\\nhelp practitioners engineer tools for analysis in other similar or related\\napplication domains as well.\\n',\n",
              " '  The problem of multi-agent learning and adaptation has attracted a great deal\\nof attention in recent years. It has been suggested that the dynamics of multi\\nagent learning can be studied using replicator equations from population\\nbiology. Most existing studies so far have been limited to discrete strategy\\nspaces with a small number of available actions. In many cases, however, the\\nchoices available to agents are better characterized by continuous spectra.\\nThis paper suggests a generalization of the replicator framework that allows to\\nstudy the adaptive dynamics of Q-learning agents with continuous strategy\\nspaces. Instead of probability vectors, agents strategies are now characterized\\nby probability measures over continuous variables. As a result, the ordinary\\ndifferential equations for the discrete case are replaced by a system of\\ncoupled integral--differential replicator equations that describe the mutual\\nevolution of individual agent strategies. We derive a set of functional\\nequations describing the steady state of the replicator dynamics, examine their\\nsolutions for several two-player games, and confirm our analytical results\\nusing simulations.\\n',\n",
              " '  This article treats the problem of learning a dictionary providing sparse\\nrepresentations for a given signal class, via $\\\\ell_1$-minimisation. The\\nproblem can also be seen as factorising a $\\\\ddim \\\\times \\\\nsig$ matrix $Y=(y_1\\n>... y_\\\\nsig), y_n\\\\in \\\\R^\\\\ddim$ of training signals into a $\\\\ddim \\\\times\\n\\\\natoms$ dictionary matrix $\\\\dico$ and a $\\\\natoms \\\\times \\\\nsig$ coefficient\\nmatrix $\\\\X=(x_1... x_\\\\nsig), x_n \\\\in \\\\R^\\\\natoms$, which is sparse. The exact\\nquestion studied here is when a dictionary coefficient pair $(\\\\dico,\\\\X)$ can be\\nrecovered as local minimum of a (nonconvex) $\\\\ell_1$-criterion with input\\n$Y=\\\\dico \\\\X$. First, for general dictionaries and coefficient matrices,\\nalgebraic conditions ensuring local identifiability are derived, which are then\\nspecialised to the case when the dictionary is a basis. Finally, assuming a\\nrandom Bernoulli-Gaussian sparse model on the coefficient matrix, it is shown\\nthat sufficiently incoherent bases are locally identifiable with high\\nprobability. The perhaps surprising result is that the typically sufficient\\nnumber of training samples $\\\\nsig$ grows up to a logarithmic factor only\\nlinearly with the signal dimension, i.e. $\\\\nsig \\\\approx C \\\\natoms \\\\log\\n\\\\natoms$, in contrast to previous approaches requiring combinatorially many\\nsamples.\\n',\n",
              " '  Motivated by the philosophy and phenomenal success of compressed sensing, the\\nproblem of reconstructing a matrix from a sampling of its entries has attracted\\nmuch attention recently. Such a problem can be viewed as an\\ninformation-theoretic variant of the well-studied matrix completion problem,\\nand the main objective is to design an efficient algorithm that can reconstruct\\na matrix by inspecting only a small number of its entries. Although this is an\\nimpossible task in general, Cand\\\\`es and co-authors have recently shown that\\nunder a so-called incoherence assumption, a rank $r$ $n\\\\times n$ matrix can be\\nreconstructed using semidefinite programming (SDP) after one inspects\\n$O(nr\\\\log^6n)$ of its entries. In this paper we propose an alternative approach\\nthat is much more efficient and can reconstruct a larger class of matrices by\\ninspecting a significantly smaller number of the entries. Specifically, we\\nfirst introduce a class of so-called stable matrices and show that it includes\\nall those that satisfy the incoherence assumption. Then, we propose a\\nrandomized basis pursuit (RBP) algorithm and show that it can reconstruct a\\nstable rank $r$ $n\\\\times n$ matrix after inspecting $O(nr\\\\log n)$ of its\\nentries. Our sampling bound is only a logarithmic factor away from the\\ninformation-theoretic limit and is essentially optimal. Moreover, the runtime\\nof the RBP algorithm is bounded by $O(nr^2\\\\log n+n^2r)$, which compares very\\nfavorably with the $\\\\Omega(n^4r^2\\\\log^{12}n)$ runtime of the SDP-based\\nalgorithm. Perhaps more importantly, our algorithm will provide an exact\\nreconstruction of the input matrix in polynomial time. By contrast, the\\nSDP-based algorithm can only provide an approximate one in polynomial time.\\n',\n",
              " '  Growing neuropsychological and neurophysiological evidence suggests that the\\nvisual cortex uses parts-based representations to encode, store and retrieve\\nrelevant objects. In such a scheme, objects are represented as a set of\\nspatially distributed local features, or parts, arranged in stereotypical\\nfashion. To encode the local appearance and to represent the relations between\\nthe constituent parts, there has to be an appropriate memory structure formed\\nby previous experience with visual objects. Here, we propose a model how a\\nhierarchical memory structure supporting efficient storage and rapid recall of\\nparts-based representations can be established by an experience-driven process\\nof self-organization. The process is based on the collaboration of slow\\nbidirectional synaptic plasticity and homeostatic unit activity regulation,\\nboth running at the top of fast activity dynamics with winner-take-all\\ncharacter modulated by an oscillatory rhythm. These neural mechanisms lay down\\nthe basis for cooperation and competition between the distributed units and\\ntheir synaptic connections. Choosing human face recognition as a test task, we\\nshow that, under the condition of open-ended, unsupervised incremental\\nlearning, the system is able to form memory traces for individual faces in a\\nparts-based fashion. On a lower memory layer the synaptic structure is\\ndeveloped to represent local facial features and their interrelations, while\\nthe identities of different persons are captured explicitly on a higher layer.\\nAn additional property of the resulting representations is the sparseness of\\nboth the activity during the recall and the synaptic patterns comprising the\\nmemory traces.\\n',\n",
              " '  This paper presents a new hybrid learning algorithm for unsupervised\\nclassification tasks. We combined Fuzzy c-means learning algorithm and a\\nsupervised version of Minimerror to develop a hybrid incremental strategy\\nallowing unsupervised classifications. We applied this new approach to a\\nreal-world database in order to know if the information contained in unlabeled\\nfeatures of a Geographic Information System (GIS), allows to well classify it.\\nFinally, we compared our results to a classical supervised classification\\nobtained by a multilayer perceptron.\\n',\n",
              " \"  The problem of graphical model selection is to correctly estimate the graph\\nstructure of a Markov random field given samples from the underlying\\ndistribution. We analyze the information-theoretic limitations of the problem\\nof graph selection for binary Markov random fields under high-dimensional\\nscaling, in which the graph size $p$ and the number of edges $k$, and/or the\\nmaximal node degree $d$ are allowed to increase to infinity as a function of\\nthe sample size $n$. For pairwise binary Markov random fields, we derive both\\nnecessary and sufficient conditions for correct graph selection over the class\\n$\\\\mathcal{G}_{p,k}$ of graphs on $p$ vertices with at most $k$ edges, and over\\nthe class $\\\\mathcal{G}_{p,d}$ of graphs on $p$ vertices with maximum degree at\\nmost $d$. For the class $\\\\mathcal{G}_{p, k}$, we establish the existence of\\nconstants $c$ and $c'$ such that if $\\\\numobs < c k \\\\log p$, any method has\\nerror probability at least 1/2 uniformly over the family, and we demonstrate a\\ngraph decoder that succeeds with high probability uniformly over the family for\\nsample sizes $\\\\numobs > c' k^2 \\\\log p$. Similarly, for the class\\n$\\\\mathcal{G}_{p,d}$, we exhibit constants $c$ and $c'$ such that for $n < c d^2\\n\\\\log p$, any method fails with probability at least 1/2, and we demonstrate a\\ngraph decoder that succeeds with high probability for $n > c' d^3 \\\\log p$.\\n\",\n",
              " '  We analyze the expected cost of a greedy active learning algorithm. Our\\nanalysis extends previous work to a more general setting in which different\\nqueries have different costs. Moreover, queries may have more than two possible\\nresponses and the distribution over hypotheses may be non uniform. Specific\\napplications include active learning with label costs, active learning for\\nmulticlass and partial label queries, and batch mode active learning. We also\\ndiscuss an approximate version of interest when there are very many queries.\\n',\n",
              " '  Information distance is a parameter-free similarity measure based on\\ncompression, used in pattern recognition, data mining, phylogeny, clustering,\\nand classification. The notion of information distance is extended from pairs\\nto multiples (finite lists). We study maximal overlap, metricity, universality,\\nminimal overlap, additivity, and normalized information distance in multiples.\\nWe use the theoretical notion of Kolmogorov complexity which for practical\\npurposes is approximated by the length of the compressed version of the file\\ninvolved, using a real-world compression program.\\n  {\\\\em Index Terms}-- Information distance, multiples, pattern recognition,\\ndata mining, similarity, Kolmogorov complexity\\n',\n",
              " '  We present a novel approach for learning nonlinear dynamic models, which\\nleads to a new set of tools capable of solving problems that are otherwise\\ndifficult. We provide theory showing this new approach is consistent for models\\nwith long range structure, and apply the approach to motion capture and\\nhigh-dimensional video data, yielding results superior to standard\\nalternatives.\\n',\n",
              " \"  Catalogs of periodic variable stars contain large numbers of periodic\\nlight-curves (photometric time series data from the astrophysics domain).\\nSeparating anomalous objects from well-known classes is an important step\\ntowards the discovery of new classes of astronomical objects. Most anomaly\\ndetection methods for time series data assume either a single continuous time\\nseries or a set of time series whose periods are aligned. Light-curve data\\nprecludes the use of these methods as the periods of any given pair of\\nlight-curves may be out of sync. One may use an existing anomaly detection\\nmethod if, prior to similarity calculation, one performs the costly act of\\naligning two light-curves, an operation that scales poorly to massive data\\nsets. This paper presents PCAD, an unsupervised anomaly detection method for\\nlarge sets of unsynchronized periodic time-series data, that outputs a ranked\\nlist of both global and local anomalies. It calculates its anomaly score for\\neach light-curve in relation to a set of centroids produced by a modified\\nk-means clustering algorithm. Our method is able to scale to large data sets\\nthrough the use of sampling. We validate our method on both light-curve data\\nand other time series data sets. We demonstrate its effectiveness at finding\\nknown anomalies, and discuss the effect of sample size and number of centroids\\non our results. We compare our method to naive solutions and existing time\\nseries anomaly detection methods for unphased data, and show that PCAD's\\nreported anomalies are comparable to or better than all other methods. Finally,\\nastrophysicists on our team have verified that PCAD finds true anomalies that\\nmight be indicative of novel astrophysical phenomena.\\n\",\n",
              " '  This paper studies quantum annealing (QA) for clustering, which can be seen\\nas an extension of simulated annealing (SA). We derive a QA algorithm for\\nclustering and propose an annealing schedule, which is crucial in practice.\\nExperiments show the proposed QA algorithm finds better clustering assignments\\nthan SA. Furthermore, QA is as easy as SA to implement.\\n',\n",
              " '  This paper presents studies on a deterministic annealing algorithm based on\\nquantum annealing for variational Bayes (QAVB) inference, which can be seen as\\nan extension of the simulated annealing for variational Bayes (SAVB) inference.\\nQAVB is as easy as SAVB to implement. Experiments revealed QAVB finds a better\\nlocal optimum than SAVB in terms of the variational free energy in latent\\nDirichlet allocation (LDA).\\n',\n",
              " '  We use co-evolutionary genetic algorithms to model the players\\' learning\\nprocess in several Cournot models, and evaluate them in terms of their\\nconvergence to the Nash Equilibrium. The \"social-learning\" versions of the two\\nco-evolutionary algorithms we introduce, establish Nash Equilibrium in those\\nmodels, in contrast to the \"individual learning\" versions which, as we see\\nhere, do not imply the convergence of the players\\' strategies to the Nash\\noutcome. When players use \"canonical co-evolutionary genetic algorithms\" as\\nlearning algorithms, the process of the game is an ergodic Markov Chain, and\\ntherefore we analyze simulation results using both the relevant methodology and\\nmore general statistical tests, to find that in the \"social\" case, states\\nleading to NE play are highly frequent at the stationary distribution of the\\nchain, in contrast to the \"individual learning\" case, when NE is not reached at\\nall in our simulations; to find that the expected Hamming distance of the\\nstates at the limiting distribution from the \"NE state\" is significantly\\nsmaller in the \"social\" than in the \"individual learning case\"; to estimate the\\nexpected time that the \"social\" algorithms need to get to the \"NE state\" and\\nverify their robustness and finally to show that a large fraction of the games\\nplayed are indeed at the Nash Equilibrium.\\n',\n",
              " \"  We present three related ways of using Transfer Learning to improve feature\\nselection. The three methods address different problems, and hence share\\ndifferent kinds of information between tasks or feature classes, but all three\\nare based on the information theoretic Minimum Description Length (MDL)\\nprinciple and share the same underlying Bayesian interpretation. The first\\nmethod, MIC, applies when predictive models are to be built simultaneously for\\nmultiple tasks (``simultaneous transfer'') that share the same set of features.\\nMIC allows each feature to be added to none, some, or all of the task models\\nand is most beneficial for selecting a small set of predictive features from a\\nlarge pool of features, as is common in genomic and biological datasets. Our\\nsecond method, TPC (Three Part Coding), uses a similar methodology for the case\\nwhen the features can be divided into feature classes. Our third method,\\nTransfer-TPC, addresses the ``sequential transfer'' problem in which the task\\nto which we want to transfer knowledge may not be known in advance and may have\\ndifferent amounts of data than the other tasks. Transfer-TPC is most beneficial\\nwhen we want to transfer knowledge between tasks which have unequal amounts of\\nlabeled data, for example the data for disambiguating the senses of different\\nverbs. We demonstrate the effectiveness of these approaches with experimental\\nresults on real world data pertaining to genomics and to Word Sense\\nDisambiguation (WSD).\\n\",\n",
              " '  Many regression problems involve not one but several response variables\\n(y\\'s). Often the responses are suspected to share a common underlying\\nstructure, in which case it may be advantageous to share information across\\nthem; this is known as multitask learning. As a special case, we can use\\nmultiple responses to better identify shared predictive features -- a project\\nwe might call multitask feature selection.\\n  This thesis is organized as follows. Section 1 introduces feature selection\\nfor regression, focusing on ell_0 regularization methods and their\\ninterpretation within a Minimum Description Length (MDL) framework. Section 2\\nproposes a novel extension of MDL feature selection to the multitask setting.\\nThe approach, called the \"Multiple Inclusion Criterion\" (MIC), is designed to\\nborrow information across regression tasks by more easily selecting features\\nthat are associated with multiple responses. We show in experiments on\\nsynthetic and real biological data sets that MIC can reduce prediction error in\\nsettings where features are at least partially shared across responses. Section\\n3 surveys hypothesis testing by regression with a single response, focusing on\\nthe parallel between the standard Bonferroni correction and an MDL approach.\\nMirroring the ideas in Section 2, Section 4 proposes a novel MIC approach to\\nhypothesis testing with multiple responses and shows that on synthetic data\\nwith significant sharing of features across responses, MIC sometimes\\noutperforms standard FDR-controlling methods in terms of finding true positives\\nfor a given level of false positives. Section 5 concludes.\\n',\n",
              " '  Many learning machines that have hierarchical structure or hidden variables\\nare now being used in information science, artificial intelligence, and\\nbioinformatics. However, several learning machines used in such fields are not\\nregular but singular statistical models, hence their generalization performance\\nis still left unknown. To overcome these problems, in the previous papers, we\\nproved new equations in statistical learning, by which we can estimate the\\nBayes generalization loss from the Bayes training loss and the functional\\nvariance, on the condition that the true distribution is a singularity\\ncontained in a learning machine. In this paper, we prove that the same\\nequations hold even if a true distribution is not contained in a parametric\\nmodel. Also we prove that, the proposed equations in a regular case are\\nasymptotically equivalent to the Takeuchi information criterion. Therefore, the\\nproposed equations are always applicable without any condition on the unknown\\ntrue distribution.\\n',\n",
              " '  The problem of classifying sonar signals from rocks and mines first studied\\nby Gorman and Sejnowski has become a benchmark against which many learning\\nalgorithms have been tested. We show that both the training set and the test\\nset of this benchmark are linearly separable, although with different\\nhyperplanes. Moreover, the complete set of learning and test patterns together,\\nis also linearly separable. We give the weights that separate these sets, which\\nmay be used to compare results found by other algorithms.\\n',\n",
              " '  The avalanche quantity of the information developed by mankind has led to\\nconcept of automation of knowledge extraction - Data Mining ([1]). This\\ndirection is connected with a wide spectrum of problems - from recognition of\\nthe fuzzy set to creation of search machines. Important component of Data\\nMining is processing of the text information. Such problems lean on concept of\\nclassification and clustering ([2]). Classification consists in definition of\\nan accessory of some element (text) to one of in advance created classes.\\nClustering means splitting a set of elements (texts) on clusters which quantity\\nare defined by localization of elements of the given set in vicinities of these\\nsome natural centers of these clusters. Realization of a problem of\\nclassification initially should lean on the given postulates, basic of which -\\nthe aprioristic information on primary set of texts and a measure of affinity\\nof elements and classes.\\n',\n",
              " '  An approach to the acceleration of parametric weak classifier boosting is\\nproposed. Weak classifier is called parametric if it has fixed number of\\nparameters and, so, can be represented as a point into multidimensional space.\\nGenetic algorithm is used instead of exhaustive search to learn parameters of\\nsuch classifier. Proposed approach also takes cases when effective algorithm\\nfor learning some of the classifier parameters exists into account. Experiments\\nconfirm that such an approach can dramatically decrease classifier training\\ntime while keeping both training and test errors small.\\n',\n",
              " '  General-purpose, intelligent, learning agents cycle through sequences of\\nobservations, actions, and rewards that are complex, uncertain, unknown, and\\nnon-Markovian. On the other hand, reinforcement learning is well-developed for\\nsmall finite state Markov decision processes (MDPs). Up to now, extracting the\\nright state representations out of bare observations, that is, reducing the\\ngeneral agent setup to the MDP framework, is an art that involves significant\\neffort by designers. The primary goal of this work is to automate the reduction\\nprocess and thereby significantly expand the scope of many existing\\nreinforcement learning algorithms and the agents that employ them. Before we\\ncan think of mechanizing this search for suitable MDPs, we need a formal\\nobjective criterion. The main contribution of this article is to develop such a\\ncriterion. I also integrate the various parts into one learning algorithm.\\nExtensions to more realistic dynamic Bayesian networks are developed in Part\\nII. The role of POMDPs is also considered there.\\n',\n",
              " '  KNN is one of the most popular classification methods, but it often fails to\\nwork well with inappropriate choice of distance metric or due to the presence\\nof numerous class-irrelevant features. Linear feature transformation methods\\nhave been widely applied to extract class-relevant information to improve kNN\\nclassification, which is very limited in many applications. Kernels have been\\nused to learn powerful non-linear feature transformations, but these methods\\nfail to scale to large datasets. In this paper, we present a scalable\\nnon-linear feature mapping method based on a deep neural network pretrained\\nwith restricted boltzmann machines for improving kNN classification in a\\nlarge-margin framework, which we call DNet-kNN. DNet-kNN can be used for both\\nclassification and for supervised dimensionality reduction. The experimental\\nresults on two benchmark handwritten digit datasets show that DNet-kNN has much\\nbetter performance than large-margin kNN using a linear mapping and kNN based\\non a deep autoencoder pretrained with retricted boltzmann machines.\\n',\n",
              " \"  Given a matrix M of low-rank, we consider the problem of reconstructing it\\nfrom noisy observations of a small, random subset of its entries. The problem\\narises in a variety of applications, from collaborative filtering (the `Netflix\\nproblem') to structure-from-motion and positioning. We study a low complexity\\nalgorithm introduced by Keshavan et al.(2009), based on a combination of\\nspectral techniques and manifold optimization, that we call here OptSpace. We\\nprove performance guarantees that are order-optimal in a number of\\ncircumstances.\\n\",\n",
              " '  Clusters of genes that have evolved by repeated segmental duplication present\\ndifficult challenges throughout genomic analysis, from sequence assembly to\\nfunctional analysis. Improved understanding of these clusters is of utmost\\nimportance, since they have been shown to be the source of evolutionary\\ninnovation, and have been linked to multiple diseases, including HIV and a\\nvariety of cancers. Previously, Zhang et al. (2008) developed an algorithm for\\nreconstructing parsimonious evolutionary histories of such gene clusters, using\\nonly human genomic sequence data. In this paper, we propose a probabilistic\\nmodel for the evolution of gene clusters on a phylogeny, and an MCMC algorithm\\nfor reconstruction of duplication histories from genomic sequences in multiple\\nspecies. Several projects are underway to obtain high quality BAC-based\\nassemblies of duplicated clusters in multiple species, and we anticipate that\\nour method will be useful in analyzing these valuable new data sets.\\n',\n",
              " '  The paper proposes a new message passing algorithm for cycle-free factor\\ngraphs. The proposed \"entropy message passing\" (EMP) algorithm may be viewed as\\nsum-product message passing over the entropy semiring, which has previously\\nappeared in automata theory. The primary use of EMP is to compute the entropy\\nof a model. However, EMP can also be used to compute expressions that appear in\\nexpectation maximization and in gradient descent algorithms.\\n',\n",
              " '  Traffic forecasting from past observed traffic data with small calculation\\ncomplexity is one of important problems for planning of servers and networks.\\nFocusing on World Wide Web (WWW) traffic as fundamental investigation, this\\npaper would deal with Bayesian forecasting of network traffic on the time\\nvarying Poisson model from a viewpoint from statistical decision theory. Under\\nthis model, we would show that the estimated forecasting value is obtained by\\nsimple arithmetic calculation and expresses real WWW traffic well from both\\ntheoretical and empirical points of view.\\n',\n",
              " '  In this paper, we present two classes of Bayesian approaches to the\\ntwo-sample problem. Our first class of methods extends the Bayesian t-test to\\ninclude all parametric models in the exponential family and their conjugate\\npriors. Our second class of methods uses Dirichlet process mixtures (DPM) of\\nsuch conjugate-exponential distributions as flexible nonparametric priors over\\nthe unknown distributions.\\n',\n",
              " '  In this paper, the mining of hybrid association rules with rough set approach\\nis investigated as the algorithm RSHAR.The RSHAR algorithm is constituted of\\ntwo steps mainly. At first, to join the participant tables into a general table\\nto generate the rules which is expressing the relationship between two or more\\ndomains that belong to several different tables in a database. Then we apply\\nthe mapping code on selected dimension, which can be added directly into the\\ninformation system as one certain attribute. To find the association rules,\\nfrequent itemsets are generated in second step where candidate itemsets are\\ngenerated through equivalence classes and also transforming the mapping code in\\nto real dimensions. The searching method for candidate itemset is similar to\\napriori algorithm. The analysis of the performance of algorithm has been\\ncarried out.\\n',\n",
              " '  Two ubiquitous aspects of large-scale data analysis are that the data often\\nhave heavy-tailed properties and that diffusion-based or spectral-based methods\\nare often used to identify and extract structure of interest. Perhaps\\nsurprisingly, popular distribution-independent methods such as those based on\\nthe VC dimension fail to provide nontrivial results for even simple learning\\nproblems such as binary classification in these two settings. In this paper, we\\ndevelop distribution-dependent learning methods that can be used to provide\\ndimension-independent sample complexity bounds for the binary classification\\nproblem in these two popular settings. In particular, we provide bounds on the\\nsample complexity of maximum margin classifiers when the magnitude of the\\nentries in the feature vector decays according to a power law and also when\\nlearning is performed with the so-called Diffusion Maps kernel. Both of these\\nresults rely on bounding the annealed entropy of gap-tolerant classifiers in a\\nHilbert space. We provide such a bound, and we demonstrate that our proof\\ntechnique generalizes to the case when the margin is measured with respect to\\nmore general Banach space norms. The latter result is of potential interest in\\ncases where modeling the relationship between data elements as a dot product in\\na Hilbert space is too restrictive.\\n',\n",
              " '  In recent years, the spectral analysis of appropriately defined kernel\\nmatrices has emerged as a principled way to extract the low-dimensional\\nstructure often prevalent in high-dimensional data. Here we provide an\\nintroduction to spectral methods for linear and nonlinear dimension reduction,\\nemphasizing ways to overcome the computational limitations currently faced by\\npractitioners with massive datasets. In particular, a data subsampling or\\nlandmark selection process is often employed to construct a kernel based on\\npartial information, followed by an approximate spectral analysis termed the\\nNystrom extension. We provide a quantitative framework to analyse this\\nprocedure, and use it to demonstrate algorithmic performance bounds on a range\\nof practical approaches designed to optimize the landmark selection process. We\\ncompare the practical implications of these bounds by way of real-world\\nexamples drawn from the field of computer vision, whereby low-dimensional\\nmanifold structure is shown to emerge from high-dimensional video data streams.\\n',\n",
              " '  In this paper, we present the step by step knowledge acquisition process by\\nchoosing a structured method through using a questionnaire as a knowledge\\nacquisition tool. Here we want to depict the problem domain as, how to evaluate\\nteachers performance in higher education through the use of expert system\\ntechnology. The problem is how to acquire the specific knowledge for a selected\\nproblem efficiently and effectively from human experts and encode it in the\\nsuitable computer format. Acquiring knowledge from human experts in the process\\nof expert systems development is one of the most common problems cited till\\nyet. This questionnaire was sent to 87 domain experts within all public and\\nprivate universities in Pakistani. Among them 25 domain experts sent their\\nvaluable opinions. Most of the domain experts were highly qualified, well\\nexperienced and highly responsible persons. The whole questionnaire was divided\\ninto 15 main groups of factors, which were further divided into 99 individual\\nquestions. These facts were analyzed further to give a final shape to the\\nquestionnaire. This knowledge acquisition technique may be used as a learning\\ntool for further research work.\\n',\n",
              " '  Fitting probabilistic models to data is often difficult, due to the general\\nintractability of the partition function and its derivatives. Here we propose a\\nnew parameter estimation technique that does not require computing an\\nintractable normalization factor or sampling from the equilibrium distribution\\nof the model. This is achieved by establishing dynamics that would transform\\nthe observed data distribution into the model distribution, and then setting as\\nthe objective the minimization of the KL divergence between the data\\ndistribution and the distribution produced by running the dynamics for an\\ninfinitesimal time. Score matching, minimum velocity learning, and certain\\nforms of contrastive divergence are shown to be special cases of this learning\\ntechnique. We demonstrate parameter estimation in Ising models, deep belief\\nnetworks and an independent component analysis model of natural scenes. In the\\nIsing model case, current state of the art techniques are outperformed by at\\nleast an order of magnitude in learning time, with lower error in recovered\\ncoupling parameters.\\n',\n",
              " \"  Security protocols often use randomization to achieve probabilistic\\nnon-determinism. This non-determinism, in turn, is used in obfuscating the\\ndependence of observable values on secret data. Since the correctness of\\nsecurity protocols is very important, formal analysis of security protocols has\\nbeen widely studied in literature. Randomized security protocols have also been\\nanalyzed using formal techniques such as process-calculi and probabilistic\\nmodel checking. In this paper, we consider the problem of validating\\nimplementations of randomized protocols. Unlike previous approaches which treat\\nthe protocol as a white-box, our approach tries to verify an implementation\\nprovided as a black box. Our goal is to infer the secrecy guarantees provided\\nby a security protocol through statistical techniques. We learn the\\nprobabilistic dependency of the observable outputs on secret inputs using\\nBayesian network. This is then used to approximate the leakage of secret. In\\norder to evaluate the accuracy of our statistical approach, we compare our\\ntechnique with the probabilistic model checking technique on two examples:\\ncrowds protocol and dining crypotgrapher's protocol.\\n\",\n",
              " '  We describe an adaptation and application of a search-based structured\\nprediction algorithm \"Searn\" to unsupervised learning problems. We show that it\\nis possible to reduce unsupervised learning to supervised learning and\\ndemonstrate a high-quality unsupervised shift-reduce parsing model. We\\nadditionally show a close connection between unsupervised Searn and expectation\\nmaximization. Finally, we demonstrate the efficacy of a semi-supervised\\nextension. The key idea that enables this is an application of the predict-self\\nidea for unsupervised learning.\\n',\n",
              " \"  In our previous work, we proposed a systematic cross-layer framework for\\ndynamic multimedia systems, which allows each layer to make autonomous and\\nforesighted decisions that maximize the system's long-term performance, while\\nmeeting the application's real-time delay constraints. The proposed solution\\nsolved the cross-layer optimization offline, under the assumption that the\\nmultimedia system's probabilistic dynamics were known a priori. In practice,\\nhowever, these dynamics are unknown a priori and therefore must be learned\\nonline. In this paper, we address this problem by allowing the multimedia\\nsystem layers to learn, through repeated interactions with each other, to\\nautonomously optimize the system's long-term performance at run-time. We\\npropose two reinforcement learning algorithms for optimizing the system under\\ndifferent design constraints: the first algorithm solves the cross-layer\\noptimization in a centralized manner, and the second solves it in a\\ndecentralized manner. We analyze both algorithms in terms of their required\\ncomputation, memory, and inter-layer communication overheads. After noting that\\nthe proposed reinforcement learning algorithms learn too slowly, we introduce a\\ncomplementary accelerated learning algorithm that exploits partial knowledge\\nabout the system's dynamics in order to dramatically improve the system's\\nperformance. In our experiments, we demonstrate that decentralized learning can\\nperform as well as centralized learning, while enabling the layers to act\\nautonomously. Additionally, we show that existing application-independent\\nreinforcement learning algorithms, and existing myopic learning algorithms\\ndeployed in multimedia systems, perform significantly worse than our proposed\\napplication-aware and foresighted learning methods.\\n\",\n",
              " '  This article describes a new type of artificial neuron, called the authors\\n\"cyberneuron\". Unlike classical models of artificial neurons, this type of\\nneuron used table substitution instead of the operation of multiplication of\\ninput values for the weights. This allowed to significantly increase the\\ninformation capacity of a single neuron, but also greatly simplify the process\\nof learning. Considered an example of the use of \"cyberneuron\" with the task of\\ndetecting computer viruses.\\n',\n",
              " '  This paper has been withdrawn due to an error found by Dana Angluin and Lev\\nReyzin.\\n',\n",
              " '  Specialized intelligent systems can be found everywhere: finger print,\\nhandwriting, speech, and face recognition, spam filtering, chess and other game\\nprograms, robots, et al. This decade the first presumably complete mathematical\\ntheory of artificial intelligence based on universal\\ninduction-prediction-decision-action has been proposed. This\\ninformation-theoretic approach solidifies the foundations of inductive\\ninference and artificial intelligence. Getting the foundations right usually\\nmarks a significant progress and maturing of a field. The theory provides a\\ngold standard and guidance for researchers working on intelligent algorithms.\\nThe roots of universal induction have been laid exactly half-a-century ago and\\nthe roots of universal intelligence exactly one decade ago. So it is timely to\\ntake stock of what has been achieved and what remains to be done. Since there\\nare already good recent surveys, I describe the state-of-the-art only in\\npassing and refer the reader to the literature. This article concentrates on\\nthe open problems in universal induction and its extension to universal\\nintelligence.\\n',\n",
              " '  We learn multiple hypotheses for related tasks under a latent hierarchical\\nrelationship between tasks. We exploit the intuition that for domain\\nadaptation, we wish to share classifier structure, but for multitask learning,\\nwe wish to share covariance structure. Our hierarchical model is seen to\\nsubsume several previously proposed multitask learning models and performs well\\non three distinct real-world data sets.\\n',\n",
              " '  We present an algorithmic framework for learning multiple related tasks. Our\\nframework exploits a form of prior knowledge that relates the output spaces of\\nthese tasks. We present PAC learning results that analyze the conditions under\\nwhich such learning is possible. We present results on learning a shallow\\nparser and named-entity recognition system that exploits our framework, showing\\nconsistent improvements over baseline methods.\\n',\n",
              " '  We present Searn, an algorithm for integrating search and learning to solve\\ncomplex structured prediction problems such as those that occur in natural\\nlanguage, speech, computational biology, and vision. Searn is a meta-algorithm\\nthat transforms these complex problems into simple classification problems to\\nwhich any binary classifier may be applied. Unlike current algorithms for\\nstructured learning that require decomposition of both the loss function and\\nthe feature functions over the predicted structure, Searn is able to learn\\nprediction functions for any loss function and any class of features. Moreover,\\nSearn comes with a strong, natural theoretical guarantee: good performance on\\nthe derived classification problems implies good performance on the structured\\nprediction problem.\\n',\n",
              " '  We develop a Bayesian framework for tackling the supervised clustering\\nproblem, the generic problem encountered in tasks such as reference matching,\\ncoreference resolution, identity uncertainty and record linkage. Our clustering\\nmodel is based on the Dirichlet process prior, which enables us to define\\ndistributions over the countably infinite sets that naturally arise in this\\nproblem. We add supervision to our model by positing the existence of a set of\\nunobserved random variables (we call these \"reference types\") that are generic\\nacross all clusters. Inference in our framework, which requires integrating\\nover infinitely many parameters, is solved using Markov chain Monte Carlo\\ntechniques. We present algorithms for both conjugate and non-conjugate priors.\\nWe present a simple--but general--parameterization of our model based on a\\nGaussian assumption. We evaluate this model on one artificial task and three\\nreal-world tasks, comparing it against both unsupervised and state-of-the-art\\nsupervised algorithms. Our results show that our model is able to outperform\\nother models across a variety of tasks and performance metrics.\\n',\n",
              " '  Mappings to structured output spaces (strings, trees, partitions, etc.) are\\ntypically learned using extensions of classification algorithms to simple\\ngraphical structures (eg., linear chains) in which search and parameter\\nestimation can be performed exactly. Unfortunately, in many complex problems,\\nit is rare that exact search or parameter estimation is tractable. Instead of\\nlearning exact models and searching via heuristic means, we embrace this\\ndifficulty and treat the structured output problem in terms of approximate\\nsearch. We present a framework for learning as search optimization, and two\\nparameter updates with convergence theorems and bounds. Empirical evidence\\nshows that our integrated approach to learning and decoding can outperform\\nexact models at smaller computational cost.\\n',\n",
              " '  In this paper we present a method for learning the parameters of a mixture of\\n$k$ identical spherical Gaussians in $n$-dimensional space with an arbitrarily\\nsmall separation between the components. Our algorithm is polynomial in all\\nparameters other than $k$. The algorithm is based on an appropriate grid search\\nover the space of parameters. The theoretical analysis of the algorithm hinges\\non a reduction of the problem to 1 dimension and showing that two 1-dimensional\\nmixtures whose densities are close in the $L^2$ norm must have similar means\\nand mixing coefficients. To produce such a lower bound for the $L^2$ norm in\\nterms of the distances between the corresponding means, we analyze the behavior\\nof the Fourier transform of a mixture of Gaussians in 1 dimension around the\\norigin, which turns out to be closely related to the properties of the\\nVandermonde matrix obtained from the component means. Analysis of this matrix\\ntogether with basic function approximation results allows us to provide a lower\\nbound for the norm of the mixture in the Fourier domain.\\n  In recent years much research has been aimed at understanding the\\ncomputational aspects of learning parameters of Gaussians mixture distributions\\nin high dimension. To the best of our knowledge all existing work on learning\\nparameters of Gaussian mixtures assumes minimum separation between components\\nof the mixture which is an increasing function of either the dimension of the\\nspace $n$ or the number of components $k$. In our paper we prove the first\\nresult showing that parameters of a $n$-dimensional Gaussian mixture model with\\narbitrarily small component separation can be learned in time polynomial in\\n$n$.\\n',\n",
              " '  This paper is withdrawn due to some errors, which are corrected in\\narXiv:0912.0071v4 [cs.LG].\\n',\n",
              " '  Dirichlet process (DP) mixture models provide a flexible Bayesian framework\\nfor density estimation. Unfortunately, their flexibility comes at a cost:\\ninference in DP mixture models is computationally expensive, even when\\nconjugate distributions are used. In the common case when one seeks only a\\nmaximum a posteriori assignment of data points to clusters, we show that search\\nalgorithms provide a practical alternative to expensive MCMC and variational\\ntechniques. When a true posterior sample is desired, the solution found by\\nsearch can serve as a good initializer for MCMC. Experimental results show that\\nusing these techniques is it possible to apply DP mixture models to very large\\ndata sets.\\n',\n",
              " \"  We present BayeSum (for ``Bayesian summarization''), a model for sentence\\nextraction in query-focused summarization. BayeSum leverages the common case in\\nwhich multiple documents are relevant to a single query. Using these documents\\nas reinforcement for query terms, BayeSum is not afflicted by the paucity of\\ninformation in short queries. We show that approximate inference in BayeSum is\\npossible on large data sets and results in a state-of-the-art summarization\\nsystem. Furthermore, we show how BayeSum can be understood as a justified query\\nexpansion technique in the language modeling for IR framework.\\n\",\n",
              " \"  We describe an approach to domain adaptation that is appropriate exactly in\\nthe case when one has enough ``target'' data to do slightly better than just\\nusing only ``source'' data. Our approach is incredibly simple, easy to\\nimplement as a preprocessing step (10 lines of Perl!) and outperforms\\nstate-of-the-art approaches on a range of datasets. Moreover, it is trivially\\nextended to a multi-domain adaptation problem, where one has data from a\\nvariety of different domains.\\n\",\n",
              " '  We consider a class of fully stochastic and fully distributed algorithms,\\nthat we prove to learn equilibria in games.\\n  Indeed, we consider a family of stochastic distributed dynamics that we prove\\nto converge weakly (in the sense of weak convergence for probabilistic\\nprocesses) towards their mean-field limit, i.e an ordinary differential\\nequation (ODE) in the general case. We focus then on a class of stochastic\\ndynamics where this ODE turns out to be related to multipopulation replicator\\ndynamics.\\n  Using facts known about convergence of this ODE, we discuss the convergence\\nof the initial stochastic dynamics: For general games, there might be\\nnon-convergence, but when convergence of the ODE holds, considered stochastic\\nalgorithms converge towards Nash equilibria. For games admitting Lyapunov\\nfunctions, that we call Lyapunov games, the stochastic dynamics converge. We\\nprove that any ordinal potential game, and hence any potential game is a\\nLyapunov game, with a multiaffine Lyapunov function. For Lyapunov games with a\\nmultiaffine Lyapunov function, we prove that this Lyapunov function is a\\nsuper-martingale over the stochastic dynamics. This leads a way to provide\\nbounds on their time of convergence by martingale arguments. This applies in\\nparticular for many classes of games that have been considered in literature,\\nincluding several load balancing game scenarios and congestion games.\\n',\n",
              " '  Principal component analysis (PCA) is a widely used technique for data\\nanalysis and dimension reduction with numerous applications in science and\\nengineering. However, the standard PCA suffers from the fact that the principal\\ncomponents (PCs) are usually linear combinations of all the original variables,\\nand it is thus often difficult to interpret the PCs. To alleviate this\\ndrawback, various sparse PCA approaches were proposed in literature [15, 6, 17,\\n28, 8, 25, 18, 7, 16]. Despite success in achieving sparsity, some important\\nproperties enjoyed by the standard PCA are lost in these methods such as\\nuncorrelation of PCs and orthogonality of loading vectors. Also, the total\\nexplained variance that they attempt to maximize can be too optimistic. In this\\npaper we propose a new formulation for sparse PCA, aiming at finding sparse and\\nnearly uncorrelated PCs with orthogonal loading vectors while explaining as\\nmuch of the total variance as possible. We also develop a novel augmented\\nLagrangian method for solving a class of nonsmooth constrained optimization\\nproblems, which is well suited for our formulation of sparse PCA. We show that\\nit converges to a feasible point, and moreover under some regularity\\nassumptions, it converges to a stationary point. Additionally, we propose two\\nnonmonotone gradient methods for solving the augmented Lagrangian subproblems,\\nand establish their global and local convergence. Finally, we compare our\\nsparse PCA approach with several existing methods on synthetic, random, and\\nreal data, respectively. The computational results demonstrate that the sparse\\nPCs produced by our approach substantially outperform those by other methods in\\nterms of total explained variance, correlation of PCs, and orthogonality of\\nloading vectors.\\n',\n",
              " '  This paper suggests the use of intelligent network-aware processing agents in\\nwireless local area network drivers to generate metrics for bandwidth\\nestimation based on real-time channel statistics to enable wireless multimedia\\napplication adaptation. Various configurations in the wireless digital home are\\nstudied and the experimental results with performance variations are presented.\\n',\n",
              " '  The paper describes a neural approach for modelling and control of a\\nturbocharged Diesel engine. A neural model, whose structure is mainly based on\\nsome physical equations describing the engine behaviour, is built for the\\nrotation speed and the exhaust gas opacity. The model is composed of three\\ninterconnected neural submodels, each of them constituting a nonlinear\\nmulti-input single-output error model. The structural identification and the\\nparameter estimation from data gathered on a real engine are described. The\\nneural direct model is then used to determine a neural controller of the\\nengine, in a specialized training scheme minimising a multivariable criterion.\\nSimulations show the effect of the pollution constraint weighting on a\\ntrajectory tracking of the engine speed. Neural networks, which are flexible\\nand parsimonious nonlinear black-box models, with universal approximation\\ncapabilities, can accurately describe or control complex nonlinear systems,\\nwith little a priori theoretical knowledge. The presented work extends optimal\\nneuro-control to the multivariable case and shows the flexibility of neural\\noptimisers. Considering the preliminary results, it appears that neural\\nnetworks can be used as embedded models for engine control, to satisfy the more\\nand more restricting pollutant emission legislation. Particularly, they are\\nable to model nonlinear dynamics and outperform during transients the control\\nschemes based on static mappings.\\n',\n",
              " '  In a multi-armed bandit (MAB) problem, an online algorithm makes a sequence\\nof choices. In each round it chooses from a time-invariant set of alternatives\\nand receives the payoff associated with this alternative. While the case of\\nsmall strategy sets is by now well-understood, a lot of recent work has focused\\non MAB problems with exponentially or infinitely large strategy sets, where one\\nneeds to assume extra structure in order to make the problem tractable. In\\nparticular, recent literature considered information on similarity between\\narms.\\n  We consider similarity information in the setting of \"contextual bandits\", a\\nnatural extension of the basic MAB problem where before each round an algorithm\\nis given the \"context\" -- a hint about the payoffs in this round. Contextual\\nbandits are directly motivated by placing advertisements on webpages, one of\\nthe crucial problems in sponsored search. A particularly simple way to\\nrepresent similarity information in the contextual bandit setting is via a\\n\"similarity distance\" between the context-arm pairs which gives an upper bound\\non the difference between the respective expected payoffs.\\n  Prior work on contextual bandits with similarity uses \"uniform\" partitions of\\nthe similarity space, which is potentially wasteful. We design more efficient\\nalgorithms that are based on adaptive partitions adjusted to \"popular\" context\\nand \"high-payoff\" arms.\\n',\n",
              " '  Sparse coding--that is, modelling data vectors as sparse linear combinations\\nof basis elements--is widely used in machine learning, neuroscience, signal\\nprocessing, and statistics. This paper focuses on the large-scale matrix\\nfactorization problem that consists of learning the basis set, adapting it to\\nspecific data. Variations of this problem include dictionary learning in signal\\nprocessing, non-negative matrix factorization and sparse principal component\\nanalysis. In this paper, we propose to address these tasks with a new online\\noptimization algorithm, based on stochastic approximations, which scales up\\ngracefully to large datasets with millions of training samples, and extends\\nnaturally to various matrix factorization formulations, making it suitable for\\na wide range of learning problems. A proof of convergence is presented, along\\nwith experiments with natural images and genomic data demonstrating that it\\nleads to state-of-the-art performance in terms of speed and optimization for\\nboth small and large datasets.\\n',\n",
              " '  We consider the task of opportunistic channel access in a primary system\\ncomposed of independent Gilbert-Elliot channels where the secondary (or\\nopportunistic) user does not dispose of a priori information regarding the\\nstatistical characteristics of the system. It is shown that this problem may be\\ncast into the framework of model-based learning in a specific class of\\nPartially Observed Markov Decision Processes (POMDPs) for which we introduce an\\nalgorithm aimed at striking an optimal tradeoff between the exploration (or\\nestimation) and exploitation requirements. We provide finite horizon regret\\nbounds for this algorithm as well as a numerical evaluation of its performance\\nin the single channel model as well as in the case of stochastically identical\\nchannels.\\n',\n",
              " \"  We propose a nonparametric Bayesian factor regression model that accounts for\\nuncertainty in the number of factors, and the relationship between factors. To\\naccomplish this, we propose a sparse variant of the Indian Buffet Process and\\ncouple this with a hierarchical model over factors, based on Kingman's\\ncoalescent. We apply this model to two problems (factor analysis and factor\\nregression) in gene-expression data analysis.\\n\",\n",
              " '  We present a streaming model for large-scale classification (in the context\\nof $\\\\ell_2$-SVM) by leveraging connections between learning and computational\\ngeometry. The streaming model imposes the constraint that only a single pass\\nover the data is allowed. The $\\\\ell_2$-SVM is known to have an equivalent\\nformulation in terms of the minimum enclosing ball (MEB) problem, and an\\nefficient algorithm based on the idea of \\\\emph{core sets} exists (Core Vector\\nMachine, CVM). CVM learns a $(1+\\\\varepsilon)$-approximate MEB for a set of\\npoints and yields an approximate solution to corresponding SVM instance.\\nHowever CVM works in batch mode requiring multiple passes over the data. This\\npaper presents a single-pass SVM which is based on the minimum enclosing ball\\nof streaming data. We show that the MEB updates for the streaming case can be\\neasily adapted to learn the SVM weight vector in a way similar to using online\\nstochastic gradient updates. Our algorithm performs polylogarithmic computation\\nat each example, and requires very small and constant storage. Experimental\\nresults show that, even in such restrictive settings, we can learn efficiently\\nin just one pass and get accuracies comparable to other state-of-the-art SVM\\nsolvers (batch and online). We also give an analysis of the algorithm, and\\ndiscuss some open issues and possible extensions.\\n',\n",
              " '  Which ads should we display in sponsored search in order to maximize our\\nrevenue? How should we dynamically rank information sources to maximize value\\nof information? These applications exhibit strong diminishing returns:\\nSelection of redundant ads and information sources decreases their marginal\\nutility. We show that these and other problems can be formalized as repeatedly\\nselecting an assignment of items to positions to maximize a sequence of\\nmonotone submodular functions that arrive one by one. We present an efficient\\nalgorithm for this general problem and analyze it in the no-regret model. Our\\nalgorithm possesses strong theoretical guarantees, such as a performance ratio\\nthat converges to the optimal constant of 1-1/e. We empirically evaluate our\\nalgorithm on two real-world online optimization problems on the web: ad\\nallocation with submodular utilities, and dynamically ranking blogs to detect\\ninformation cascades.\\n',\n",
              " '  The maze traversal problem (finding the shortest distance to the goal from\\nany position in a maze) has been an interesting challenge in computational\\nintelligence. Recent work has shown that the cellular simultaneous recurrent\\nneural network (CSRN) can solve this problem for simple mazes. This thesis\\nfocuses on exploiting relevant information about the maze to improve learning\\nand decrease the training time for the CSRN to solve mazes. Appropriate\\nvariables are identified to create useful clusters using relevant information.\\nThe CSRN was next modified to allow for an additional external input. With this\\nadditional input, several methods were tested and results show that clustering\\nthe mazes improves the overall learning of the traversal problem for the CSRN.\\n',\n",
              " '  In real life, media information has time attributes either implicitly or\\nexplicitly known as temporal data. This paper investigates the usefulness of\\napplying Bayesian classification to an interval encoded temporal database with\\nprioritized items. The proposed method performs temporal mining by encoding the\\ndatabase with weighted items which prioritizes the items according to their\\nimportance from the user perspective. Naive Bayesian classification helps in\\nmaking the resulting temporal rules more effective. The proposed priority based\\ntemporal mining (PBTM) method added with classification aids in solving\\nproblems in a well informed and systematic manner. The experimental results are\\nobtained from the complaints database of the telecommunications system, which\\nshows the feasibility of this method of classification based temporal mining.\\n',\n",
              " '  This work describes a method of approximating matrix permanents efficiently\\nusing belief propagation. We formulate a probability distribution whose\\npartition function is exactly the permanent, then use Bethe free energy to\\napproximate this partition function. After deriving some speedups to standard\\nbelief propagation, the resulting algorithm requires $(n^2)$ time per\\niteration. Finally, we demonstrate the advantages of using this approximation.\\n',\n",
              " \"  In this paper, we consider uplink transmissions involving multiple users\\ncommunicating with a base station over a fading channel. We assume that the\\nbase station does not coordinate the transmissions of the users and hence the\\nusers employ random access communication. The situation is modeled as a\\nnon-cooperative repeated game with incomplete information. Each user attempts\\nto minimize its long term power consumption subject to a minimum rate\\nrequirement. We propose a two timescale stochastic gradient algorithm (TTSGA)\\nfor tuning the users' transmission probabilities. The algorithm includes a\\n'waterfilling threshold update mechanism' that ensures that the rate\\nconstraints are satisfied. We prove that under the algorithm, the users'\\ntransmission probabilities converge to a Nash equilibrium. Moreover, we also\\nprove that the rate constraints are satisfied; this is also demonstrated using\\nsimulation studies.\\n\",\n",
              " '  We study the problem of estimating the time delay between two signals\\nrepresenting delayed, irregularly sampled and noisy versions of the same\\nunderlying pattern. We propose and demonstrate an evolutionary algorithm for\\nthe (hyper)parameter estimation of a kernel-based technique in the context of\\nan astronomical problem, namely estimating the time delay between two\\ngravitationally lensed signals from a distant quasar. Mixed types (integer and\\nreal) are used to represent variables within the evolutionary algorithm. We\\ntest the algorithm on several artificial data sets, and also on real\\nastronomical observations of quasar Q0957+561. By carrying out a statistical\\nanalysis of the results we present a detailed comparison of our method with the\\nmost popular methods for time delay estimation in astrophysics. Our method\\nyields more accurate and more stable time delay estimates: for Q0957+561, we\\nobtain 419.6 days for the time delay between images A and B. Our methodology\\ncan be readily applied to current state-of-the-art optical monitoring data in\\nastronomy, but can also be applied in other disciplines involving similar time\\nseries data.\\n',\n",
              " '  We develop abc-logitboost, based on the prior work on abc-boost and robust\\nlogitboost. Our extensive experiments on a variety of datasets demonstrate the\\nconsiderable improvement of abc-logitboost over logitboost and abc-mart.\\n',\n",
              " '  Detection of rare variants by resequencing is important for the\\nidentification of individuals carrying disease variants. Rapid sequencing by\\nnew technologies enables low-cost resequencing of target regions, although it\\nis still prohibitive to test more than a few individuals. In order to improve\\ncost trade-offs, it has recently been suggested to apply pooling designs which\\nenable the detection of carriers of rare alleles in groups of individuals.\\nHowever, this was shown to hold only for a relatively low number of individuals\\nin a pool, and requires the design of pooling schemes for particular cases.\\n  We propose a novel pooling design, based on a compressed sensing approach,\\nwhich is both general, simple and efficient. We model the experimental\\nprocedure and show via computer simulations that it enables the recovery of\\nrare allele carriers out of larger groups than were possible before, especially\\nin situations where high coverage is obtained for each individual.\\n  Our approach can also be combined with barcoding techniques to enhance\\nperformance and provide a feasible solution based on current resequencing\\ncosts. For example, when targeting a small enough genomic region (~100\\nbase-pairs) and using only ~10 sequencing lanes and ~10 distinct barcodes, one\\ncan recover the identity of 4 rare allele carriers out of a population of over\\n4000 individuals.\\n',\n",
              " '  The selection of features that are relevant for a prediction or\\nclassification problem is an important problem in many domains involving\\nhigh-dimensional data. Selecting features helps fighting the curse of\\ndimensionality, improving the performances of prediction or classification\\nmethods, and interpreting the application. In a nonlinear context, the mutual\\ninformation is widely used as relevance criterion for features and sets of\\nfeatures. Nevertheless, it suffers from at least three major limitations:\\nmutual information estimators depend on smoothing parameters, there is no\\ntheoretically justified stopping criterion in the feature selection greedy\\nprocedure, and the estimation itself suffers from the curse of dimensionality.\\nThis chapter shows how to deal with these problems. The two first ones are\\naddressed by using resampling techniques that provide a statistical basis to\\nselect the estimator parameters and to stop the search procedure. The third one\\nis addressed by modifying the mutual information criterion into a measure of\\nhow features are complementary (and not only informative) for the problem at\\nhand.\\n',\n",
              " '  Median clustering extends popular neural data analysis methods such as the\\nself-organizing map or neural gas to general data structures given by a\\ndissimilarity matrix only. This offers flexible and robust global data\\ninspection methods which are particularly suited for a variety of data as\\noccurs in biomedical domains. In this chapter, we give an overview about median\\nclustering and its properties and extensions, with a particular focus on\\nefficient implementations adapted to large scale data analysis.\\n',\n",
              " '  Background: Hidden Markov models are widely employed by numerous\\nbioinformatics programs used today. Applications range widely from comparative\\ngene prediction to time-series analyses of micro-array data. The parameters of\\nthe underlying models need to be adjusted for specific data sets, for example\\nthe genome of a particular species, in order to maximize the prediction\\naccuracy. Computationally efficient algorithms for parameter training are thus\\nkey to maximizing the usability of a wide range of bioinformatics applications.\\n  Results: We introduce two computationally efficient training algorithms, one\\nfor Viterbi training and one for stochastic expectation maximization (EM)\\ntraining, which render the memory requirements independent of the sequence\\nlength. Unlike the existing algorithms for Viterbi and stochastic EM training\\nwhich require a two-step procedure, our two new algorithms require only one\\nstep and scan the input sequence in only one direction. We also implement these\\ntwo new algorithms and the already published linear-memory algorithm for EM\\ntraining into the hidden Markov model compiler HMM-Converter and examine their\\nrespective practical merits for three small example models.\\n  Conclusions: Bioinformatics applications employing hidden Markov models can\\nuse the two algorithms in order to make Viterbi training and stochastic EM\\ntraining more computationally efficient. Using these algorithms, parameter\\ntraining can thus be attempted for more complex models and longer training\\nsequences. The two new algorithms have the added advantage of being easier to\\nimplement than the corresponding default algorithms for Viterbi training and\\nstochastic EM training.\\n',\n",
              " '  This paper introduces a principled approach for the design of a scalable\\ngeneral reinforcement learning agent. Our approach is based on a direct\\napproximation of AIXI, a Bayesian optimality notion for general reinforcement\\nlearning agents. Previously, it has been unclear whether the theory of AIXI\\ncould motivate the design of practical algorithms. We answer this hitherto open\\nquestion in the affirmative, by providing the first computationally feasible\\napproximation to the AIXI agent. To develop our approximation, we introduce a\\nnew Monte-Carlo Tree Search algorithm along with an agent-specific extension to\\nthe Context Tree Weighting algorithm. Empirically, we present a set of\\nencouraging results on a variety of stochastic and partially observable\\ndomains. We conclude by proposing a number of directions for future research.\\n',\n",
              " '  We consider the problem of high-dimensional non-linear variable selection for\\nsupervised learning. Our approach is based on performing linear selection among\\nexponentially many appropriately defined positive definite kernels that\\ncharacterize non-linear interactions between the original variables. To select\\nefficiently from these many kernels, we use the natural hierarchical structure\\nof the problem to extend the multiple kernel learning framework to kernels that\\ncan be embedded in a directed acyclic graph; we show that it is then possible\\nto perform kernel selection through a graph-adapted sparsity-inducing norm, in\\npolynomial time in the number of selected kernels. Moreover, we study the\\nconsistency of variable selection in high-dimensional settings, showing that\\nunder certain assumptions, our regularization framework allows a number of\\nirrelevant variables which is exponential in the number of observations. Our\\nsimulations on synthetic datasets and datasets from the UCI repository show\\nstate-of-the-art predictive performance for non-linear regression problems.\\n',\n",
              " '  Given $n$ points in a $d$ dimensional Euclidean space, the Minimum Enclosing\\nBall (MEB) problem is to find the ball with the smallest radius which contains\\nall $n$ points. We give a $O(nd\\\\Qcal/\\\\sqrt{\\\\epsilon})$ approximation algorithm\\nfor producing an enclosing ball whose radius is at most $\\\\epsilon$ away from\\nthe optimum (where $\\\\Qcal$ is an upper bound on the norm of the points). This\\nimproves existing results using \\\\emph{coresets}, which yield a $O(nd/\\\\epsilon)$\\ngreedy algorithm. Finding the Minimum Enclosing Convex Polytope (MECP) is a\\nrelated problem wherein a convex polytope of a fixed shape is given and the aim\\nis to find the smallest magnification of the polytope which encloses the given\\npoints. For this problem we present a $O(mnd\\\\Qcal/\\\\epsilon)$ approximation\\nalgorithm, where $m$ is the number of faces of the polytope. Our algorithms\\nborrow heavily from convex duality and recently developed techniques in\\nnon-smooth optimization, and are in contrast with existing methods which rely\\non geometric arguments. In particular, we specialize the excessive gap\\nframework of \\\\citet{Nesterov05a} to obtain our results.\\n',\n",
              " '  Conditional Random Fields (CRFs) constitute a popular and efficient approach\\nfor supervised sequence labelling. CRFs can cope with large description spaces\\nand can integrate some form of structural dependency between labels. In this\\ncontribution, we address the issue of efficient feature selection for CRFs\\nbased on imposing sparsity through an L1 penalty. We first show how sparsity of\\nthe parameter set can be exploited to significantly speed up training and\\nlabelling. We then introduce coordinate descent parameter update schemes for\\nCRFs with L1 regularization. We finally provide some empirical comparisons of\\nthe proposed approach with state-of-the-art CRF training strategies. In\\nparticular, it is shown that the proposed approach is able to take profit of\\nthe sparsity to speed up processing and hence potentially handle larger\\ndimensional models.\\n',\n",
              " '  Regularized risk minimization with the binary hinge loss and its variants\\nlies at the heart of many machine learning problems. Bundle methods for\\nregularized risk minimization (BMRM) and the closely related SVMStruct are\\nconsidered the best general purpose solvers to tackle this problem. It was\\nrecently shown that BMRM requires $O(1/\\\\epsilon)$ iterations to converge to an\\n$\\\\epsilon$ accurate solution. In the first part of the paper we use the\\nHadamard matrix to construct a regularized risk minimization problem and show\\nthat these rates cannot be improved. We then show how one can exploit the\\nstructure of the objective function to devise an algorithm for the binary hinge\\nloss which converges to an $\\\\epsilon$ accurate solution in\\n$O(1/\\\\sqrt{\\\\epsilon})$ iterations.\\n',\n",
              " '  The Web has enabled the availability of a huge amount of useful information,\\nbut has also eased the ability to spread false information and rumors across\\nmultiple sources, making it hard to distinguish between what is true and what\\nis not. Recent examples include the premature Steve Jobs obituary, the second\\nbankruptcy of United airlines, the creation of Black Holes by the operation of\\nthe Large Hadron Collider, etc. Since it is important to permit the expression\\nof dissenting and conflicting opinions, it would be a fallacy to try to ensure\\nthat the Web provides only consistent information. However, to help in\\nseparating the wheat from the chaff, it is essential to be able to determine\\ndependence between sources. Given the huge number of data sources and the vast\\nvolume of conflicting data available on the Web, doing so in a scalable manner\\nis extremely challenging and has not been addressed by existing work yet.\\n  In this paper, we present a set of research problems and propose some\\npreliminary solutions on the issues involved in discovering dependence between\\nsources. We also discuss how this knowledge can benefit a variety of\\ntechnologies, such as data integration and Web 2.0, that help users manage and\\naccess the totality of the available information from various sources.\\n',\n",
              " '  Pac-Bayes bounds are among the most accurate generalization bounds for\\nclassifiers learned from independently and identically distributed (IID) data,\\nand it is particularly so for margin classifiers: there have been recent\\ncontributions showing how practical these bounds can be either to perform model\\nselection (Ambroladze et al., 2007) or even to directly guide the learning of\\nlinear classifiers (Germain et al., 2009). However, there are many practical\\nsituations where the training data show some dependencies and where the\\ntraditional IID assumption does not hold. Stating generalization bounds for\\nsuch frameworks is therefore of the utmost interest, both from theoretical and\\npractical standpoints. In this work, we propose the first - to the best of our\\nknowledge - Pac-Bayes generalization bounds for classifiers trained on data\\nexhibiting interdependencies. The approach undertaken to establish our results\\nis based on the decomposition of a so-called dependency graph that encodes the\\ndependencies within the data, in sets of independent data, thanks to graph\\nfractional covers. Our bounds are very general, since being able to find an\\nupper bound on the fractional chromatic number of the dependency graph is\\nsufficient to get new Pac-Bayes bounds for specific settings. We show how our\\nresults can be used to derive bounds for ranking statistics (such as Auc) and\\nclassifiers trained on data distributed according to a stationary {\\\\ss}-mixing\\nprocess. In the way, we show how our approach seemlessly allows us to deal with\\nU-processes. As a side note, we also provide a Pac-Bayes generalization bound\\nfor classifiers learned on data from stationary $\\\\varphi$-mixing distributions.\\n',\n",
              " \"  This paper addresses the problem of finding the nearest neighbor (or one of\\nthe R-nearest neighbors) of a query object q in a database of n objects. In\\ncontrast with most existing approaches, we can only access the ``hidden'' space\\nin which the objects live through a similarity oracle. The oracle, given two\\nreference objects and a query object, returns the reference object closest to\\nthe query object. The oracle attempts to model the behavior of human users,\\ncapable of making statements about similarity, but not of assigning meaningful\\nnumerical values to distances between objects.\\n\",\n",
              " \"  For the universal hypothesis testing problem, where the goal is to decide\\nbetween the known null hypothesis distribution and some other unknown\\ndistribution, Hoeffding proposed a universal test in the nineteen sixties.\\nHoeffding's universal test statistic can be written in terms of\\nKullback-Leibler (K-L) divergence between the empirical distribution of the\\nobservations and the null hypothesis distribution. In this paper a modification\\nof Hoeffding's test is considered based on a relaxation of the K-L divergence\\ntest statistic, referred to as the mismatched divergence. The resulting\\nmismatched test is shown to be a generalized likelihood-ratio test (GLRT) for\\nthe case where the alternate distribution lies in a parametric family of the\\ndistributions characterized by a finite dimensional parameter, i.e., it is a\\nsolution to the corresponding composite hypothesis testing problem. For certain\\nchoices of the alternate distribution, it is shown that both the Hoeffding test\\nand the mismatched test have the same asymptotic performance in terms of error\\nexponents. A consequence of this result is that the GLRT is optimal in\\ndifferentiating a particular distribution from others in an exponential family.\\nIt is also shown that the mismatched test has a significant advantage over the\\nHoeffding test in terms of finite sample size performance. This advantage is\\ndue to the difference in the asymptotic variances of the two test statistics\\nunder the null hypothesis. In particular, the variance of the K-L divergence\\ngrows linearly with the alphabet size, making the test impractical for\\napplications involving large alphabet distributions. The variance of the\\nmismatched divergence on the other hand grows linearly with the dimension of\\nthe parameter space, and can hence be controlled through a prudent choice of\\nthe function class defining the mismatched divergence.\\n\",\n",
              " \"  We consider the problem of boosting the accuracy of weak learning algorithms\\nin the agnostic learning framework of Haussler (1992) and Kearns et al. (1992).\\nKnown algorithms for this problem (Ben-David et al., 2001; Gavinsky, 2002;\\nKalai et al., 2008) follow the same strategy as boosting algorithms in the PAC\\nmodel: the weak learner is executed on the same target function but over\\ndifferent distributions on the domain. We demonstrate boosting algorithms for\\nthe agnostic learning framework that only modify the distribution on the labels\\nof the points (or, equivalently, modify the target function). This allows\\nboosting a distribution-specific weak agnostic learner to a strong agnostic\\nlearner with respect to the same distribution.\\n  When applied to the weak agnostic parity learning algorithm of Goldreich and\\nLevin (1989) our algorithm yields a simple PAC learning algorithm for DNF and\\nan agnostic learning algorithm for decision trees over the uniform distribution\\nusing membership queries. These results substantially simplify Jackson's famous\\nDNF learning algorithm (1994) and the recent result of Gopalan et al. (2008).\\n  We also strengthen the connection to hard-core set constructions discovered\\nby Klivans and Servedio (1999) by demonstrating that hard-core set\\nconstructions that achieve the optimal hard-core set size (given by Holenstein\\n(2005) and Barak et al. (2009)) imply distribution-specific agnostic boosting\\nalgorithms. Conversely, our boosting algorithm gives a simple hard-core set\\nconstruction with an (almost) optimal hard-core set size.\\n\",\n",
              " '  Actor-Critic based approaches were among the first to address reinforcement\\nlearning in a general setting. Recently, these algorithms have gained renewed\\ninterest due to their generality, good convergence properties, and possible\\nbiological relevance. In this paper, we introduce an online temporal difference\\nbased actor-critic algorithm which is proved to converge to a neighborhood of a\\nlocal maximum of the average reward. Linear function approximation is used by\\nthe critic in order estimate the value function, and the temporal difference\\nsignal, which is passed from the critic to the actor. The main distinguishing\\nfeature of the present convergence proof is that both the actor and the critic\\noperate on a similar time scale, while in most current convergence proofs they\\nare required to have very different time scales in order to converge. Moreover,\\nthe same temporal difference signal is used to update the parameters of both\\nthe actor and the critic. A limitation of the proposed approach, compared to\\nresults available for two time scale convergence, is that convergence is\\nguaranteed only to a neighborhood of an optimal value, rather to an optimal\\nvalue itself. The single time scale and identical temporal difference signal\\nused by the actor and the critic, may provide a step towards constructing more\\nbiologically realistic models of reinforcement learning in the brain.\\n',\n",
              " '  We describe the Median K-Flats (MKF) algorithm, a simple online method for\\nhybrid linear modeling, i.e., for approximating data by a mixture of flats.\\nThis algorithm simultaneously partitions the data into clusters while finding\\ntheir corresponding best approximating l1 d-flats, so that the cumulative l1\\nerror is minimized. The current implementation restricts d-flats to be\\nd-dimensional linear subspaces. It requires a negligible amount of storage, and\\nits complexity, when modeling data consisting of N points in D-dimensional\\nEuclidean space with K d-dimensional linear subspaces, is of order O(n K d D+n\\nd^2 D), where n is the number of iterations required for convergence\\n(empirically on the order of 10^4). Since it is an online algorithm, data can\\nbe supplied to it incrementally and it can incrementally produce the\\ncorresponding output. The performance of the algorithm is carefully evaluated\\nusing synthetic and real data.\\n',\n",
              " '  Ensemble learning aims to improve generalization ability by using multiple\\nbase learners. It is well-known that to construct a good ensemble, the base\\nlearners should be accurate as well as diverse. In this paper, unlabeled data\\nis exploited to facilitate ensemble learning by helping augment the diversity\\namong the base learners. Specifically, a semi-supervised ensemble method named\\nUDEED is proposed. Unlike existing semi-supervised ensemble methods where\\nerror-prone pseudo-labels are estimated for unlabeled data to enlarge the\\nlabeled data to improve accuracy, UDEED works by maximizing accuracies of base\\nlearners on labeled data while maximizing diversity among them on unlabeled\\ndata. Experiments show that UDEED can effectively utilize unlabeled data for\\nensemble learning and is highly competitive to well-established semi-supervised\\nensemble methods.\\n',\n",
              " '  There has been a tremendous growth in publicly available digital video\\nfootage over the past decade. This has necessitated the development of new\\ntechniques in computer vision geared towards efficient analysis, storage and\\nretrieval of such data. Many mid-level computer vision tasks such as\\nsegmentation, object detection, tracking, etc. involve an inference problem\\nbased on the video data available. Video data has a high degree of spatial and\\ntemporal coherence. The property must be intelligently leveraged in order to\\nobtain better results.\\n  Graphical models, such as Markov Random Fields, have emerged as a powerful\\ntool for such inference problems. They are naturally suited for expressing the\\nspatial dependencies present in video data, It is however, not clear, how to\\nextend the existing techniques for the problem of inference over time. This\\nthesis explores the Path Probability Method, a variational technique in\\nstatistical mechanics, in the context of graphical models and approximate\\ninference problems. It extends the method to a general framework for problems\\ninvolving inference in time, resulting in an algorithm, \\\\emph{DynBP}. We\\nexplore the relation of the algorithm with existing techniques, and find the\\nalgorithm competitive with existing approaches.\\n  The main contribution of this thesis are the extended GBP algorithm, the\\nextension of Path Probability Methods to the DynBP algorithm and the\\nrelationship between them. We have also explored some applications in computer\\nvision involving temporal evolution with promising results.\\n',\n",
              " '  We propose a randomized algorithm for training Support vector machines(SVMs)\\non large datasets. By using ideas from Random projections we show that the\\ncombinatorial dimension of SVMs is $O({log} n)$ with high probability. This\\nestimate of combinatorial dimension is used to derive an iterative algorithm,\\ncalled RandSVM, which at each step calls an existing solver to train SVMs on a\\nrandomly chosen subset of size $O({log} n)$. The algorithm has probabilistic\\nguarantees and is capable of training SVMs with Kernels for both classification\\nand regression problems. Experiments done on synthetic and real life data sets\\ndemonstrate that the algorithm scales up existing SVM learners, without loss of\\naccuracy.\\n',\n",
              " '  The Minimum Description Length (MDL) principle selects the model that has the\\nshortest code for data plus model. We show that for a countable class of\\nmodels, MDL predictions are close to the true distribution in a strong sense.\\nThe result is completely general. No independence, ergodicity, stationarity,\\nidentifiability, or other assumption on the model class need to be made. More\\nformally, we show that for any countable class of models, the distributions\\nselected by MDL (or MAP) asymptotically predict (merge with) the true measure\\nin the class in total variation distance. Implications for non-i.i.d. domains\\nlike time-series forecasting, discriminative learning, and reinforcement\\nlearning are discussed.\\n',\n",
              " '  We investigate the problem of learning a topic model - the well-known Latent\\nDirichlet Allocation - in a distributed manner, using a cluster of C processors\\nand dividing the corpus to be learned equally among them. We propose a simple\\napproximated method that can be tuned, trading speed for accuracy according to\\nthe task at hand. Our approach is asynchronous, and therefore suitable for\\nclusters of heterogenous machines.\\n',\n",
              " '  Let $\\\\XX$ be a compact, smooth, connected, Riemannian manifold without\\nboundary, $G:\\\\XX\\\\times\\\\XX\\\\to \\\\RR$ be a kernel. Analogous to a radial basis\\nfunction network, an eignet is an expression of the form $\\\\sum_{j=1}^M\\na_jG(\\\\circ,y_j)$, where $a_j\\\\in\\\\RR$, $y_j\\\\in\\\\XX$, $1\\\\le j\\\\le M$. We describe a\\ndeterministic, universal algorithm for constructing an eignet for approximating\\nfunctions in $L^p(\\\\mu;\\\\XX)$ for a general class of measures $\\\\mu$ and kernels\\n$G$. Our algorithm yields linear operators. Using the minimal separation\\namongst the centers $y_j$ as the cost of approximation, we give modulus of\\nsmoothness estimates for the degree of approximation by our eignets, and show\\nby means of a converse theorem that these are the best possible for every\\n\\\\emph{individual function}. We also give estimates on the coefficients $a_j$ in\\nterms of the norm of the eignet. Finally, we demonstrate that if any sequence\\nof eignets satisfies the optimal estimates for the degree of approximation of a\\nsmooth function, measured in terms of the minimal separation, then the\\nderivatives of the eignets also approximate the corresponding derivatives of\\nthe target function in an optimal manner.\\n',\n",
              " '  We give the first non-trivial upper bounds on the average sensitivity and\\nnoise sensitivity of polynomial threshold functions. More specifically, for a\\nBoolean function f on n variables equal to the sign of a real, multivariate\\npolynomial of total degree d we prove\\n  1) The average sensitivity of f is at most O(n^{1-1/(4d+6)}) (we also give a\\ncombinatorial proof of the bound O(n^{1-1/2^d}).\\n  2) The noise sensitivity of f with noise rate \\\\delta is at most\\nO(\\\\delta^{1/(4d+6)}).\\n  Previously, only bounds for the linear case were known. Along the way we show\\nnew structural theorems about random restrictions of polynomial threshold\\nfunctions obtained via hypercontractivity. These structural results may be of\\nindependent interest as they provide a generic template for transforming\\nproblems related to polynomial threshold functions defined on the Boolean\\nhypercube to polynomial threshold functions defined in Gaussian space.\\n',\n",
              " '  Minimizing the rank of a matrix subject to affine constraints is a\\nfundamental problem with many important applications in machine learning and\\nstatistics. In this paper we propose a simple and fast algorithm SVP (Singular\\nValue Projection) for rank minimization with affine constraints (ARMP) and show\\nthat SVP recovers the minimum rank solution for affine constraints that satisfy\\nthe \"restricted isometry property\" and show robustness of our method to noise.\\nOur results improve upon a recent breakthrough by Recht, Fazel and Parillo\\n(RFP07) and Lee and Bresler (LB09) in three significant ways:\\n  1) our method (SVP) is significantly simpler to analyze and easier to\\nimplement,\\n  2) we give recovery guarantees under strictly weaker isometry assumptions\\n  3) we give geometric convergence guarantees for SVP even in presense of noise\\nand, as demonstrated empirically, SVP is significantly faster on real-world and\\nsynthetic problems.\\n  In addition, we address the practically important problem of low-rank matrix\\ncompletion (MCP), which can be seen as a special case of ARMP. We empirically\\ndemonstrate that our algorithm recovers low-rank incoherent matrices from an\\nalmost optimal number of uniformly sampled entries. We make partial progress\\ntowards proving exact recovery and provide some intuition for the strong\\nperformance of SVP applied to matrix completion by showing a more restricted\\nisometry property. Our algorithm outperforms existing methods, such as those of\\n\\\\cite{RFP07,CR08,CT09,CCS08,KOM09,LB09}, for ARMP and the matrix-completion\\nproblem by an order of magnitude and is also significantly more robust to\\nnoise.\\n',\n",
              " '  This version is ***superseded*** by a full version that can be found at\\nhttp://www.itu.dk/people/pagh/papers/mining-jour.pdf, which contains stronger\\ntheoretical results and fixes a mistake in the reporting of experiments.\\n  Abstract: Sampling-based methods have previously been proposed for the\\nproblem of finding interesting associations in data, even for low-support\\nitems. While these methods do not guarantee precise results, they can be vastly\\nmore efficient than approaches that rely on exact counting. However, for many\\nsimilarity measures no such methods have been known. In this paper we show how\\na wide variety of measures can be supported by a simple biased sampling method.\\nThe method also extends to find high-confidence association rules. We\\ndemonstrate theoretically that our method is superior to exact methods when the\\nthreshold for \"interesting similarity/confidence\" is above the average pairwise\\nsimilarity/confidence, and the average support is not too low. Our method is\\nparticularly good when transactions contain many items. We confirm in\\nexperiments on standard association mining benchmarks that this gives a\\nsignificant speedup on real data sets (sometimes much larger than the\\ntheoretical guarantees). Reductions in computation time of over an order of\\nmagnitude, and significant savings in space, are observed.\\n',\n",
              " '  Suppose the signal x is realized by driving a k-sparse signal u through an\\narbitrary unknown stable discrete-linear time invariant system H. These types\\nof processes arise naturally in Reflection Seismology. In this paper we are\\ninterested in several problems: (a) Blind-Deconvolution: Can we recover both\\nthe filter $H$ and the sparse signal $u$ from noisy measurements? (b)\\nCompressive Sensing: Is x compressible in the conventional sense of compressed\\nsensing? Namely, can x, u and H be reconstructed from a sparse set of\\nmeasurements. We develop novel L1 minimization methods to solve both cases and\\nestablish sufficient conditions for exact recovery for the case when the\\nunknown system H is auto-regressive (i.e. all pole) of a known order. In the\\ncompressed sensing/sampling setting it turns out that both H and x can be\\nreconstructed from O(k log(n)) measurements under certain technical conditions\\non the support structure of u. Our main idea is to pass x through a linear time\\ninvariant system G and collect O(k log(n)) sequential measurements. The filter\\nG is chosen suitably, namely, its associated Toeplitz matrix satisfies the RIP\\nproperty. We develop a novel LP optimization algorithm and show that both the\\nunknown filter H and the sparse input u can be reliably estimated.\\n',\n",
              " '  In Data Mining, the usefulness of association rules is strongly limited by\\nthe huge amount of delivered rules. In this paper we propose a new approach to\\nprune and filter discovered rules. Using Domain Ontologies, we strengthen the\\nintegration of user knowledge in the post-processing task. Furthermore, an\\ninteractive and iterative framework is designed to assist the user along the\\nanalyzing task. On the one hand, we represent user domain knowledge using a\\nDomain Ontology over database. On the other hand, a novel technique is\\nsuggested to prune and to filter discovered rules. The proposed framework was\\napplied successfully over the client database provided by Nantes Habitat.\\n',\n",
              " '  User authentication and intrusion detection differ from standard\\nclassification problems in that while we have data generated from legitimate\\nusers, impostor or intrusion data is scarce or non-existent. We review existing\\ntechniques for dealing with this problem and propose a novel alternative based\\non a principled statistical decision-making view point. We examine the\\ntechnique on a toy problem and validate it on complex real-world data from an\\nRFID based access control system. The results indicate that it can\\nsignificantly outperform the classical world model approach. The method could\\nbe more generally useful in other decision-making scenarios where there is a\\nlack of adversary data.\\n',\n",
              " '  There is growing body of learning problems for which it is natural to\\norganize the parameters into matrix, so as to appropriately regularize the\\nparameters under some matrix norm (in order to impose some more sophisticated\\nprior knowledge). This work describes and analyzes a systematic method for\\nconstructing such matrix-based, regularization methods. In particular, we focus\\non how the underlying statistical properties of a given problem can help us\\ndecide which regularization function is appropriate.\\n  Our methodology is based on the known duality fact: that a function is\\nstrongly convex with respect to some norm if and only if its conjugate function\\nis strongly smooth with respect to the dual norm. This result has already been\\nfound to be a key component in deriving and analyzing several learning\\nalgorithms. We demonstrate the potential of this framework by deriving novel\\ngeneralization and regret bounds for multi-task learning, multi-class learning,\\nand kernel learning.\\n',\n",
              " '  Gaussian processes (GPs) provide a probabilistic nonparametric representation\\nof functions in regression, classification, and other problems. Unfortunately,\\nexact learning with GPs is intractable for large datasets. A variety of\\napproximate GP methods have been proposed that essentially map the large\\ndataset into a small set of basis points. The most advanced of these, the\\nvariable-sigma GP (VSGP) (Walder et al., 2008), allows each basis point to have\\nits own length scale. However, VSGP was only derived for regression. We\\ndescribe how VSGP can be applied to classification and other problems, by\\nderiving it as an expectation propagation algorithm. In this view, sparse GP\\napproximations correspond to a KL-projection of the true posterior onto a\\ncompact exponential family of GPs. VSGP constitutes one such family, and we\\nshow how to enlarge this family to get additional accuracy. In particular, we\\nshow that endowing each basis point with its own full covariance matrix\\nprovides a significant increase in approximation power.\\n',\n",
              " '  Zoonosis refers to the transmission of infectious diseases from animal to\\nhuman. The increasing number of zoonosis incidence makes the great losses to\\nlives, including humans and animals, and also the impact in social economic. It\\nmotivates development of a system that can predict the future number of\\nzoonosis occurrences in human. This paper analyses and presents the use of\\nSeasonal Autoregressive Integrated Moving Average (SARIMA) method for\\ndeveloping a forecasting model that able to support and provide prediction\\nnumber of zoonosis human incidence. The dataset for model development was\\ncollected on a time series data of human tuberculosis occurrences in United\\nStates which comprises of fourteen years of monthly data obtained from a study\\npublished by Centers for Disease Control and Prevention (CDC). Several trial\\nmodels of SARIMA were compared to obtain the most appropriate model. Then,\\ndiagnostic tests were used to determine model validity. The result showed that\\nthe SARIMA(9,0,14)(12,1,24)12 is the fittest model. While in the measure of\\naccuracy, the selected model achieved 0.062 of Theils U value. It implied that\\nthe model was highly accurate and a close fit. It was also indicated the\\ncapability of final model to closely represent and made prediction based on the\\ntuberculosis historical dataset.\\n',\n",
              " '  We introduce the Reduced-Rank Hidden Markov Model (RR-HMM), a generalization\\nof HMMs that can model smooth state evolution as in Linear Dynamical Systems\\n(LDSs) as well as non-log-concave predictive distributions as in\\ncontinuous-observation HMMs. RR-HMMs assume an m-dimensional latent state and n\\ndiscrete observations, with a transition matrix of rank k <= m. This implies\\nthe dynamics evolve in a k-dimensional subspace, while the shape of the set of\\npredictive distributions is determined by m. Latent state belief is represented\\nwith a k-dimensional state vector and inference is carried out entirely in R^k,\\nmaking RR-HMMs as computationally efficient as k-state HMMs yet more\\nexpressive. To learn RR-HMMs, we relax the assumptions of a recently proposed\\nspectral learning algorithm for HMMs (Hsu, Kakade and Zhang 2009) and apply it\\nto learn k-dimensional observable representations of rank-k RR-HMMs. The\\nalgorithm is consistent and free of local optima, and we extend its performance\\nguarantees to cover the RR-HMM case. We show how this algorithm can be used in\\nconjunction with a kernel density estimator to efficiently model\\nhigh-dimensional multivariate continuous data. We also relax the assumption\\nthat single observations are sufficient to disambiguate state, and extend the\\nalgorithm accordingly. Experiments on synthetic data and a toy video, as well\\nas on a difficult robot vision modeling problem, yield accurate models that\\ncompare favorably with standard alternatives in simulation quality and\\nprediction capability.\\n',\n",
              " '  We consider a problem of significant practical importance, namely, the\\nreconstruction of a low-rank data matrix from a small subset of its entries.\\nThis problem appears in many areas such as collaborative filtering, computer\\nvision and wireless sensor networks. In this paper, we focus on the matrix\\ncompletion problem in the case when the observed samples are corrupted by\\nnoise. We compare the performance of three state-of-the-art matrix completion\\nalgorithms (OptSpace, ADMiRA and FPCA) on a single simulation platform and\\npresent numerical results. We show that in practice these efficient algorithms\\ncan be used to reconstruct real data matrices, as well as randomly generated\\nmatrices, accurately.\\n',\n",
              " '  We present promising results for real-time vehicle visual detection, obtained\\nwith adaBoost using new original ?keypoints presence features?. These\\nweak-classifiers produce a boolean response based on presence or absence in the\\ntested image of a ?keypoint? (~ a SURF interest point) with a descriptor\\nsufficiently similar (i.e. within a given distance) to a reference descriptor\\ncharacterizing the feature. A first experiment was conducted on a public image\\ndataset containing lateral-viewed cars, yielding 95% recall with 95% precision\\non test set. Moreover, analysis of the positions of adaBoost-selected keypoints\\nshow that they correspond to a specific part of the object category (such as\\n?wheel? or ?side skirt?) and thus have a ?semantic? meaning.\\n',\n",
              " '  This paper shows how to improve the real-time object detection in complex\\nrobotics applications, by exploring new visual features as AdaBoost weak\\nclassifiers. These new features are symmetric Haar filters (enforcing global\\nhorizontal and vertical symmetry) and N-connexity control points. Experimental\\nevaluation on a car database show that the latter appear to provide the best\\nresults for the vehicle-detection problem.\\n',\n",
              " '  We present promising results for visual object categorization, obtained with\\nadaBoost using new original ?keypoints-based features?. These weak-classifiers\\nproduce a boolean response based on presence or absence in the tested image of\\na ?keypoint? (a kind of SURF interest point) with a descriptor sufficiently\\nsimilar (i.e. within a given distance) to a reference descriptor characterizing\\nthe feature. A first experiment was conducted on a public image dataset\\ncontaining lateral-viewed cars, yielding 95% recall with 95% precision on test\\nset. Preliminary tests on a small subset of a pedestrians database also gives\\npromising 97% recall with 92 % precision, which shows the generality of our new\\nfamily of features. Moreover, analysis of the positions of adaBoost-selected\\nkeypoints show that they correspond to a specific part of the object category\\n(such as ?wheel? or ?side skirt? in the case of lateral-cars) and thus have a\\n?semantic? meaning. We also made a first test on video for detecting vehicles\\nfrom adaBoostselected keypoints filtered in real-time from all detected\\nkeypoints.\\n',\n",
              " \"  Recently a new clustering algorithm called 'affinity propagation' (AP) has\\nbeen proposed, which efficiently clustered sparsely related data by passing\\nmessages between data points. However, we want to cluster large scale data\\nwhere the similarities are not sparse in many cases. This paper presents two\\nvariants of AP for grouping large scale data with a dense similarity matrix.\\nThe local approach is partition affinity propagation (PAP) and the global\\nmethod is landmark affinity propagation (LAP). PAP passes messages in the\\nsubsets of data first and then merges them as the number of initial step of\\niterations; it can effectively reduce the number of iterations of clustering.\\nLAP passes messages between the landmark data points first and then clusters\\nnon-landmark data points; it is a large global approximation method to speed up\\nclustering. Experiments are conducted on many datasets, such as random data\\npoints, manifold subspaces, images of faces and Chinese calligraphy, and the\\nresults demonstrate that the two approaches are feasible and practicable.\\n\",\n",
              " '  In this paper we adapt online estimation strategies to perform model-based\\nclustering on large networks. Our work focuses on two algorithms, the first\\nbased on the SAEM algorithm, and the second on variational methods. These two\\nstrategies are compared with existing approaches on simulated and real data. We\\nuse the method to decipher the connexion structure of the political websphere\\nduring the US political campaign in 2008. We show that our online EM-based\\nalgorithms offer a good trade-off between precision and speed, when estimating\\nparameters for mixture distributions in the context of random graphs.\\n',\n",
              " '  We formulate and study a decentralized multi-armed bandit (MAB) problem.\\nThere are M distributed players competing for N independent arms. Each arm,\\nwhen played, offers i.i.d. reward according to a distribution with an unknown\\nparameter. At each time, each player chooses one arm to play without exchanging\\nobservations or any information with other players. Players choosing the same\\narm collide, and, depending on the collision model, either no one receives\\nreward or the colliding players share the reward in an arbitrary way. We show\\nthat the minimum system regret of the decentralized MAB grows with time at the\\nsame logarithmic order as in the centralized counterpart where players act\\ncollectively as a single entity by exchanging observations and making decisions\\njointly. A decentralized policy is constructed to achieve this optimal order\\nwhile ensuring fairness among players and without assuming any pre-agreement or\\ninformation exchange among players. Based on a Time Division Fair Sharing\\n(TDFS) of the M best arms, the proposed policy is constructed and its order\\noptimality is proven under a general reward model. Furthermore, the basic\\nstructure of the TDFS policy can be used with any order-optimal single-player\\npolicy to achieve order optimality in the decentralized setting. We also\\nestablish a lower bound on the system regret growth rate for a general class of\\ndecentralized polices, to which the proposed policy belongs. This problem finds\\npotential applications in cognitive radio networks, multi-channel communication\\nsystems, multi-agent systems, web search and advertising, and social networks.\\n',\n",
              " \"  In this paper, spectrum access in cognitive radio networks is modeled as a\\nrepeated auction game subject to monitoring and entry costs. For secondary\\nusers, sensing costs are incurred as the result of primary users' activity.\\nFurthermore, each secondary user pays the cost of transmissions upon successful\\nbidding for a channel. Knowledge regarding other secondary users' activity is\\nlimited due to the distributed nature of the network. The resulting formulation\\nis thus a dynamic game with incomplete information. In this paper, an efficient\\nbidding learning algorithm is proposed based on the outcome of past\\ntransactions. As demonstrated through extensive simulations, the proposed\\ndistributed scheme outperforms a myopic one-stage algorithm, and can achieve a\\ngood balance between efficiency and fairness.\\n\",\n",
              " '  The learning of appropriate distance metrics is a critical problem in image\\nclassification and retrieval. In this work, we propose a boosting-based\\ntechnique, termed \\\\BoostMetric, for learning a Mahalanobis distance metric. One\\nof the primary difficulties in learning such a metric is to ensure that the\\nMahalanobis matrix remains positive semidefinite. Semidefinite programming is\\nsometimes used to enforce this constraint, but does not scale well.\\n\\\\BoostMetric is instead based on a key observation that any positive\\nsemidefinite matrix can be decomposed into a linear positive combination of\\ntrace-one rank-one matrices. \\\\BoostMetric thus uses rank-one positive\\nsemidefinite matrices as weak learners within an efficient and scalable\\nboosting-based learning process. The resulting method is easy to implement,\\ndoes not require tuning, and can accommodate various types of constraints.\\nExperiments on various datasets show that the proposed algorithm compares\\nfavorably to those state-of-the-art methods in terms of classification accuracy\\nand running time.\\n',\n",
              " '  In this paper we discuss the techniques involved in the design of the famous\\nstatistical spam filters that include Naive Bayes, Term Frequency-Inverse\\nDocument Frequency, K-Nearest Neighbor, Support Vector Machine, and Bayes\\nAdditive Regression Tree. We compare these techniques with each other in terms\\nof accuracy, recall, precision, etc. Further, we discuss the effectiveness and\\nlimitations of statistical filters in filtering out various types of spam from\\nlegitimate e-mails.\\n',\n",
              " '  We examine the complexity of learning the distributions produced by\\nfinite-state quantum sources. We show how prior techniques for learning hidden\\nMarkov models can be adapted to the quantum generator model to find that the\\nanalogous state of affairs holds: information-theoretically, a polynomial\\nnumber of samples suffice to approximately identify the distribution, but\\ncomputationally, the problem is as hard as learning parities with noise, a\\nnotorious open question in computational learning theory.\\n',\n",
              " '  Most of the non-asymptotic theoretical work in regression is carried out for\\nthe square loss, where estimators can be obtained through closed-form\\nexpressions. In this paper, we use and extend tools from the convex\\noptimization literature, namely self-concordant functions, to provide simple\\nextensions of theoretical results for the square loss to the logistic loss. We\\napply the extension techniques to logistic regression with regularization by\\nthe $\\\\ell_2$-norm and regularization by the $\\\\ell_1$-norm, showing that new\\nresults for binary classification through logistic regression can be easily\\nderived from corresponding results for least-squares regression.\\n',\n",
              " '  We study the problem of online regression. We prove a theoretical bound on\\nthe square loss of Ridge Regression. We do not make any assumptions about input\\nvectors or outcomes. We also show that Bayesian Ridge Regression can be thought\\nof as an online algorithm competing with all the Gaussian linear experts.\\n',\n",
              " '  We consider the problem of reconstructing a low-rank matrix from a small\\nsubset of its entries. In this paper, we describe the implementation of an\\nefficient algorithm called OptSpace, based on singular value decomposition\\nfollowed by local manifold optimization, for solving the low-rank matrix\\ncompletion problem. It has been shown that if the number of revealed entries is\\nlarge enough, the output of singular value decomposition gives a good estimate\\nfor the original matrix, so that local optimization reconstructs the correct\\nmatrix with high probability. We present numerical results which show that this\\nalgorithm can reconstruct the low rank matrix exactly from a very small subset\\nof its entries. We further study the robustness of the algorithm with respect\\nto noise, and its performance on actual collaborative filtering datasets.\\n',\n",
              " '  (ABRIDGED) In previous work, two platforms have been developed for testing\\ncomputer-vision algorithms for robotic planetary exploration (McGuire et al.\\n2004b,2005; Bartolo et al. 2007). The wearable-computer platform has been\\ntested at geological and astrobiological field sites in Spain (Rivas\\nVaciamadrid and Riba de Santiuste), and the phone-camera has been tested at a\\ngeological field site in Malta. In this work, we (i) apply a Hopfield\\nneural-network algorithm for novelty detection based upon color, (ii) integrate\\na field-capable digital microscope on the wearable computer platform, (iii)\\ntest this novelty detection with the digital microscope at Rivas Vaciamadrid,\\n(iv) develop a Bluetooth communication mode for the phone-camera platform, in\\norder to allow access to a mobile processing computer at the field sites, and\\n(v) test the novelty detection on the Bluetooth-enabled phone-camera connected\\nto a netbook computer at the Mars Desert Research Station in Utah. This systems\\nengineering and field testing have together allowed us to develop a real-time\\ncomputer-vision system that is capable, for example, of identifying lichens as\\nnovel within a series of images acquired in semi-arid desert environments. We\\nacquired sequences of images of geologic outcrops in Utah and Spain consisting\\nof various rock types and colors to test this algorithm. The algorithm robustly\\nrecognized previously-observed units by their color, while requiring only a\\nsingle image or a few images to learn colors as familiar, demonstrating its\\nfast learning capability.\\n',\n",
              " '  We propose a novel non-parametric adaptive anomaly detection algorithm for\\nhigh dimensional data based on score functions derived from nearest neighbor\\ngraphs on $n$-point nominal data. Anomalies are declared whenever the score of\\na test sample falls below $\\\\alpha$, which is supposed to be the desired false\\nalarm level. The resulting anomaly detector is shown to be asymptotically\\noptimal in that it is uniformly most powerful for the specified false alarm\\nlevel, $\\\\alpha$, for the case when the anomaly density is a mixture of the\\nnominal and a known density. Our algorithm is computationally efficient, being\\nlinear in dimension and quadratic in data size. It does not require choosing\\ncomplicated tuning parameters or function approximation classes and it can\\nadapt to local structure such as local change in dimensionality. We demonstrate\\nthe algorithm on both artificial and real data sets in high dimensional feature\\nspaces.\\n',\n",
              " '  We consider the problem of learning the structure of Ising models (pairwise\\nbinary Markov random fields) from i.i.d. samples. While several methods have\\nbeen proposed to accomplish this task, their relative merits and limitations\\nremain somewhat obscure. By analyzing a number of concrete examples, we show\\nthat low-complexity algorithms systematically fail when the Markov random field\\ndevelops long-range correlations. More precisely, this phenomenon appears to be\\nrelated to the Ising model phase transition (although it does not coincide with\\nit).\\n',\n",
              " '  Metric and kernel learning are important in several machine learning\\napplications. However, most existing metric learning algorithms are limited to\\nlearning metrics over low-dimensional data, while existing kernel learning\\nalgorithms are often limited to the transductive setting and do not generalize\\nto new data points. In this paper, we study metric learning as a problem of\\nlearning a linear transformation of the input data. We show that for\\nhigh-dimensional data, a particular framework for learning a linear\\ntransformation of the data based on the LogDet divergence can be efficiently\\nkernelized to learn a metric (or equivalently, a kernel function) over an\\narbitrarily high dimensional space. We further demonstrate that a wide class of\\nconvex loss functions for learning linear transformations can similarly be\\nkernelized, thereby considerably expanding the potential applications of metric\\nlearning. We demonstrate our learning approach by applying it to large-scale\\nreal world problems in computer vision and text mining.\\n',\n",
              " '  The versatility of exponential families, along with their attendant convexity\\nproperties, make them a popular and effective statistical model. A central\\nissue is learning these models in high-dimensions, such as when there is some\\nsparsity pattern of the optimal parameter. This work characterizes a certain\\nstrong convexity property of general exponential families, which allow their\\ngeneralization ability to be quantified. In particular, we show how this\\nproperty can be used to analyze generic exponential families under L_1\\nregularization.\\n',\n",
              " '  In this paper, we prove a crucial theorem called Mirroring Theorem which\\naffirms that given a collection of samples with enough information in it such\\nthat it can be classified into classes and subclasses then (i) There exists a\\nmapping which classifies and subclassifies these samples (ii) There exists a\\nhierarchical classifier which can be constructed by using Mirroring Neural\\nNetworks (MNNs) in combination with a clustering algorithm that can approximate\\nthis mapping. Thus, the proof of the Mirroring theorem provides a theoretical\\nbasis for the existence and a practical feasibility of constructing\\nhierarchical classifiers, given the maps. Our proposed Mirroring Theorem can\\nalso be considered as an extension to Kolmogrovs theorem in providing a\\nrealistic solution for unsupervised classification. The techniques we develop,\\nare general in nature and have led to the construction of learning machines\\nwhich are (i) tree like in structure, (ii) modular (iii) with each module\\nrunning on a common algorithm (tandem algorithm) and (iv) selfsupervised. We\\nhave actually built the architecture, developed the tandem algorithm of such a\\nhierarchical classifier and demonstrated it on an example problem.\\n',\n",
              " '  Ensemble methods, such as stacking, are designed to boost predictive accuracy\\nby blending the predictions of multiple machine learning models. Recent work\\nhas shown that the use of meta-features, additional inputs describing each\\nexample in a dataset, can boost the performance of ensemble methods, but the\\ngreatest reported gains have come from nonlinear procedures requiring\\nsignificant tuning and training time. Here, we present a linear technique,\\nFeature-Weighted Linear Stacking (FWLS), that incorporates meta-features for\\nimproved accuracy while retaining the well-known virtues of linear regression\\nregarding speed, stability, and interpretability. FWLS combines model\\npredictions linearly using coefficients that are themselves linear functions of\\nmeta-features. This technique was a key facet of the solution of the second\\nplace team in the recently concluded Netflix Prize competition. Significant\\nincreases in accuracy over standard linear stacking are demonstrated on the\\nNetflix Prize collaborative filtering dataset.\\n',\n",
              " '  Last year, in 2008, I gave a talk titled {\\\\it Quantum Calisthenics}. This\\nyear I am going to tell you about how the work I described then has spun off\\ninto a most unlikely direction. What I am going to talk about is how one maps\\nthe problem of finding clusters in a given data set into a problem in quantum\\nmechanics. I will then use the tricks I described to let quantum evolution lets\\nthe clusters come together on their own.\\n',\n",
              " '  This article applies Machine Learning techniques to solve Intrusion Detection\\nproblems within computer networks. Due to complex and dynamic nature of\\ncomputer networks and hacking techniques, detecting malicious activities\\nremains a challenging task for security experts, that is, currently available\\ndefense systems suffer from low detection capability and high number of false\\nalarms. To overcome such performance limitations, we propose a novel Machine\\nLearning algorithm, namely Boosted Subspace Probabilistic Neural Network\\n(BSPNN), which integrates an adaptive boosting technique and a semi parametric\\nneural network to obtain good tradeoff between accuracy and generality. As the\\nresult, learning bias and generalization variance can be significantly\\nminimized. Substantial experiments on KDD 99 intrusion benchmark indicate that\\nour model outperforms other state of the art learning algorithms, with\\nsignificantly improved detection accuracy, minimal false alarms and relatively\\nsmall computational complexity.\\n',\n",
              " \"  Tree reconstruction methods are often judged by their accuracy, measured by\\nhow close they get to the true tree. Yet most reconstruction methods like ML do\\nnot explicitly maximize this accuracy. To address this problem, we propose a\\nBayesian solution. Given tree samples, we propose finding the tree estimate\\nwhich is closest on average to the samples. This ``median'' tree is known as\\nthe Bayes estimator (BE). The BE literally maximizes posterior expected\\naccuracy, measured in terms of closeness (distance) to the true tree. We\\ndiscuss a unified framework of BE trees, focusing especially on tree distances\\nwhich are expressible as squared euclidean distances. Notable examples include\\nRobinson--Foulds distance, quartet distance, and squared path difference. Using\\nsimulated data, we show Bayes estimators can be efficiently computed in\\npractice by hill climbing. We also show that Bayes estimators achieve higher\\naccuracy, compared to maximum likelihood and neighbor joining.\\n\",\n",
              " '  The Lipschitz multi-armed bandit (MAB) problem generalizes the classical\\nmulti-armed bandit problem by assuming one is given side information consisting\\nof a priori upper bounds on the difference in expected payoff between certain\\npairs of strategies. Classical results of (Lai and Robbins 1985) and (Auer et\\nal. 2002) imply a logarithmic regret bound for the Lipschitz MAB problem on\\nfinite metric spaces. Recent results on continuum-armed bandit problems and\\ntheir generalizations imply lower bounds of $\\\\sqrt{t}$, or stronger, for many\\ninfinite metric spaces such as the unit interval. Is this dichotomy universal?\\nWe prove that the answer is yes: for every metric space, the optimal regret of\\na Lipschitz MAB algorithm is either bounded above by any $f\\\\in \\\\omega(\\\\log t)$,\\nor bounded below by any $g\\\\in o(\\\\sqrt{t})$. Perhaps surprisingly, this\\ndichotomy does not coincide with the distinction between finite and infinite\\nmetric spaces; instead it depends on whether the completion of the metric space\\nis compact and countable. Our proof connects upper and lower bound techniques\\nin online learning with classical topological notions such as perfect sets and\\nthe Cantor-Bendixson theorem. Among many other results, we show a similar\\ndichotomy for the \"full-feedback\" (a.k.a., \"best-expert\") version.\\n',\n",
              " '  Machine Learning is usually defined as a subfield of AI, which is busy with\\ninformation extraction from raw data sets. Despite of its common acceptance and\\nwidespread recognition, this definition is wrong and groundless. Meaningful\\ninformation does not belong to the data that bear it. It belongs to the\\nobservers of the data and it is a shared agreement and a convention among them.\\nTherefore, this private information cannot be extracted from the data by any\\nmeans. Therefore, all further attempts of Machine Learning apologists to\\njustify their funny business are inappropriate.\\n',\n",
              " \"  We consider computation of permanent of a positive $(N\\\\times N)$ non-negative\\nmatrix, $P=(P_i^j|i,j=1,\\\\cdots,N)$, or equivalently the problem of weighted\\ncounting of the perfect matchings over the complete bipartite graph $K_{N,N}$.\\nThe problem is known to be of likely exponential complexity. Stated as the\\npartition function $Z$ of a graphical model, the problem allows exact Loop\\nCalculus representation [Chertkov, Chernyak '06] in terms of an interior\\nminimum of the Bethe Free Energy functional over non-integer doubly stochastic\\nmatrix of marginal beliefs, $\\\\beta=(\\\\beta_i^j|i,j=1,\\\\cdots,N)$, also\\ncorrespondent to a fixed point of the iterative message-passing algorithm of\\nthe Belief Propagation (BP) type. Our main result is an explicit expression of\\nthe exact partition function (permanent) in terms of the matrix of BP\\nmarginals, $\\\\beta$, as $Z=\\\\mbox{Perm}(P)=Z_{BP}\\n\\\\mbox{Perm}(\\\\beta_i^j(1-\\\\beta_i^j))/\\\\prod_{i,j}(1-\\\\beta_i^j)$, where $Z_{BP}$\\nis the BP expression for the permanent stated explicitly in terms if $\\\\beta$.\\nWe give two derivations of the formula, a direct one based on the Bethe Free\\nEnergy and an alternative one combining the Ihara graph-$\\\\zeta$ function and\\nthe Loop Calculus approaches. Assuming that the matrix $\\\\beta$ of the Belief\\nPropagation marginals is calculated, we provide two lower bounds and one\\nupper-bound to estimate the multiplicative term. Two complementary lower bounds\\nare based on the Gurvits-van der Waerden theorem and on a relation between the\\nmodified permanent and determinant respectively.\\n\",\n",
              " '  Current methods for determining whether a time series exhibits fractal\\nstructure (FS) rely on subjective assessments on estimators of the Hurst\\nexponent (H). Here, I introduce the Bayesian Assessment of Scaling, an\\nanalytical framework for drawing objective and accurate inferences on the FS of\\ntime series. The technique exploits the scaling property of the diffusion\\nassociated to a time series. The resulting criterion is simple to compute and\\nrepresents an accurate characterization of the evidence supporting different\\nhypotheses on the scaling regime of a time series. Additionally, a closed-form\\nMaximum Likelihood estimator of H is derived from the criterion, and this\\nestimator outperforms the best available estimators.\\n',\n",
              " '  This paper describes a methodology for detecting anomalies from sequentially\\nobserved and potentially noisy data. The proposed approach consists of two main\\nelements: (1) {\\\\em filtering}, or assigning a belief or likelihood to each\\nsuccessive measurement based upon our ability to predict it from previous noisy\\nobservations, and (2) {\\\\em hedging}, or flagging potential anomalies by\\ncomparing the current belief against a time-varying and data-adaptive\\nthreshold. The threshold is adjusted based on the available feedback from an\\nend user. Our algorithms, which combine universal prediction with recent work\\non online convex programming, do not require computing posterior distributions\\ngiven all current observations and involve simple primal-dual parameter\\nupdates. At the heart of the proposed approach lie exponential-family models\\nwhich can be used in a wide variety of contexts and applications, and which\\nyield methods that achieve sublinear per-round regret against both static and\\nslowly varying product distributions with marginals drawn from the same\\nexponential family. Moreover, the regret against static distributions coincides\\nwith the minimax value of the corresponding online strongly convex game. We\\nalso prove bounds on the number of mistakes made during the hedging step\\nrelative to the best offline choice of the threshold with access to all\\nestimated beliefs and feedback signals. We validate the theory on synthetic\\ndata drawn from a time-varying distribution over binary vectors of high\\ndimensionality, as well as on the Enron email dataset.\\n',\n",
              " '  A natural optimization model that formulates many online resource allocation\\nand revenue management problems is the online linear program (LP) in which the\\nconstraint matrix is revealed column by column along with the corresponding\\nobjective coefficient. In such a model, a decision variable has to be set each\\ntime a column is revealed without observing the future inputs and the goal is\\nto maximize the overall objective function. In this paper, we provide a\\nnear-optimal algorithm for this general class of online problems under the\\nassumption of random order of arrival and some mild conditions on the size of\\nthe LP right-hand-side input. Specifically, our learning-based algorithm works\\nby dynamically updating a threshold price vector at geometric time intervals,\\nwhere the dual prices learned from the revealed columns in the previous period\\nare used to determine the sequential decisions in the current period. Due to\\nthe feature of dynamic learning, the competitiveness of our algorithm improves\\nover the past study of the same problem. We also present a worst-case example\\nshowing that the performance of our algorithm is near-optimal.\\n',\n",
              " '  Recursive Neural Networks are non-linear adaptive models that are able to\\nlearn deep structured information. However, these models have not yet been\\nbroadly accepted. This fact is mainly due to its inherent complexity. In\\nparticular, not only for being extremely complex information processing models,\\nbut also because of a computational expensive learning phase. The most popular\\ntraining method for these models is back-propagation through the structure.\\nThis algorithm has been revealed not to be the most appropriate for structured\\nprocessing due to problems of convergence, while more sophisticated training\\nmethods enhance the speed of convergence at the expense of increasing\\nsignificantly the computational cost. In this paper, we firstly perform an\\nanalysis of the underlying principles behind these models aimed at\\nunderstanding their computational power. Secondly, we propose an approximate\\nsecond order stochastic learning algorithm. The proposed algorithm dynamically\\nadapts the learning rate throughout the training phase of the network without\\nincurring excessively expensive computational effort. The algorithm operates in\\nboth on-line and batch modes. Furthermore, the resulting learning scheme is\\nrobust against the vanishing gradients problem. The advantages of the proposed\\nalgorithm are demonstrated with a real-world application example.\\n',\n",
              " '  We present in this paper a study on the ability and the benefits of using a\\nkeystroke dynamics authentication method for collaborative systems.\\nAuthentication is a challenging issue in order to guarantee the security of use\\nof collaborative systems during the access control step. Many solutions exist\\nin the state of the art such as the use of one time passwords or smart-cards.\\nWe focus in this paper on biometric based solutions that do not necessitate any\\nadditional sensor. Keystroke dynamics is an interesting solution as it uses\\nonly the keyboard and is invisible for users. Many methods have been published\\nin this field. We make a comparative study of many of them considering the\\noperational constraints of use for collaborative systems.\\n',\n",
              " '  The Sample Compression Conjecture of Littlestone & Warmuth has remained\\nunsolved for over two decades. This paper presents a systematic geometric\\ninvestigation of the compression of finite maximum concept classes. Simple\\narrangements of hyperplanes in Hyperbolic space, and Piecewise-Linear\\nhyperplane arrangements, are shown to represent maximum classes, generalizing\\nthe corresponding Euclidean result. A main result is that PL arrangements can\\nbe swept by a moving hyperplane to unlabeled d-compress any finite maximum\\nclass, forming a peeling scheme as conjectured by Kuzmin & Warmuth. A corollary\\nis that some d-maximal classes cannot be embedded into any maximum class of VC\\ndimension d+k, for any constant k. The construction of the PL sweeping involves\\nPachner moves on the one-inclusion graph, corresponding to moves of a\\nhyperplane across the intersection of d other hyperplanes. This extends the\\nwell known Pachner moves for triangulations to cubical complexes.\\n',\n",
              " '  In conventional supervised pattern recognition tasks, model selection is\\ntypically accomplished by minimizing the classification error rate on a set of\\nso-called development data, subject to ground-truth labeling by human experts\\nor some other means. In the context of speech processing systems and other\\nlarge-scale practical applications, however, such labeled development data are\\ntypically costly and difficult to obtain. This article proposes an alternative\\nsemi-supervised framework for likelihood-based model selection that leverages\\nunlabeled data by using trained classifiers representing each model to\\nautomatically generate putative labels. The errors that result from this\\nautomatic labeling are shown to be amenable to results from robust statistics,\\nwhich in turn provide for minimax-optimal censored likelihood ratio tests that\\nrecover the nonparametric sign test as a limiting case. This approach is then\\nvalidated experimentally using a state-of-the-art automatic speech recognition\\nsystem to select between candidate word pronunciations using unlabeled speech\\ndata that only potentially contain instances of the words under test. Results\\nprovide supporting evidence for the utility of this approach, and suggest that\\nit may also find use in other applications of machine learning.\\n',\n",
              " '  We analyze the convergence behaviour of a recently proposed algorithm for\\nregularized estimation called Dual Augmented Lagrangian (DAL). Our analysis is\\nbased on a new interpretation of DAL as a proximal minimization algorithm. We\\ntheoretically show under some conditions that DAL converges super-linearly in a\\nnon-asymptotic and global sense. Due to a special modelling of sparse\\nestimation problems in the context of machine learning, the assumptions we make\\nare milder and more natural than those made in conventional analysis of\\naugmented Lagrangian algorithms. In addition, the new interpretation enables us\\nto generalize DAL to wide varieties of sparse estimation problems. We\\nexperimentally confirm our analysis in a large scale $\\\\ell_1$-regularized\\nlogistic regression problem and extensively compare the efficiency of DAL\\nalgorithm to previously proposed algorithms on both synthetic and benchmark\\ndatasets.\\n',\n",
              " \"  Serious Games (SGs) have experienced a tremendous outburst these last years.\\nVideo game companies have been producing fun, user-friendly SGs, but their\\neducational value has yet to be proven. Meanwhile, cognition research scientist\\nhave been developing SGs in such a way as to guarantee an educational gain, but\\nthe fun and attractive characteristics featured often would not meet the\\npublic's expectations. The ideal SG must combine these two aspects while still\\nbeing economically viable. In this article, we propose a production chain model\\nto efficiently conceive and produce SGs that are certified for their\\neducational gain and fun qualities. Each step of this chain will be described\\nalong with the human actors, the tools and the documents that intervene.\\n\",\n",
              " '  This document describes concisely the ubiquitous class of exponential family\\ndistributions met in statistics. The first part recalls definitions and\\nsummarizes main properties and duality with Bregman divergences (all proofs are\\nskipped). The second part lists decompositions and related formula of common\\nexponential family distributions. We recall the Fisher-Rao-Riemannian\\ngeometries and the dual affine connection information geometries of statistical\\nmanifolds. It is intended to maintain and update this document and catalog by\\nadding new distribution items.\\n',\n",
              " \"  Explaining adaptive behavior is a central problem in artificial intelligence\\nresearch. Here we formalize adaptive agents as mixture distributions over\\nsequences of inputs and outputs (I/O). Each distribution of the mixture\\nconstitutes a `possible world', but the agent does not know which of the\\npossible worlds it is actually facing. The problem is to adapt the I/O stream\\nin a way that is compatible with the true world. A natural measure of\\nadaptation can be obtained by the Kullback-Leibler (KL) divergence between the\\nI/O distribution of the true world and the I/O distribution expected by the\\nagent that is uncertain about possible worlds. In the case of pure input\\nstreams, the Bayesian mixture provides a well-known solution for this problem.\\nWe show, however, that in the case of I/O streams this solution breaks down,\\nbecause outputs are issued by the agent itself and require a different\\nprobabilistic syntax as provided by intervention calculus. Based on this\\ncalculus, we obtain a Bayesian control rule that allows modeling adaptive\\nbehavior with mixture distributions over I/O streams. This rule might allow for\\na novel approach to adaptive control based on a minimum KL-principle.\\n\",\n",
              " '  Images can be segmented by first using a classifier to predict an affinity\\ngraph that reflects the degree to which image pixels must be grouped together\\nand then partitioning the graph to yield a segmentation. Machine learning has\\nbeen applied to the affinity classifier to produce affinity graphs that are\\ngood in the sense of minimizing edge misclassification rates. However, this\\nerror measure is only indirectly related to the quality of segmentations\\nproduced by ultimately partitioning the affinity graph. We present the first\\nmachine learning algorithm for training a classifier to produce affinity graphs\\nthat are good in the sense of producing segmentations that directly minimize\\nthe Rand index, a well known segmentation performance measure. The Rand index\\nmeasures segmentation performance by quantifying the classification of the\\nconnectivity of image pixel pairs after segmentation. By using the simple graph\\npartitioning algorithm of finding the connected components of the thresholded\\naffinity graph, we are able to train an affinity classifier to directly\\nminimize the Rand index of segmentations resulting from the graph partitioning.\\nOur learning algorithm corresponds to the learning of maximin affinities\\nbetween image pixel pairs, which are predictive of the pixel-pair connectivity.\\n',\n",
              " '  A dictionary defines words in terms of other words. Definitions can tell you\\nthe meanings of words you don\\'t know, but only if you know the meanings of the\\ndefining words. How many words do you need to know (and which ones) in order to\\nbe able to learn all the rest from definitions? We reduced dictionaries to\\ntheir \"grounding kernels\" (GKs), about 10% of the dictionary, from which all\\nthe other words could be defined. The GK words turned out to have\\npsycholinguistic correlates: they were learned at an earlier age and more\\nconcrete than the rest of the dictionary. But one can compress still more: the\\nGK turns out to have internal structure, with a strongly connected \"kernel\\ncore\" (KC) and a surrounding layer, from which a hierarchy of definitional\\ndistances can be derived, all the way out to the periphery of the full\\ndictionary. These definitional distances, too, are correlated with\\npsycholinguistic variables (age of acquisition, concreteness, imageability,\\noral and written frequency) and hence perhaps with the \"mental lexicon\" in each\\nof our heads.\\n',\n",
              " \"  Several recent studies in privacy-preserving learning have considered the\\ntrade-off between utility or risk and the level of differential privacy\\nguaranteed by mechanisms for statistical query processing. In this paper we\\nstudy this trade-off in private Support Vector Machine (SVM) learning. We\\npresent two efficient mechanisms, one for the case of finite-dimensional\\nfeature mappings and one for potentially infinite-dimensional feature mappings\\nwith translation-invariant kernels. For the case of translation-invariant\\nkernels, the proposed mechanism minimizes regularized empirical risk in a\\nrandom Reproducing Kernel Hilbert Space whose kernel uniformly approximates the\\ndesired kernel with high probability. This technique, borrowed from large-scale\\nlearning, allows the mechanism to respond with a finite encoding of the\\nclassifier, even when the function class is of infinite VC dimension.\\nDifferential privacy is established using a proof technique from algorithmic\\nstability. Utility--the mechanism's response function is pointwise\\nepsilon-close to non-private SVM with probability 1-delta--is proven by\\nappealing to the smoothness of regularized empirical risk minimization with\\nrespect to small perturbations to the feature mapping. We conclude with a lower\\nbound on the optimal differential privacy of the SVM. This negative result\\nstates that for any delta, no mechanism can be simultaneously\\n(epsilon,delta)-useful and beta-differentially private for small epsilon and\\nsmall beta.\\n\",\n",
              " '  Privacy-preserving machine learning algorithms are crucial for the\\nincreasingly common setting in which personal data, such as medical or\\nfinancial records, are analyzed. We provide general techniques to produce\\nprivacy-preserving approximations of classifiers learned via (regularized)\\nempirical risk minimization (ERM). These algorithms are private under the\\n$\\\\epsilon$-differential privacy definition due to Dwork et al. (2006). First we\\napply the output perturbation ideas of Dwork et al. (2006), to ERM\\nclassification. Then we propose a new method, objective perturbation, for\\nprivacy-preserving machine learning algorithm design. This method entails\\nperturbing the objective function before optimizing over classifiers. If the\\nloss and regularizer satisfy certain convexity and differentiability criteria,\\nwe prove theoretical results showing that our algorithms preserve privacy, and\\nprovide generalization bounds for linear and nonlinear kernels. We further\\npresent a privacy-preserving technique for tuning the parameters in general\\nmachine learning algorithms, thereby providing end-to-end privacy guarantees\\nfor the training process. We apply these results to produce privacy-preserving\\nanalogues of regularized logistic regression and support vector machines. We\\nobtain encouraging results from evaluating their performance on real\\ndemographic and benchmark data sets. Our results show that both theoretically\\nand empirically, objective perturbation is superior to the previous\\nstate-of-the-art, output perturbation, in managing the inherent tradeoff\\nbetween privacy and learning performance.\\n',\n",
              " '  One of the most popular algorithms for clustering in Euclidean space is the\\n$k$-means algorithm; $k$-means is difficult to analyze mathematically, and few\\ntheoretical guarantees are known about it, particularly when the data is {\\\\em\\nwell-clustered}. In this paper, we attempt to fill this gap in the literature\\nby analyzing the behavior of $k$-means on well-clustered data. In particular,\\nwe study the case when each cluster is distributed as a different Gaussian --\\nor, in other words, when the input comes from a mixture of Gaussians.\\n  We analyze three aspects of the $k$-means algorithm under this assumption.\\nFirst, we show that when the input comes from a mixture of two spherical\\nGaussians, a variant of the 2-means algorithm successfully isolates the\\nsubspace containing the means of the mixture components. Second, we show an\\nexact expression for the convergence of our variant of the 2-means algorithm,\\nwhen the input is a very large number of samples from a mixture of spherical\\nGaussians. Our analysis does not require any lower bound on the separation\\nbetween the mixture components.\\n  Finally, we study the sample requirement of $k$-means; for a mixture of 2\\nspherical Gaussians, we show an upper bound on the number of samples required\\nby a variant of 2-means to get close to the true solution. The sample\\nrequirement grows with increasing dimensionality of the data, and decreasing\\nseparation between the means of the Gaussians. To match our upper bound, we\\nshow an information-theoretic lower bound on any algorithm that learns mixtures\\nof two spherical Gaussians; our lower bound indicates that in the case when the\\noverlap between the probability masses of the two distributions is small, the\\nsample requirement of $k$-means is {\\\\em near-optimal}.\\n',\n",
              " '  Isometric feature mapping (Isomap) is a promising manifold learning method.\\nHowever, Isomap fails to work on data which distribute on clusters in a single\\nmanifold or manifolds. Many works have been done on extending Isomap to\\nmulti-manifolds learning. In this paper, we first proposed a new\\nmulti-manifolds learning algorithm (M-Isomap) with help of a general procedure.\\nThe new algorithm preserves intra-manifold geodesics and multiple\\ninter-manifolds edges precisely. Compared with previous methods, this algorithm\\ncan isometrically learn data distributed on several manifolds. Secondly, the\\noriginal multi-cluster manifold learning algorithm first proposed in\\n\\\\cite{DCIsomap} and called D-C Isomap has been revised so that the revised D-C\\nIsomap can learn multi-manifolds data. Finally, the features and effectiveness\\nof the proposed multi-manifolds learning algorithms are demonstrated and\\ncompared through experiments.\\n',\n",
              " '  In a previous publication we proposed discrete global optimization as a\\nmethod to train a strong binary classifier constructed as a thresholded sum\\nover weak classifiers. Our motivation was to cast the training of a classifier\\ninto a format amenable to solution by the quantum adiabatic algorithm. Applying\\nadiabatic quantum computing (AQC) promises to yield solutions that are superior\\nto those which can be achieved with classical heuristic solvers. Interestingly\\nwe found that by using heuristic solvers to obtain approximate solutions we\\ncould already gain an advantage over the standard method AdaBoost. In this\\ncommunication we generalize the baseline method to large scale classifier\\ntraining. By large scale we mean that either the cardinality of the dictionary\\nof candidate weak classifiers or the number of weak learners used in the strong\\nclassifier exceed the number of variables that can be handled effectively in a\\nsingle global optimization. For such situations we propose an iterative and\\npiecewise approach in which a subset of weak classifiers is selected in each\\niteration via global optimization. The strong classifier is then constructed by\\nconcatenating the subsets of weak classifiers. We show in numerical studies\\nthat the generalized method again successfully competes with AdaBoost. We also\\nprovide theoretical arguments as to why the proposed optimization method, which\\ndoes not only minimize the empirical loss but also adds L0-norm regularization,\\nis superior to versions of boosting that only minimize the empirical loss. By\\nconducting a Quantum Monte Carlo simulation we gather evidence that the quantum\\nadiabatic algorithm is able to handle a generic training problem efficiently.\\n',\n",
              " '  In this paper, we propose a special fusion method for combining ensembles of\\nbase classifiers utilizing new neural networks in order to improve overall\\nefficiency of classification. While ensembles are designed such that each\\nclassifier is trained independently while the decision fusion is performed as a\\nfinal procedure, in this method, we would be interested in making the fusion\\nprocess more adaptive and efficient. This new combiner, called Neural Network\\nKernel Least Mean Square1, attempts to fuse outputs of the ensembles of\\nclassifiers. The proposed Neural Network has some special properties such as\\nKernel abilities,Least Mean Square features, easy learning over variants of\\npatterns and traditional neuron capabilities. Neural Network Kernel Least Mean\\nSquare is a special neuron which is trained with Kernel Least Mean Square\\nproperties. This new neuron is used as a classifiers combiner to fuse outputs\\nof base neural network classifiers. Performance of this method is analyzed and\\ncompared with other fusion methods. The analysis represents higher performance\\nof our new method as opposed to others.\\n',\n",
              " '  Biogeography is the study of the geographical distribution of biological\\norganisms. The mindset of the engineer is that we can learn from nature.\\nBiogeography Based Optimization is a burgeoning nature inspired technique to\\nfind the optimal solution of the problem. Satellite image classification is an\\nimportant task because it is the only way we can know about the land cover map\\nof inaccessible areas. Though satellite images have been classified in past by\\nusing various techniques, the researchers are always finding alternative\\nstrategies for satellite image classification so that they may be prepared to\\nselect the most appropriate technique for the feature extraction task in hand.\\nThis paper is focused on classification of the satellite image of a particular\\nland cover using the theory of Biogeography based Optimization. The original\\nBBO algorithm does not have the inbuilt property of clustering which is\\nrequired during image classification. Hence modifications have been proposed to\\nthe original algorithm and the modified algorithm is used to classify the\\nsatellite image of a given region. The results indicate that highly accurate\\nland cover features can be extracted effectively when the proposed algorithm is\\nused.\\n',\n",
              " '  Feature selection is an indispensable preprocessing step when mining huge\\ndatasets that can significantly improve the overall system performance.\\nTherefore in this paper we focus on a hybrid approach of feature selection.\\nThis method falls into two phases. The filter phase select the features with\\nhighest information gain and guides the initialization of search process for\\nwrapper phase whose output the final feature subset. The final feature subsets\\nare passed through the Knearest neighbor classifier for classification of\\nattacks. The effectiveness of this algorithm is demonstrated on DARPA KDDCUP99\\ncyber attack dataset.\\n',\n",
              " '  After building a classifier with modern tools of machine learning we\\ntypically have a black box at hand that is able to predict well for unseen\\ndata. Thus, we get an answer to the question what is the most likely label of a\\ngiven unseen data point. However, most methods will provide no answer why the\\nmodel predicted the particular label for a single instance and what features\\nwere most influential for that particular instance. The only method that is\\ncurrently able to provide such explanations are decision trees. This paper\\nproposes a procedure which (based on a set of assumptions) allows to explain\\nthe decisions of any classification method.\\n',\n",
              " \"  Despite the conventional wisdom that proactive security is superior to\\nreactive security, we show that reactive security can be competitive with\\nproactive security as long as the reactive defender learns from past attacks\\ninstead of myopically overreacting to the last attack. Our game-theoretic model\\nfollows common practice in the security literature by making worst-case\\nassumptions about the attacker: we grant the attacker complete knowledge of the\\ndefender's strategy and do not require the attacker to act rationally. In this\\nmodel, we bound the competitive ratio between a reactive defense algorithm\\n(which is inspired by online learning theory) and the best fixed proactive\\ndefense. Additionally, we show that, unlike proactive defenses, this reactive\\nstrategy is robust to a lack of information about the attacker's incentives and\\nknowledge.\\n\",\n",
              " '  In this paper, we consider delay-optimal power and subcarrier allocation\\ndesign for OFDMA systems with $N_F$ subcarriers, $K$ mobiles and one base\\nstation. There are $K$ queues at the base station for the downlink traffic to\\nthe $K$ mobiles with heterogeneous packet arrivals and delay requirements. We\\nshall model the problem as a $K$-dimensional infinite horizon average reward\\nMarkov Decision Problem (MDP) where the control actions are assumed to be a\\nfunction of the instantaneous Channel State Information (CSI) as well as the\\njoint Queue State Information (QSI). This problem is challenging because it\\ncorresponds to a stochastic Network Utility Maximization (NUM) problem where\\ngeneral solution is still unknown. We propose an {\\\\em online stochastic value\\niteration} solution using {\\\\em stochastic approximation}. The proposed power\\ncontrol algorithm, which is a function of both the CSI and the QSI, takes the\\nform of multi-level water-filling. We prove that under two mild conditions in\\nTheorem 1 (One is the stepsize condition. The other is the condition on\\naccessibility of the Markov Chain, which can be easily satisfied in most of the\\ncases we are interested.), the proposed solution converges to the optimal\\nsolution almost surely (with probability 1) and the proposed framework offers a\\npossible solution to the general stochastic NUM problem. By exploiting the\\nbirth-death structure of the queue dynamics, we obtain a reduced complexity\\ndecomposed solution with linear $\\\\mathcal{O}(KN_F)$ complexity and\\n$\\\\mathcal{O}(K)$ memory requirement.\\n',\n",
              " '  Association rule mining plays vital part in knowledge mining. The difficult\\ntask is discovering knowledge or useful rules from the large number of rules\\ngenerated for reduced support. For pruning or grouping rules, several\\ntechniques are used such as rule structure cover methods, informative cover\\nmethods, rule clustering, etc. Another way of selecting association rules is\\nbased on interestingness measures such as support, confidence, correlation, and\\nso on. In this paper, we study how rule clusters of the pattern Xi - Y are\\ndistributed over different interestingness measures.\\n',\n",
              " '  This paper proposes a method of gesture recognition with a focus on important\\nactions for distinguishing similar gestures. The method generates a partial\\naction sequence by using optical flow images, expresses the sequence in the\\neigenspace, and checks the feature vector sequence by applying an optimum\\npath-searching method of weighted graph to focus the important actions. Also\\npresented are the results of an experiment on the recognition of similar sign\\nlanguage words.\\n',\n",
              " \"  A fundamental task in detecting foreground objects in both static and dynamic\\nscenes is to take the best choice of color system representation and the\\nefficient technique for background modeling. We propose in this paper a\\nnon-parametric algorithm dedicated to segment and to detect objects in color\\nimages issued from a football sports meeting. Indeed segmentation by pixel\\nconcern many applications and revealed how the method is robust to detect\\nobjects, even in presence of strong shadows and highlights. In the other hand\\nto refine their playing strategy such as in football, handball, volley ball,\\nRugby..., the coach need to have a maximum of technical-tactics information\\nabout the on-going of the game and the players. We propose in this paper a\\nrange of algorithms allowing the resolution of many problems appearing in the\\nautomated process of team identification, where each player is affected to his\\ncorresponding team relying on visual data. The developed system was tested on a\\nmatch of the Tunisian national competition. This work is prominent for many\\nnext computer vision studies as it's detailed in this study.\\n\",\n",
              " '  This paper presents a tumor detection algorithm from mammogram. The proposed\\nsystem focuses on the solution of two problems. One is how to detect tumors as\\nsuspicious regions with a very weak contrast to their background and another is\\nhow to extract features which categorize tumors. The tumor detection method\\nfollows the scheme of (a) mammogram enhancement. (b) The segmentation of the\\ntumor area. (c) The extraction of features from the segmented tumor area. (d)\\nThe use of SVM classifier. The enhancement can be defined as conversion of the\\nimage quality to a better and more understandable level. The mammogram\\nenhancement procedure includes filtering, top hat operation, DWT. Then the\\ncontrast stretching is used to increase the contrast of the image. The\\nsegmentation of mammogram images has been playing an important role to improve\\nthe detection and diagnosis of breast cancer. The most common segmentation\\nmethod used is thresholding. The features are extracted from the segmented\\nbreast area. Next stage include, which classifies the regions using the SVM\\nclassifier. The method was tested on 75 mammographic images, from the mini-MIAS\\ndatabase. The methodology achieved a sensitivity of 88.75%.\\n',\n",
              " '  A central problem in artificial intelligence is that of planning to maximize\\nfuture reward under uncertainty in a partially observable environment. In this\\npaper we propose and demonstrate a novel algorithm which accurately learns a\\nmodel of such an environment directly from sequences of action-observation\\npairs. We then close the loop from observations to actions by planning in the\\nlearned model and recovering a policy which is near-optimal in the original\\nenvironment. Specifically, we present an efficient and statistically consistent\\nspectral algorithm for learning the parameters of a Predictive State\\nRepresentation (PSR). We demonstrate the algorithm by learning a model of a\\nsimulated high-dimensional, vision-based mobile robot planning task, and then\\nperform approximate point-based planning in the learned PSR. Analysis of our\\nresults shows that the algorithm learns a state space which efficiently\\ncaptures the essential features of the environment. This representation allows\\naccurate prediction with a small number of parameters, and enables successful\\nand efficient planning.\\n',\n",
              " '  We provide asymptotically sharp bounds for the Gaussian surface area and the\\nGaussian noise sensitivity of polynomial threshold functions. In particular we\\nshow that if $f$ is a degree-$d$ polynomial threshold function, then its\\nGaussian sensitivity at noise rate $\\\\epsilon$ is less than some quantity\\nasymptotic to $\\\\frac{d\\\\sqrt{2\\\\epsilon}}{\\\\pi}$ and the Gaussian surface area is\\nat most $\\\\frac{d}{\\\\sqrt{2\\\\pi}}$. Furthermore these bounds are asymptotically\\ntight as $\\\\epsilon\\\\to 0$ and $f$ the threshold function of a product of $d$\\ndistinct homogeneous linear functions.\\n',\n",
              " '  Mobile ad hoc networking (MANET) has become an exciting and important\\ntechnology in recent years because of the rapid proliferation of wireless\\ndevices. MANETs are highly vulnerable to attacks due to the open medium,\\ndynamically changing network topology and lack of centralized monitoring point.\\nIt is important to search new architecture and mechanisms to protect the\\nwireless networks and mobile computing application. IDS analyze the network\\nactivities by means of audit data and use patterns of well-known attacks or\\nnormal profile to detect potential attacks. There are two methods to analyze:\\nmisuse detection and anomaly detection. Misuse detection is not effective\\nagainst unknown attacks and therefore, anomaly detection method is used. In\\nthis approach, the audit data is collected from each mobile node after\\nsimulating the attack and compared with the normal behavior of the system. If\\nthere is any deviation from normal behavior then the event is considered as an\\nattack. Some of the features of collected audit data may be redundant or\\ncontribute little to the detection process. So it is essential to select the\\nimportant features to increase the detection rate. This paper focuses on\\nimplementing two feature selection methods namely, markov blanket discovery and\\ngenetic algorithm. In genetic algorithm, bayesian network is constructed over\\nthe collected features and fitness function is calculated. Based on the fitness\\nvalue the features are selected. Markov blanket discovery also uses bayesian\\nnetwork and the features are selected depending on the minimum description\\nlength. During the evaluation phase, the performances of both approaches are\\ncompared based on detection rate and false alarm rate.\\n',\n",
              " '  Among all the partition based clustering algorithms K-means is the most\\npopular and well known method. It generally shows impressive results even in\\nconsiderably large data sets. The computational complexity of K-means does not\\nsuffer from the size of the data set. The main disadvantage faced in performing\\nthis clustering is that the selection of initial means. If the user does not\\nhave adequate knowledge about the data set, it may lead to erroneous results.\\nThe algorithm Automatic Initialization of Means (AIM), which is an extension to\\nK-means, has been proposed to overcome the problem of initial mean generation.\\nIn this paper an attempt has been made to compare the performance of the\\nalgorithms through implementation\\n',\n",
              " '  Many applications require optimizing an unknown, noisy function that is\\nexpensive to evaluate. We formalize this task as a multi-armed bandit problem,\\nwhere the payoff function is either sampled from a Gaussian process (GP) or has\\nlow RKHS norm. We resolve the important open problem of deriving regret bounds\\nfor this setting, which imply novel convergence rates for GP optimization. We\\nanalyze GP-UCB, an intuitive upper-confidence based algorithm, and bound its\\ncumulative regret in terms of maximal information gain, establishing a novel\\nconnection between GP optimization and experimental design. Moreover, by\\nbounding the latter in terms of operator spectra, we obtain explicit sublinear\\nregret bounds for many commonly used covariance functions. In some important\\ncases, our bounds have surprisingly weak dependence on the dimensionality. In\\nour experiments on real sensor data, GP-UCB compares favorably with other\\nheuristical GP optimization approaches.\\n',\n",
              " '  The major challenge in designing a discriminative learning algorithm for\\npredicting structured data is to address the computational issues arising from\\nthe exponential size of the output space. Existing algorithms make different\\nassumptions to ensure efficient, polynomial time estimation of model\\nparameters. For several combinatorial structures, including cycles, partially\\nordered sets, permutations and other graph classes, these assumptions do not\\nhold. In this thesis, we address the problem of designing learning algorithms\\nfor predicting combinatorial structures by introducing two new assumptions: (i)\\nThe first assumption is that a particular counting problem can be solved\\nefficiently. The consequence is a generalisation of the classical ridge\\nregression for structured prediction. (ii) The second assumption is that a\\nparticular sampling problem can be solved efficiently. The consequence is a new\\ntechnique for designing and analysing probabilistic structured prediction\\nmodels. These results can be applied to solve several complex learning problems\\nincluding but not limited to multi-label classification, multi-category\\nhierarchical classification, and label ranking.\\n',\n",
              " '  The problem is sequence prediction in the following setting. A sequence\\n$x_1,...,x_n,...$ of discrete-valued observations is generated according to\\nsome unknown probabilistic law (measure) $\\\\mu$. After observing each outcome,\\nit is required to give the conditional probabilities of the next observation.\\nThe measure $\\\\mu$ belongs to an arbitrary but known class $C$ of stochastic\\nprocess measures. We are interested in predictors $\\\\rho$ whose conditional\\nprobabilities converge (in some sense) to the \"true\" $\\\\mu$-conditional\\nprobabilities if any $\\\\mu\\\\in C$ is chosen to generate the sequence. The\\ncontribution of this work is in characterizing the families $C$ for which such\\npredictors exist, and in providing a specific and simple form in which to look\\nfor a solution. We show that if any predictor works, then there exists a\\nBayesian predictor, whose prior is discrete, and which works too. We also find\\nseveral sufficient and necessary conditions for the existence of a predictor,\\nin terms of topological characterizations of the family $C$, as well as in\\nterms of local behaviour of the measures in $C$, which in some cases lead to\\nprocedures for constructing such predictors. It should be emphasized that the\\nframework is completely general: the stochastic processes considered are not\\nrequired to be i.i.d., stationary, or to belong to any parametric or countable\\nfamily.\\n',\n",
              " '  Let X be randomly chosen from {-1,1}^n, and let Y be randomly chosen from the\\nstandard spherical Gaussian on R^n. For any (possibly unbounded) polytope P\\nformed by the intersection of k halfspaces, we prove that\\n  |Pr [X belongs to P] - Pr [Y belongs to P]| < log^{8/5}k * Delta, where Delta\\nis a parameter that is small for polytopes formed by the intersection of\\n\"regular\" halfspaces (i.e., halfspaces with low influence). The novelty of our\\ninvariance principle is the polylogarithmic dependence on k. Previously, only\\nbounds that were at least linear in k were known. We give two important\\napplications of our main result: (1) A polylogarithmic in k bound on the\\nBoolean noise sensitivity of intersections of k \"regular\" halfspaces (previous\\nwork gave bounds linear in k). (2) A pseudorandom generator (PRG) with seed\\nlength O((log n)*poly(log k,1/delta)) that delta-fools all polytopes with k\\nfaces with respect to the Gaussian distribution. We also obtain PRGs with\\nsimilar parameters that fool polytopes formed by intersection of regular\\nhalfspaces over the hypercube. Using our PRG constructions, we obtain the first\\ndeterministic quasi-polynomial time algorithms for approximately counting the\\nnumber of solutions to a broad class of integer programs, including dense\\ncovering problems and contingency tables.\\n',\n",
              " '  There has been a lot of recent work on Bayesian methods for reinforcement\\nlearning exhibiting near-optimal online performance. The main obstacle facing\\nsuch methods is that in most problems of interest, the optimal solution\\ninvolves planning in an infinitely large tree. However, it is possible to\\nobtain stochastic lower and upper bounds on the value of each tree node. This\\nenables us to use stochastic branch and bound algorithms to search the tree\\nefficiently. This paper proposes two such algorithms and examines their\\ncomplexity in this setting.\\n',\n",
              " '  Analogical reasoning depends fundamentally on the ability to learn and\\ngeneralize about relations between objects. We develop an approach to\\nrelational learning which, given a set of pairs of objects\\n$\\\\mathbf{S}=\\\\{A^{(1)}:B^{(1)},A^{(2)}:B^{(2)},\\\\ldots,A^{(N)}:B ^{(N)}\\\\}$,\\nmeasures how well other pairs A:B fit in with the set $\\\\mathbf{S}$. Our work\\naddresses the following question: is the relation between objects A and B\\nanalogous to those relations found in $\\\\mathbf{S}$? Such questions are\\nparticularly relevant in information retrieval, where an investigator might\\nwant to search for analogous pairs of objects that match the query set of\\ninterest. There are many ways in which objects can be related, making the task\\nof measuring analogies very challenging. Our approach combines a similarity\\nmeasure on function spaces with Bayesian analysis to produce a ranking. It\\nrequires data containing features of the objects of interest and a link matrix\\nspecifying which relationships exist; no further attributes of such\\nrelationships are necessary. We illustrate the potential of our method on text\\nanalysis and information networks. An application on discovering functional\\ninteractions between pairs of proteins is discussed in detail, where we show\\nthat our approach can work in practice even if a small set of protein pairs is\\nprovided.\\n',\n",
              " '  Networks are ubiquitous in science and have become a focal point for\\ndiscussion in everyday life. Formal statistical models for the analysis of\\nnetwork data have emerged as a major topic of interest in diverse areas of\\nstudy, and most of these involve a form of graphical representation.\\nProbability models on graphs date back to 1959. Along with empirical studies in\\nsocial psychology and sociology from the 1960s, these early works generated an\\nactive network community and a substantial literature in the 1970s. This effort\\nmoved into the statistical literature in the late 1970s and 1980s, and the past\\ndecade has seen a burgeoning network literature in statistical physics and\\ncomputer science. The growth of the World Wide Web and the emergence of online\\nnetworking communities such as Facebook, MySpace, and LinkedIn, and a host of\\nmore specialized professional network communities has intensified interest in\\nthe study of networks and network data. Our goal in this review is to provide\\nthe reader with an entry point to this burgeoning literature. We begin with an\\noverview of the historical development of statistical network modeling and then\\nwe introduce a number of examples that have been studied in the network\\nliterature. Our subsequent discussion focuses on a number of prominent static\\nand dynamic network models and their interconnections. We emphasize formal\\nmodel descriptions, and pay special attention to the interpretation of\\nparameters and their estimation. We end with a description of some open\\nproblems and challenges for machine learning and statistics.\\n',\n",
              " '  In this paper we consider the problem of reconstructing a hidden weighted\\nhypergraph of constant rank using additive queries. We prove the following: Let\\n$G$ be a weighted hidden hypergraph of constant rank with n vertices and $m$\\nhyperedges. For any $m$ there exists a non-adaptive algorithm that finds the\\nedges of the graph and their weights using $$ O(\\\\frac{m\\\\log n}{\\\\log m}) $$\\nadditive queries. This solves the open problem in [S. Choi, J. H. Kim. Optimal\\nQuery Complexity Bounds for Finding Graphs. {\\\\em STOC}, 749--758,~2008].\\n  When the weights of the hypergraph are integers that are less than\\n$O(poly(n^d/m))$ where $d$ is the rank of the hypergraph (and therefore for\\nunweighted hypergraphs) there exists a non-adaptive algorithm that finds the\\nedges of the graph and their weights using $$ O(\\\\frac{m\\\\log \\\\frac{n^d}{m}}{\\\\log\\nm}). $$ additive queries.\\n  Using the information theoretic bound the above query complexities are tight.\\n',\n",
              " '  Starting with a similarity function between objects, it is possible to define\\na distance metric on pairs of objects, and more generally on probability\\ndistributions over them. These distance metrics have a deep basis in functional\\nanalysis, measure theory and geometric measure theory, and have a rich\\nstructure that includes an isometric embedding into a (possibly infinite\\ndimensional) Hilbert space. They have recently been applied to numerous\\nproblems in machine learning and shape analysis.\\n  In this paper, we provide the first algorithmic analysis of these distance\\nmetrics. Our main contributions are as follows: (i) We present fast\\napproximation algorithms for computing the kernel distance between two point\\nsets P and Q that runs in near-linear time in the size of (P cup Q) (note that\\nan explicit calculation would take quadratic time). (ii) We present\\npolynomial-time algorithms for approximately minimizing the kernel distance\\nunder rigid transformation; they run in time O(n + poly(1/epsilon, log n)).\\n(iii) We provide several general techniques for reducing complex objects to\\nconvenient sparse representations (specifically to point sets or sets of points\\nsets) which approximately preserve the kernel distance. In particular, this\\nallows us to reduce problems of computing the kernel distance between various\\ntypes of objects such as curves, surfaces, and distributions to computing the\\nkernel distance between point sets. These take advantage of the reproducing\\nkernel Hilbert space and a new relation linking binary range spaces to\\ncontinuous range spaces with bounded fat-shattering dimension.\\n',\n",
              " '  We consider the problem of analyzing the heterogeneity of clustering\\ndistributions for multiple groups of observed data, each of which is indexed by\\na covariate value, and inferring global clusters arising from observations\\naggregated over the covariate domain. We propose a novel Bayesian nonparametric\\nmethod reposing on the formalism of spatial modeling and a nested hierarchy of\\nDirichlet processes. We provide an analysis of the model properties, relating\\nand contrasting the notions of local and global clusters. We also provide an\\nefficient inference algorithm, and demonstrate the utility of our method in\\nseveral data examples, including the problem of object tracking and a global\\nclustering analysis of functional data where the functional identity\\ninformation is not available.\\n',\n",
              " '  A bag-of-words based probabilistic classifier is trained using regularized\\nlogistic regression to detect vandalism in the English Wikipedia. Isotonic\\nregression is used to calibrate the class membership probabilities. Learning\\ncurve, reliability, ROC, and cost analysis are performed.\\n',\n",
              " '  Multi-class classification is one of the most important tasks in machine\\nlearning. In this paper we consider two online multi-class classification\\nproblems: classification by a linear model and by a kernelized model. The\\nquality of predictions is measured by the Brier loss function. We suggest two\\ncomputationally efficient algorithms to work with these problems and prove\\ntheoretical guarantees on their losses. We kernelize one of the algorithms and\\nprove theoretical guarantees on its loss. We perform experiments and compare\\nour algorithms with logistic regression.\\n',\n",
              " '  Knowing the largest rate at which data can be sent on an end-to-end path such\\nthat the egress rate is equal to the ingress rate with high probability can be\\nvery practical when choosing transmission rates in video streaming or selecting\\npeers in peer-to-peer applications. We introduce probabilistic available\\nbandwidth, which is defined in terms of ingress rates and egress rates of\\ntraffic on a path, rather than in terms of capacity and utilization of the\\nconstituent links of the path like the standard available bandwidth metric. In\\nthis paper, we describe a distributed algorithm, based on a probabilistic\\ngraphical model and Bayesian active learning, for simultaneously estimating the\\nprobabilistic available bandwidth of multiple paths through a network. Our\\nprocedure exploits the fact that each packet train provides information not\\nonly about the path it traverses, but also about any path that shares a link\\nwith the monitored path. Simulations and PlanetLab experiments indicate that\\nthis process can dramatically reduce the number of probes required to generate\\naccurate estimates.\\n',\n",
              " '  This empirical study is mainly devoted to comparing four tree-based boosting\\nalgorithms: mart, abc-mart, robust logitboost, and abc-logitboost, for\\nmulti-class classification on a variety of publicly available datasets. Some of\\nthose datasets have been thoroughly tested in prior studies using a broad range\\nof classification algorithms including SVM, neural nets, and deep learning.\\n  In terms of the empirical classification errors, our experiment results\\ndemonstrate:\\n  1. Abc-mart considerably improves mart. 2. Abc-logitboost considerably\\nimproves (robust) logitboost. 3. Robust) logitboost} considerably improves mart\\non most datasets. 4. Abc-logitboost considerably improves abc-mart on most\\ndatasets. 5. These four boosting algorithms (especially abc-logitboost)\\noutperform SVM on many datasets. 6. Compared to the best deep learning methods,\\nthese four boosting algorithms (especially abc-logitboost) are competitive.\\n',\n",
              " '  We present several theoretical contributions which allow Lie groups to be fit\\nto high dimensional datasets. Transformation operators are represented in their\\neigen-basis, reducing the computational complexity of parameter estimation to\\nthat of training a linear transformation model. A transformation specific\\n\"blurring\" operator is introduced that allows inference to escape local minima\\nvia a smoothing of the transformation space. A penalty on traversed manifold\\ndistance is added which encourages the discovery of sparse, minimal distance,\\ntransformations between states. Both learning and inference are demonstrated\\nusing these methods for the full set of affine transformations on natural image\\npatches. Transformation operators are then trained on natural video sequences.\\nIt is shown that the learned video transformations provide a better description\\nof inter-frame differences than the standard motion model based on rigid\\ntranslation.\\n',\n",
              " '  Discovering latent representations of the observed world has become\\nincreasingly more relevant in data analysis. Much of the effort concentrates on\\nbuilding latent variables which can be used in prediction problems, such as\\nclassification and regression. A related goal of learning latent structure from\\ndata is that of identifying which hidden common causes generate the\\nobservations, such as in applications that require predicting the effect of\\npolicies. This will be the main problem tackled in our contribution: given a\\ndataset of indicators assumed to be generated by unknown and unmeasured common\\ncauses, we wish to discover which hidden common causes are those, and how they\\ngenerate our data. This is possible under the assumption that observed\\nvariables are linear functions of the latent causes with additive noise.\\nPrevious results in the literature present solutions for the case where each\\nobserved variable is a noisy function of a single latent variable. We show how\\nto extend the existing results for some cases where observed variables measure\\nmore than one latent variable.\\n',\n",
              " '  Manifold learning is a hot research topic in the field of computer science\\nand has many applications in the real world. A main drawback of manifold\\nlearning methods is, however, that there is no explicit mappings from the input\\ndata manifold to the output embedding. This prohibits the application of\\nmanifold learning methods in many practical problems such as classification and\\ntarget detection. Previously, in order to provide explicit mappings for\\nmanifold learning methods, many methods have been proposed to get an\\napproximate explicit representation mapping with the assumption that there\\nexists a linear projection between the high-dimensional data samples and their\\nlow-dimensional embedding. However, this linearity assumption may be too\\nrestrictive. In this paper, an explicit nonlinear mapping is proposed for\\nmanifold learning, based on the assumption that there exists a polynomial\\nmapping between the high-dimensional data samples and their low-dimensional\\nrepresentations. As far as we know, this is the first time that an explicit\\nnonlinear mapping for manifold learning is given. In particular, we apply this\\nto the method of Locally Linear Embedding (LLE) and derive an explicit\\nnonlinear manifold learning algorithm, named Neighborhood Preserving Polynomial\\nEmbedding (NPPE). Experimental results on both synthetic and real-world data\\nshow that the proposed mapping is much more effective in preserving the local\\nneighborhood information and the nonlinear geometry of the high-dimensional\\ndata samples than previous work.\\n',\n",
              " '  In this paper, the framework of kernel machines with two layers is\\nintroduced, generalizing classical kernel methods. The new learning methodology\\nprovide a formal connection between computational architectures with multiple\\nlayers and the theme of kernel learning in standard regularization methods.\\nFirst, a representer theorem for two-layer networks is presented, showing that\\nfinite linear combinations of kernels on each layer are optimal architectures\\nwhenever the corresponding functions solve suitable variational problems in\\nreproducing kernel Hilbert spaces (RKHS). The input-output map expressed by\\nthese architectures turns out to be equivalent to a suitable single-layer\\nkernel machines in which the kernel function is also learned from the data.\\nRecently, the so-called multiple kernel learning methods have attracted\\nconsiderable attention in the machine learning literature. In this paper,\\nmultiple kernel learning methods are shown to be specific cases of kernel\\nmachines with two layers in which the second layer is linear. Finally, a simple\\nand effective multiple kernel learning method called RLS2 (regularized least\\nsquares with two layers) is introduced, and his performances on several\\nlearning problems are extensively analyzed. An open source MATLAB toolbox to\\ntrain and validate RLS2 models with a Graphic User Interface is available.\\n',\n",
              " '  The aim of this work is to address the question of whether we can in\\nprinciple design rational decision-making agents or artificial intelligences\\nembedded in computable physics such that their decisions are optimal in\\nreasonable mathematical senses. Recent developments in rare event probability\\nestimation, recursive bayesian inference, neural networks, and probabilistic\\nplanning are sufficient to explicitly approximate reinforcement learners of the\\nAIXI style with non-trivial model classes (here, the class of resource-bounded\\nTuring machines). Consideration of the effects of resource limitations in a\\nconcrete implementation leads to insights about possible architectures for\\nlearning systems using optimal decision makers as components.\\n',\n",
              " '  Bayes statistics and statistical physics have the common mathematical\\nstructure, where the log likelihood function corresponds to the random\\nHamiltonian. Recently, it was discovered that the asymptotic learning curves in\\nBayes estimation are subject to a universal law, even if the log likelihood\\nfunction can not be approximated by any quadratic form. However, it is left\\nunknown what mathematical property ensures such a universal law. In this paper,\\nwe define a renormalizable condition of the statistical estimation problem, and\\nshow that, under such a condition, the asymptotic learning curves are ensured\\nto be subject to the universal law, even if the true distribution is\\nunrealizable and singular for a statistical model. Also we study a\\nnonrenormalizable case, in which the learning curves have the different\\nasymptotic behaviors from the universal law.\\n',\n",
              " '  This paper concerns the construction of tests for universal hypothesis\\ntesting problems, in which the alternate hypothesis is poorly modeled and the\\nobservation space is large. The mismatched universal test is a feature-based\\ntechnique for this purpose. In prior work it is shown that its\\nfinite-observation performance can be much better than the (optimal) Hoeffding\\ntest, and good performance depends crucially on the choice of features. The\\ncontributions of this paper include: 1) We obtain bounds on the number of\\n\\\\epsilon distinguishable distributions in an exponential family. 2) This\\nmotivates a new framework for feature extraction, cast as a rank-constrained\\noptimization problem. 3) We obtain a gradient-based algorithm to solve the\\nrank-constrained optimization problem and prove its local convergence.\\n',\n",
              " '  Approximate message passing algorithms proved to be extremely effective in\\nreconstructing sparse signals from a small number of incoherent linear\\nmeasurements. Extensive numerical experiments further showed that their\\ndynamics is accurately tracked by a simple one-dimensional iteration termed\\nstate evolution. In this paper we provide the first rigorous foundation to\\nstate evolution. We prove that indeed it holds asymptotically in the large\\nsystem limit for sensing matrices with independent and identically distributed\\ngaussian entries.\\n  While our focus is on message passing algorithms for compressed sensing, the\\nanalysis extends beyond this setting, to a general class of algorithms on dense\\ngraphs. In this context, state evolution plays the role that density evolution\\nhas for sparse graphs.\\n  The proof technique is fundamentally different from the standard approach to\\ndensity evolution, in that it copes with large number of short loops in the\\nunderlying factor graph. It relies instead on a conditioning technique recently\\ndeveloped by Erwin Bolthausen in the context of spin glass theory.\\n',\n",
              " '  Associative Classifier is a novel technique which is the integration of\\nAssociation Rule Mining and Classification. The difficult task in building\\nAssociative Classifier model is the selection of relevant rules from a large\\nnumber of class association rules (CARs). A very popular method of ordering\\nrules for selection is based on confidence, support and antecedent size (CSA).\\nOther methods are based on hybrid orderings in which CSA method is combined\\nwith other measures. In the present work, we study the effect of using\\ndifferent interestingness measures of Association rules in CAR rule ordering\\nand selection for associative classifier.\\n',\n",
              " '  Identity verification of authentic persons by their multiview faces is a real\\nvalued problem in machine vision. Multiview faces are having difficulties due\\nto non-linear representation in the feature space. This paper illustrates the\\nusability of the generalization of LDA in the form of canonical covariate for\\nface recognition to multiview faces. In the proposed work, the Gabor filter\\nbank is used to extract facial features that characterized by spatial\\nfrequency, spatial locality and orientation. Gabor face representation captures\\nsubstantial amount of variations of the face instances that often occurs due to\\nillumination, pose and facial expression changes. Convolution of Gabor filter\\nbank to face images of rotated profile views produce Gabor faces with high\\ndimensional features vectors. Canonical covariate is then used to Gabor faces\\nto reduce the high dimensional feature spaces into low dimensional subspaces.\\nFinally, support vector machines are trained with canonical sub-spaces that\\ncontain reduced set of features and perform recognition task. The proposed\\nsystem is evaluated with UMIST face database. The experiment results\\ndemonstrate the efficiency and robustness of the proposed system with high\\nrecognition rates.\\n',\n",
              " '  In this paper, we introduce elements of probabilistic model that is suitable\\nfor modeling of learning algorithms in biologically plausible artificial neural\\nnetworks framework. Model is based on two of the main concepts in quantum\\nphysics - a density matrix and the Born rule. As an example, we will show that\\nproposed probabilistic interpretation is suitable for modeling of on-line\\nlearning algorithms for PSA, which are preferably realized by a parallel\\nhardware based on very simple computational units. Proposed concept (model) can\\nbe used in the context of improving algorithm convergence speed, learning\\nfactor choice, or input signal scale robustness. We are going to see how the\\nBorn rule and the Hebbian learning rule are connected\\n',\n",
              " '  We consider a generalization of stochastic bandits where the set of arms,\\n$\\\\cX$, is allowed to be a generic measurable space and the mean-payoff function\\nis \"locally Lipschitz\" with respect to a dissimilarity function that is known\\nto the decision maker. Under this condition we construct an arm selection\\npolicy, called HOO (hierarchical optimistic optimization), with improved regret\\nbounds compared to previous results for a large class of problems. In\\nparticular, our results imply that if $\\\\cX$ is the unit hypercube in a\\nEuclidean space and the mean-payoff function has a finite number of global\\nmaxima around which the behavior of the function is locally continuous with a\\nknown smoothness degree, then the expected regret of HOO is bounded up to a\\nlogarithmic factor by $\\\\sqrt{n}$, i.e., the rate of growth of the regret is\\nindependent of the dimension of the space. We also prove the minimax optimality\\nof our algorithm when the dissimilarity is a metric. Our basic strategy has\\nquadratic computational complexity as a function of the number of time steps\\nand does not rely on the doubling trick. We also introduce a modified strategy,\\nwhich relies on the doubling trick but runs in linearithmic time. Both results\\nare improvements with respect to previous approaches.\\n',\n",
              " '  This paper presents a framework aimed at monitoring the behavior of aircraft\\nin a given airspace. Nominal trajectories are determined and learned using data\\ndriven methods. Standard procedures are used by air traffic controllers (ATC)\\nto guide aircraft, ensure the safety of the airspace, and to maximize the\\nrunway occupancy. Even though standard procedures are used by ATC, the control\\nof the aircraft remains with the pilots, leading to a large variability in the\\nflight patterns observed. Two methods to identify typical operations and their\\nvariability from recorded radar tracks are presented. This knowledge base is\\nthen used to monitor the conformance of current operations against operations\\npreviously identified as standard. A tool called AirTrajectoryMiner is\\npresented, aiming at monitoring the instantaneous health of the airspace, in\\nreal time. The airspace is \"healthy\" when all aircraft are flying according to\\nthe nominal procedures. A measure of complexity is introduced, measuring the\\nconformance of current flight to nominal flight patterns. When an aircraft does\\nnot conform, the complexity increases as more attention from ATC is required to\\nensure a safe separation between aircraft.\\n',\n",
              " '  In this paper we have investigated the performance of PSO Particle Swarm\\nOptimization based clustering on few real world data sets and one artificial\\ndata set. The performances are measured by two metric namely quantization error\\nand inter-cluster distance. The K means clustering algorithm is first\\nimplemented for all data sets, the results of which form the basis of\\ncomparison of PSO based approaches. We have explored different variants of PSO\\nsuch as gbest, lbest ring, lbest vonneumann and Hybrid PSO for comparison\\npurposes. The results reveal that PSO based clustering algorithms perform\\nbetter compared to K means in all data sets.\\n',\n",
              " '  This paper proposes an efficient technique for partitioning large biometric\\ndatabase during identification. In this technique feature vector which\\ncomprises of global and local descriptors extracted from offline signature are\\nused by fuzzy clustering technique to partition the database. As biometric\\nfeatures posses no natural order of sorting, thus it is difficult to index them\\nalphabetically or numerically. Hence, some supervised criteria is required to\\npartition the search space. At the time of identification the fuzziness\\ncriterion is introduced to find the nearest clusters for declaring the identity\\nof query sample. The system is tested using bin-miss rate and performs better\\nin comparison to traditional k-means approach.\\n',\n",
              " '  This paper uses Support Vector Machines (SVM) to fuse multiple classifiers\\nfor an offline signature system. From the signature images, global and local\\nfeatures are extracted and the signatures are verified with the help of\\nGaussian empirical rule, Euclidean and Mahalanobis distance based classifiers.\\nSVM is used to fuse matching scores of these matchers. Finally, recognition of\\nquery signatures is done by comparing it with all signatures of the database.\\nThe proposed system is tested on a signature database contains 5400 offline\\nsignatures of 600 individuals and the results are found to be promising.\\n',\n",
              " '  The paper deals with on-line regression settings with signals belonging to a\\nBanach lattice. Our algorithms work in a semi-online setting where all the\\ninputs are known in advance and outcomes are unknown and given step by step. We\\napply the Aggregating Algorithm to construct a prediction method whose\\ncumulative loss over all the input vectors is comparable with the cumulative\\nloss of any linear functional on the Banach lattice. As a by-product we get an\\nalgorithm that takes signals from an arbitrary domain. Its cumulative loss is\\ncomparable with the cumulative loss of any predictor function from Besov and\\nTriebel-Lizorkin spaces. We describe several applications of our setting.\\n',\n",
              " \"  We consider a group of Bayesian agents who try to estimate a state of the\\nworld $\\\\theta$ through interaction on a social network. Each agent $v$\\ninitially receives a private measurement of $\\\\theta$: a number $S_v$ picked\\nfrom a Gaussian distribution with mean $\\\\theta$ and standard deviation one.\\nThen, in each discrete time iteration, each reveals its estimate of $\\\\theta$ to\\nits neighbors, and, observing its neighbors' actions, updates its belief using\\nBayes' Law.\\n  This process aggregates information efficiently, in the sense that all the\\nagents converge to the belief that they would have, had they access to all the\\nprivate measurements. We show that this process is computationally efficient,\\nso that each agent's calculation can be easily carried out. We also show that\\non any graph the process converges after at most $2N \\\\cdot D$ steps, where $N$\\nis the number of agents and $D$ is the diameter of the network. Finally, we\\nshow that on trees and on distance transitive-graphs the process converges\\nafter $D$ steps, and that it preserves privacy, so that agents learn very\\nlittle about the private signal of most other agents, despite the efficient\\naggregation of information. Our results extend those in an unpublished\\nmanuscript of the first and last authors.\\n\",\n",
              " '  We analyse the prequential plug-in codes relative to one-parameter\\nexponential families M. We show that if data are sampled i.i.d. from some\\ndistribution outside M, then the redundancy of any plug-in prequential code\\ngrows at rate larger than 1/2 ln(n) in the worst case. This means that plug-in\\ncodes, such as the Rissanen-Dawid ML code, may behave inferior to other\\nimportant universal codes such as the 2-part MDL, Shtarkov and Bayes codes, for\\nwhich the redundancy is always 1/2 ln(n) + O(1). However, we also show that a\\nslight modification of the ML plug-in code, \"almost\" in the model, does achieve\\nthe optimal redundancy even if the the true distribution is outside M.\\n',\n",
              " \"  The performance in higher secondary school education in India is a turning\\npoint in the academic lives of all students. As this academic performance is\\ninfluenced by many factors, it is essential to develop predictive data mining\\nmodel for students' performance so as to identify the slow learners and study\\nthe influence of the dominant factors on their academic performance. In the\\npresent investigation, a survey cum experimental methodology was adopted to\\ngenerate a database and it was constructed from a primary and a secondary\\nsource. While the primary data was collected from the regular students, the\\nsecondary data was gathered from the school and office of the Chief Educational\\nOfficer (CEO). A total of 1000 datasets of the year 2006 from five different\\nschools in three different districts of Tamilnadu were collected. The raw data\\nwas preprocessed in terms of filling up missing values, transforming values in\\none form into another and relevant attribute/ variable selection. As a result,\\nwe had 772 student records, which were used for CHAID prediction model\\nconstruction. A set of prediction rules were extracted from CHIAD prediction\\nmodel and the efficiency of the generated CHIAD prediction model was found. The\\naccuracy of the present model was compared with other model and it has been\\nfound to be satisfactory.\\n\",\n",
              " \"  The recent increase in dimensionality of data has thrown a great challenge to\\nthe existing dimensionality reduction methods in terms of their effectiveness.\\nDimensionality reduction has emerged as one of the significant preprocessing\\nsteps in machine learning applications and has been effective in removing\\ninappropriate data, increasing learning accuracy, and improving\\ncomprehensibility. Feature redundancy exercises great influence on the\\nperformance of classification process. Towards the better classification\\nperformance, this paper addresses the usefulness of truncating the highly\\ncorrelated and redundant attributes. Here, an effort has been made to verify\\nthe utility of dimensionality reduction by applying LVQ (Learning Vector\\nQuantization) method on two Benchmark datasets of 'Pima Indian Diabetic\\npatients' and 'Lung cancer patients'.\\n\",\n",
              " \"  Adaptive control problems are notoriously difficult to solve even in the\\npresence of plant-specific controllers. One way to by-pass the intractable\\ncomputation of the optimal policy is to restate the adaptive control as the\\nminimization of the relative entropy of a controller that ignores the true\\nplant dynamics from an informed controller. The solution is given by the\\nBayesian control rule-a set of equations characterizing a stochastic adaptive\\ncontroller for the class of possible plant dynamics. Here, the Bayesian control\\nrule is applied to derive BCR-MDP, a controller to solve undiscounted Markov\\ndecision processes with finite state and action spaces and unknown dynamics. In\\nparticular, we derive a non-parametric conjugate prior distribution over the\\npolicy space that encapsulates the agent's whole relevant history and we\\npresent a Gibbs sampler to draw random policies from this distribution.\\nPreliminary results show that BCR-MDP successfully avoids sub-optimal limit\\ncycles due to its built-in mechanism to balance exploration versus\\nexploitation.\\n\",\n",
              " '  A key problem in sensor networks is to decide which sensors to query when, in\\norder to obtain the most useful information (e.g., for performing accurate\\nprediction), subject to constraints (e.g., on power and bandwidth). In many\\napplications the utility function is not known a priori, must be learned from\\ndata, and can even change over time. Furthermore for large sensor networks\\nsolving a centralized optimization problem to select sensors is not feasible,\\nand thus we seek a fully distributed solution. In this paper, we present\\nDistributed Online Greedy (DOG), an efficient, distributed algorithm for\\nrepeatedly selecting sensors online, only receiving feedback about the utility\\nof the selected sensors. We prove very strong theoretical no-regret guarantees\\nthat apply whenever the (unknown) utility function satisfies a natural\\ndiminishing returns property called submodularity. Our algorithm has extremely\\nlow communication requirements, and scales well to large sensor deployments. We\\nextend DOG to allow observation-dependent sensor selection. We empirically\\ndemonstrate the effectiveness of our algorithm on several real-world sensing\\ntasks.\\n',\n",
              " '  Recently Kutin and Niyogi investigated several notions of algorithmic\\nstability--a property of a learning map conceptually similar to\\ncontinuity--showing that training-stability is sufficient for consistency of\\nEmpirical Risk Minimization while distribution-free CV-stability is necessary\\nand sufficient for having finite VC-dimension. This paper concerns a phase\\ntransition in the training stability of ERM, conjectured by the same authors.\\nKutin and Niyogi proved that ERM on finite hypothesis spaces containing a\\nunique risk minimizer has training stability that scales exponentially with\\nsample size, and conjectured that the existence of multiple risk minimizers\\nprevents even super-quadratic convergence. We prove this result for the\\nstrictly weaker notion of CV-stability, positively resolving the conjecture.\\n',\n",
              " '  Estimating intrinsic dimensionality of data is a classic problem in pattern\\nrecognition and statistics. Principal Component Analysis (PCA) is a powerful\\ntool in discovering dimensionality of data sets with a linear structure; it,\\nhowever, becomes ineffective when data have a nonlinear structure. In this\\npaper, we propose a new PCA-based method to estimate intrinsic dimension of\\ndata with nonlinear structures. Our method works by first finding a minimal\\ncover of the data set, then performing PCA locally on each subset in the cover\\nand finally giving the estimation result by checking up the data variance on\\nall small neighborhood regions. The proposed method utilizes the whole data set\\nto estimate its intrinsic dimension and is convenient for incremental learning.\\nIn addition, our new PCA procedure can filter out noise in data and converge to\\na stable estimation with the neighborhood region size increasing. Experiments\\non synthetic and real world data sets show effectiveness of the proposed\\nmethod.\\n',\n",
              " '  Using virtual stock markets with artificial interacting software investors,\\naka agent-based models (ABMs), we present a method to reverse engineer\\nreal-world financial time series. We model financial markets as made of a large\\nnumber of interacting boundedly rational agents. By optimizing the similarity\\nbetween the actual data and that generated by the reconstructed virtual stock\\nmarket, we obtain parameters and strategies, which reveal some of the inner\\nworkings of the target stock market. We validate our approach by out-of-sample\\npredictions of directional moves of the Nasdaq Composite Index.\\n',\n",
              " \"  We extend the Chow-Liu algorithm for general random variables while the\\nprevious versions only considered finite cases. In particular, this paper\\napplies the generalization to Suzuki's learning algorithm that generates from\\ndata forests rather than trees based on the minimum description length by\\nbalancing the fitness of the data to the forest and the simplicity of the\\nforest. As a result, we successfully obtain an algorithm when both of the\\nGaussian and finite random variables are present.\\n\",\n",
              " '  The ability to monitor the progress of students academic performance is a\\ncritical issue to the academic community of higher learning. A system for\\nanalyzing students results based on cluster analysis and uses standard\\nstatistical algorithms to arrange their scores data according to the level of\\ntheir performance is described. In this paper, we also implemented k mean\\nclustering algorithm for analyzing students result data. The model was combined\\nwith the deterministic model to analyze the students results of a private\\nInstitution in Nigeria which is a good benchmark to monitor the progression of\\nacademic performance of students in higher Institution for the purpose of\\nmaking an effective decision by the academic planners.\\n',\n",
              " '  We show that matrix completion with trace-norm regularization can be\\nsignificantly hurt when entries of the matrix are sampled non-uniformly. We\\nintroduce a weighted version of the trace-norm regularizer that works well also\\nwith non-uniform sampling. Our experimental results demonstrate that the\\nweighted trace-norm regularization indeed yields significant gains on the\\n(highly non-uniformly sampled) Netflix dataset.\\n',\n",
              " '  Recently, new approaches to adaptive control have sought to reformulate the\\nproblem as a minimization of a relative entropy criterion to obtain tractable\\nsolutions. In particular, it has been shown that minimizing the expected\\ndeviation from the causal input-output dependencies of the true plant leads to\\na new promising stochastic control rule called the Bayesian control rule. This\\nwork proves the convergence of the Bayesian control rule under two sufficient\\nassumptions: boundedness, which is an ergodicity condition; and consistency,\\nwhich is an instantiation of the sure-thing principle.\\n',\n",
              " '  File type identification and file type clustering may be difficult tasks that\\nhave an increasingly importance in the field of computer and network security.\\nClassical methods of file type detection including considering file extensions\\nand magic bytes can be easily spoofed. Content-based file type detection is a\\nnewer way that is taken into account recently. In this paper, a new\\ncontent-based method for the purpose of file type detection and file type\\nclustering is proposed that is based on the PCA and neural networks. The\\nproposed method has a good accuracy and is fast enough.\\n',\n",
              " \"  Statistical query (SQ) learning model of Kearns (1993) is a natural\\nrestriction of the PAC learning model in which a learning algorithm is allowed\\nto obtain estimates of statistical properties of the examples but cannot see\\nthe examples themselves. We describe a new and simple characterization of the\\nquery complexity of learning in the SQ learning model. Unlike the previously\\nknown bounds on SQ learning our characterization preserves the accuracy and the\\nefficiency of learning. The preservation of accuracy implies that that our\\ncharacterization gives the first characterization of SQ learning in the\\nagnostic learning framework. The preservation of efficiency is achieved using a\\nnew boosting technique and allows us to derive a new approach to the design of\\nevolutionary algorithms in Valiant's (2006) model of evolvability. We use this\\napproach to demonstrate the existence of a large class of monotone evolutionary\\nlearning algorithms based on square loss performance estimation. These results\\ndiffer significantly from the few known evolutionary algorithms and give\\nevidence that evolvability in Valiant's model is a more versatile phenomenon\\nthan there had been previous reason to suspect.\\n\",\n",
              " '  We introduce a natural generalization of submodular set cover and exact\\nactive learning with a finite hypothesis class (query learning). We call this\\nnew problem interactive submodular set cover. Applications include advertising\\nin social networks with hidden information. We give an approximation guarantee\\nfor a novel greedy algorithm and give a hardness of approximation result which\\nmatches up to constant factors. We also discuss negative results for simpler\\napproaches and present encouraging early experimental results.\\n',\n",
              " '  India is a multi-lingual country where Roman script is often used alongside\\ndifferent Indic scripts in a text document. To develop a script specific\\nhandwritten Optical Character Recognition (OCR) system, it is therefore\\nnecessary to identify the scripts of handwritten text correctly. In this paper,\\nwe present a system, which automatically separates the scripts of handwritten\\nwords from a document, written in Bangla or Devanagri mixed with Roman scripts.\\nIn this script separation technique, we first, extract the text lines and words\\nfrom document pages using a script independent Neighboring Component Analysis\\ntechnique. Then we have designed a Multi Layer Perceptron (MLP) based\\nclassifier for script separation, trained with 8 different wordlevel holistic\\nfeatures. Two equal sized datasets, one with Bangla and Roman scripts and the\\nother with Devanagri and Roman scripts, are prepared for the system evaluation.\\nOn respective independent text samples, word-level script identification\\naccuracies of 99.29% and 98.43% are achieved.\\n',\n",
              " '  A novel approach for recognition of handwritten compound Bangla characters,\\nalong with the Basic characters of Bangla alphabet, is presented here. Compared\\nto English like Roman script, one of the major stumbling blocks in Optical\\nCharacter Recognition (OCR) of handwritten Bangla script is the large number of\\ncomplex shaped character classes of Bangla alphabet. In addition to 50 basic\\ncharacter classes, there are nearly 160 complex shaped compound character\\nclasses in Bangla alphabet. Dealing with such a large varieties of handwritten\\ncharacters with a suitably designed feature set is a challenging problem.\\nUncertainty and imprecision are inherent in handwritten script. Moreover, such\\na large varieties of complex shaped characters, some of which have close\\nresemblance, makes the problem of OCR of handwritten Bangla characters more\\ndifficult. Considering the complexity of the problem, the present approach\\nmakes an attempt to identify compound character classes from most frequently to\\nless frequently occurred ones, i.e., in order of importance. This is to develop\\na frame work for incrementally increasing the number of learned classes of\\ncompound characters from more frequently occurred ones to less frequently\\noccurred ones along with Basic characters. On experimentation, the technique is\\nobserved produce an average recognition rate of 79.25 after three fold cross\\nvalidation of data with future scope of improvement and extension.\\n',\n",
              " '  Nowadays government and private agencies use remote sensing imagery for a\\nwide range of applications from military applications to farm development. The\\nimages may be a panchromatic, multispectral, hyperspectral or even\\nultraspectral of terra bytes. Remote sensing image classification is one\\namongst the most significant application worlds for remote sensing. A few\\nnumber of image classification algorithms have proved good precision in\\nclassifying remote sensing data. But, of late, due to the increasing\\nspatiotemporal dimensions of the remote sensing data, traditional\\nclassification algorithms have exposed weaknesses necessitating further\\nresearch in the field of remote sensing image classification. So an efficient\\nclassifier is needed to classify the remote sensing images to extract\\ninformation. We are experimenting with both supervised and unsupervised\\nclassification. Here we compare the different classification methods and their\\nperformances. It is found that Mahalanobis classifier performed the best in our\\nclassification.\\n',\n",
              " '  We address the problem of learning in an online, bandit setting where the\\nlearner must repeatedly select among $K$ actions, but only receives partial\\nfeedback based on its choices. We establish two new facts: First, using a new\\nalgorithm called Exp4.P, we show that it is possible to compete with the best\\nin a set of $N$ experts with probability $1-\\\\delta$ while incurring regret at\\nmost $O(\\\\sqrt{KT\\\\ln(N/\\\\delta)})$ over $T$ time steps. The new algorithm is\\ntested empirically in a large-scale, real-world dataset. Second, we give a new\\nalgorithm called VE that competes with a possibly infinite set of policies of\\nVC-dimension $d$ while incurring regret at most $O(\\\\sqrt{T(d\\\\ln(T) + \\\\ln\\n(1/\\\\delta))})$ with probability $1-\\\\delta$. These guarantees improve on those\\nof all previous algorithms, whether in a stochastic or adversarial environment,\\nand bring us closer to providing supervised learning type guarantees for the\\ncontextual bandit setting.\\n',\n",
              " '  We consider the dimensionality-reduction problem (finding a subspace\\napproximation of observed data) for contaminated data in the high dimensional\\nregime, where the number of observations is of the same magnitude as the number\\nof variables of each observation, and the data set contains some (arbitrarily)\\ncorrupted observations. We propose a High-dimensional Robust Principal\\nComponent Analysis (HR-PCA) algorithm that is tractable, robust to contaminated\\npoints, and easily kernelizable. The resulting subspace has a bounded deviation\\nfrom the desired one, achieves maximal robustness -- a breakdown point of 50%\\nwhile all existing algorithms have a breakdown point of zero, and unlike\\nordinary PCA algorithms, achieves optimality in the limit case where the\\nproportion of corrupted points goes to zero.\\n',\n",
              " '  In a variety of disciplines such as social sciences, psychology, medicine and\\neconomics, the recorded data are considered to be noisy measurements of latent\\nvariables connected by some causal structure. This corresponds to a family of\\ngraphical models known as the structural equation model with latent variables.\\nWhile linear non-Gaussian variants have been well-studied, inference in\\nnonparametric structural equation models is still underdeveloped. We introduce\\na sparse Gaussian process parameterization that defines a non-linear structure\\nconnecting latent variables, unlike common formulations of Gaussian process\\nlatent variable models. The sparse parameterization is given a full Bayesian\\ntreatment without compromising Markov chain Monte Carlo efficiency. We compare\\nthe stability of the sampling procedure and the predictive ability of the model\\nagainst the current practice.\\n',\n",
              " '  We analyze and evaluate an online gradient descent algorithm with adaptive\\nper-coordinate adjustment of learning rates. Our algorithm can be thought of as\\nan online version of batch gradient descent with a diagonal preconditioner.\\nThis approach leads to regret bounds that are stronger than those of standard\\nonline gradient descent for general online convex optimization problems.\\nExperimentally, we show that our algorithm is competitive with state-of-the-art\\nalgorithms for large scale machine learning problems.\\n',\n",
              " \"  We introduce a new online convex optimization algorithm that adaptively\\nchooses its regularization function based on the loss functions observed so\\nfar. This is in contrast to previous algorithms that use a fixed regularization\\nfunction such as L2-squared, and modify it only via a single time-dependent\\nparameter. Our algorithm's regret bounds are worst-case optimal, and for\\ncertain realistic classes of loss functions they are much better than existing\\nbounds. These bounds are problem-dependent, which means they can exploit the\\nstructure of the actual problem instance. Critically, however, our algorithm\\ndoes not need to know this structure in advance. Rather, we prove competitive\\nguarantees that show the algorithm provides a bound within a constant factor of\\nthe best possible bound (of a certain functional form) in hindsight.\\n\",\n",
              " '  Semisupervised learning has emerged as a popular framework for improving\\nmodeling accuracy while controlling labeling cost. Based on an extension of\\nstochastic composite likelihood we quantify the asymptotic accuracy of\\ngenerative semi-supervised learning. In doing so, we complement\\ndistribution-free analysis by providing an alternative framework to measure the\\nvalue associated with different labeling policies and resolve the fundamental\\nquestion of how much data to label and in what manner. We demonstrate our\\napproach with both simulation studies and real world experiments using naive\\nBayes for text classification and MRFs and CRFs for structured prediction in\\nNLP.\\n',\n",
              " '  We explore the striking mathematical connections that exist between market\\nscoring rules, cost function based prediction markets, and no-regret learning.\\nWe show that any cost function based prediction market can be interpreted as an\\nalgorithm for the commonly studied problem of learning from expert advice by\\nequating trades made in the market with losses observed by the learning\\nalgorithm. If the loss of the market organizer is bounded, this bound can be\\nused to derive an O(sqrt(T)) regret bound for the corresponding learning\\nalgorithm. We then show that the class of markets with convex cost functions\\nexactly corresponds to the class of Follow the Regularized Leader learning\\nalgorithms, with the choice of a cost function in the market corresponding to\\nthe choice of a regularizer in the learning problem. Finally, we show an\\nequivalence between market scoring rules and prediction markets with convex\\ncost functions. This implies that market scoring rules can also be interpreted\\nnaturally as Follow the Regularized Leader algorithms, and may be of\\nindependent interest. These connections provide new insight into how it is that\\ncommonly studied markets, such as the Logarithmic Market Scoring Rule, can\\naggregate opinions into accurate estimates of the likelihood of future events.\\n',\n",
              " '  Learning linear combinations of multiple kernels is an appealing strategy\\nwhen the right choice of features is unknown. Previous approaches to multiple\\nkernel learning (MKL) promote sparse kernel combinations to support\\ninterpretability and scalability. Unfortunately, this 1-norm MKL is rarely\\nobserved to outperform trivial baselines in practical applications. To allow\\nfor robust kernel mixtures, we generalize MKL to arbitrary norms. We devise new\\ninsights on the connection between several existing MKL formulations and\\ndevelop two efficient interleaved optimization strategies for arbitrary norms,\\nlike p-norms with p>1. Empirically, we demonstrate that the interleaved\\noptimization strategies are much faster compared to the commonly used wrapper\\napproaches. A theoretical analysis and an experiment on controlled artificial\\ndata experiment sheds light on the appropriateness of sparse, non-sparse and\\n$\\\\ell_\\\\infty$-norm MKL in various scenarios. Empirical applications of p-norm\\nMKL to three real-world problems from computational biology show that\\nnon-sparse MKL achieves accuracies that go beyond the state-of-the-art.\\n',\n",
              " '  We provide a sound and consistent foundation for the use of \\\\emph{nonrandom}\\nexploration data in \"contextual bandit\" or \"partially labeled\" settings where\\nonly the value of a chosen action is learned.\\n  The primary challenge in a variety of settings is that the exploration\\npolicy, in which \"offline\" data is logged, is not explicitly known. Prior\\nsolutions here require either control of the actions during the learning\\nprocess, recorded random exploration, or actions chosen obliviously in a\\nrepeated manner. The techniques reported here lift these restrictions, allowing\\nthe learning of a policy for choosing actions given features from historical\\ndata where no randomization occurred or was logged.\\n  We empirically verify our solution on two reasonably sized sets of real-world\\ndata obtained from Yahoo!.\\n',\n",
              " '  Personalized web services strive to adapt their services (advertisements,\\nnews articles, etc) to individual users by making use of both content and user\\ninformation. Despite a few recent advances, this problem remains challenging\\nfor at least two reasons. First, web service is featured with dynamically\\nchanging pools of content, rendering traditional collaborative filtering\\nmethods inapplicable. Second, the scale of most web services of practical\\ninterest calls for solutions that are both fast in learning and computation.\\n  In this work, we model personalized recommendation of news articles as a\\ncontextual bandit problem, a principled approach in which a learning algorithm\\nsequentially selects articles to serve users based on contextual information\\nabout the users and articles, while simultaneously adapting its\\narticle-selection strategy based on user-click feedback to maximize total user\\nclicks.\\n  The contributions of this work are three-fold. First, we propose a new,\\ngeneral contextual bandit algorithm that is computationally efficient and well\\nmotivated from learning theory. Second, we argue that any bandit algorithm can\\nbe reliably evaluated offline using previously recorded random traffic.\\nFinally, using this offline evaluation method, we successfully applied our new\\nalgorithm to a Yahoo! Front Page Today Module dataset containing over 33\\nmillion events. Results showed a 12.5% click lift compared to a standard\\ncontext-free bandit algorithm, and the advantage becomes even greater when data\\ngets more scarce.\\n',\n",
              " '  The ability to detect weak distributed activation patterns in networks is\\ncritical to several applications, such as identifying the onset of anomalous\\nactivity or incipient congestion in the Internet, or faint traces of a\\nbiochemical spread by a sensor network. This is a challenging problem since\\nweak distributed patterns can be invisible in per node statistics as well as a\\nglobal network-wide aggregate. Most prior work considers situations in which\\nthe activation/non-activation of each node is statistically independent, but\\nthis is unrealistic in many problems. In this paper, we consider structured\\npatterns arising from statistical dependencies in the activation process. Our\\ncontributions are three-fold. First, we propose a sparsifying transform that\\nsuccinctly represents structured activation patterns that conform to a\\nhierarchical dependency graph. Second, we establish that the proposed transform\\nfacilitates detection of very weak activation patterns that cannot be detected\\nwith existing methods. Third, we show that the structure of the hierarchical\\ndependency graph governing the activation process, and hence the network\\ntransform, can be learnt from very few (logarithmic in network size)\\nindependent snapshots of network activity.\\n',\n",
              " '  Many popular linear classifiers, such as logistic regression, boosting, or\\nSVM, are trained by optimizing a margin-based risk function. Traditionally,\\nthese risk functions are computed based on a labeled dataset. We develop a\\nnovel technique for estimating such risks using only unlabeled data and the\\nmarginal label distribution. We prove that the proposed risk estimator is\\nconsistent on high-dimensional datasets and demonstrate it on synthetic and\\nreal-world data. In particular, we show how the estimate is used for evaluating\\nclassifiers in transfer learning, and for training classifiers with no labeled\\ndata whatsoever.\\n',\n",
              " '  A key issue in statistics and machine learning is to automatically select the\\n\"right\" model complexity, e.g., the number of neighbors to be averaged over in\\nk nearest neighbor (kNN) regression or the polynomial degree in regression with\\npolynomials. We suggest a novel principle - the Loss Rank Principle (LoRP) -\\nfor model selection in regression and classification. It is based on the loss\\nrank, which counts how many other (fictitious) data would be fitted better.\\nLoRP selects the model that has minimal loss rank. Unlike most penalized\\nmaximum likelihood variants (AIC, BIC, MDL), LoRP depends only on the\\nregression functions and the loss function. It works without a stochastic noise\\nmodel, and is directly applicable to any non-parametric regressor, like kNN.\\n',\n",
              " '  In this paper, we propose a unified algorithmic framework for solving many\\nknown variants of \\\\mds. Our algorithm is a simple iterative scheme with\\nguaranteed convergence, and is \\\\emph{modular}; by changing the internals of a\\nsingle subroutine in the algorithm, we can switch cost functions and target\\nspaces easily. In addition to the formal guarantees of convergence, our\\nalgorithms are accurate; in most cases, they converge to better quality\\nsolutions than existing methods, in comparable time. We expect that this\\nframework will be useful for a number of \\\\mds variants that have not yet been\\nstudied.\\n  Our framework extends to embedding high-dimensional points lying on a sphere\\nto points on a lower dimensional sphere, preserving geodesic distances. As a\\ncompliment to this result, we also extend the Johnson-Lindenstrauss Lemma to\\nthis spherical setting, where projecting to a random $O((1/\\\\eps^2) \\\\log\\nn)$-dimensional sphere causes $\\\\eps$-distortion.\\n',\n",
              " '  Maximum likelihood estimators are often of limited practical use due to the\\nintensive computation they require. We propose a family of alternative\\nestimators that maximize a stochastic variation of the composite likelihood\\nfunction. Each of the estimators resolve the computation-accuracy tradeoff\\ndifferently, and taken together they span a continuous spectrum of\\ncomputation-accuracy tradeoff resolutions. We prove the consistency of the\\nestimators, provide formulas for their asymptotic variance, statistical\\nrobustness, and computational complexity. We discuss experimental results in\\nthe context of Boltzmann machines and conditional random fields. The\\ntheoretical and experimental studies demonstrate the effectiveness of the\\nestimators when the computational resources are insufficient. They also\\ndemonstrate that in some cases reduced computational complexity is associated\\nwith robustness thereby increasing statistical accuracy.\\n',\n",
              " '  We present an approach to semi-supervised learning based on an exponential\\nfamily characterization. Our approach generalizes previous work on coupled\\npriors for hybrid generative/discriminative models. Our model is more flexible\\nand natural than previous approaches. Experimental results on several data sets\\nshow that our approach also performs better in practice.\\n',\n",
              " '  Several variants of a stochastic local search process for constructing the\\nsynaptic weights of an Ising perceptron are studied. In this process, binary\\npatterns are sequentially presented to the Ising perceptron and are then\\nlearned as the synaptic weight configuration is modified through a chain of\\nsingle- or double-weight flips within the compatible weight configuration space\\nof the earlier learned patterns. This process is able to reach a storage\\ncapacity of $\\\\alpha \\\\approx 0.63$ for pattern length N = 101 and $\\\\alpha\\n\\\\approx 0.41$ for N = 1001. If in addition a relearning process is exploited,\\nthe learning performance is further improved to a storage capacity of $\\\\alpha\\n\\\\approx 0.80$ for N = 101 and $\\\\alpha \\\\approx 0.42$ for N=1001. We found that,\\nfor a given learning task, the solutions constructed by the random walk\\nlearning process are separated by a typical Hamming distance, which decreases\\nwith the constraint density $\\\\alpha$ of the learning task; at a fixed value of\\n$\\\\alpha$, the width of the Hamming distance distributions decreases with $N$.\\n',\n",
              " '  Computers understand very little of the meaning of human language. This\\nprofoundly limits our ability to give instructions to computers, the ability of\\ncomputers to explain their actions to us, and the ability of computers to\\nanalyse and process text. Vector space models (VSMs) of semantics are beginning\\nto address these limits. This paper surveys the use of VSMs for semantic\\nprocessing of text. We organize the literature on VSMs according to the\\nstructure of the matrix in a VSM. There are currently three broad classes of\\nVSMs, based on term-document, word-context, and pair-pattern matrices, yielding\\nthree classes of applications. We survey a broad range of applications in these\\nthree categories and we take a detailed look at a specific open source project\\nin each category. Our goal in this survey is to show the breadth of\\napplications of VSMs for semantics, to provide a new perspective on VSMs for\\nthose who are already familiar with the area, and to provide pointers into the\\nliterature for those who are less familiar with the field.\\n',\n",
              " '  Next to the shortest path distance, the second most popular distance function\\nbetween vertices in a graph is the commute distance (resistance distance). For\\ntwo vertices u and v, the hitting time H_{uv} is the expected time it takes a\\nrandom walk to travel from u to v. The commute time is its symmetrized version\\nC_{uv} = H_{uv} + H_{vu}. In our paper we study the behavior of hitting times\\nand commute distances when the number n of vertices in the graph is very large.\\nWe prove that as n converges to infinty, hitting times and commute distances\\nconverge to expressions that do not take into account the global structure of\\nthe graph at all. Namely, the hitting time H_{uv} converges to 1/d_v and the\\ncommute time to 1/d_u + 1/d_v where d_u and d_v denote the degrees of vertices\\nu and v. In these cases, the hitting and commute times are misleading in the\\nsense that they do not provide information about the structure of the graph. We\\nfocus on two major classes of random graphs: random geometric graphs (k-nearest\\nneighbor graphs, epsilon-graphs, Gaussian similarity graphs) and random graphs\\nwith given expected degrees (in particular, Erdos-Renyi graphs with and without\\nplanted partitions)\\n',\n",
              " '  Structured output prediction is an important machine learning problem both in\\ntheory and practice, and the max-margin Markov network (\\\\mcn) is an effective\\napproach. All state-of-the-art algorithms for optimizing \\\\mcn\\\\ objectives take\\nat least $O(1/\\\\epsilon)$ number of iterations to find an $\\\\epsilon$ accurate\\nsolution. Recent results in structured optimization suggest that faster rates\\nare possible by exploiting the structure of the objective function. Towards\\nthis end \\\\citet{Nesterov05} proposed an excessive gap reduction technique based\\non Euclidean projections which converges in $O(1/\\\\sqrt{\\\\epsilon})$ iterations\\non strongly convex functions. Unfortunately when applied to \\\\mcn s, this\\napproach does not admit graphical model factorization which, as in many\\nexisting algorithms, is crucial for keeping the cost per iteration tractable.\\nIn this paper, we present a new excessive gap reduction technique based on\\nBregman projections which admits graphical model factorization naturally, and\\nconverges in $O(1/\\\\sqrt{\\\\epsilon})$ iterations. Compared with existing\\nalgorithms, the convergence rate of our method has better dependence on\\n$\\\\epsilon$ and other parameters of the problem, and can be easily kernelized.\\n',\n",
              " '  Unlike static documents, version controlled documents are continuously edited\\nby one or more authors. Such collaborative revision process makes traditional\\nmodeling and visualization techniques inappropriate. In this paper we propose a\\nnew representation based on local space-time smoothing that captures important\\nrevision patterns. We demonstrate the applicability of our framework using\\nexperiments on synthetic and real-world data.\\n',\n",
              " \"  In recent years, predicting the user's next request in web navigation has\\nreceived much attention. An information source to be used for dealing with such\\nproblem is the left information by the previous web users stored at the web\\naccess log on the web servers. Purposed systems for this problem work based on\\nthis idea that if a large number of web users request specific pages of a\\nwebsite on a given session, it can be concluded that these pages are satisfying\\nsimilar information needs, and therefore they are conceptually related. In this\\nstudy, a new clustering approach is introduced that employs logical path\\nstoring of a website pages as another parameter which is regarded as a\\nsimilarity parameter and conceptual relation between web pages. The results of\\nsimulation have shown that the proposed approach is more than others precise in\\ndetermining the clusters.\\n\",\n",
              " \"  This paper introduces an evaluation methodologies for the e-learners'\\nbehaviour that will be a feedback to the decision makers in e-learning system.\\nLearner's profile plays a crucial role in the evaluation process to improve the\\ne-learning process performance. The work focuses on the clustering of the\\ne-learners based on their behaviour into specific categories that represent the\\nlearner's profiles. The learners' classes named as regular, workers, casual,\\nbad, and absent. The work may answer the question of how to return bad students\\nto be regular ones. The work presented the use of different fuzzy clustering\\ntechniques as fuzzy c-means and kernelized fuzzy c-means to find the learners'\\ncategories and predict their profiles. The paper presents the main phases as\\ndata description, preparation, features selection, and the experiments design\\nusing different fuzzy clustering models. Analysis of the obtained results and\\ncomparison with the real world behavior of those learners proved that there is\\na match with percentage of 78%. Fuzzy clustering reflects the learners'\\nbehavior more than crisp clustering. Comparison between FCM and KFCM proved\\nthat the KFCM is much better than FCM in predicting the learners' behaviour.\\n\",\n",
              " '  Most Web page classification models typically apply the bag of words (BOW)\\nmodel to represent the feature space. The original BOW representation, however,\\nis unable to recognize semantic relationships between terms. One possible\\nsolution is to apply the topic model approach based on the Latent Dirichlet\\nAllocation algorithm to cluster the term features into a set of latent topics.\\nTerms assigned into the same topic are semantically related. In this paper, we\\npropose a novel hierarchical classification method based on a topic model and\\nby integrating additional term features from neighboring pages. Our\\nhierarchical classification method consists of two phases: (1) feature\\nrepresentation by using a topic model and integrating neighboring pages, and\\n(2) hierarchical Support Vector Machines (SVM) classification model constructed\\nfrom a confusion matrix. From the experimental results, the approach of using\\nthe proposed hierarchical SVM model by integrating current page with\\nneighboring pages via the topic model yielded the best performance with the\\naccuracy equal to 90.33% and the F1 measure of 90.14%; an improvement of 5.12%\\nand 5.13% over the original SVM model, respectively.\\n',\n",
              " '  Text Document classification aims in associating one or more predefined\\ncategories based on the likelihood suggested by the training set of labeled\\ndocuments. Many machine learning algorithms play a vital role in training the\\nsystem with predefined categories among which Na\\\\\"ive Bayes has some intriguing\\nfacts that it is simple, easy to implement and draws better accuracy in large\\ndatasets in spite of the na\\\\\"ive dependence. The importance of Na\\\\\"ive Bayes\\nMachine learning approach has felt hence the study has been taken up for text\\ndocument classification and the statistical event models available. This survey\\nthe various feature selection methods has been discussed and compared along\\nwith the metrics related to text document classification.\\n',\n",
              " \"  We apply the method of defensive forecasting, based on the use of\\ngame-theoretic supermartingales, to prediction with expert advice. In the\\ntraditional setting of a countable number of experts and a finite number of\\noutcomes, the Defensive Forecasting Algorithm is very close to the well-known\\nAggregating Algorithm. Not only the performance guarantees but also the\\npredictions are the same for these two methods of fundamentally different\\nnature. We discuss also a new setting where the experts can give advice\\nconditional on the learner's future decision. Both the algorithms can be\\nadapted to the new setting and give the same performance guarantees as in the\\ntraditional setting. Finally, we outline an application of defensive\\nforecasting to a setting with several loss functions.\\n\",\n",
              " '  In this paper, we consider the problem of real-time transmission scheduling\\nover time-varying channels. We first formulate the transmission scheduling\\nproblem as a Markov decision process (MDP) and systematically unravel the\\nstructural properties (e.g. concavity in the state-value function and\\nmonotonicity in the optimal scheduling policy) exhibited by the optimal\\nsolutions. We then propose an online learning algorithm which preserves these\\nstructural properties and achieves -optimal solutions for an arbitrarily small\\n. The advantages of the proposed online method are that: (i) it does not\\nrequire a priori knowledge of the traffic arrival and channel statistics and\\n(ii) it adaptively approximates the state-value functions using piece-wise\\nlinear functions and has low storage and computation complexity. We also extend\\nthe proposed low-complexity online learning solution to the prioritized data\\ntransmission. The simulation results demonstrate that the proposed method\\nachieves significantly better utility (or delay)-energy trade-offs when\\ncomparing to existing state-of-art online optimization methods.\\n',\n",
              " '  In this paper we address an issue that has been brought to the attention of\\nthe database community with the advent of the Semantic Web, i.e. the issue of\\nhow ontologies (and semantics conveyed by them) can help solving typical\\ndatabase problems, through a better understanding of KR aspects related to\\ndatabases. In particular, we investigate this issue from the ILP perspective by\\nconsidering two database problems, (i) the definition of views and (ii) the\\ndefinition of constraints, for a database whose schema is represented also by\\nmeans of an ontology. Both can be reformulated as ILP problems and can benefit\\nfrom the expressive and deductive power of the KR framework DL+log. We\\nillustrate the application scenarios by means of examples. Keywords: Inductive\\nLogic Programming, Relational Databases, Ontologies, Description Logics, Hybrid\\nKnowledge Representation and Reasoning Systems. Note: To appear in Theory and\\nPractice of Logic Programming (TPLP).\\n',\n",
              " '  Classifiers are often used to detect miscreant activities. We study how an\\nadversary can efficiently query a classifier to elicit information that allows\\nthe adversary to evade detection at near-minimal cost. We generalize results of\\nLowd and Meek (2005) to convex-inducing classifiers. We present algorithms that\\nconstruct undetected instances of near-minimal cost using only polynomially\\nmany queries in the dimension of the space and without reverse engineering the\\ndecision boundary.\\n',\n",
              " '  Given a set of data, biclustering aims at finding simultaneous partitions in\\nbiclusters of its samples and of the features which are used for representing\\nthe samples. Consistent biclusterings allow to obtain correct classifications\\nof the samples from the known classification of the features, and vice versa,\\nand they are very useful for performing supervised classifications. The problem\\nof finding consistent biclusterings can be seen as a feature selection problem,\\nwhere the features that are not relevant for classification purposes are\\nremoved from the set of data, while the total number of features is maximized\\nin order to preserve information. This feature selection problem can be\\nformulated as a linear fractional 0-1 optimization problem. We propose a\\nreformulation of this problem as a bilevel optimization problem, and we present\\na heuristic algorithm for an efficient solution of the reformulated problem.\\nComputational experiments show that the presented algorithm is able to find\\nbetter solutions with respect to the ones obtained by employing previously\\npresented heuristic algorithms.\\n',\n",
              " \"  We consider a living organism as an observer of the evolution of its\\nenvironment recording sensory information about the state space X of the\\nenvironment in real time. Sensory information is sampled and then processed on\\ntwo levels. On the biological level, the organism serves as an evaluation\\nmechanism of the subjective relevance of the incoming data to the observer: the\\nobserver assigns excitation values to events in X it could recognize using its\\nsensory equipment. On the algorithmic level, sensory input is used for updating\\na database, the memory of the observer whose purpose is to serve as a\\ngeometric/combinatorial model of X, whose nodes are weighted by the excitation\\nvalues produced by the evaluation mechanism. These values serve as a guidance\\nsystem for deciding how the database should transform as observation data\\nmounts. We define a searching problem for the proposed model and discuss the\\nmodel's flexibility and its computational efficiency, as well as the\\npossibility of implementing it as a dynamic network of neuron-like units. We\\nshow how various easily observable properties of the human memory and thought\\nprocess can be explained within the framework of this model. These include:\\nreasoning (with efficiency bounds), errors, temporary and permanent loss of\\ninformation. We are also able to define general learning problems in terms of\\nthe new model, such as the language acquisition problem.\\n\",\n",
              " '  Solving stochastic optimization problems under partial observability, where\\none needs to adaptively make decisions with uncertain outcomes, is a\\nfundamental but notoriously difficult challenge. In this paper, we introduce\\nthe concept of adaptive submodularity, generalizing submodular set functions to\\nadaptive policies. We prove that if a problem satisfies this property, a simple\\nadaptive greedy algorithm is guaranteed to be competitive with the optimal\\npolicy. In addition to providing performance guarantees for both stochastic\\nmaximization and coverage, adaptive submodularity can be exploited to\\ndrastically speed up the greedy algorithm by using lazy evaluations. We\\nillustrate the usefulness of the concept by giving several examples of adaptive\\nsubmodular objectives arising in diverse applications including sensor\\nplacement, viral marketing and active learning. Proving adaptive submodularity\\nfor these problems allows us to recover existing results in these applications\\nas special cases, improve approximation guarantees and handle natural\\ngeneralizations.\\n',\n",
              " '  To understand complex biological systems, the research community has produced\\nhuge corpus of gene expression data. A large number of clustering approaches\\nhave been proposed for the analysis of gene expression data. However,\\nextracting important biological knowledge is still harder. To address this\\ntask, clustering techniques are used. In this paper, hybrid Hierarchical\\nk-Means algorithm is used for clustering and biclustering gene expression data\\nis used. To discover both local and global clustering structure biclustering\\nand clustering algorithms are utilized. A validation technique, Figure of Merit\\nis used to determine the quality of clustering results. Appropriate knowledge\\nis mined from the clusters by embedding a BLAST similarity search program into\\nthe clustering and biclustering process. To discover both local and global\\nclustering structure biclustering and clustering algorithms are utilized. To\\ndetermine the quality of clustering results, a validation technique, Figure of\\nMerit is used. Appropriate knowledge is mined from the clusters by embedding a\\nBLAST similarity search program into the clustering and biclustering process.\\n',\n",
              " '  We show that for many classes of symmetric two-player games, the simple\\ndecision rule \"imitate-the-best\" can hardly be beaten by any other decision\\nrule. We provide necessary and sufficient conditions for imitation to be\\nunbeatable and show that it can only be beaten by much in games that are of the\\nrock-scissors-paper variety. Thus, in many interesting examples, like 2x2\\ngames, Cournot duopoly, price competition, rent seeking, public goods games,\\ncommon pool resource games, minimum effort coordination games, arms race,\\nsearch, bargaining, etc., imitation cannot be beaten by much even by a very\\nclever opponent.\\n',\n",
              " '  Current statistical models for structured prediction make simplifying\\nassumptions about the underlying output graph structure, such as assuming a\\nlow-order Markov chain, because exact inference becomes intractable as the\\ntree-width of the underlying graph increases. Approximate inference algorithms,\\non the other hand, force one to trade off representational power with\\ncomputational efficiency. In this paper, we propose two new types of\\nprobabilistic graphical models, large margin Boltzmann machines (LMBMs) and\\nlarge margin sigmoid belief networks (LMSBNs), for structured prediction.\\nLMSBNs in particular allow a very fast inference algorithm for arbitrary graph\\nstructures that runs in polynomial time with a high probability. This\\nprobability is data-distribution dependent and is maximized in learning. The\\nnew approach overcomes the representation-efficiency trade-off in previous\\nmodels and allows fast structured prediction with complicated graph structures.\\nWe present results from applying a fully connected model to multi-label scene\\nclassification and demonstrate that the proposed approach can yield significant\\nperformance gains over current state-of-the-art methods.\\n',\n",
              " '  Probabilistic matrix factorization (PMF) is a powerful method for modeling\\ndata associated with pairwise relationships, finding use in collaborative\\nfiltering, computational biology, and document analysis, among other areas. In\\nmany domains, there is additional information that can assist in prediction.\\nFor example, when modeling movie ratings, we might know when the rating\\noccurred, where the user lives, or what actors appear in the movie. It is\\ndifficult, however, to incorporate this side information into the PMF model. We\\npropose a framework for incorporating side information by coupling together\\nmultiple PMF problems via Gaussian process priors. We replace scalar latent\\nfeatures with functions that vary over the space of side information. The GP\\npriors on these functions require them to vary smoothly and share information.\\nWe successfully use this new method to predict the scores of professional\\nbasketball games, where side information about the venue and date of the game\\nare relevant for the outcome.\\n',\n",
              " '  This paper introduces and motivates the use of hybrid robust feature\\nextraction technique for spoken language identification (LID) system. The\\nspeech recognizers use a parametric form of a signal to get the most important\\ndistinguishable features of speech signal for recognition task. In this paper\\nMel-frequency cepstral coefficients (MFCC), Perceptual linear prediction\\ncoefficients (PLP) along with two hybrid features are used for language\\nIdentification. Two hybrid features, Bark Frequency Cepstral Coefficients\\n(BFCC) and Revised Perceptual Linear Prediction Coefficients (RPLP) were\\nobtained from combination of MFCC and PLP. Two different classifiers, Vector\\nQuantization (VQ) with Dynamic Time Warping (DTW) and Gaussian Mixture Model\\n(GMM) were used for classification. The experiment shows better identification\\nrate using hybrid feature extraction techniques compared to conventional\\nfeature extraction methods.BFCC has shown better performance than MFCC with\\nboth classifiers. RPLP along with GMM has shown best identification performance\\namong all feature extraction techniques.\\n',\n",
              " \"  To improve the performance of speaker identification systems, an effective\\nand robust method is proposed to extract speech features, capable of operating\\nin noisy environment. Based on the time-frequency multi-resolution property of\\nwavelet transform, the input speech signal is decomposed into various frequency\\nchannels. For capturing the characteristic of the signal, the Mel-Frequency\\nCepstral Coefficients (MFCCs) of the wavelet channels are calculated. Hidden\\nMarkov Models (HMMs) were used for the recognition stage as they give better\\nrecognition for the speaker's features than Dynamic Time Warping (DTW).\\nComparison of the proposed approach with the MFCCs conventional feature\\nextraction method shows that the proposed method not only effectively reduces\\nthe influence of noise, but also improves recognition. A recognition rate of\\n99.3% was obtained using the proposed feature extraction technique compared to\\n98.7% using the MFCCs. When the test patterns were corrupted by additive white\\nGaussian noise with 20 dB S/N ratio, the recognition rate was 97.3% using the\\nproposed method compared to 93.3% using the MFCCs.\\n\",\n",
              " '  Thanks to the Eslo1 (\"Enqu\\\\^ete sociolinguistique d\\'Orl\\\\\\'eans\", i.e.\\n\"Sociolinguistic Inquiery of Orl\\\\\\'eans\") campain, a large oral corpus has been\\ngathered and transcribed in a textual format. The purpose of the work presented\\nhere is to associate a morpho-syntactic label to each unit of this corpus. To\\nthis aim, we have first studied the specificities of the necessary labels, and\\ntheir various possible levels of description. This study has led to a new\\noriginal hierarchical structuration of labels. Then, considering that our new\\nset of labels was different from the one used in every available software, and\\nthat these softwares usually do not fit for oral data, we have built a new\\nlabeling tool by a Machine Learning approach, from data labeled by Cordial and\\ncorrected by hand. We have applied linear CRF (Conditional Random Fields)\\ntrying to take the best possible advantage of the linguistic knowledge that was\\nused to define the set of labels. We obtain an accuracy between 85 and 90%,\\ndepending of the parameters used.\\n',\n",
              " '  This paper uses Support Vector Machines (SVM) to fuse multiple classifiers\\nfor an offline signature system. From the signature images, global and local\\nfeatures are extracted and the signatures are verified with the help of\\nGaussian empirical rule, Euclidean and Mahalanobis distance based classifiers.\\nSVM is used to fuse matching scores of these matchers. Finally, recognition of\\nquery signatures is done by comparing it with all signatures of the database.\\nThe proposed system is tested on a signature database contains 5400 offline\\nsignatures of 600 individuals and the results are found to be promising.\\n',\n",
              " '  Contextual bandit algorithms have become popular for online recommendation\\nsystems such as Digg, Yahoo! Buzz, and news recommendation in general.\\n\\\\emph{Offline} evaluation of the effectiveness of new algorithms in these\\napplications is critical for protecting online user experiences but very\\nchallenging due to their \"partial-label\" nature. Common practice is to create a\\nsimulator which simulates the online environment for the problem at hand and\\nthen run an algorithm against this simulator. However, creating simulator\\nitself is often difficult and modeling bias is usually unavoidably introduced.\\nIn this paper, we introduce a \\\\emph{replay} methodology for contextual bandit\\nalgorithm evaluation. Different from simulator-based approaches, our method is\\ncompletely data-driven and very easy to adapt to different applications. More\\nimportantly, our method can provide provably unbiased evaluations. Our\\nempirical results on a large-scale news article recommendation dataset\\ncollected from Yahoo! Front Page conform well with our theoretical results.\\nFurthermore, comparisons between our offline replay and online bucket\\nevaluation of several contextual bandit algorithms show accuracy and\\neffectiveness of our offline evaluation method.\\n',\n",
              " '  In this paper, a novel method for representation and recognition of the\\nfacial expressions in two-dimensional image sequences is presented. We apply a\\nvariation of two-dimensional heteroscedastic linear discriminant analysis\\n(2DHLDA) algorithm, as an efficient dimensionality reduction technique, to\\nGabor representation of the input sequence. 2DHLDA is an extension of the\\ntwo-dimensional linear discriminant analysis (2DLDA) approach and it removes\\nthe equal within-class covariance. By applying 2DHLDA in two directions, we\\neliminate the correlations between both image columns and image rows. Then, we\\nperform a one-dimensional LDA on the new features. This combined method can\\nalleviate the small sample size problem and instability encountered by HLDA.\\nAlso, employing both geometric and appearance features and using an ensemble\\nlearning scheme based on data fusion, we create a classifier which can\\nefficiently classify the facial expressions. The proposed method is robust to\\nillumination changes and it can properly represent temporal information as well\\nas subtle changes in facial muscles. We provide experiments on Cohn-Kanade\\ndatabase that show the superiority of the proposed method. KEYWORDS:\\ntwo-dimensional heteroscedastic linear discriminant analysis (2DHLDA), subspace\\nlearning, facial expression analysis, Gabor wavelets, ensemble learning.\\n',\n",
              " '  We propose in this paper an exploratory analysis algorithm for functional\\ndata. The method partitions a set of functions into $K$ clusters and represents\\neach cluster by a simple prototype (e.g., piecewise constant). The total number\\nof segments in the prototypes, $P$, is chosen by the user and optimally\\ndistributed among the clusters via two dynamic programming algorithms. The\\npractical relevance of the method is shown on two real world datasets.\\n',\n",
              " '  Facial Action Coding System consists of 44 action units (AUs) and more than\\n7000 combinations. Hidden Markov models (HMMs) classifier has been used\\nsuccessfully to recognize facial action units (AUs) and expressions due to its\\nability to deal with AU dynamics. However, a separate HMM is necessary for each\\nsingle AU and each AU combination. Since combinations of AU numbering in\\nthousands, a more efficient method will be needed. In this paper an accurate\\nreal-time sequence-based system for representation and recognition of facial\\nAUs is presented. Our system has the following characteristics: 1) employing a\\nmixture of HMMs and neural network, we develop a novel accurate classifier,\\nwhich can deal with AU dynamics, recognize subtle changes, and it is also\\nrobust to intensity variations, 2) although we use an HMM for each single AU\\nonly, by employing a neural network we can recognize each single and\\ncombination AU, and 3) using both geometric and appearance-based features, and\\napplying efficient dimension reduction techniques, our system is robust to\\nillumination changes and it can represent the temporal information involved in\\nformation of the facial expressions. Extensive experiments on Cohn-Kanade\\ndatabase show the superiority of the proposed method, in comparison with other\\nclassifiers. Keywords: classifier design and evaluation, data fusion, facial\\naction units (AUs), hidden Markov models (HMMs), neural network (NN).\\n',\n",
              " '  In this paper a novel efficient method for representation of facial action\\nunits by encoding an image sequence as a fourth-order tensor is presented. The\\nmultilinear tensor-based extension of the biased discriminant analysis (BDA)\\nalgorithm, called multilinear biased discriminant analysis (MBDA), is first\\nproposed. Then, we apply the MBDA and two-dimensional BDA (2DBDA) algorithms,\\nas the dimensionality reduction techniques, to Gabor representations and the\\ngeometric features of the input image sequence respectively. The proposed\\nscheme can deal with the asymmetry between positive and negative samples as\\nwell as curse of dimensionality dilemma. Extensive experiments on Cohn-Kanade\\ndatabase show the superiority of the proposed method for representation of the\\nsubtle changes and the temporal information involved in formation of the facial\\nexpressions. As an accurate tool, this representation can be applied to many\\nareas such as recognition of spontaneous and deliberate facial expressions,\\nmulti modal/media human computer interaction and lie detection efforts.\\n',\n",
              " '  The main function of IDS (Intrusion Detection System) is to protect the\\nsystem, analyze and predict the behaviors of users. Then these behaviors will\\nbe considered an attack or a normal behavior. Though IDS has been developed for\\nmany years, the large number of return alert messages makes managers maintain\\nsystem inefficiently. In this paper, we use RST (Rough Set Theory) and SVM\\n(Support Vector Machine) to detect intrusions. First, RST is used to preprocess\\nthe data and reduce the dimensions. Next, the features were selected by RST\\nwill be sent to SVM model to learn and test respectively. The method is\\neffective to decrease the space density of data. The experiments will compare\\nthe results with different methods and show RST and SVM schema could improve\\nthe false positive rate and accuracy.\\n',\n",
              " '  In this paper a novel method called Extended Two-Dimensional PCA (E2DPCA) is\\nproposed which is an extension to the original 2DPCA. We state that the\\ncovariance matrix of 2DPCA is equivalent to the average of the main diagonal of\\nthe covariance matrix of PCA. This implies that 2DPCA eliminates some\\ncovariance information that can be useful for recognition. E2DPCA instead of\\njust using the main diagonal considers a radius of r diagonals around it and\\nexpands the averaging so as to include the covariance information within those\\ndiagonals. The parameter r unifies PCA and 2DPCA. r = 1 produces the covariance\\nof 2DPCA, r = n that of PCA. Hence, by controlling r it is possible to control\\nthe trade-offs between recognition accuracy and energy compression (fewer\\ncoefficients), and between training and recognition complexity. Experiments on\\nORL face database show improvement in both recognition accuracy and recognition\\ntime over the original 2DPCA.\\n',\n",
              " '  This paper introduces a novel message-passing (MP) framework for the\\ncollaborative filtering (CF) problem associated with recommender systems. We\\nmodel the movie-rating prediction problem popularized by the Netflix Prize,\\nusing a probabilistic factor graph model and study the model by deriving\\ngeneralization error bounds in terms of the training error. Based on the model,\\nwe develop a new MP algorithm, termed IMP, for learning the model. To show\\nsuperiority of the IMP algorithm, we compare it with the closely related\\nexpectation-maximization (EM) based algorithm and a number of other matrix\\ncompletion algorithms. Our simulation results on Netflix data show that, while\\nthe methods perform similarly with large amounts of data, the IMP algorithm is\\nsuperior for small amounts of data. This improves the cold-start problem of the\\nCF systems in practice. Another advantage of the IMP algorithm is that it can\\nbe analyzed using the technique of density evolution (DE) that was originally\\ndeveloped for MP decoding of error-correcting codes.\\n',\n",
              " '  In density estimation task, maximum entropy model (Maxent) can effectively\\nuse reliable prior information via certain constraints, i.e., linear\\nconstraints without empirical parameters. However, reliable prior information\\nis often insufficient, and the selection of uncertain constraints becomes\\nnecessary but poses considerable implementation complexity. Improper setting of\\nuncertain constraints can result in overfitting or underfitting. To solve this\\nproblem, a generalization of Maxent, under Tsallis entropy framework, is\\nproposed. The proposed method introduces a convex quadratic constraint for the\\ncorrection of (expected) Tsallis entropy bias (TEB). Specifically, we\\ndemonstrate that the expected Tsallis entropy of sampling distributions is\\nsmaller than the Tsallis entropy of the underlying real distribution. This\\nexpected entropy reduction is exactly the (expected) TEB, which can be\\nexpressed by a closed-form formula and act as a consistent and unbiased\\ncorrection. TEB indicates that the entropy of a specific sampling distribution\\nshould be increased accordingly. This entails a quantitative re-interpretation\\nof the Maxent principle. By compensating TEB and meanwhile forcing the\\nresulting distribution to be close to the sampling distribution, our\\ngeneralized TEBC Maxent can be expected to alleviate the overfitting and\\nunderfitting. We also present a connection between TEB and Lidstone estimator.\\nAs a result, TEB-Lidstone estimator is developed by analytically identifying\\nthe rate of probability correction in Lidstone. Extensive empirical evaluation\\nshows promising performance of both TEBC Maxent and TEB-Lidstone in comparison\\nwith various state-of-the-art density estimation methods.\\n',\n",
              " '  This paper discusses the knowledge integration of clinical information\\nextracted from distributed medical ontology in order to ameliorate a machine\\nlearning-based multi-label coding assignment system. The proposed approach is\\nimplemented using a decision tree based cascade hierarchical technique on the\\nuniversity hospital data for patients with Coronary Heart Disease (CHD). The\\npreliminary results obtained show a satisfactory finding.\\n',\n",
              " '  Clustering is an unsupervised learning method that constitutes a cornerstone\\nof an intelligent data analysis process. It is used for the exploration of\\ninter-relationships among a collection of patterns, by organizing them into\\nhomogeneous clusters. Clustering has been dynamically applied to a variety of\\ntasks in the field of Information Retrieval (IR). Clustering has become one of\\nthe most active area of research and the development. Clustering attempts to\\ndiscover the set of consequential groups where those within each group are more\\nclosely related to one another than the others assigned to different groups.\\nThe resultant clusters can provide a structure for organizing large bodies of\\ntext for efficient browsing and searching. There exists a wide variety of\\nclustering algorithms that has been intensively studied in the clustering\\nproblem. Among the algorithms that remain the most common and effectual, the\\niterative optimization clustering algorithms have been demonstrated reasonable\\nperformance for clustering, e.g. the Expectation Maximization (EM) algorithm\\nand its variants, and the well known k-means algorithm. This paper presents an\\nanalysis on how partition method clustering techniques - EM, K -means and K*\\nMeans algorithm work on heartspect dataset with below mentioned features -\\nPurity, Entropy, CPU time, Cluster wise analysis, Mean value analysis and inter\\ncluster distance. Thus the paper finally provides the experimental results of\\ndatasets for five clusters to strengthen the results that the quality of the\\nbehavior in clusters in EM algorithm is far better than k-means algorithm and\\nk*means algorithm.\\n',\n",
              " '  This paper proposes a novel similarity measure for clustering sequential\\ndata. We first construct a common state-space by training a single\\nprobabilistic model with all the sequences in order to get a unified\\nrepresentation for the dataset. Then, distances are obtained attending to the\\ntransition matrices induced by each sequence in that state-space. This approach\\nsolves some of the usual overfitting and scalability issues of the existing\\nsemi-parametric techniques, that rely on training a model for each sequence.\\nEmpirical studies on both synthetic and real-world datasets illustrate the\\nadvantages of the proposed similarity measure for clustering sequences.\\n',\n",
              " '  Back-propagation with gradient method is the most popular learning algorithm\\nfor feed-forward neural networks. However, it is critical to determine a proper\\nfixed learning rate for the algorithm. In this paper, an optimized recursive\\nalgorithm is presented for online learning based on matrix operation and\\noptimization methods analytically, which can avoid the trouble to select a\\nproper learning rate for the gradient method. The proof of weak convergence of\\nthe proposed algorithm also is given. Although this approach is proposed for\\nthree-layer, feed-forward neural networks, it could be extended to multiple\\nlayer feed-forward neural networks. The effectiveness of the proposed\\nalgorithms applied to the identification of behavior of a two-input and\\ntwo-output non-linear dynamic system is demonstrated by simulation experiments.\\n',\n",
              " '  In this paper, we propose a novel policy iteration method, called dynamic\\npolicy programming (DPP), to estimate the optimal policy in the\\ninfinite-horizon Markov decision processes. We prove the finite-iteration and\\nasymptotic l\\\\infty-norm performance-loss bounds for DPP in the presence of\\napproximation/estimation error. The bounds are expressed in terms of the\\nl\\\\infty-norm of the average accumulated error as opposed to the l\\\\infty-norm of\\nthe error in the case of the standard approximate value iteration (AVI) and the\\napproximate policy iteration (API). This suggests that DPP can achieve a better\\nperformance than AVI and API since it averages out the simulation noise caused\\nby Monte-Carlo sampling throughout the learning process. We examine this\\ntheoretical results numerically by com- paring the performance of the\\napproximate variants of DPP with existing reinforcement learning (RL) methods\\non different problem domains. Our results show that, in all cases, DPP-based\\nalgorithms outperform other RL methods by a wide margin.\\n',\n",
              " '  In regular statistical models, the leave-one-out cross-validation is\\nasymptotically equivalent to the Akaike information criterion. However, since\\nmany learning machines are singular statistical models, the asymptotic behavior\\nof the cross-validation remains unknown. In previous studies, we established\\nthe singular learning theory and proposed a widely applicable information\\ncriterion, the expectation value of which is asymptotically equal to the\\naverage Bayes generalization loss. In the present paper, we theoretically\\ncompare the Bayes cross-validation loss and the widely applicable information\\ncriterion and prove two theorems. First, the Bayes cross-validation loss is\\nasymptotically equivalent to the widely applicable information criterion as a\\nrandom variable. Therefore, model selection and hyperparameter optimization\\nusing these two values are asymptotically equivalent. Second, the sum of the\\nBayes generalization error and the Bayes cross-validation error is\\nasymptotically equal to $2\\\\lambda/n$, where $\\\\lambda$ is the real log canonical\\nthreshold and $n$ is the number of training samples. Therefore the relation\\nbetween the cross-validation error and the generalization error is determined\\nby the algebraic geometrical structure of a learning machine. We also clarify\\nthat the deviance information criteria are different from the Bayes\\ncross-validation and the widely applicable information criterion.\\n',\n",
              " \"  We present a solution to the problem of understanding a system that produces\\na sequence of temporally ordered observations. Our solution is based on\\ngenerating and interpreting a set of temporal decision rules. A temporal\\ndecision rule is a decision rule that can be used to predict or retrodict the\\nvalue of a decision attribute, using condition attributes that are observed at\\ntimes other than the decision attribute's time of observation. A rule set,\\nconsisting of a set of temporal decision rules with the same decision\\nattribute, can be interpreted by our Temporal Investigation Method for\\nEnregistered Record Sequences (TIMERS) to signify an instantaneous, an acausal\\nor a possibly causal relationship between the condition attributes and the\\ndecision attribute. We show the effectiveness of our method, by describing a\\nnumber of experiments with both synthetic and real temporal data.\\n\",\n",
              " \"  For a class of quantized open chaotic systems satisfying a natural dynamical\\nassumption, we show that the study of the resolvent, and hence of scattering\\nand resonances, can be reduced to the study of a family of open quantum maps,\\nthat is of finite dimensional operators obtained by quantizing the Poincar\\\\'e\\nmap associated with the flow near the set of trapped trajectories.\\n\",\n",
              " '  In this work we investigate the relationship between Bregman distances and\\nregularized Logistic Regression model. We present a detailed study of Bregman\\nDistance minimization, a family of generalized entropy measures associated with\\nconvex functions. We convert the L1-regularized logistic regression into this\\nmore general framework and propose a primal-dual method based algorithm for\\nlearning the parameters. We pose L1-regularized logistic regression into\\nBregman distance minimization and then apply non-linear constrained\\noptimization techniques to estimate the parameters of the logistic model.\\n',\n",
              " '  Given data drawn from a mixture of multivariate Gaussians, a basic problem is\\nto accurately estimate the mixture parameters. We give an algorithm for this\\nproblem that has a running time, and data requirement polynomial in the\\ndimension and the inverse of the desired accuracy, with provably minimal\\nassumptions on the Gaussians. As simple consequences of our learning algorithm,\\nwe can perform near-optimal clustering of the sample points and density\\nestimation for mixtures of k Gaussians, efficiently. The building blocks of our\\nalgorithm are based on the work Kalai et al. [STOC 2010] that gives an\\nefficient algorithm for learning mixtures of two Gaussians by considering a\\nseries of projections down to one dimension, and applying the method of moments\\nto each univariate projection. A major technical hurdle in Kalai et al. is\\nshowing that one can efficiently learn univariate mixtures of two Gaussians. In\\ncontrast, because pathological scenarios can arise when considering univariate\\nprojections of mixtures of more than two Gaussians, the bulk of the work in\\nthis paper concerns how to leverage an algorithm for learning univariate\\nmixtures (of many Gaussians) to yield an efficient algorithm for learning in\\nhigh dimensions. Our algorithm employs hierarchical clustering and rescaling,\\ntogether with delicate methods for backtracking and recovering from failures\\nthat can occur in our univariate algorithm. Finally, while the running time and\\ndata requirements of our algorithm depend exponentially on the number of\\nGaussians in the mixture, we prove that such a dependence is necessary.\\n',\n",
              " '  We describe and analyze efficient algorithms for learning a linear predictor\\nfrom examples when the learner can only view a few attributes of each training\\nexample. This is the case, for instance, in medical research, where each\\npatient participating in the experiment is only willing to go through a small\\nnumber of tests. Our analysis bounds the number of additional examples\\nsufficient to compensate for the lack of full information on each training\\nexample. We demonstrate the efficiency of our algorithms by showing that when\\nrunning on digit recognition data, they obtain a high prediction accuracy even\\nwhen the learner gets to see only four pixels of each image.\\n',\n",
              " '  Biological data objects often have both of the following features: (i) they\\nare functions rather than single numbers or vectors, and (ii) they are\\ncorrelated due to phylogenetic relationships. In this paper we give a flexible\\nstatistical model for such data, by combining assumptions from phylogenetics\\nwith Gaussian processes. We describe its use as a nonparametric Bayesian prior\\ndistribution, both for prediction (placing posterior distributions on ancestral\\nfunctions) and model selection (comparing rates of evolution across a\\nphylogeny, or identifying the most likely phylogenies consistent with the\\nobserved data). Our work is integrative, extending the popular phylogenetic\\nBrownian Motion and Ornstein-Uhlenbeck models to functional data and Bayesian\\ninference, and extending Gaussian Process regression to phylogenies. We provide\\na brief illustration of the application of our method.\\n',\n",
              " '  The question of polynomial learnability of probability distributions,\\nparticularly Gaussian mixture distributions, has recently received significant\\nattention in theoretical computer science and machine learning. However,\\ndespite major progress, the general question of polynomial learnability of\\nGaussian mixture distributions still remained open. The current work resolves\\nthe question of polynomial learnability for Gaussian mixtures in high dimension\\nwith an arbitrary fixed number of components. The result on learning Gaussian\\nmixtures relies on an analysis of distributions belonging to what we call\\n\"polynomial families\" in low dimension. These families are characterized by\\ntheir moments being polynomial in parameters and include almost all common\\nprobability distributions as well as their mixtures and products. Using tools\\nfrom real algebraic geometry, we show that parameters of any distribution\\nbelonging to such a family can be learned in polynomial time and using a\\npolynomial number of sample points. The result on learning polynomial families\\nis quite general and is of independent interest. To estimate parameters of a\\nGaussian mixture distribution in high dimensions, we provide a deterministic\\nalgorithm for dimensionality reduction. This allows us to reduce learning a\\nhigh-dimensional mixture to a polynomial number of parameter estimations in low\\ndimension. Combining this reduction with the results on polynomial families\\nyields our result on learning arbitrary Gaussian mixtures in high dimensions.\\n',\n",
              " '  The problem of clustering is considered, for the case when each data point is\\na sample generated by a stationary ergodic process. We propose a very natural\\nasymptotic notion of consistency, and show that simple consistent algorithms\\nexist, under most general non-parametric assumptions. The notion of consistency\\nis as follows: two samples should be put into the same cluster if and only if\\nthey were generated by the same distribution. With this notion of consistency,\\nclustering generalizes such classical statistical problems as homogeneity\\ntesting and process classification. We show that, for the case of a known\\nnumber of clusters, consistency can be achieved under the only assumption that\\nthe joint distribution of the data is stationary ergodic (no parametric or\\nMarkovian assumptions, no assumptions of independence, neither between nor\\nwithin the samples). If the number of clusters is unknown, consistency can be\\nachieved under appropriate assumptions on the mixing rates of the processes.\\n(again, no parametric or independence assumptions). In both cases we give\\nexamples of simple (at most quadratic in each argument) algorithms which are\\nconsistent.\\n',\n",
              " '  We consider model-based reinforcement learning in finite Markov De- cision\\nProcesses (MDPs), focussing on so-called optimistic strategies. In MDPs,\\noptimism can be implemented by carrying out extended value it- erations under a\\nconstraint of consistency with the estimated model tran- sition probabilities.\\nThe UCRL2 algorithm by Auer, Jaksch and Ortner (2009), which follows this\\nstrategy, has recently been shown to guarantee near-optimal regret bounds. In\\nthis paper, we strongly argue in favor of using the Kullback-Leibler (KL)\\ndivergence for this purpose. By studying the linear maximization problem under\\nKL constraints, we provide an ef- ficient algorithm, termed KL-UCRL, for\\nsolving KL-optimistic extended value iteration. Using recent deviation bounds\\non the KL divergence, we prove that KL-UCRL provides the same guarantees as\\nUCRL2 in terms of regret. However, numerical experiments on classical\\nbenchmarks show a significantly improved behavior, particularly when the MDP\\nhas reduced connectivity. To support this observation, we provide elements of\\ncom- parison between the two algorithms based on geometric considerations.\\n',\n",
              " '  We introduce a class of neural networks derived from probabilistic models in\\nthe form of Bayesian networks. By imposing additional assumptions about the\\nnature of the probabilistic models represented in the networks, we derive\\nneural networks with standard dynamics that require no training to determine\\nthe synaptic weights, that perform accurate calculation of the mean values of\\nthe random variables, that can pool multiple sources of evidence, and that deal\\ncleanly and consistently with inconsistent or contradictory evidence. The\\npresented neural networks capture many properties of Bayesian networks,\\nproviding distributed versions of probabilistic models.\\n',\n",
              " '  We propose a novel problem formulation of learning a single task when the\\ndata are provided in different feature spaces. Each such space is called an\\noutlook, and is assumed to contain both labeled and unlabeled data. The\\nobjective is to take advantage of the data from all the outlooks to better\\nclassify each of the outlooks. We devise an algorithm that computes optimal\\naffine mappings from different outlooks to a target outlook by matching moments\\nof the empirical distributions. We further derive a probabilistic\\ninterpretation of the resulting algorithm and a sample complexity bound\\nindicating how many samples are needed to adequately find the mapping. We\\nreport the results of extensive experiments on activity recognition tasks that\\nshow the value of the proposed approach in boosting performance.\\n',\n",
              " '  In Bayesian machine learning, conjugate priors are popular, mostly due to\\nmathematical convenience. In this paper, we show that there are deeper reasons\\nfor choosing a conjugate prior. Specifically, we formulate the conjugate prior\\nin the form of Bregman divergence and show that it is the inherent geometry of\\nconjugate priors that makes them appropriate and intuitive. This geometric\\ninterpretation allows one to view the hyperparameters of conjugate priors as\\nthe {\\\\it effective} sample points, thus providing additional intuition. We use\\nthis geometric understanding of conjugate priors to derive the hyperparameters\\nand expression of the prior used to couple the generative and discriminative\\ncomponents of a hybrid model for semi-supervised learning.\\n',\n",
              " '  As increasing amounts of sensitive personal information is aggregated into\\ndata repositories, it has become important to develop mechanisms for processing\\nthe data without revealing information about individual data instances. The\\ndifferential privacy model provides a framework for the development and\\ntheoretical analysis of such mechanisms. In this paper, we propose an algorithm\\nfor learning a discriminatively trained multi-class Gaussian classifier that\\nsatisfies differential privacy using a large margin loss function with a\\nperturbed regularization term. We present a theoretical upper bound on the\\nexcess risk of the classifier introduced by the perturbation.\\n',\n",
              " '  In this paper, we consider the distributive queue-aware power and subband\\nallocation design for a delay-optimal OFDMA uplink system with one base\\nstation, $K$ users and $N_F$ independent subbands. Each mobile has an uplink\\nqueue with heterogeneous packet arrivals and delay requirements. We model the\\nproblem as an infinite horizon average reward Markov Decision Problem (MDP)\\nwhere the control actions are functions of the instantaneous Channel State\\nInformation (CSI) as well as the joint Queue State Information (QSI). To\\naddress the distributive requirement and the issue of exponential memory\\nrequirement and computational complexity, we approximate the subband allocation\\nQ-factor by the sum of the per-user subband allocation Q-factor and derive a\\ndistributive online stochastic learning algorithm to estimate the per-user\\nQ-factor and the Lagrange multipliers (LM) simultaneously and determine the\\ncontrol actions using an auction mechanism. We show that under the proposed\\nauction mechanism, the distributive online learning converges almost surely\\n(with probability 1). For illustration, we apply the proposed distributive\\nstochastic learning framework to an application example with exponential packet\\nsize distribution. We show that the delay-optimal power control has the {\\\\em\\nmulti-level water-filling} structure where the CSI determines the instantaneous\\npower allocation and the QSI determines the water-level. The proposed algorithm\\nhas linear signaling overhead and computational complexity $\\\\mathcal O(KN)$,\\nwhich is desirable from an implementation perspective.\\n',\n",
              " '  We consider the problem of reinforcement learning using function\\napproximation, where the approximating basis can change dynamically while\\ninteracting with the environment. A motivation for such an approach is\\nmaximizing the value function fitness to the problem faced. Three errors are\\nconsidered: approximation square error, Bellman residual, and projected Bellman\\nresidual. Algorithms under the actor-critic framework are presented, and shown\\nto converge. The advantage of such an adaptive basis is demonstrated in\\nsimulations.\\n',\n",
              " '  We introduce two kernels that extend the mean map, which embeds probability\\nmeasures in Hilbert spaces. The generative mean map kernel (GMMK) is a smooth\\nsimilarity measure between probabilistic models. The latent mean map kernel\\n(LMMK) generalizes the non-iid formulation of Hilbert space embeddings of\\nempirical distributions in order to incorporate latent variable models. When\\ncomparing certain classes of distributions, the GMMK exhibits beneficial\\nregularization and generalization properties not shown for previous generative\\nkernels. We present experiments comparing support vector machine performance\\nusing the GMMK and LMMK between hidden Markov models to the performance of\\nother methods on discrete and continuous observation sequence data. The results\\nsuggest that, in many cases, the GMMK has generalization error competitive with\\nor better than other methods.\\n',\n",
              " '  This paper presents a method for automated healing as part of off-line\\nautomated troubleshooting. The method combines statistical learning with\\nconstraint optimization. The automated healing aims at locally optimizing radio\\nresource management (RRM) or system parameters of cells with poor performance\\nin an iterative manner. The statistical learning processes the data using\\nLogistic Regression (LR) to extract closed form (functional) relations between\\nKey Performance Indicators (KPIs) and Radio Resource Management (RRM)\\nparameters. These functional relations are then processed by an optimization\\nengine which proposes new parameter values. The advantage of the proposed\\nformulation is the small number of iterations required by the automated healing\\nmethod to converge, making it suitable for off-line implementation. The\\nproposed method is applied to heal an Inter-Cell Interference Coordination\\n(ICIC) process in a 3G Long Term Evolution (LTE) network which is based on\\nsoft-frequency reuse scheme. Numerical simulations illustrate the benefits of\\nthe proposed approach.\\n',\n",
              " '  In this work, decision tree learning algorithms and fuzzy inferencing systems\\nare applied for galaxy morphology classification. In particular, the CART, the\\nC4.5, the Random Forest and fuzzy logic algorithms are studied and reliable\\nclassifiers are developed to distinguish between spiral galaxies, elliptical\\ngalaxies or star/unknown galactic objects. Morphology information for the\\ntraining and testing datasets is obtained from the Galaxy Zoo project while the\\ncorresponding photometric and spectra parameters are downloaded from the SDSS\\nDR7 catalogue.\\n',\n",
              " \"  Recent research on multiple kernel learning has lead to a number of\\napproaches for combining kernels in regularized risk minimization. The proposed\\napproaches include different formulations of objectives and varying\\nregularization strategies. In this paper we present a unifying general\\noptimization criterion for multiple kernel learning and show how existing\\nformulations are subsumed as special cases. We also derive the criterion's dual\\nrepresentation, which is suitable for general smooth optimization algorithms.\\nFinally, we evaluate multiple kernel learning in this framework analytically\\nusing a Rademacher complexity bound on the generalization error and empirically\\nin a set of experiments.\\n\",\n",
              " \"  One of the objectives of designing feature selection learning algorithms is\\nto obtain classifiers that depend on a small number of attributes and have\\nverifiable future performance guarantees. There are few, if any, approaches\\nthat successfully address the two goals simultaneously. Performance guarantees\\nbecome crucial for tasks such as microarray data analysis due to very small\\nsample sizes resulting in limited empirical evaluation. To the best of our\\nknowledge, such algorithms that give theoretical bounds on the future\\nperformance have not been proposed so far in the context of the classification\\nof gene expression data. In this work, we investigate the premise of learning a\\nconjunction (or disjunction) of decision stumps in Occam's Razor, Sample\\nCompression, and PAC-Bayes learning settings for identifying a small subset of\\nattributes that can be used to perform reliable classification tasks. We apply\\nthe proposed approaches for gene identification from DNA microarray data and\\ncompare our results to those of well known successful approaches proposed for\\nthe task. We show that our algorithm not only finds hypotheses with much\\nsmaller number of genes while giving competitive classification accuracy but\\nalso have tight risk guarantees on future performance unlike other approaches.\\nThe proposed approaches are general and extensible in terms of both designing\\nnovel algorithms and application to other domains.\\n\",\n",
              " '  In many networks, vertices have hidden attributes, or types, that are\\ncorrelated with the networks topology. If the topology is known but these\\nattributes are not, and if learning the attributes is costly, we need a method\\nfor choosing which vertex to query in order to learn as much as possible about\\nthe attributes of the other vertices. We assume the network is generated by a\\nstochastic block model, but we make no assumptions about its assortativity or\\ndisassortativity. We choose which vertex to query using two methods: 1)\\nmaximizing the mutual information between its attributes and those of the\\nothers (a well-known approach in active learning) and 2) maximizing the average\\nagreement between two independent samples of the conditional Gibbs\\ndistribution. Experimental results show that both these methods do much better\\nthan simple heuristics. They also consistently identify certain vertices as\\nimportant by querying them early on.\\n',\n",
              " '  The problem of clustering is considered, for the case when each data point is\\na sample generated by a stationary ergodic process. We propose a very natural\\nasymptotic notion of consistency, and show that simple consistent algorithms\\nexist, under most general non-parametric assumptions. The notion of consistency\\nis as follows: two samples should be put into the same cluster if and only if\\nthey were generated by the same distribution. With this notion of consistency,\\nclustering generalizes such classical statistical problems as homogeneity\\ntesting and process classification. We show that, for the case of a known\\nnumber of clusters, consistency can be achieved under the only assumption that\\nthe joint distribution of the data is stationary ergodic (no parametric or\\nMarkovian assumptions, no assumptions of independence, neither between nor\\nwithin the samples). If the number of clusters is unknown, consistency can be\\nachieved under appropriate assumptions on the mixing rates of the processes.\\n(again, no parametric or independence assumptions). In both cases we give\\nexamples of simple (at most quadratic in each argument) algorithms which are\\nconsistent.\\n',\n",
              " \"  Although the real reproducing kernels are used in an increasing number of\\nmachine learning problems, complex kernels have not, yet, been used, in spite\\nof their potential interest in applications such as communications. In this\\nwork, we focus our attention on the complex gaussian kernel and its possible\\napplication in the complex Kernel LMS algorithm. In order to derive the\\ngradients needed to develop the complex kernel LMS (CKLMS), we employ the\\npowerful tool of Wirtinger's Calculus, which has recently attracted much\\nattention in the signal processing community. Writinger's calculus simplifies\\ncomputations and offers an elegant tool for treating complex signals. To this\\nend, the notion of Writinger's calculus is extended to include complex RKHSs.\\nExperiments verify that the CKLMS offers significant performance improvements\\nover the traditional complex LMS or Widely Linear complex LMS (WL-LMS)\\nalgorithms, when dealing with nonlinearities.\\n\",\n",
              " \"  Over the last decade, kernel methods for nonlinear processing have\\nsuccessfully been used in the machine learning community. However, so far, the\\nemphasis has been on batch techniques. It is only recently, that online\\nadaptive techniques have been considered in the context of signal processing\\ntasks. To the best of our knowledge, no kernel-based strategy has been\\ndeveloped, so far, that is able to deal with complex valued signals. In this\\npaper, we take advantage of a technique called complexification of real RKHSs\\nto attack this problem. In order to derive gradients and subgradients of\\noperators that need to be defined on the associated complex RKHSs, we employ\\nthe powerful tool ofWirtinger's Calculus, which has recently attracted much\\nattention in the signal processing community. Writinger's calculus simplifies\\ncomputations and offers an elegant tool for treating complex signals. To this\\nend, in this paper, the notion of Writinger's calculus is extended, for the\\nfirst time, to include complex RKHSs and use it to derive the Complex Kernel\\nLeast-Mean-Square (CKLMS) algorithm. Experiments verify that the CKLMS can be\\nused to derive nonlinear stable algorithms, which offer significant performance\\nimprovements over the traditional complex LMS orWidely Linear complex LMS\\n(WL-LMS) algorithms, when dealing with nonlinearities.\\n\",\n",
              " '  For each $p \\\\in (0,2]$, we present a randomized algorithm that returns an\\n$\\\\epsilon$-approximation of the $p$th frequency moment of a data stream $F_p =\\n\\\\sum_{i = 1}^n \\\\abs{f_i}^p$. The algorithm requires space $O(\\\\epsilon^{-2} \\\\log\\n(mM)(\\\\log n))$ and processes each stream update using time $O((\\\\log n) (\\\\log\\n\\\\epsilon^{-1}))$. It is nearly optimal in terms of space (lower bound\\n$O(\\\\epsilon^{-2} \\\\log (mM))$ as well as time and is the first algorithm with\\nthese properties. The technique separates heavy hitters from the remaining\\nitems in the stream using an appropriate threshold and estimates the\\ncontribution of the heavy hitters and the light elements to $F_p$ separately. A\\nkey component is the design of an unbiased estimator for $\\\\abs{f_i}^p$ whose\\ndata structure has low update time and low variance.\\n',\n",
              " '  Semi-supervised support vector machines (S3VMs) are a kind of popular\\napproaches which try to improve learning performance by exploiting unlabeled\\ndata. Though S3VMs have been found helpful in many situations, they may\\ndegenerate performance and the resultant generalization ability may be even\\nworse than using the labeled data only. In this paper, we try to reduce the\\nchance of performance degeneration of S3VMs. Our basic idea is that, rather\\nthan exploiting all unlabeled data, the unlabeled instances should be selected\\nsuch that only the ones which are very likely to be helpful are exploited,\\nwhile some highly risky unlabeled instances are avoided. We propose the\\nS3VM-\\\\emph{us} method by using hierarchical clustering to select the unlabeled\\ninstances. Experiments on a broad range of data sets over eighty-eight\\ndifferent settings show that the chance of performance degeneration of\\nS3VM-\\\\emph{us} is much smaller than that of existing S3VMs.\\n',\n",
              " '  We study prediction with expert advice in the setting where the losses are\\naccumulated with some discounting---the impact of old losses may gradually\\nvanish. We generalize the Aggregating Algorithm and the Aggregating Algorithm\\nfor Regression to this case, propose a suitable new variant of exponential\\nweights algorithm, and prove respective loss bounds.\\n',\n",
              " '  Cyclic coordinate descent is a classic optimization method that has witnessed\\na resurgence of interest in machine learning. Reasons for this include its\\nsimplicity, speed and stability, as well as its competitive performance on\\n$\\\\ell_1$ regularized smooth optimization problems. Surprisingly, very little is\\nknown about its finite time convergence behavior on these problems. Most\\nexisting results either just prove convergence or provide asymptotic rates. We\\nfill this gap in the literature by proving $O(1/k)$ convergence rates (where\\n$k$ is the iteration counter) for two variants of cyclic coordinate descent\\nunder an isotonicity assumption. Our analysis proceeds by comparing the\\nobjective values attained by the two variants with each other, as well as with\\nthe gradient descent algorithm. We show that the iterates generated by the\\ncyclic coordinate descent methods remain better than those of gradient descent\\nuniformly over time.\\n',\n",
              " '  In this paper, we formulate a novel problem for finding blackhole and volcano\\npatterns in a large directed graph. Specifically, a blackhole pattern is a\\ngroup which is made of a set of nodes in a way such that there are only inlinks\\nto this group from the rest nodes in the graph. In contrast, a volcano pattern\\nis a group which only has outlinks to the rest nodes in the graph. Both\\npatterns can be observed in real world. For instance, in a trading network, a\\nblackhole pattern may represent a group of traders who are manipulating the\\nmarket. In the paper, we first prove that the blackhole mining problem is a\\ndual problem of finding volcanoes. Therefore, we focus on finding the blackhole\\npatterns. Along this line, we design two pruning schemes to guide the blackhole\\nfinding process. In the first pruning scheme, we strategically prune the search\\nspace based on a set of pattern-size-independent pruning rules and develop an\\niBlackhole algorithm. The second pruning scheme follows a divide-and-conquer\\nstrategy to further exploit the pruning results from the first pruning scheme.\\nIndeed, a target directed graphs can be divided into several disconnected\\nsubgraphs by the first pruning scheme, and thus the blackhole finding can be\\nconducted in each disconnected subgraph rather than in a large graph. Based on\\nthese two pruning schemes, we also develop an iBlackhole-DC algorithm. Finally,\\nexperimental results on real-world data show that the iBlackhole-DC algorithm\\ncan be several orders of magnitude faster than the iBlackhole algorithm, which\\nhas a huge computational advantage over a brute-force method.\\n',\n",
              " '  We derive generalization bounds for learning algorithms based on their\\nrobustness: the property that if a testing sample is \"similar\" to a training\\nsample, then the testing error is close to the training error. This provides a\\nnovel approach, different from the complexity or stability arguments, to study\\ngeneralization of learning algorithms. We further show that a weak notion of\\nrobustness is both sufficient and necessary for generalizability, which implies\\nthat robustness is a fundamental property for learning algorithms to work.\\n',\n",
              " '  We present a class of models that, via a simple construction, enables exact,\\nincremental, non-parametric, polynomial-time, Bayesian inference of conditional\\nmeasures. The approach relies upon creating a sequence of covers on the\\nconditioning variable and maintaining a different model for each set within a\\ncover. Inference remains tractable by specifying the probabilistic model in\\nterms of a random walk within the sequence of covers. We demonstrate the\\napproach on problems of conditional density estimation, which, to our knowledge\\nis the first closed-form, non-parametric Bayesian approach to this problem.\\n',\n",
              " '  We study online learning when individual instances are corrupted by\\nadversarially chosen random noise. We assume the noise distribution is unknown,\\nand may change over time with no restriction other than having zero mean and\\nbounded variance. Our technique relies on a family of unbiased estimators for\\nnon-linear functions, which may be of independent interest. We show that a\\nvariant of online gradient descent can learn functions in any dot-product\\n(e.g., polynomial) or Gaussian kernel space with any analytic convex loss\\nfunction. Our variant uses randomized estimates that need to query a random\\nnumber of noisy copies of each instance, where with high probability this\\nnumber is upper bounded by a constant. Allowing such multiple queries cannot be\\navoided: Indeed, we show that online learning is in general impossible when\\nonly one noisy copy of each instance can be accessed.\\n',\n",
              " '  The concept of overfitting in model selection is explained and demonstrated\\nwith an example. After providing some background information on information\\ntheory and Kolmogorov complexity, we provide a short explanation of Minimum\\nDescription Length and error minimization. We conclude with a discussion of the\\ntypical features of overfitting in model selection.\\n',\n",
              " \"  This paper presents a concise tutorial on spectral clustering for broad\\nspectrum graphs which include unipartite (undirected) graph, bipartite graph,\\nand directed graph. We show how to transform bipartite graph and directed graph\\ninto corresponding unipartite graph, therefore allowing a unified treatment to\\nall cases. In bipartite graph, we show that the relaxed solution to the $K$-way\\nco-clustering can be found by computing the left and right eigenvectors of the\\ndata matrix. This gives a theoretical basis for $K$-way spectral co-clustering\\nalgorithms proposed in the literatures. We also show that solving row and\\ncolumn co-clustering is equivalent to solving row and column clustering\\nseparately, thus giving a theoretical support for the claim: ``column\\nclustering implies row clustering and vice versa''. And in the last part, we\\ngeneralize the Ky Fan theorem---which is the central theorem for explaining\\nspectral clustering---to rectangular complex matrix motivated by the results\\nfrom bipartite graph analysis.\\n\",\n",
              " '  Data analysis and data mining are concerned with unsupervised pattern finding\\nand structure determination in data sets. \"Structure\" can be understood as\\nsymmetry and a range of symmetries are expressed by hierarchy. Such symmetries\\ndirectly point to invariants, that pinpoint intrinsic properties of the data\\nand of the background empirical domain of interest. We review many aspects of\\nhierarchy here, including ultrametric topology, generalized ultrametric,\\nlinkages with lattices and other discrete algebraic structures and with p-adic\\nnumber representations. By focusing on symmetries in data we have a powerful\\nmeans of structuring and analyzing massive, high dimensional data stores. We\\nillustrate the powerfulness of hierarchical clustering in case studies in\\nchemistry and finance, and we provide pointers to other published case studies.\\n',\n",
              " \"  We introduce a theory of sequential causal inference in which learners in a\\nchain estimate a structural model from their upstream teacher and then pass\\nsamples from the model to their downstream student. It extends the population\\ndynamics of genetic drift, recasting Kimura's selectively neutral theory as a\\nspecial case of a generalized drift process using structured populations with\\nmemory. We examine the diffusion and fixation properties of several drift\\nprocesses and propose applications to learning, inference, and evolution. We\\nalso demonstrate how the organization of drift process space controls fidelity,\\nfacilitates innovations, and leads to information loss in sequential learning\\nwith and without memory.\\n\",\n",
              " '  We consider the question of the stability of evolutionary algorithms to\\ngradual changes, or drift, in the target concept. We define an algorithm to be\\nresistant to drift if, for some inverse polynomial drift rate in the target\\nfunction, it converges to accuracy 1 -- \\\\epsilon , with polynomial resources,\\nand then stays within that accuracy indefinitely, except with probability\\n\\\\epsilon , at any one time. We show that every evolution algorithm, in the\\nsense of Valiant (2007; 2009), can be converted using the Correlational Query\\ntechnique of Feldman (2008), into such a drift resistant algorithm. For certain\\nevolutionary algorithms, such as for Boolean conjunctions, we give bounds on\\nthe rates of drift that they can resist. We develop some new evolution\\nalgorithms that are resistant to significant drift. In particular, we give an\\nalgorithm for evolving linear separators over the spherically symmetric\\ndistribution that is resistant to a drift rate of O(\\\\epsilon /n), and another\\nalgorithm over the more general product normal distributions that resists a\\nsmaller drift rate.\\n  The above translation result can be also interpreted as one on the robustness\\nof the notion of evolvability itself under changes of definition. As a second\\nresult in that direction we show that every evolution algorithm can be\\nconverted to a quasi-monotonic one that can evolve from any starting point\\nwithout the performance ever dipping significantly below that of the starting\\npoint. This permits the somewhat unnatural feature of arbitrary performance\\ndegradations to be removed from several known robustness translations.\\n',\n",
              " \"  We consider the problem of learning a structured multi-task regression, where\\nthe output consists of multiple responses that are related by a graph and the\\ncorrelated response variables are dependent on the common inputs in a sparse\\nbut synergistic manner. Previous methods such as l1/l2-regularized multi-task\\nregression assume that all of the output variables are equally related to the\\ninputs, although in many real-world problems, outputs are related in a complex\\nmanner. In this paper, we propose graph-guided fused lasso (GFlasso) for\\nstructured multi-task regression that exploits the graph structure over the\\noutput variables. We introduce a novel penalty function based on fusion penalty\\nto encourage highly correlated outputs to share a common set of relevant\\ninputs. In addition, we propose a simple yet efficient proximal-gradient method\\nfor optimizing GFlasso that can also be applied to any optimization problems\\nwith a convex smooth loss and the general class of fusion penalty defined on\\narbitrary graph structures. By exploiting the structure of the non-smooth\\n''fusion penalty'', our method achieves a faster convergence rate than the\\nstandard first-order method, sub-gradient method, and is significantly more\\nscalable than the widely adopted second-order cone-programming and\\nquadratic-programming formulations. In addition, we provide an analysis of the\\nconsistency property of the GFlasso model. Experimental results not only\\ndemonstrate the superiority of GFlasso over the standard lasso but also show\\nthe efficiency and scalability of our proximal-gradient method.\\n\",\n",
              " '  We describe and analyze a new algorithm for agnostically learning\\nkernel-based halfspaces with respect to the \\\\emph{zero-one} loss function.\\nUnlike most previous formulations which rely on surrogate convex loss functions\\n(e.g. hinge-loss in SVM and log-loss in logistic regression), we provide finite\\ntime/sample guarantees with respect to the more natural zero-one loss function.\\nThe proposed algorithm can learn kernel-based halfspaces in worst-case time\\n$\\\\poly(\\\\exp(L\\\\log(L/\\\\epsilon)))$, for $\\\\emph{any}$ distribution, where $L$ is a\\nLipschitz constant (which can be thought of as the reciprocal of the margin),\\nand the learned classifier is worse than the optimal halfspace by at most\\n$\\\\epsilon$. We also prove a hardness result, showing that under a certain\\ncryptographic assumption, no algorithm can learn kernel-based halfspaces in\\ntime polynomial in $L$.\\n',\n",
              " \"  Cross-document coreference, the problem of resolving entity mentions across\\nmulti-document collections, is crucial to automated knowledge base construction\\nand data mining tasks. However, the scarcity of large labeled data sets has\\nhindered supervised machine learning research for this task. In this paper we\\ndevelop and demonstrate an approach based on ``distantly-labeling'' a data set\\nfrom which we can train a discriminative cross-document coreference model. In\\nparticular we build a dataset of more than a million people mentions extracted\\nfrom 3.5 years of New York Times articles, leverage Wikipedia for distant\\nlabeling with a generative model (and measure the reliability of such\\nlabeling); then we train and evaluate a conditional random field coreference\\nmodel that has factors on cross-document entities as well as mention-pairs.\\nThis coreference model obtains high accuracy in resolving mentions and entities\\nthat are not present in the training data, indicating applicability to\\nnon-Wikipedia data. Given the large amount of data, our work is also an\\nexercise demonstrating the scalability of our approach.\\n\",\n",
              " '  We study the problem of estimating high-dimensional regression models\\nregularized by a structured sparsity-inducing penalty that encodes prior\\nstructural information on either the input or output variables. We consider two\\nwidely adopted types of penalties of this kind as motivating examples: (1) the\\ngeneral overlapping-group-lasso penalty, generalized from the group-lasso\\npenalty; and (2) the graph-guided-fused-lasso penalty, generalized from the\\nfused-lasso penalty. For both types of penalties, due to their nonseparability\\nand nonsmoothness, developing an efficient optimization method remains a\\nchallenging problem. In this paper we propose a general optimization approach,\\nthe smoothing proximal gradient (SPG) method, which can solve structured sparse\\nregression problems with any smooth convex loss under a wide spectrum of\\nstructured sparsity-inducing penalties. Our approach combines a smoothing\\ntechnique with an effective proximal gradient method. It achieves a convergence\\nrate significantly faster than the standard first-order methods, subgradient\\nmethods, and is much more scalable than the most widely used interior-point\\nmethods. The efficiency and scalability of our method are demonstrated on both\\nsimulation experiments and real genetic data sets.\\n',\n",
              " \"  This paper proposes some extensions to the work on kernels dedicated to\\nstring or time series global alignment based on the aggregation of scores\\nobtained by local alignments. The extensions we propose allow to construct,\\nfrom classical recursive definition of elastic distances, recursive edit\\ndistance (or time-warp) kernels that are positive definite if some sufficient\\nconditions are satisfied. The sufficient conditions we end-up with are original\\nand weaker than those proposed in earlier works, although a recursive\\nregularizing term is required to get the proof of the positive definiteness as\\na direct consequence of the Haussler's convolution theorem. The classification\\nexperiment we conducted on three classical time warp distances (two of which\\nbeing metrics), using Support Vector Machine classifier, leads to conclude\\nthat, when the pairwise distance matrix obtained from the training data is\\n\\\\textit{far} from definiteness, the positive definite recursive elastic kernels\\noutperform in general the distance substituting kernels for the classical\\nelastic distances we have tested.\\n\",\n",
              " \"  The present report, has been inspired by the need of the author and its\\ncolleagues to understand the underlying theory of Wirtinger's Calculus and to\\nfurther extend it to include the kernel case. The aim of the present manuscript\\nis twofold: a) it endeavors to provide a more rigorous presentation of the\\nrelated material, focusing on aspects that the author finds more insightful and\\nb) it extends the notions of Wirtinger's calculus on general Hilbert spaces\\n(such as Reproducing Hilbert Kernel Spaces).\\n\",\n",
              " '  Most learning to rank research has assumed that the utility of different\\ndocuments is independent, which results in learned ranking functions that\\nreturn redundant results. The few approaches that avoid this have rather\\nunsatisfyingly lacked theoretical foundations, or do not scale. We present a\\nlearning-to-rank formulation that optimizes the fraction of satisfied users,\\nwith several scalable algorithms that explicitly takes document similarity and\\nranking context into account. Our formulation is a non-trivial common\\ngeneralization of two multi-armed bandit models from the literature: \"ranked\\nbandits\" (Radlinski et al., ICML 2008) and \"Lipschitz bandits\" (Kleinberg et\\nal., STOC 2008). We present theoretical justifications for this approach, as\\nwell as a near-optimal algorithm. Our evaluation adds optimizations that\\nimprove empirical performance, and shows that our algorithms learn orders of\\nmagnitude more quickly than previous approaches.\\n',\n",
              " \"  The contribution of this paper is to provide a semantic model (using soft\\nconstraints) of the words used by web-users to describe objects in a language\\ngame; a game in which one user describes a selected object of those composing\\nthe scene, and another user has to guess which object has been described. The\\ngiven description needs to be non ambiguous and accurate enough to allow other\\nusers to guess the described shape correctly.\\n  To build these semantic models the descriptions need to be analyzed to\\nextract the syntax and words' classes used. We have modeled the meaning of\\nthese descriptions using soft constraints as a way for grounding the meaning.\\n  The descriptions generated by the system took into account the context of the\\nobject to avoid ambiguous descriptions, and allowed users to guess the\\ndescribed object correctly 72% of the times.\\n\",\n",
              " '  Rapid identification of object from radar cross section (RCS) signals is\\nimportant for many space and military applications. This identification is a\\nproblem in pattern recognition which either neural networks or support vector\\nmachines should prove to be high-speed. Bayesian networks would also provide\\nvalue but require significant preprocessing of the signals. In this paper, we\\ndescribe the use of a support vector machine for object identification from\\nsynthesized RCS data. Our best results are from data fusion of X-band and\\nS-band signals, where we obtained 99.4%, 95.3%, 100% and 95.6% correct\\nidentification for cylinders, frusta, spheres, and polygons, respectively. We\\nalso compare our results with a Bayesian approach and show that the SVM is\\nthree orders of magnitude faster, as measured by the number of floating point\\noperations.\\n',\n",
              " '  This paper provides a theoretical explanation on the clustering aspect of\\nnonnegative matrix factorization (NMF). We prove that even without imposing\\northogonality nor sparsity constraint on the basis and/or coefficient matrix,\\nNMF still can give clustering results, thus providing a theoretical support for\\nmany works, e.g., Xu et al. [1] and Kim et al. [2], that show the superiority\\nof the standard NMF as a clustering method.\\n',\n",
              " \"  Standard hybrid learners that use domain knowledge require stronger knowledge\\nthat is hard and expensive to acquire. However, weaker domain knowledge can\\nbenefit from prior knowledge while being cost effective. Weak knowledge in the\\nform of feature relative importance (FRI) is presented and explained. Feature\\nrelative importance is a real valued approximation of a feature's importance\\nprovided by experts. Advantage of using this knowledge is demonstrated by IANN,\\na modified multilayer neural network algorithm. IANN is a very simple\\nmodification of standard neural network algorithm but attains significant\\nperformance gains. Experimental results in the field of molecular biology show\\nhigher performance over other empirical learning algorithms including standard\\nbackpropagation and support vector machines. IANN performance is even\\ncomparable to a theory refinement system KBANN that uses stronger domain\\nknowledge. This shows Feature relative importance can improve performance of\\nexisting empirical learning algorithms significantly with minimal effort.\\n\",\n",
              " '  The sample complexity of active learning under the realizability assumption\\nhas been well-studied. The realizability assumption, however, rarely holds in\\npractice. In this paper, we theoretically characterize the sample complexity of\\nactive learning in the non-realizable case under multi-view setting. We prove\\nthat, with unbounded Tsybakov noise, the sample complexity of multi-view active\\nlearning can be $\\\\widetilde{O}(\\\\log\\\\frac{1}{\\\\epsilon})$, contrasting to\\nsingle-view setting where the polynomial improvement is the best possible\\nachievement. We also prove that in general multi-view setting the sample\\ncomplexity of active learning with unbounded Tsybakov noise is\\n$\\\\widetilde{O}(\\\\frac{1}{\\\\epsilon})$, where the order of $1/\\\\epsilon$ is\\nindependent of the parameter in Tsybakov noise, contrasting to previous\\npolynomial bounds where the order of $1/\\\\epsilon$ is related to the parameter\\nin Tsybakov noise.\\n',\n",
              " '  A sequence $x_1,\\\\dots,x_n,\\\\dots$ of discrete-valued observations is generated\\naccording to some unknown probabilistic law (measure) $\\\\mu$. After observing\\neach outcome, one is required to give conditional probabilities of the next\\nobservation. The realizable case is when the measure $\\\\mu$ belongs to an\\narbitrary but known class $\\\\mathcal C$ of process measures. The non-realizable\\ncase is when $\\\\mu$ is completely arbitrary, but the prediction performance is\\nmeasured with respect to a given set $\\\\mathcal C$ of process measures. We are\\ninterested in the relations between these problems and between their solutions,\\nas well as in characterizing the cases when a solution exists and finding these\\nsolutions. We show that if the quality of prediction is measured using the\\ntotal variation distance, then these problems coincide, while if it is measured\\nusing the expected average KL divergence, then they are different. For some of\\nthe formalizations we also show that when a solution exists, it can be obtained\\nas a Bayes mixture over a countable subset of $\\\\mathcal C$. We also obtain\\nseveral characterization of those sets $\\\\mathcal C$ for which solutions to the\\nconsidered problems exist. As an illustration to the general results obtained,\\nwe show that a solution to the non-realizable case of the sequence prediction\\nproblem exists for the set of all finite-memory processes, but does not exist\\nfor the set of all stationary processes.\\n  It should be emphasized that the framework is completely general: the\\nprocesses measures considered are not required to be i.i.d., mixing,\\nstationary, or to belong to any parametric family.\\n',\n",
              " '  Model selection in clustering requires (i) to specify a suitable clustering\\nprinciple and (ii) to control the model order complexity by choosing an\\nappropriate number of clusters depending on the noise level in the data. We\\nadvocate an information theoretic perspective where the uncertainty in the\\nmeasurements quantizes the set of data partitionings and, thereby, induces\\nuncertainty in the solution space of clusterings. A clustering model, which can\\ntolerate a higher level of fluctuations in the measurements than alternative\\nmodels, is considered to be superior provided that the clustering solution is\\nequally informative. This tradeoff between \\\\emph{informativeness} and\\n\\\\emph{robustness} is used as a model selection criterion. The requirement that\\ndata partitionings should generalize from one data set to an equally probable\\nsecond data set gives rise to a new notion of structure induced information.\\n',\n",
              " '  In the framework of prediction with expert advice, we consider a recently\\nintroduced kind of regret bounds: the bounds that depend on the effective\\ninstead of nominal number of experts. In contrast to the NormalHedge bound,\\nwhich mainly depends on the effective number of experts and also weakly depends\\non the nominal one, we obtain a bound that does not contain the nominal number\\nof experts at all. We use the defensive forecasting method and introduce an\\napplication of defensive forecasting to multivalued supermartingales.\\n',\n",
              " \"  Exchangeable random variables form an important and well-studied\\ngeneralization of i.i.d. variables, however simple examples show that no\\nnontrivial concept or function classes are PAC learnable under general\\nexchangeable data inputs $X_1,X_2,\\\\ldots$. Inspired by the work of Berti and\\nRigo on a Glivenko--Cantelli theorem for exchangeable inputs, we propose a new\\nparadigm, adequate for learning from exchangeable data: predictive PAC\\nlearnability. A learning rule $\\\\mathcal L$ for a function class $\\\\mathscr F$ is\\npredictive PAC if for every $\\\\e,\\\\delta>0$ and each function $f\\\\in {\\\\mathscr\\nF}$, whenever $\\\\abs{\\\\sigma}\\\\geq s(\\\\delta,\\\\e)$, we have with confidence\\n$1-\\\\delta$ that the expected difference between $f(X_{n+1})$ and the image of\\n$f\\\\vert\\\\sigma$ under $\\\\mathcal L$ does not exceed $\\\\e$ conditionally on\\n$X_1,X_2,\\\\ldots,X_n$. Thus, instead of learning the function $f$ as such, we\\nare learning to a given accuracy $\\\\e$ the predictive behaviour of $f$ at the\\nfuture points $X_i(\\\\omega)$, $i>n$ of the sample path. Using de Finetti's\\ntheorem, we show that if a universally separable function class $\\\\mathscr F$ is\\ndistribution-free PAC learnable under i.i.d. inputs, then it is\\ndistribution-free predictive PAC learnable under exchangeable inputs, with a\\nslightly worse sample complexity.\\n\",\n",
              " '  We consider the problem of sequential prediction and provide tools to study\\nthe minimax value of the associated game. Classical statistical learning theory\\nprovides several useful complexity measures to study learning with i.i.d. data.\\nOur proposed sequential complexities can be seen as extensions of these\\nmeasures to the sequential setting. The developed theory is shown to yield\\nprecise learning guarantees for the problem of sequential prediction. In\\nparticular, we show necessary and sufficient conditions for online learnability\\nin the setting of supervised learning. Several examples show the utility of our\\nframework: we can establish learnability without having to exhibit an explicit\\nonline learning algorithm.\\n',\n",
              " '  The paper addresses the problem of learning a regression model parameterized\\nby a fixed-rank positive semidefinite matrix. The focus is on the nonlinear\\nnature of the search space and on scalability to high-dimensional problems. The\\nmathematical developments rely on the theory of gradient descent algorithms\\nadapted to the Riemannian geometry that underlies the set of fixed-rank\\npositive semidefinite matrices. In contrast with previous contributions in the\\nliterature, no restrictions are imposed on the range space of the learned\\nmatrix. The resulting algorithms maintain a linear complexity in the problem\\nsize and enjoy important invariance properties. We apply the proposed\\nalgorithms to the problem of learning a distance function parameterized by a\\npositive semidefinite matrix. Good performance is observed on classical\\nbenchmarks.\\n',\n",
              " '  Representing distributions over permutations can be a daunting task due to\\nthe fact that the number of permutations of $n$ objects scales factorially in\\n$n$. One recent way that has been used to reduce storage complexity has been to\\nexploit probabilistic independence, but as we argue, full independence\\nassumptions impose strong sparsity constraints on distributions and are\\nunsuitable for modeling rankings. We identify a novel class of independence\\nstructures, called \\\\emph{riffled independence}, encompassing a more expressive\\nfamily of distributions while retaining many of the properties necessary for\\nperforming efficient inference and reducing sample complexity. In riffled\\nindependence, one draws two permutations independently, then performs the\\n\\\\emph{riffle shuffle}, common in card games, to combine the two permutations to\\nform a single permutation. Within the context of ranking, riffled independence\\ncorresponds to ranking disjoint sets of objects independently, then\\ninterleaving those rankings. In this paper, we provide a formal introduction to\\nriffled independence and present algorithms for using riffled independence\\nwithin Fourier-theoretic frameworks which have been explored by a number of\\nrecent papers. Additionally, we propose an automated method for discovering\\nsets of items which are riffle independent from a training set of rankings. We\\nshow that our clustering-like algorithms can be used to discover meaningful\\nlatent coalitions from real preference ranking datasets and to learn the\\nstructure of hierarchically decomposable models based on riffled independence.\\n',\n",
              " \"  Calibrated strategies can be obtained by performing strategies that have no\\ninternal regret in some auxiliary game. Such strategies can be constructed\\nexplicitly with the use of Blackwell's approachability theorem, in an other\\nauxiliary game. We establish the converse: a strategy that approaches a convex\\n$B$-set can be derived from the construction of a calibrated strategy. We\\ndevelop these tools in the framework of a game with partial monitoring, where\\nplayers do not observe the actions of their opponents but receive random\\nsignals, to define a notion of internal regret and construct strategies that\\nhave no such regret.\\n\",\n",
              " '  In dyadic prediction, labels must be predicted for pairs (dyads) whose\\nmembers possess unique identifiers and, sometimes, additional features called\\nside-information. Special cases of this problem include collaborative filtering\\nand link prediction. We present the first model for dyadic prediction that\\nsatisfies several important desiderata: (i) labels may be ordinal or nominal,\\n(ii) side-information can be easily exploited if present, (iii) with or without\\nside-information, latent features are inferred for dyad members, (iv) it is\\nresistant to sample-selection bias, (v) it can learn well-calibrated\\nprobabilities, and (vi) it can scale to very large datasets. To our knowledge,\\nno existing method satisfies all the above criteria. In particular, many\\nmethods assume that the labels are ordinal and ignore side-information when it\\nis present. Experimental results show that the new method is competitive with\\nstate-of-the-art methods for the special cases of collaborative filtering and\\nlink prediction, and that it makes accurate predictions on nominal data.\\n',\n",
              " '  Recently, it has been proved in Babadi et al. that in noisy compressed\\nsensing, a joint typical estimator can asymptotically achieve the Cramer-Rao\\nlower bound of the problem.To prove this result, this paper used a lemma,which\\nis provided in Akcakaya et al,that comprises the main building block of the\\nproof. This lemma is based on the assumption of Gaussianity of the measurement\\nmatrix and its randomness in the domain of noise. In this correspondence, we\\ngeneralize the results obtained in Babadi et al by dropping the Gaussianity\\nassumption on the measurement matrix. In fact, by considering the measurement\\nmatrix as a deterministic matrix in our analysis, we find a theorem similar to\\nthe main theorem of Babadi et al for a family of randomly generated (but\\ndeterministic in the noise domain) measurement matrices that satisfy a\\ngeneralized condition known as The Concentration of Measures Inequality. By\\nthis, we finally show that under our generalized assumptions, the Cramer-Rao\\nbound of the estimation is achievable by using the typical estimator introduced\\nin Babadi et al.\\n',\n",
              " '  We present and analyze an agnostic active learning algorithm that works\\nwithout keeping a version space. This is unlike all previous approaches where a\\nrestricted set of candidate hypotheses is maintained throughout learning, and\\nonly hypotheses from this set are ever returned. By avoiding this version space\\napproach, our algorithm sheds the computational burden and brittleness\\nassociated with maintaining version spaces, yet still allows for substantial\\nimprovements over supervised learning for classification.\\n',\n",
              " '  This paper studies the outlier detection problem from the point of view of\\npenalized regressions. Our regression model adds one mean shift parameter for\\neach of the $n$ data points. We then apply a regularization favoring a sparse\\nvector of mean shift parameters. The usual $L_1$ penalty yields a convex\\ncriterion, but we find that it fails to deliver a robust estimator. The $L_1$\\npenalty corresponds to soft thresholding. We introduce a thresholding (denoted\\nby $\\\\Theta$) based iterative procedure for outlier detection ($\\\\Theta$-IPOD). A\\nversion based on hard thresholding correctly identifies outliers on some hard\\ntest problems. We find that $\\\\Theta$-IPOD is much faster than iteratively\\nreweighted least squares for large data because each iteration costs at most\\n$O(np)$ (and sometimes much less) avoiding an $O(np^2)$ least squares estimate.\\nWe describe the connection between $\\\\Theta$-IPOD and $M$-estimators. Our\\nproposed method has one tuning parameter with which to both identify outliers\\nand estimate regression coefficients. A data-dependent choice can be made based\\non BIC. The tuned $\\\\Theta$-IPOD shows outstanding performance in identifying\\noutliers in various situations in comparison to other existing approaches. This\\nmethodology extends to high-dimensional modeling with $p\\\\gg n$, if both the\\ncoefficient vector and the outlier pattern are sparse.\\n',\n",
              " '  This manuscripts contains the proofs for \"A Primal-Dual Message-Passing\\nAlgorithm for Approximated Large Scale Structured Prediction\".\\n',\n",
              " \"  Over the last decade, kernel methods for nonlinear processing have\\nsuccessfully been used in the machine learning community. The primary\\nmathematical tool employed in these methods is the notion of the Reproducing\\nKernel Hilbert Space. However, so far, the emphasis has been on batch\\ntechniques. It is only recently, that online techniques have been considered in\\nthe context of adaptive signal processing tasks. Moreover, these efforts have\\nonly been focussed on real valued data sequences. To the best of our knowledge,\\nno adaptive kernel-based strategy has been developed, so far, for complex\\nvalued signals. Furthermore, although the real reproducing kernels are used in\\nan increasing number of machine learning problems, complex kernels have not,\\nyet, been used, in spite of their potential interest in applications that deal\\nwith complex signals, with Communications being a typical example. In this\\npaper, we present a general framework to attack the problem of adaptive\\nfiltering of complex signals, using either real reproducing kernels, taking\\nadvantage of a technique called \\\\textit{complexification} of real RKHSs, or\\ncomplex reproducing kernels, highlighting the use of the complex gaussian\\nkernel. In order to derive gradients of operators that need to be defined on\\nthe associated complex RKHSs, we employ the powerful tool of Wirtinger's\\nCalculus, which has recently attracted attention in the signal processing\\ncommunity. To this end, in this paper, the notion of Wirtinger's calculus is\\nextended, for the first time, to include complex RKHSs and use it to derive\\nseveral realizations of the Complex Kernel Least-Mean-Square (CKLMS) algorithm.\\nExperiments verify that the CKLMS offers significant performance improvements\\nover several linear and nonlinear algorithms, when dealing with nonlinearities.\\n\",\n",
              " \"  We study two-player security games which can be viewed as sequences of\\nnonzero-sum matrix games played by an Attacker and a Defender. The evolution of\\nthe game is based on a stochastic fictitious play process, where players do not\\nhave access to each other's payoff matrix. Each has to observe the other's\\nactions up to present and plays the action generated based on the best response\\nto these observations. In a regular fictitious play process, each player makes\\na maximum likelihood estimate of her opponent's mixed strategy, which results\\nin a time-varying update based on the previous estimate and current action. In\\nthis paper, we explore an alternative scheme for frequency update, whose mean\\ndynamic is instead time-invariant. We examine convergence properties of the\\nmean dynamic of the fictitious play process with such an update scheme, and\\nestablish local stability of the equilibrium point when both players are\\nrestricted to two actions. We also propose an adaptive algorithm based on this\\ntime-invariant frequency update.\\n\",\n",
              " '  We present a novel algorithm for segmentation of natural images that\\nharnesses the principle of minimum description length (MDL). Our method is\\nbased on observations that a homogeneously textured region of a natural image\\ncan be well modeled by a Gaussian distribution and the region boundary can be\\neffectively coded by an adaptive chain code. The optimal segmentation of an\\nimage is the one that gives the shortest coding length for encoding all\\ntextures and boundaries in the image, and is obtained via an agglomerative\\nclustering process applied to a hierarchy of decreasing window sizes as\\nmulti-scale texture features. The optimal segmentation also provides an\\naccurate estimate of the overall coding length and hence the true entropy of\\nthe image. We test our algorithm on the publicly available Berkeley\\nSegmentation Dataset. It achieves state-of-the-art segmentation results\\ncompared to other existing methods.\\n',\n",
              " '  For the additive white Gaussian noise channel with average codeword power\\nconstraint, new coding methods are devised in which the codewords are sparse\\nsuperpositions, that is, linear combinations of subsets of vectors from a given\\ndesign, with the possible messages indexed by the choice of subset. Decoding is\\nby least squares, tailored to the assumed form of linear combination.\\nCommunication is shown to be reliable with error probability exponentially\\nsmall for all rates up to the Shannon capacity.\\n',\n",
              " '  For the additive Gaussian noise channel with average codeword power\\nconstraint, sparse superposition codes and adaptive successive decoding is\\ndeveloped. Codewords are linear combinations of subsets of vectors, with the\\nmessage indexed by the choice of subset. A feasible decoding algorithm is\\npresented. Communication is reliable with error probability exponentially small\\nfor all rates below the Shannon capacity.\\n',\n",
              " '  Online learning has become increasingly popular on handling massive data. The\\nsequential nature of online learning, however, requires a centralized learner\\nto store data and update parameters. In this paper, we consider online learning\\nwith {\\\\em distributed} data sources. The autonomous learners update local\\nparameters based on local data sources and periodically exchange information\\nwith a small subset of neighbors in a communication network. We derive the\\nregret bound for strongly convex functions that generalizes the work by Ram et\\nal. (2010) for convex functions. Most importantly, we show that our algorithm\\nhas \\\\emph{intrinsic} privacy-preserving properties, and we prove the sufficient\\nand necessary conditions for privacy preservation in the network. These\\nconditions imply that for networks with greater-than-one connectivity, a\\nmalicious learner cannot reconstruct the subgradients (and sensitive raw data)\\nof other learners, which makes our algorithm appealing in privacy sensitive\\napplications.\\n',\n",
              " '  The past few years have seen a surge of interest in the field of\\nprobabilistic logic learning and statistical relational learning. In this\\nendeavor, many probabilistic logics have been developed. ProbLog is a recent\\nprobabilistic extension of Prolog motivated by the mining of large biological\\nnetworks. In ProbLog, facts can be labeled with probabilities. These facts are\\ntreated as mutually independent random variables that indicate whether these\\nfacts belong to a randomly sampled program. Different kinds of queries can be\\nposed to ProbLog programs. We introduce algorithms that allow the efficient\\nexecution of these queries, discuss their implementation on top of the\\nYAP-Prolog system, and evaluate their performance in the context of large\\nnetworks of biological entities.\\n',\n",
              " '  Feature selection refers to the problem of selecting relevant features which\\nproduce the most predictive outcome. In particular, feature selection task is\\ninvolved in datasets containing huge number of features. Rough set theory has\\nbeen one of the most successful methods used for feature selection. However,\\nthis method is still not able to find optimal subsets. This paper proposes a\\nnew feature selection method based on Rough set theory hybrid with Bee Colony\\nOptimization (BCO) in an attempt to combat this. This proposed work is applied\\nin the medical domain to find the minimal reducts and experimentally compared\\nwith the Quick Reduct, Entropy Based Reduct, and other hybrid Rough Set methods\\nsuch as Genetic Algorithm (GA), Ant Colony Optimization (ACO) and Particle\\nSwarm Optimization (PSO).\\n',\n",
              " \"  This paper studies the MINLIP estimator for the identification of Wiener\\nsystems consisting of a sequence of a linear FIR dynamical model, and a\\nmonotonically increasing (or decreasing) static function. Given $T$\\nobservations, this algorithm boils down to solving a convex quadratic program\\nwith $O(T)$ variables and inequality constraints, implementing an inference\\ntechnique which is based entirely on model complexity control. The resulting\\nestimates of the linear submodel are found to be almost consistent when no\\nnoise is present in the data, under a condition of smoothness of the true\\nnonlinearity and local Persistency of Excitation (local PE) of the data. This\\nresult is novel as it does not rely on classical tools as a 'linearization'\\nusing a Taylor decomposition, nor exploits stochastic properties of the data.\\nIt is indicated how to extend the method to cope with noisy data, and empirical\\nevidence contrasts performance of the estimator against other recently proposed\\ntechniques.\\n\",\n",
              " '  Designing and implementing efficient, provably correct parallel machine\\nlearning (ML) algorithms is challenging. Existing high-level parallel\\nabstractions like MapReduce are insufficiently expressive while low-level tools\\nlike MPI and Pthreads leave ML experts repeatedly solving the same design\\nchallenges. By targeting common patterns in ML, we developed GraphLab, which\\nimproves upon abstractions like MapReduce by compactly expressing asynchronous\\niterative algorithms with sparse computational dependencies while ensuring data\\nconsistency and achieving a high degree of parallel performance. We demonstrate\\nthe expressiveness of the GraphLab framework by designing and implementing\\nparallel versions of belief propagation, Gibbs sampling, Co-EM, Lasso and\\nCompressed Sensing. We show that using GraphLab we can achieve excellent\\nparallel performance on large scale real-world problems.\\n',\n",
              " '  Abc-boost is a new line of boosting algorithms for multi-class\\nclassification, by utilizing the commonly used sum-to-zero constraint. To\\nimplement abc-boost, a base class must be identified at each boosting step.\\nPrior studies used a very expensive procedure based on exhaustive search for\\ndetermining the base class at each boosting step. Good testing performances of\\nabc-boost (implemented as abc-mart and abc-logitboost) on a variety of datasets\\nwere reported.\\n  For large datasets, however, the exhaustive search strategy adopted in prior\\nabc-boost algorithms can be too prohibitive. To overcome this serious\\nlimitation, this paper suggests a heuristic by introducing Gaps when computing\\nthe base class during training. That is, we update the choice of the base class\\nonly for every $G$ boosting steps (i.e., G=1 in prior studies). We test this\\nidea on large datasets (Covertype and Poker) as well as datasets of moderate\\nsizes. Our preliminary results are very encouraging. On the large datasets,\\neven with G=100 (or larger), there is essentially no loss of test accuracy. On\\nthe moderate datasets, no obvious loss of test accuracy is observed when G<=\\n20~50. Therefore, aided by this heuristic, it is promising that abc-boost will\\nbe a practical tool for accurate multi-class classification.\\n',\n",
              " '  Variable selection and dimension reduction are two commonly adopted\\napproaches for high-dimensional data analysis, but have traditionally been\\ntreated separately. Here we propose an integrated approach, called sparse\\ngradient learning (SGL), for variable selection and dimension reduction via\\nlearning the gradients of the prediction function directly from samples. By\\nimposing a sparsity constraint on the gradients, variable selection is achieved\\nby selecting variables corresponding to non-zero partial derivatives, and\\neffective dimensions are extracted based on the eigenvectors of the derived\\nsparse empirical gradient covariance matrix. An error analysis is given for the\\nconvergence of the estimated gradients to the true ones in both the Euclidean\\nand the manifold setting. We also develop an efficient forward-backward\\nsplitting algorithm to solve the SGL problem, making the framework practically\\nscalable for medium or large datasets. The utility of SGL for variable\\nselection and feature extraction is explicitly given and illustrated on\\nartificial data as well as real-world examples. The main advantages of our\\nmethod include variable selection for both linear and nonlinear predictions,\\neffective dimension reduction with sparse loadings, and an efficient algorithm\\nfor large p, small n problems.\\n',\n",
              " '  rdering of regression or classification coefficients occurs in many\\nreal-world applications. Fused Lasso exploits this ordering by explicitly\\nregularizing the differences between neighboring coefficients through an\\n$\\\\ell_1$ norm regularizer. However, due to nonseparability and nonsmoothness of\\nthe regularization term, solving the fused Lasso problem is computationally\\ndemanding. Existing solvers can only deal with problems of small or medium\\nsize, or a special case of the fused Lasso problem in which the predictor\\nmatrix is identity matrix. In this paper, we propose an iterative algorithm\\nbased on split Bregman method to solve a class of large-scale fused Lasso\\nproblems, including a generalized fused Lasso and a fused Lasso support vector\\nclassifier. We derive our algorithm using augmented Lagrangian method and prove\\nits convergence properties. The performance of our method is tested on both\\nartificial data and real-world applications including proteomic data from mass\\nspectrometry and genomic data from array CGH. We demonstrate that our method is\\nmany times faster than the existing solvers, and show that it is especially\\nefficient for large p, small n problems.\\n',\n",
              " \"  In response to a 1997 problem of M. Vidyasagar, we state a necessary and\\nsufficient condition for distribution-free PAC learnability of a concept class\\n$\\\\mathscr C$ under the family of all non-atomic (diffuse) measures on the\\ndomain $\\\\Omega$. Clearly, finiteness of the classical Vapnik-Chervonenkis\\ndimension of $\\\\mathscr C$ is a sufficient, but no longer necessary, condition.\\nBesides, learnability of $\\\\mathscr C$ under non-atomic measures does not imply\\nthe uniform Glivenko-Cantelli property with regard to non-atomic measures. Our\\nlearnability criterion is stated in terms of a combinatorial parameter\\n$\\\\VC({\\\\mathscr C}\\\\,{\\\\mathrm{mod}}\\\\,\\\\omega_1)$ which we call the VC dimension of\\n$\\\\mathscr C$ modulo countable sets. The new parameter is obtained by\\n``thickening up'' single points in the definition of VC dimension to\\nuncountable ``clusters''. Equivalently, $\\\\VC(\\\\mathscr C\\\\modd\\\\omega_1)\\\\leq d$ if\\nand only if every countable subclass of $\\\\mathscr C$ has VC dimension $\\\\leq d$\\noutside a countable subset of $\\\\Omega$. The new parameter can be also expressed\\nas the classical VC dimension of $\\\\mathscr C$ calculated on a suitable subset\\nof a compactification of $\\\\Omega$. We do not make any measurability assumptions\\non $\\\\mathscr C$, assuming instead the validity of Martin's Axiom (MA).\\n\",\n",
              " '  We tackle the problem of multi-class relational sequence learning using\\nrelevant patterns discovered from a set of labelled sequences. To deal with\\nthis problem, firstly each relational sequence is mapped into a feature vector\\nusing the result of a feature construction method. Since, the efficacy of\\nsequence learning algorithms strongly depends on the features used to represent\\nthe sequences, the second step is to find an optimal subset of the constructed\\nfeatures leading to high classification accuracy. This feature selection task\\nhas been solved adopting a wrapper approach that uses a stochastic local search\\nalgorithm embedding a naive Bayes classifier. The performance of the proposed\\nmethod applied to a real-world dataset shows an improvement when compared to\\nother established methods, such as hidden Markov models, Fisher kernels and\\nconditional random fields for relational sequences.\\n',\n",
              " '  Very large databases are required to store massive amounts of data that are\\ncontinuously inserted and queried. Analyzing huge data sets and extracting\\nvaluable pattern in many applications are interesting for researchers. We can\\nidentify two main groups of techniques for huge data bases mining. One group\\nrefers to streaming data and applies mining techniques whereas second group\\nattempts to solve this problem directly with efficient algorithms. Recently\\nmany researchers have focused on data stream as an efficient strategy against\\nhuge data base mining instead of mining on entire data base. The main problem\\nin data stream mining means evolving data is more difficult to detect in this\\ntechniques therefore unsupervised methods should be applied. However,\\nclustering techniques can lead us to discover hidden information. In this\\nsurvey, we try to clarify: first, the different problem definitions related to\\ndata stream clustering in general; second, the specific difficulties\\nencountered in this field of research; third, the varying assumptions,\\nheuristics, and intuitions forming the basis of different approaches; and how\\nseveral prominent solutions tackle different problems. Index Terms- Data\\nStream, Clustering, K-Means, Concept drift\\n',\n",
              " \"  Recommender systems apply data mining techniques and prediction algorithms to\\npredict users' interest on information, products and services among the\\ntremendous amount of available items. The vast growth of information on the\\nInternet as well as number of visitors to websites add some key challenges to\\nrecommender systems. These are: producing accurate recommendation, handling\\nmany recommendations efficiently and coping with the vast growth of number of\\nparticipants in the system. Therefore, new recommender system technologies are\\nneeded that can quickly produce high quality recommendations even for huge data\\nsets.\\n  To address these issues we have explored several collaborative filtering\\ntechniques such as the item based approach, which identify relationship between\\nitems and indirectly compute recommendations for users based on these\\nrelationships. The user based approach was also studied, it identifies\\nrelationships between users of similar tastes and computes recommendations\\nbased on these relationships.\\n  In this paper, we introduce the topic of recommender system. It provides ways\\nto evaluate efficiency, scalability and accuracy of recommender system. The\\npaper also analyzes different algorithms of user based and item based\\ntechniques for recommendation generation. Moreover, a simple experiment was\\nconducted using a data mining application -Weka- to apply data mining\\nalgorithms to recommender system. We conclude by proposing our approach that\\nmight enhance the quality of recommender systems.\\n\",\n",
              " '  We define and study the link prediction problem in bipartite networks,\\nspecializing general link prediction algorithms to the bipartite case. In a\\ngraph, a link prediction function of two vertices denotes the similarity or\\nproximity of the vertices. Common link prediction functions for general graphs\\nare defined using paths of length two between two nodes. Since in a bipartite\\ngraph adjacency vertices can only be connected by paths of odd lengths, these\\nfunctions do not apply to bipartite graphs. Instead, a certain class of graph\\nkernels (spectral transformation kernels) can be generalized to bipartite\\ngraphs when the positive-semidefinite kernel constraint is relaxed. This\\ngeneralization is realized by the odd component of the underlying spectral\\ntransformation. This construction leads to several new link prediction\\npseudokernels such as the matrix hyperbolic sine, which we examine for rating\\ngraphs, authorship graphs, folksonomies, document--feature networks and other\\ntypes of bipartite networks.\\n',\n",
              " '  The two parameter Poisson-Dirichlet Process (PDP), a generalisation of the\\nDirichlet Process, is increasingly being used for probabilistic modelling in\\ndiscrete areas such as language technology, bioinformatics, and image analysis.\\nThere is a rich literature about the PDP and its derivative distributions such\\nas the Chinese Restaurant Process (CRP). This article reviews some of the basic\\ntheory and then the major results needed for Bayesian modelling of discrete\\nproblems including details of priors, posteriors and computation.\\n  The PDP allows one to build distributions over countable partitions. The PDP\\nhas two other remarkable properties: first it is partially conjugate to itself,\\nwhich allows one to build hierarchies of PDPs, and second using a marginalised\\nrelative the CRP, one gets fragmentation and clustering properties that lets\\none layer partitions to build trees. This article presents the basic theory for\\nunderstanding the notion of partitions and distributions over them, the PDP and\\nthe CRP, and the important properties of conjugacy, fragmentation and\\nclustering, as well as some key related properties such as consistency and\\nconvergence. This article also presents a Bayesian interpretation of the\\nPoisson-Dirichlet process based on an improper and infinite dimensional\\nDirichlet distribution. This means we can understand the process as just\\nanother Dirichlet and thus all its sampling properties emerge naturally.\\n  The theory of PDPs is usually presented for continuous distributions (more\\ngenerally referred to as non-atomic distributions), however, when applied to\\ndiscrete distributions its remarkable conjugacy property emerges. This context\\nand basic results are also presented, as well as techniques for computing the\\nsecond order Stirling numbers that occur in the posteriors for discrete\\ndistributions.\\n',\n",
              " '  Non-negative matrix factorization (NMF) has previously been shown to be a\\nuseful decomposition for multivariate data. We interpret the factorization in a\\nnew way and use it to generate missing attributes from test data. We provide a\\njoint optimization scheme for the missing attributes as well as the NMF\\nfactors. We prove the monotonic convergence of our algorithms. We present\\nclassification results for cases with missing attributes.\\n',\n",
              " '  A new message-passing (MP) method is considered for the matrix completion\\nproblem associated with recommender systems. We attack the problem using a\\n(generative) factor graph model that is related to a probabilistic low-rank\\nmatrix factorization. Based on the model, we propose a new algorithm, termed\\nIMP, for the recovery of a data matrix from incomplete observations. The\\nalgorithm is based on a clustering followed by inference via MP (IMP). The\\nalgorithm is compared with a number of other matrix completion algorithms on\\nreal collaborative filtering (e.g., Netflix) data matrices. Our results show\\nthat, while many methods perform similarly with a large number of revealed\\nentries, the IMP algorithm outperforms all others when the fraction of observed\\nentries is small. This is helpful because it reduces the well-known cold-start\\nproblem associated with collaborative filtering (CF) systems in practice.\\n',\n",
              " \"  Classifiers are often used to detect miscreant activities. We study how an\\nadversary can systematically query a classifier to elicit information that\\nallows the adversary to evade detection while incurring a near-minimal cost of\\nmodifying their intended malfeasance. We generalize the theory of Lowd and Meek\\n(2005) to the family of convex-inducing classifiers that partition input space\\ninto two sets one of which is convex. We present query algorithms for this\\nfamily that construct undetected instances of approximately minimal cost using\\nonly polynomially-many queries in the dimension of the space and in the level\\nof approximation. Our results demonstrate that near-optimal evasion can be\\naccomplished without reverse-engineering the classifier's decision boundary. We\\nalso consider general lp costs and show that near-optimal evasion on the family\\nof convex-inducing classifiers is generally efficient for both positive and\\nnegative convexity for all levels of approximation if p=1.\\n\",\n",
              " '  Although the Music Sight Reading process has been studied from the cognitive\\npsychology view points, but the computational learning methods like the\\nReinforcement Learning have not yet been used to modeling of such processes. In\\nthis paper, with regards to essential properties of our specific problem, we\\nconsider the value function concept and will indicate that the optimum policy\\ncan be obtained by the method we offer without to be getting involved with\\ncomputing of the complex value functions. Also, we will offer a normative\\nbehavioral model for the interaction of the agent with the musical pitch\\nenvironment and by using a slightly different version of Partially observable\\nMarkov decision processes we will show that our method helps for faster\\nlearning of state-action pairs in our implemented agents.\\n',\n",
              " '  Music Sight Reading is a complex process in which when it is occurred in the\\nbrain some learning attributes would be emerged. Besides giving a model based\\non actor-critic method in the Reinforcement Learning, the agent is considered\\nto have a neural network structure. We studied on where the sight reading\\nprocess is happened and also a serious problem which is how the synaptic\\nweights would be adjusted through the learning process. The model we offer here\\nis a computational model on which an updated weights equation to fix the\\nweights is accompanied too.\\n',\n",
              " '  We find the minimax rate of convergence in Hausdorff distance for estimating\\na manifold M of dimension d embedded in R^D given a noisy sample from the\\nmanifold. We assume that the manifold satisfies a smoothness condition and that\\nthe noise distribution has compact support. We show that the optimal rate of\\nconvergence is n^{-2/(2+d)}. Thus, the minimax rate depends only on the\\ndimension of the manifold, not on the dimension of the space in which M is\\nembedded.\\n',\n",
              " '  We present a new latent-variable model employing a Gaussian mixture\\nintegrated with a feature selection procedure (the Bernoulli part of the model)\\nwhich together form a \"Latent Bernoulli-Gauss\" distribution. The model is\\napplied to MAP estimation, clustering, feature selection and collaborative\\nfiltering and fares favorably with the state-of-the-art latent-variable models.\\n',\n",
              " '  We address in this paper the problem of multi-channel signal sequence\\nlabeling. In particular, we consider the problem where the signals are\\ncontaminated by noise or may present some dephasing with respect to their\\nlabels. For that, we propose to jointly learn a SVM sample classifier with a\\ntemporal filtering of the channels. This will lead to a large margin filtering\\nthat is adapted to the specificity of each channel (noise and time-lag). We\\nderive algorithms to solve the optimization problem and we discuss different\\nfilter regularizations for automated scaling or selection of channels. Our\\napproach is tested on a non-linear toy example and on a BCI dataset. Results\\nshow that the classification performance on these problems can be improved by\\nlearning a large margin filtering.\\n',\n",
              " \"  We show that the learning sample complexity of a sigmoidal neural network\\nconstructed by Sontag (1992) required to achieve a given misclassification\\nerror under a fixed purely atomic distribution can grow arbitrarily fast: for\\nany prescribed rate of growth there is an input distribution having this rate\\nas the sample complexity, and the bound is asymptotically tight. The rate can\\nbe superexponential, a non-recursive function, etc. We further observe that\\nSontag's ANN is not Glivenko-Cantelli under any input distribution having a\\nnon-atomic part.\\n\",\n",
              " '  This paper introduces a principled approach for the design of a scalable\\ngeneral reinforcement learning agent. This approach is based on a direct\\napproximation of AIXI, a Bayesian optimality notion for general reinforcement\\nlearning agents. Previously, it has been unclear whether the theory of AIXI\\ncould motivate the design of practical algorithms. We answer this hitherto open\\nquestion in the affirmative, by providing the first computationally feasible\\napproximation to the AIXI agent. To develop our approximation, we introduce a\\nMonte Carlo Tree Search algorithm along with an agent-specific extension of the\\nContext Tree Weighting algorithm. Empirically, we present a set of encouraging\\nresults on a number of stochastic, unknown, and partially observable domains.\\n',\n",
              " '  We are studying long term sequence prediction (forecasting). We approach this\\nby investigating criteria for choosing a compact useful state representation.\\nThe state is supposed to summarize useful information from the history. We want\\na method that is asymptotically consistent in the sense it will provably\\neventually only choose between alternatives that satisfy an optimality property\\nrelated to the used criterion. We extend our work to the case where there is\\nside information that one can take advantage of and, furthermore, we briefly\\ndiscuss the active setting where an agent takes actions to achieve desirable\\noutcomes.\\n',\n",
              " \"  We consider the classical multi-armed bandit problem with Markovian rewards.\\nWhen played an arm changes its state in a Markovian fashion while it remains\\nfrozen when not played. The player receives a state-dependent reward each time\\nit plays an arm. The number of states and the state transition probabilities of\\nan arm are unknown to the player. The player's objective is to maximize its\\nlong-term total reward by learning the best arm over time. We show that under\\ncertain conditions on the state transition probabilities of the arms, a sample\\nmean based index policy achieves logarithmic regret uniformly over the total\\nnumber of trials. The result shows that sample mean based index policies can be\\napplied to learning problems under the rested Markovian bandit model without\\nloss of optimality in the order. Moreover, comparision between Anantharam's\\nindex policy and UCB shows that by choosing a small exploration parameter UCB\\ncan have a smaller regret than Anantharam's index policy.\\n\",\n",
              " '  Causality is a non-obvious concept that is often considered to be related to\\ntemporality. In this paper we present a number of past and present approaches\\nto the definition of temporality and causality from philosophical, physical,\\nand computational points of view. We note that time is an important ingredient\\nin many relationships and phenomena. The topic is then divided into the two\\nmain areas of temporal discovery, which is concerned with finding relations\\nthat are stretched over time, and causal discovery, where a claim is made as to\\nthe causal influence of certain events on others. We present a number of\\ncomputational tools used for attempting to automatically discover temporal and\\ncausal relations in data.\\n',\n",
              " '  Recovering the 3D structure of the scene from images yields useful\\ninformation for tasks such as shape and scene recognition, object detection, or\\nmotion planning and object grasping in robotics. In this thesis, we introduce a\\ngeneral machine learning approach called unsupervised CRF learning based on\\nmaximizing the conditional likelihood. We apply our approach to computer vision\\nsystems that recover the 3-D scene geometry from images. We focus on recovering\\n3D geometry from single images, stereo pairs and video sequences. Building\\nthese systems requires algorithms for doing inference as well as learning the\\nparameters of conditional Markov random fields (MRF). Our system is trained\\nunsupervisedly without using ground-truth labeled data. We employ a\\nslanted-plane stereo vision model in which we use a fixed over-segmentation to\\nsegment the left image into coherent regions called superpixels, then assign a\\ndisparity plane for each superpixel. Plane parameters are estimated by solving\\nan MRF labelling problem, through minimizing an energy fuction. We demonstrate\\nthe use of our unsupervised CRF learning algorithm for a parameterized\\nslanted-plane stereo vision model involving shape from texture cues. Our stereo\\nmodel with texture cues, only by unsupervised training, outperforms the results\\nin related work on the same stereo dataset. In this thesis, we also formulate\\nstructure and motion estimation as an energy minimization problem, in which the\\nmodel is an extension of our slanted-plane stereo vision model that also\\nhandles surface velocity. Velocity estimation is achieved by solving an MRF\\nlabeling problem using Loopy BP. Performance analysis is done using our novel\\nevaluation metrics based on the notion of view prediction error. Experiments on\\nroad-driving stereo sequences show encouraging results.\\n',\n",
              " '  It is difficult to find the optimal sparse solution of a manifold learning\\nbased dimensionality reduction algorithm. The lasso or the elastic net\\npenalized manifold learning based dimensionality reduction is not directly a\\nlasso penalized least square problem and thus the least angle regression (LARS)\\n(Efron et al. \\\\cite{LARS}), one of the most popular algorithms in sparse\\nlearning, cannot be applied. Therefore, most current approaches take indirect\\nways or have strict settings, which can be inconvenient for applications. In\\nthis paper, we proposed the manifold elastic net or MEN for short. MEN\\nincorporates the merits of both the manifold learning based dimensionality\\nreduction and the sparse learning based dimensionality reduction. By using a\\nseries of equivalent transformations, we show MEN is equivalent to the lasso\\npenalized least square problem and thus LARS is adopted to obtain the optimal\\nsparse solution of MEN. In particular, MEN has the following advantages for\\nsubsequent classification: 1) the local geometry of samples is well preserved\\nfor low dimensional data representation, 2) both the margin maximization and\\nthe classification error minimization are considered for sparse projection\\ncalculation, 3) the projection matrix of MEN improves the parsimony in\\ncomputation, 4) the elastic net penalty reduces the over-fitting problem, and\\n5) the projection matrix of MEN can be interpreted psychologically and\\nphysiologically. Experimental evidence on face recognition over various popular\\ndatasets suggests that MEN is superior to top level dimensionality reduction\\nalgorithms.\\n',\n",
              " '  Motivated by the unceasing interest in hidden Markov models (HMMs), this\\npaper re-examines hidden path inference in these models, using primarily a\\nrisk-based framework. While the most common maximum a posteriori (MAP), or\\nViterbi, path estimator and the minimum error, or Posterior Decoder (PD), have\\nlong been around, other path estimators, or decoders, have been either only\\nhinted at or applied more recently and in dedicated applications generally\\nunfamiliar to the statistical learning community. Over a decade ago, however, a\\nfamily of algorithmically defined decoders aiming to hybridize the two standard\\nones was proposed (Brushe et al., 1998). The present paper gives a careful\\nanalysis of this hybridization approach, identifies several problems and issues\\nwith it and other previously proposed approaches, and proposes practical\\nresolutions of those. Furthermore, simple modifications of the classical\\ncriteria for hidden path recognition are shown to lead to a new class of\\ndecoders. Dynamic programming algorithms to compute these decoders in the usual\\nforward-backward manner are presented. A particularly interesting subclass of\\nsuch estimators can be also viewed as hybrids of the MAP and PD estimators.\\nSimilar to previously proposed MAP-PD hybrids, the new class is parameterized\\nby a small number of tunable parameters. Unlike their algorithmic predecessors,\\nthe new risk-based decoders are more clearly interpretable, and, most\\nimportantly, work \"out of the box\" in practice, which is demonstrated on some\\nreal bioinformatics tasks and data. Some further generalizations and\\napplications are discussed in conclusion.\\n',\n",
              " \"  Search engines today present results that are often oblivious to abrupt\\nshifts in intent. For example, the query `independence day' usually refers to a\\nUS holiday, but the intent of this query abruptly changed during the release of\\na major film by that name. While no studies exactly quantify the magnitude of\\nintent-shifting traffic, studies suggest that news events, seasonal topics, pop\\nculture, etc account for 50% of all search queries. This paper shows that the\\nsignals a search engine receives can be used to both determine that a shift in\\nintent has happened, as well as find a result that is now more relevant. We\\npresent a meta-algorithm that marries a classifier with a bandit algorithm to\\nachieve regret that depends logarithmically on the number of query impressions,\\nunder certain assumptions. We provide strong evidence that this regret is close\\nto the best achievable. Finally, via a series of experiments, we demonstrate\\nthat our algorithm outperforms prior approaches, particularly as the amount of\\nintent-shifting traffic increases.\\n\",\n",
              " '  PRISM is an extension of Prolog with probabilistic predicates and built-in\\nsupport for expectation-maximization learning. Constraint Handling Rules (CHR)\\nis a high-level programming language based on multi-headed multiset rewrite\\nrules.\\n  In this paper, we introduce a new probabilistic logic formalism, called\\nCHRiSM, based on a combination of CHR and PRISM. It can be used for high-level\\nrapid prototyping of complex statistical models by means of \"chance rules\". The\\nunderlying PRISM system can then be used for several probabilistic inference\\ntasks, including probability computation and parameter learning. We define the\\nCHRiSM language in terms of syntax and operational semantics, and illustrate it\\nwith examples. We define the notion of ambiguous programs and define a\\ndistribution semantics for unambiguous programs. Next, we describe an\\nimplementation of CHRiSM, based on CHR(PRISM). We discuss the relation between\\nCHRiSM and other probabilistic logic programming languages, in particular PCHR.\\nFinally we identify potential application domains.\\n',\n",
              " '  Recently, applying the novel data mining techniques for evaluating enterprise\\nfinancial distress has received much research alternation. Support Vector\\nMachine (SVM) and back propagation neural (BPN) network has been applied\\nsuccessfully in many areas with excellent generalization results, such as rule\\nextraction, classification and evaluation. In this paper, a model based on SVM\\nwith Gaussian RBF kernel is proposed here for enterprise financial distress\\nevaluation. BPN network is considered one of the simplest and are most general\\nmethods used for supervised training of multilayered neural network. The\\ncomparative results show that through the difference between the performance\\nmeasures is marginal; SVM gives higher precision and lower error rates.\\n',\n",
              " '  Most image-search approaches today are based on the text based tags\\nassociated with the images which are mostly human generated and are subject to\\nvarious kinds of errors. The results of a query to the image database thus can\\noften be misleading and may not satisfy the requirements of the user. In this\\nwork we propose our approach to automate this tagging process of images, where\\nimage results generated can be fine filtered based on a probabilistic tagging\\nmechanism. We implement a tool which helps to automate the tagging process by\\nmaintaining a training database, wherein the system is trained to identify\\ncertain set of input images, the results generated from which are used to\\ncreate a probabilistic tagging mechanism. Given a certain set of segments in an\\nimage it calculates the probability of presence of particular keywords. This\\nprobability table is further used to generate the candidate tags for input\\nimages.\\n',\n",
              " '  We present a framework for discriminative sequence classification where the\\nlearner works directly in the high dimensional predictor space of all\\nsubsequences in the training set. This is possible by employing a new\\ncoordinate-descent algorithm coupled with bounding the magnitude of the\\ngradient for selecting discriminative subsequences fast. We characterize the\\nloss functions for which our generic learning algorithm can be applied and\\npresent concrete implementations for logistic regression (binomial\\nlog-likelihood loss) and support vector machines (squared hinge loss).\\nApplication of our algorithm to protein remote homology detection and remote\\nfold recognition results in performance comparable to that of state-of-the-art\\nmethods (e.g., kernel support vector machines). Unlike state-of-the-art\\nclassifiers, the resulting classification models are simply lists of weighted\\ndiscriminative subsequences and can thus be interpreted and related to the\\nbiological problem.\\n',\n",
              " '  We present three generalisations of Kernel Principal Components Analysis\\n(KPCA) which incorporate knowledge of the class labels of a subset of the data\\npoints. The first, MV-KPCA, penalises within class variances similar to Fisher\\ndiscriminant analysis. The second, LSKPCA is a hybrid of least squares\\nregression and kernel PCA. The final LR-KPCA is an iteratively reweighted\\nversion of the previous which achieves a sigmoid loss function on the labeled\\npoints. We provide a theoretical risk bound as well as illustrative experiments\\non real and toy data sets.\\n',\n",
              " '  The standard training method of Conditional Random Fields (CRFs) is very slow\\nfor large-scale applications. As an alternative, piecewise training divides the\\nfull graph into pieces, trains them independently, and combines the learned\\nweights at test time. In this paper, we present \\\\emph{separate} training for\\nundirected models based on the novel Co-occurrence Rate Factorization (CR-F).\\nSeparate training is a local training method. In contrast to MEMMs, separate\\ntraining is unaffected by the label bias problem. Experiments show that\\nseparate training (i) is unaffected by the label bias problem; (ii) reduces the\\ntraining time from weeks to seconds; and (iii) obtains competitive results to\\nthe standard and piecewise training on linear-chain CRFs.\\n',\n",
              " '  A learning algorithm based on primary school teaching and learning is\\npresented. The methodology is to continuously evaluate a student and to give\\nthem training on the examples for which they repeatedly fail, until, they can\\ncorrectly answer all types of questions. This incremental learning procedure\\nproduces better learning curves by demanding the student to optimally dedicate\\ntheir learning time on the failed examples. When used in machine learning, the\\nalgorithm is found to train a machine on a data with maximum variance in the\\nfeature space so that the generalization ability of the network improves. The\\nalgorithm has interesting applications in data mining, model evaluations and\\nrare objects discovery.\\n',\n",
              " '  Submodular functions are discrete functions that model laws of diminishing\\nreturns and enjoy numerous algorithmic applications. They have been used in\\nmany areas, including combinatorial optimization, machine learning, and\\neconomics. In this work we study submodular functions from a learning theoretic\\nangle. We provide algorithms for learning submodular functions, as well as\\nlower bounds on their learnability. In doing so, we uncover several novel\\nstructural results revealing ways in which submodular functions can be both\\nsurprisingly structured and surprisingly unstructured. We provide several\\nconcrete implications of our work in other domains including algorithmic game\\ntheory and combinatorial optimization.\\n  At a technical level, this research combines ideas from many areas, including\\nlearning theory (distributional learning and PAC-style analyses), combinatorics\\nand optimization (matroids and submodular functions), and pseudorandomness\\n(lossless expander graphs).\\n',\n",
              " '  Let us assume that $f$ is a continuous function defined on the unit ball of\\n$\\\\mathbb R^d$, of the form $f(x) = g (A x)$, where $A$ is a $k \\\\times d$ matrix\\nand $g$ is a function of $k$ variables for $k \\\\ll d$. We are given a budget $m\\n\\\\in \\\\mathbb N$ of possible point evaluations $f(x_i)$, $i=1,...,m$, of $f$,\\nwhich we are allowed to query in order to construct a uniform approximating\\nfunction. Under certain smoothness and variation assumptions on the function\\n$g$, and an {\\\\it arbitrary} choice of the matrix $A$, we present in this paper\\n  1. a sampling choice of the points $\\\\{x_i\\\\}$ drawn at random for each\\nfunction approximation;\\n  2. algorithms (Algorithm 1 and Algorithm 2) for computing the approximating\\nfunction, whose complexity is at most polynomial in the dimension $d$ and in\\nthe number $m$ of points.\\n  Due to the arbitrariness of $A$, the choice of the sampling points will be\\naccording to suitable random distributions and our results hold with\\noverwhelming probability. Our approach uses tools taken from the {\\\\it\\ncompressed sensing} framework, recent Chernoff bounds for sums of\\npositive-semidefinite matrices, and classical stability bounds for invariant\\nsubspaces of singular value decompositions.\\n',\n",
              " '  We give a deterministic, polynomial-time algorithm for approximately counting\\nthe number of {0,1}-solutions to any instance of the knapsack problem. On an\\ninstance of length n with total weight W and accuracy parameter eps, our\\nalgorithm produces a (1 + eps)-multiplicative approximation in time poly(n,log\\nW,1/eps). We also give algorithms with identical guarantees for general integer\\nknapsack, the multidimensional knapsack problem (with a constant number of\\nconstraints) and for contingency tables (with a constant number of rows).\\nPreviously, only randomized approximation schemes were known for these problems\\ndue to work by Morris and Sinclair and work by Dyer.\\n  Our algorithms work by constructing small-width, read-once branching programs\\nfor approximating the underlying solution space under a carefully chosen\\ndistribution. As a byproduct of this approach, we obtain new query algorithms\\nfor learning functions of k halfspaces with respect to the uniform distribution\\non {0,1}^n. The running time of our algorithm is polynomial in the accuracy\\nparameter eps. Previously even for the case of k=2, only algorithms with an\\nexponential dependence on eps were known.\\n',\n",
              " '  Following a review of metric, ultrametric and generalized ultrametric, we\\nreview their application in data analysis. We show how they allow us to explore\\nboth geometry and topology of information, starting with measured data. Some\\nthemes are then developed based on the use of metric, ultrametric and\\ngeneralized ultrametric in logic. In particular we study approximation chains\\nin an ultrametric or generalized ultrametric context. Our aim in this work is\\nto extend the scope of data analysis by facilitating reasoning based on the\\ndata analysis; and to show how quantitative and qualitative data analysis can\\nbe incorporated into logic programming.\\n',\n",
              " \"  The typical behavior of optimal solutions to portfolio optimization problems\\nwith absolute deviation and expected shortfall models using replica analysis\\nwas pioneeringly estimated by S. Ciliberti and M. M\\\\'ezard [Eur. Phys. B. 57,\\n175 (2007)]; however, they have not yet developed an approximate derivation\\nmethod for finding the optimal portfolio with respect to a given return set. In\\nthis study, an approximation algorithm based on belief propagation for the\\nportfolio optimization problem is presented using the Bethe free energy\\nformalism, and the consistency of the numerical experimental results of the\\nproposed algorithm with those of replica analysis is confirmed. Furthermore,\\nthe conjecture of H. Konno and H. Yamazaki, that the optimal solutions with the\\nabsolute deviation model and with the mean-variance model have the same typical\\nbehavior, is verified using replica analysis and the belief propagation\\nalgorithm.\\n\",\n",
              " \"  In this paper we analyze judgement aggregation problems in which a group of\\nagents independently votes on a set of complex propositions that has some\\ninterdependency constraint between them(e.g., transitivity when describing\\npreferences). We consider the issue of judgement aggregation from the\\nperspective of approximation. That is, we generalize the previous results by\\nstudying approximate judgement aggregation. We relax the main two constraints\\nassumed in the current literature, Consistency and Independence and consider\\nmechanisms that only approximately satisfy these constraints, that is, satisfy\\nthem up to a small portion of the inputs. The main question we raise is whether\\nthe relaxation of these notions significantly alters the class of satisfying\\naggregation mechanisms. The recent works for preference aggregation of Kalai,\\nMossel, and Keller fit into this framework. The main result of this paper is\\nthat, as in the case of preference aggregation, in the case of a subclass of a\\nnatural class of aggregation problems termed `truth-functional agendas', the\\nset of satisfying aggregation mechanisms does not extend non-trivially when\\nrelaxing the constraints. Our proof techniques involve Boolean Fourier\\ntransform and analysis of voter influences for voting protocols. The question\\nwe raise for Approximate Aggregation can be stated in terms of Property\\nTesting. For instance, as a corollary from our result we get a generalization\\nof the classic result for property testing of linearity of Boolean functions.\\n  An updated version (RePEc:huj:dispap:dp574R) is available at\\nhttp://www.ratio.huji.ac.il/dp_files/dp574R.pdf\\n\",\n",
              " '  Support vector machines (SVMs) are invaluable tools for many practical\\napplications in artificial intelligence, e.g., classification and event\\nrecognition. However, popular SVM solvers are not sufficiently efficient for\\napplications with a great deal of samples as well as a large number of\\nfeatures. In this paper, thus, we present NESVM, a fast gradient SVM solver\\nthat can optimize various SVM models, e.g., classical SVM, linear programming\\nSVM and least square SVM. Compared against SVM-Perf\\n\\\\cite{SVM_Perf}\\\\cite{PerfML} (its convergence rate in solving the dual SVM is\\nupper bounded by $\\\\mathcal O(1/\\\\sqrt{k})$, wherein $k$ is the number of\\niterations.) and Pegasos \\\\cite{Pegasos} (online SVM that converges at rate\\n$\\\\mathcal O(1/k)$ for the primal SVM), NESVM achieves the optimal convergence\\nrate at $\\\\mathcal O(1/k^{2})$ and a linear time complexity. In particular,\\nNESVM smoothes the non-differentiable hinge loss and $\\\\ell_1$-norm in the\\nprimal SVM. Then the optimal gradient method without any line search is adopted\\nto solve the optimization. In each iteration round, the current gradient and\\nhistorical gradients are combined to determine the descent direction, while the\\nLipschitz constant determines the step size. Only two matrix-vector\\nmultiplications are required in each iteration round. Therefore, NESVM is more\\nefficient than existing SVM solvers. In addition, NESVM is available for both\\nlinear and nonlinear kernels. We also propose \"homotopy NESVM\" to accelerate\\nNESVM by dynamically decreasing the smooth parameter and using the continuation\\nmethod. Our experiments on census income categorization, indoor/outdoor scene\\nclassification, event recognition and scene recognition suggest the efficiency\\nand the effectiveness of NESVM. The MATLAB code of NESVM will be available on\\nour website for further assessment.\\n',\n",
              " '  Sparse methods for supervised learning aim at finding good linear predictors\\nfrom as few variables as possible, i.e., with small cardinality of their\\nsupports. This combinatorial selection problem is often turned into a convex\\noptimization problem by replacing the cardinality function by its convex\\nenvelope (tightest convex lower bound), in this case the L1-norm. In this\\npaper, we investigate more general set-functions than the cardinality, that may\\nincorporate prior knowledge or structural constraints which are common in many\\napplications: namely, we show that for nondecreasing submodular set-functions,\\nthe corresponding convex envelope can be obtained from its \\\\lova extension, a\\ncommon tool in submodular analysis. This defines a family of polyhedral norms,\\nfor which we provide generic algorithmic tools (subgradients and proximal\\noperators) and theoretical results (conditions for support recovery or\\nhigh-dimensional inference). By selecting specific submodular functions, we can\\ngive a new interpretation to known norms, such as those based on\\nrank-statistics or grouped norms with potentially overlapping groups; we also\\ndefine new norms, in particular ones that can be used as non-factorial priors\\nfor supervised learning.\\n',\n",
              " '  In this paper the sequential prediction problem with expert advice is\\nconsidered for the case where losses of experts suffered at each step cannot be\\nbounded in advance. We present some modification of Kalai and Vempala algorithm\\nof following the perturbed leader where weights depend on past losses of the\\nexperts. New notions of a volume and a scaled fluctuation of a game are\\nintroduced. We present a probabilistic algorithm protected from unrestrictedly\\nlarge one-step losses. This algorithm has the optimal performance in the case\\nwhen the scaled fluctuations of one-step losses of experts of the pool tend to\\nzero.\\n',\n",
              " \"  In this paper, we propose a systematic solution to the problem of scheduling\\ndelay-sensitive media data for transmission over time-varying wireless\\nchannels. We first formulate the dynamic scheduling problem as a Markov\\ndecision process (MDP) that explicitly considers the users' heterogeneous\\nmultimedia data characteristics (e.g. delay deadlines, distortion impacts and\\ndependencies etc.) and time-varying channel conditions, which are not\\nsimultaneously considered in state-of-the-art packet scheduling algorithms.\\nThis formulation allows us to perform foresighted decisions to schedule\\nmultiple data units for transmission at each time in order to optimize the\\nlong-term utilities of the multimedia applications. The heterogeneity of the\\nmedia data enables us to express the transmission priorities between the\\ndifferent data units as a priority graph, which is a directed acyclic graph\\n(DAG). This priority graph provides us with an elegant structure to decompose\\nthe multi-data unit foresighted decision at each time into multiple single-data\\nunit foresighted decisions which can be performed sequentially, from the high\\npriority data units to the low priority data units, thereby significantly\\nreducing the computation complexity. When the statistical knowledge of the\\nmultimedia data characteristics and channel conditions is unknown a priori, we\\ndevelop a low-complexity online learning algorithm to update the value\\nfunctions which capture the impact of the current decision on the future\\nutility. The simulation results show that the proposed solution significantly\\noutperforms existing state-of-the-art scheduling solutions.\\n\",\n",
              " '  In prediction with expert advice the goal is to design online prediction\\nalgorithms that achieve small regret (additional loss on the whole data)\\ncompared to a reference scheme. In the simplest such scheme one compares to the\\nloss of the best expert in hindsight. A more ambitious goal is to split the\\ndata into segments and compare to the best expert on each segment. This is\\nappropriate if the nature of the data changes between segments. The standard\\nfixed-share algorithm is fast and achieves small regret compared to this\\nscheme.\\n  Fixed share treats the experts as black boxes: there are no assumptions about\\nhow they generate their predictions. But if the experts are learning, the\\nfollowing question arises: should the experts learn from all data or only from\\ndata in their own segment? The original algorithm naturally addresses the first\\ncase. Here we consider the second option, which is more appropriate exactly\\nwhen the nature of the data changes between segments. In general extending\\nfixed share to this second case will slow it down by a factor of T on T\\noutcomes. We show, however, that no such slowdown is necessary if the experts\\nare hidden Markov models.\\n',\n",
              " \"  A problem posed by Freund is how to efficiently track a small pool of experts\\nout of a much larger set. This problem was solved when Bousquet and Warmuth\\nintroduced their mixing past posteriors (MPP) algorithm in 2001.\\n  In Freund's problem the experts would normally be considered black boxes.\\nHowever, in this paper we re-examine Freund's problem in case the experts have\\ninternal structure that enables them to learn. In this case the problem has two\\npossible interpretations: should the experts learn from all data or only from\\nthe subsequence on which they are being tracked? The MPP algorithm solves the\\nfirst case. Our contribution is to generalise MPP to address the second option.\\nThe results we obtain apply to any expert structure that can be formalised\\nusing (expert) hidden Markov models. Curiously enough, for our interpretation\\nthere are \\\\emph{two} natural reference schemes: freezing and sleeping. For each\\nscheme, we provide an efficient prediction strategy and prove the relevant loss\\nbound.\\n\",\n",
              " '  In this paper, we have proposed an architecture of active learning SVMs with\\nrelevance feedback (RF)for classifying e-mail. This architecture combines both\\nactive learning strategies where instead of using a randomly selected training\\nset, the learner has access to a pool of unlabeled instances and can request\\nthe labels of some number of them and relevance feedback where if any mail\\nmisclassified then the next set of support vectors will be different from the\\npresent set otherwise the next set will not change. Our proposed architecture\\nwill ensure that a legitimate e-mail will not be dropped in the event of\\noverflowing mailbox. The proposed architecture also exhibits dynamic updating\\ncharacteristics making life as difficult for the spammer as possible.\\n',\n",
              " \"  The scientific method relies on the iterated processes of inference and\\ninquiry. The inference phase consists of selecting the most probable models\\nbased on the available data; whereas the inquiry phase consists of using what\\nis known about the models to select the most relevant experiment. Optimizing\\ninquiry involves searching the parameterized space of experiments to select the\\nexperiment that promises, on average, to be maximally informative. In the case\\nwhere it is important to learn about each of the model parameters, the\\nrelevance of an experiment is quantified by Shannon entropy of the distribution\\nof experimental outcomes predicted by a probable set of models. If the set of\\npotential experiments is described by many parameters, we must search this\\nhigh-dimensional entropy space. Brute force search methods will be slow and\\ncomputationally expensive. We present an entropy-based search algorithm, called\\nnested entropy sampling, to select the most informative experiment for\\nefficient experimental design. This algorithm is inspired by Skilling's nested\\nsampling algorithm used in inference and borrows the concept of a rising\\nthreshold while a set of experiment samples are maintained. We demonstrate that\\nthis algorithm not only selects highly relevant experiments, but also is more\\nefficient than brute force search. Such entropic search techniques promise to\\ngreatly benefit autonomous experimental design.\\n\",\n",
              " '  It is well known that text compression can be achieved by predicting the next\\nsymbol in the stream of text data based on the history seen up to the current\\nsymbol. The better the prediction the more skewed the conditional probability\\ndistribution of the next symbol and the shorter the codeword that needs to be\\nassigned to represent this next symbol. What about the opposite direction ?\\nsuppose we have a black box that can compress text stream. Can it be used to\\npredict the next symbol in the stream ? We introduce a criterion based on the\\nlength of the compressed data and use it to predict the next symbol. We examine\\nempirically the prediction error rate and its dependency on some compression\\nparameters.\\n',\n",
              " '  In this paper, we study two general classes of optimization algorithms for\\nkernel methods with convex loss function and quadratic norm regularization, and\\nanalyze their convergence. The first approach, based on fixed-point iterations,\\nis simple to implement and analyze, and can be easily parallelized. The second,\\nbased on coordinate descent, exploits the structure of additively separable\\nloss functions to compute solutions of line searches in closed form. Instances\\nof these general classes of algorithms are already incorporated into state of\\nthe art machine learning software for large scale problems. We start from a\\nsolution characterization of the regularized problem, obtained using\\nsub-differential calculus and resolvents of monotone operators, that holds for\\ngeneral convex loss functions regardless of differentiability. The two\\nmethodologies described in the paper can be regarded as instances of non-linear\\nJacobi and Gauss-Seidel algorithms, and are both well-suited to solve large\\nscale problems.\\n',\n",
              " '  Degrading performance of indexing schemes for exact similarity search in high\\ndimensions has long since been linked to histograms of distributions of\\ndistances and other 1-Lipschitz functions getting concentrated. We discuss this\\nobservation in the framework of the phenomenon of concentration of measure on\\nthe structures of high dimension and the Vapnik-Chervonenkis theory of\\nstatistical learning.\\n',\n",
              " '  Ink Drop Spread (IDS) is the engine of Active Learning Method (ALM), which is\\nthe methodology of soft computing. IDS, as a pattern-based processing unit,\\nextracts useful information from a system subjected to modeling. In spite of\\nits excellent potential in solving problems such as classification and modeling\\ncompared to other soft computing tools, finding its simple and fast hardware\\nimplementation is still a challenge. This paper describes a new hardware\\nimplementation of IDS method based on the memristor crossbar structure. In\\naddition of simplicity, being completely real-time, having low latency and the\\nability to continue working after the occurrence of power breakdown are some of\\nthe advantages of our proposed circuit.\\n',\n",
              " '  We consider the unconstrained optimization problem whose objective function\\nis composed of a smooth and a non-smooth conponents where the smooth component\\nis the expectation a random function. This type of problem arises in some\\ninteresting applications in machine learning. We propose a stochastic gradient\\ndescent algorithm for this class of optimization problem. When the non-smooth\\ncomponent has a particular structure, we propose another stochastic gradient\\ndescent algorithm by incorporating a smoothing method into our first algorithm.\\nThe proofs of the convergence rates of these two algorithms are given and we\\nshow the numerical performance of our algorithm by applying them to regularized\\nlinear regression problems with different sets of synthetic data.\\n',\n",
              " '  We consider a class of learning problems that involve a structured\\nsparsity-inducing norm defined as the sum of $\\\\ell_\\\\infty$-norms over groups of\\nvariables. Whereas a lot of effort has been put in developing fast optimization\\nmethods when the groups are disjoint or embedded in a specific hierarchical\\nstructure, we address here the case of general overlapping groups. To this end,\\nwe show that the corresponding optimization problem is related to network flow\\noptimization. More precisely, the proximal problem associated with the norm we\\nconsider is dual to a quadratic min-cost flow problem. We propose an efficient\\nprocedure which computes its solution exactly in polynomial time. Our algorithm\\nscales up to millions of variables, and opens up a whole new range of\\napplications for structured sparse models. We present several experiments on\\nimage and video data, demonstrating the applicability and scalability of our\\napproach for various problems.\\n',\n",
              " '  Many online, i.e., time-adaptive, inverse problems in signal processing and\\nmachine learning fall under the wide umbrella of the asymptotic minimization of\\na sequence of non-negative, convex, and continuous functions. To incorporate\\na-priori knowledge into the design, the asymptotic minimization task is usually\\nconstrained on a fixed closed convex set, which is dictated by the available\\na-priori information. To increase versatility towards the usage of the\\navailable information, the present manuscript extends the Adaptive Projected\\nSubgradient Method (APSM) by introducing an algorithmic scheme which\\nincorporates a-priori knowledge in the design via a sequence of strongly\\nattracting quasi-nonexpansive mappings in a real Hilbert space. In such a way,\\nthe benefits offered to online learning tasks by the proposed method unfold in\\ntwo ways: 1) the rich class of quasi-nonexpansive mappings provides a plethora\\nof ways to cast a-priori knowledge, and 2) by introducing a sequence of such\\nmappings, the proposed scheme is able to capture the time-varying nature of\\na-priori information. The convergence properties of the algorithm are studied,\\nseveral special cases of the method with wide applicability are shown, and the\\npotential of the proposed scheme is demonstrated by considering an increasingly\\nimportant, nowadays, online sparse system/signal recovery task.\\n',\n",
              " \"  Heavy-tailed distributions naturally occur in many real life problems.\\nUnfortunately, it is typically not possible to compute inference in closed-form\\nin graphical models which involve such heavy-tailed distributions.\\n  In this work, we propose a novel simple linear graphical model for\\nindependent latent random variables, called linear characteristic model (LCM),\\ndefined in the characteristic function domain. Using stable distributions, a\\nheavy-tailed family of distributions which is a generalization of Cauchy,\\nL\\\\'evy and Gaussian distributions, we show for the first time, how to compute\\nboth exact and approximate inference in such a linear multivariate graphical\\nmodel. LCMs are not limited to stable distributions, in fact LCMs are always\\ndefined for any random variables (discrete, continuous or a mixture of both).\\n  We provide a realistic problem from the field of computer networks to\\ndemonstrate the applicability of our construction. Other potential application\\nis iterative decoding of linear channels with non-Gaussian noise.\\n\",\n",
              " '  In this paper we consider general l0-norm minimization problems, that is, the\\nproblems with l0-norm appearing in either objective function or constraint. In\\nparticular, we first reformulate the l0-norm constrained problem as an\\nequivalent rank minimization problem and then apply the penalty decomposition\\n(PD) method proposed in [33] to solve the latter problem. By utilizing the\\nspecial structures, we then transform all matrix operations of this method to\\nvector operations and obtain a PD method that only involves vector operations.\\nUnder some suitable assumptions, we establish that any accumulation point of\\nthe sequence generated by the PD method satisfies a first-order optimality\\ncondition that is generally stronger than one natural optimality condition. We\\nfurther extend the PD method to solve the problem with the l0-norm appearing in\\nobjective function. Finally, we test the performance of our PD methods by\\napplying them to compressed sensing, sparse logistic regression and sparse\\ninverse covariance selection. The computational results demonstrate that our\\nmethods generally outperform the existing methods in terms of solution quality\\nand/or speed.\\n',\n",
              " '  In this paper we consider general rank minimization problems with rank\\nappearing in either objective function or constraint. We first establish that a\\nclass of special rank minimization problems has closed-form solutions. Using\\nthis result, we then propose penalty decomposition methods for general rank\\nminimization problems in which each subproblem is solved by a block coordinate\\ndescend method. Under some suitable assumptions, we show that any accumulation\\npoint of the sequence generated by the penalty decomposition methods satisfies\\nthe first-order optimality conditions of a nonlinear reformulation of the\\nproblems. Finally, we test the performance of our methods by applying them to\\nthe matrix completion and nearest low-rank correlation matrix problems. The\\ncomputational results demonstrate that our methods are generally comparable or\\nsuperior to the existing methods in terms of solution quality.\\n',\n",
              " '  Directed acyclic graphs (DAGs) are a popular framework to express\\nmultivariate probability distributions. Acyclic directed mixed graphs (ADMGs)\\nare generalizations of DAGs that can succinctly capture much richer sets of\\nconditional independencies, and are especially useful in modeling the effects\\nof latent variables implicitly. Unfortunately there are currently no good\\nparameterizations of general ADMGs. In this paper, we apply recent work on\\ncumulative distribution networks and copulas to propose one one general\\nconstruction for ADMG models. We consider a simple parameter estimation\\napproach, and report some encouraging experimental results.\\n',\n",
              " \"  Post-genomic research deals with challenging problems in screening genomes of\\norganisms for particular functions or potential for being the targets of\\ngenetic engineering for desirable biological features. 'Phenotyping' of wild\\ntype and mutants is a time-consuming and costly effort by many individuals.\\nThis article is a preliminary progress report in research on large-scale\\nautomation of phenotyping steps (imaging, informatics and data analysis) needed\\nto study plant gene-proteins networks that influence growth and development of\\nplants. Our results undermine the significance of phenotypic traits that are\\nimplicit in patterns of dynamics in plant root response to sudden changes of\\nits environmental conditions, such as sudden re-orientation of the root tip\\nagainst the gravity vector. Including dynamic features besides the common\\nmorphological ones has paid off in design of robust and accurate machine\\nlearning methods to automate a typical phenotyping scenario, i.e. to\\ndistinguish the wild type from the mutants.\\n\",\n",
              " '  We propose a novel feature selection strategy to discover\\nlanguage-independent acoustic features that tend to be responsible for emotions\\nregardless of languages, linguistics and other factors. Experimental results\\nsuggest that the language-independent feature subset discovered yields the\\nperformance comparable to the full feature set on various emotional speech\\ncorpora.\\n',\n",
              " '  The group Lasso is an extension of the Lasso for feature selection on\\n(predefined) non-overlapping groups of features. The non-overlapping group\\nstructure limits its applicability in practice. There have been several recent\\nattempts to study a more general formulation, where groups of features are\\ngiven, potentially with overlaps between the groups. The resulting optimization\\nis, however, much more challenging to solve due to the group overlaps. In this\\npaper, we consider the efficient optimization of the overlapping group Lasso\\npenalized problem. We reveal several key properties of the proximal operator\\nassociated with the overlapping group Lasso, and compute the proximal operator\\nby solving the smooth and convex dual problem, which allows the use of the\\ngradient descent type of algorithms for the optimization. We have performed\\nempirical evaluations using the breast cancer gene expression data set, which\\nconsists of 8,141 genes organized into (overlapping) gene sets. Experimental\\nresults demonstrate the efficiency and effectiveness of the proposed algorithm.\\n',\n",
              " '  We formulate weighted graph clustering as a prediction problem: given a\\nsubset of edge weights we analyze the ability of graph clustering to predict\\nthe remaining edge weights. This formulation enables practical and theoretical\\ncomparison of different approaches to graph clustering as well as comparison of\\ngraph clustering with other possible ways to model the graph. We adapt the\\nPAC-Bayesian analysis of co-clustering (Seldin and Tishby, 2008; Seldin, 2009)\\nto derive a PAC-Bayesian generalization bound for graph clustering. The bound\\nshows that graph clustering should optimize a trade-off between empirical data\\nfit and the mutual information that clusters preserve on the graph nodes. A\\nsimilar trade-off derived from information-theoretic considerations was already\\nshown to produce state-of-the-art results in practice (Slonim et al., 2005;\\nYom-Tov and Slonim, 2009). This paper supports the empirical evidence by\\nproviding a better theoretical foundation, suggesting formal generalization\\nguarantees, and offering a more accurate way to deal with finite sample issues.\\nWe derive a bound minimization algorithm and show that it provides good results\\nin real-life problems and that the derived PAC-Bayesian bound is reasonably\\ntight.\\n',\n",
              " '  We motivate and analyse a new Tree Search algorithm, GPTS, based on recent\\ntheoretical advances in the use of Gaussian Processes for Bandit problems. We\\nconsider tree paths as arms and we assume the target/reward function is drawn\\nfrom a GP distribution. The posterior mean and variance, after observing data,\\nare used to define confidence intervals for the function values, and we\\nsequentially play arms with highest upper confidence bounds. We give an\\nefficient implementation of GPTS and we adapt previous regret bounds by\\ndetermining the decay rate of the eigenvalues of the kernel matrix on the whole\\nset of tree paths. We consider two kernels in the feature space of binary\\nvectors indexed by the nodes of the tree: linear and Gaussian. The regret grows\\nin square root of the number of iterations T, up to a logarithmic factor, with\\na constant that improves with bigger Gaussian kernel widths. We focus on\\npractical values of T, smaller than the number of arms. Finally, we apply GPTS\\nto Open Loop Planning in discounted Markov Decision Processes by modelling the\\nreward as a discounted sum of independent Gaussian Processes. We report similar\\nregret bounds to those of the OLOP algorithm.\\n',\n",
              " '  Low-rank matrix approximations are often used to help scale standard machine\\nlearning algorithms to large-scale problems. Recently, matrix coherence has\\nbeen used to characterize the ability to extract global information from a\\nsubset of matrix entries in the context of these low-rank approximations and\\nother sampling-based algorithms, e.g., matrix com- pletion, robust PCA. Since\\ncoherence is defined in terms of the singular vectors of a matrix and is\\nexpensive to compute, the practical significance of these results largely\\nhinges on the following question: Can we efficiently and accurately estimate\\nthe coherence of a matrix? In this paper we address this question. We propose a\\nnovel algorithm for estimating coherence from a small number of columns,\\nformally analyze its behavior, and derive a new coherence-based matrix\\napproximation bound based on this analysis. We then present extensive\\nexperimental results on synthetic and real datasets that corroborate our\\nworst-case theoretical analysis, yet provide strong support for the use of our\\nproposed algorithm whenever low-rank approximation is being considered. Our\\nalgorithm efficiently and accurately estimates matrix coherence across a wide\\nrange of datasets, and these coherence estimates are excellent predictors of\\nthe effectiveness of sampling-based matrix approximation on a case-by-case\\nbasis.\\n',\n",
              " '  Phishing is an increasingly sophisticated method to steal personal user\\ninformation using sites that pretend to be legitimate. In this paper, we take\\nthe following steps to identify phishing URLs. First, we carefully select\\nlexical features of the URLs that are resistant to obfuscation techniques used\\nby attackers. Second, we evaluate the classification accuracy when using only\\nlexical features, both automatically and hand-selected, vs. when using\\nadditional features. We show that lexical features are sufficient for all\\npractical purposes. Third, we thoroughly compare several classification\\nalgorithms, and we propose to use an online method (AROW) that is able to\\novercome noisy training data. Based on the insights gained from our analysis,\\nwe propose PhishDef, a phishing detection system that uses only URL names and\\ncombines the above three elements. PhishDef is a highly accurate method (when\\ncompared to state-of-the-art approaches over real datasets), lightweight (thus\\nappropriate for online and client-side deployment), proactive (based on online\\nclassification rather than blacklists), and resilient to training data\\ninaccuracies (thus enabling the use of large noisy training data).\\n',\n",
              " '  This paper introduces an approach to Reinforcement Learning Algorithm by\\ncomparing their immediate rewards using a variation of Q-Learning algorithm.\\nUnlike the conventional Q-Learning, the proposed algorithm compares current\\nreward with immediate reward of past move and work accordingly. Relative reward\\nbased Q-learning is an approach towards interactive learning. Q-Learning is a\\nmodel free reinforcement learning method that used to learn the agents. It is\\nobserved that under normal circumstances algorithm take more episodes to reach\\noptimal Q-value due to its normal reward or sometime negative reward. In this\\nnew form of algorithm agents select only those actions which have a higher\\nimmediate reward signal in comparison to previous one. The contribution of this\\narticle is the presentation of new Q-Learning Algorithm in order to maximize\\nthe performance of algorithm and reduce the number of episode required to reach\\noptimal Q-value. Effectiveness of proposed algorithm is simulated in a 20 x20\\nGrid world deterministic environment and the result for the two forms of\\nQ-Learning Algorithms is given.\\n',\n",
              " '  We study three families of online convex optimization algorithms:\\nfollow-the-proximally-regularized-leader (FTRL-Proximal), regularized dual\\naveraging (RDA), and composite-objective mirror descent. We first prove\\nequivalence theorems that show all of these algorithms are instantiations of a\\ngeneral FTRL update. This provides theoretical insight on previous experimental\\nobservations. In particular, even though the FOBOS composite mirror descent\\nalgorithm handles L1 regularization explicitly, it has been observed that RDA\\nis even more effective at producing sparsity. Our results demonstrate that\\nFOBOS uses subgradient approximations to the L1 penalty from previous rounds,\\nleading to less sparsity than RDA, which handles the cumulative penalty in\\nclosed form. The FTRL-Proximal algorithm can be seen as a hybrid of these two,\\nand outperforms both on a large, real-world dataset.\\n  Our second contribution is a unified analysis which produces regret bounds\\nthat match (up to logarithmic terms) or improve the best previously known\\nbounds. This analysis also extends these algorithms in two important ways: we\\nsupport a more general type of composite objective and we analyze implicit\\nupdates, which replace the subgradient approximation of the current loss\\nfunction with an exact optimization.\\n',\n",
              " '  We propose a novel hybrid loss for multiclass and structured prediction\\nproblems that is a convex combination of log loss for Conditional Random Fields\\n(CRFs) and a multiclass hinge loss for Support Vector Machines (SVMs). We\\nprovide a sufficient condition for when the hybrid loss is Fisher consistent\\nfor classification. This condition depends on a measure of dominance between\\nlabels - specifically, the gap in per observation probabilities between the\\nmost likely labels. We also prove Fisher consistency is necessary for\\nparametric consistency when learning models such as CRFs.\\n  We demonstrate empirically that the hybrid loss typically performs as least\\nas well as - and often better than - both of its constituent losses on variety\\nof tasks. In doing so we also provide an empirical comparison of the efficacy\\nof probabilistic and margin based approaches to multiclass and structured\\nprediction and the effects of label dominance on these results.\\n',\n",
              " '  We investigate fast methods that allow to quickly eliminate variables\\n(features) in supervised learning problems involving a convex loss function and\\na $l_1$-norm penalty, leading to a potentially substantial reduction in the\\nnumber of variables prior to running the supervised learning algorithm. The\\nmethods are not heuristic: they only eliminate features that are {\\\\em\\nguaranteed} to be absent after solving the learning problem. Our framework\\napplies to a large class of problems, including support vector machine\\nclassification, logistic regression and least-squares.\\n  The complexity of the feature elimination step is negligible compared to the\\ntypical computational effort involved in the sparse supervised learning\\nproblem: it grows linearly with the number of features times the number of\\nexamples, with much better count if data is sparse. We apply our method to data\\nsets arising in text classification and observe a dramatic reduction of the\\ndimensionality, hence in computational effort required to solve the learning\\nproblem, especially when very sparse classifiers are sought. Our method allows\\nto immediately extend the scope of existing algorithms, allowing us to run them\\non data sets of sizes that were out of their reach before.\\n',\n",
              " '  Recent theoretical and empirical work in statistical machine learning has\\ndemonstrated the importance of learning algorithms for deep architectures,\\ni.e., function classes obtained by composing multiple non-linear\\ntransformations. Self-taught learning (exploiting unlabeled examples or\\nexamples from other distributions) has already been applied to deep learners,\\nbut mostly to show the advantage of unlabeled examples. Here we explore the\\nadvantage brought by {\\\\em out-of-distribution examples}. For this purpose we\\ndeveloped a powerful generator of stochastic variations and noise processes for\\ncharacter images, including not only affine transformations but also slant,\\nlocal elastic deformations, changes in thickness, background images, grey level\\nchanges, contrast, occlusion, and various types of noise. The\\nout-of-distribution examples are obtained from these highly distorted images or\\nby including examples of object classes different from those in the target test\\nset. We show that {\\\\em deep learners benefit more from out-of-distribution\\nexamples than a corresponding shallow learner}, at least in the area of\\nhandwritten character recognition. In fact, we show that they beat previously\\npublished results and reach human-level performance on both handwritten digit\\nclassification and 62-class handwritten character recognition.\\n',\n",
              " '  In this paper we present a new algorithm for learning oblique decision trees.\\nMost of the current decision tree algorithms rely on impurity measures to\\nassess the goodness of hyperplanes at each node while learning a decision tree\\nin a top-down fashion. These impurity measures do not properly capture the\\ngeometric structures in the data. Motivated by this, our algorithm uses a\\nstrategy to assess the hyperplanes in such a way that the geometric structure\\nin the data is taken into account. At each node of the decision tree, we find\\nthe clustering hyperplanes for both the classes and use their angle bisectors\\nas the split rule at that node. We show through empirical studies that this\\nidea leads to small decision trees and better performance. We also present some\\nanalysis to show that the angle bisectors of clustering hyperplanes that we use\\nas the split rules at each node, are solutions of an interesting optimization\\nproblem and hence argue that this is a principled method of learning a decision\\ntree.\\n',\n",
              " \"  Margin theory provides one of the most popular explanations to the success of\\n\\\\texttt{AdaBoost}, where the central point lies in the recognition that\\n\\\\textit{margin} is the key for characterizing the performance of\\n\\\\texttt{AdaBoost}. This theory has been very influential, e.g., it has been\\nused to argue that \\\\texttt{AdaBoost} usually does not overfit since it tends to\\nenlarge the margin even after the training error reaches zero. Previously the\\n\\\\textit{minimum margin bound} was established for \\\\texttt{AdaBoost}, however,\\n\\\\cite{Breiman1999} pointed out that maximizing the minimum margin does not\\nnecessarily lead to a better generalization. Later, \\\\cite{Reyzin:Schapire2006}\\nemphasized that the margin distribution rather than minimum margin is crucial\\nto the performance of \\\\texttt{AdaBoost}. In this paper, we first present the\\n\\\\textit{$k$th margin bound} and further study on its relationship to previous\\nwork such as the minimum margin bound and Emargin bound. Then, we improve the\\nprevious empirical Bernstein bounds\\n\\\\citep{Maurer:Pontil2009,Audibert:Munos:Szepesvari2009}, and based on such\\nfindings, we defend the margin-based explanation against Breiman's doubts by\\nproving a new generalization error bound that considers exactly the same\\nfactors as \\\\cite{Schapire:Freund:Bartlett:Lee1998} but is sharper than\\n\\\\cite{Breiman1999}'s minimum margin bound. By incorporating factors such as\\naverage margin and variance, we present a generalization error bound that is\\nheavily related to the whole margin distribution. We also provide margin\\ndistribution bounds for generalization error of voting classifiers in finite\\nVC-dimension space.\\n\",\n",
              " \"  In this work, we propose a new optimization framework for multiclass boosting\\nlearning. In the literature, AdaBoost.MO and AdaBoost.ECC are the two\\nsuccessful multiclass boosting algorithms, which can use binary weak learners.\\nWe explicitly derive these two algorithms' Lagrange dual problems based on\\ntheir regularized loss functions. We show that the Lagrange dual formulations\\nenable us to design totally-corrective multiclass algorithms by using the\\nprimal-dual optimization technique. Experiments on benchmark data sets suggest\\nthat our multiclass boosting can achieve a comparable generalization capability\\nwith state-of-the-art, but the convergence speed is much faster than stage-wise\\ngradient descent boosting. In other words, the new totally corrective\\nalgorithms can maximize the margin more aggressively.\\n\",\n",
              " '  Web applications suffer from cross-site scripting (XSS) attacks that\\nresulting from incomplete or incorrect input sanitization. Learning the\\nstructure of attack vectors could enrich the variety of manifestations in\\ngenerated XSS attacks. In this study, we focus on generating more threatening\\nXSS attacks for the state-of-the-art detection approaches that can find\\npotential XSS vulnerabilities in Web applications, and propose a mechanism for\\nstructural learning of attack vectors with the aim of generating mutated XSS\\nattacks in a fully automatic way. Mutated XSS attack generation depends on the\\nanalysis of attack vectors and the structural learning mechanism. For the\\nkernel of the learning mechanism, we use a Hidden Markov model (HMM) as the\\nstructure of the attack vector model to capture the implicit manner of the\\nattack vector, and this manner is benefited from the syntax meanings that are\\nlabeled by the proposed tokenizing mechanism. Bayes theorem is used to\\ndetermine the number of hidden states in the model for generalizing the\\nstructure model. The paper has the contributions as following: (1)\\nautomatically learn the structure of attack vectors from practical data\\nanalysis to modeling a structure model of attack vectors, (2) mimic the manners\\nand the elements of attack vectors to extend the ability of testing tool for\\nidentifying XSS vulnerabilities, (3) be helpful to verify the flaws of\\nblacklist sanitization procedures of Web applications. We evaluated the\\nproposed mechanism by Burp Intruder with a dataset collected from public XSS\\narchives. The results show that mutated XSS attack generation can identify\\npotential vulnerabilities.\\n',\n",
              " '  Recently there is a line of research work proposing to employ Spectral\\nClustering (SC) to segment (group){Throughout the paper, we use segmentation,\\nclustering, and grouping, and their verb forms, interchangeably.}\\nhigh-dimensional structural data such as those (approximately) lying on\\nsubspaces {We follow {liu2010robust} and use the term \"subspace\" to denote both\\nlinear subspaces and affine subspaces. There is a trivial conversion between\\nlinear subspaces and affine subspaces as mentioned therein.} or low-dimensional\\nmanifolds. By learning the affinity matrix in the form of sparse\\nreconstruction, techniques proposed in this vein often considerably boost the\\nperformance in subspace settings where traditional SC can fail. Despite the\\nsuccess, there are fundamental problems that have been left unsolved: the\\nspectrum property of the learned affinity matrix cannot be gauged in advance,\\nand there is often one ugly symmetrization step that post-processes the\\naffinity for SC input. Hence we advocate to enforce the symmetric positive\\nsemidefinite constraint explicitly during learning (Low-Rank Representation\\nwith Positive SemiDefinite constraint, or LRR-PSD), and show that factually it\\ncan be solved in an exquisite scheme efficiently instead of general-purpose SDP\\nsolvers that usually scale up poorly. We provide rigorous mathematical\\nderivations to show that, in its canonical form, LRR-PSD is equivalent to the\\nrecently proposed Low-Rank Representation (LRR) scheme {liu2010robust}, and\\nhence offer theoretic and practical insights to both LRR-PSD and LRR, inviting\\nfuture research. As per the computational cost, our proposal is at most\\ncomparable to that of LRR, if not less. We validate our theoretic analysis and\\noptimization scheme by experiments on both synthetic and real data sets.\\n',\n",
              " '  We establish an excess risk bound of O(H R_n^2 + R_n \\\\sqrt{H L*}) for\\nempirical risk minimization with an H-smooth loss function and a hypothesis\\nclass with Rademacher complexity R_n, where L* is the best risk achievable by\\nthe hypothesis class. For typical hypothesis classes where R_n = \\\\sqrt{R/n},\\nthis translates to a learning rate of O(RH/n) in the separable (L*=0) case and\\nO(RH/n + \\\\sqrt{L^* RH/n}) more generally. We also provide similar guarantees\\nfor online and stochastic convex optimization with a smooth non-negative\\nobjective.\\n',\n",
              " '  We propose a novel reformulation of the stochastic optimal control problem as\\nan approximate inference problem, demonstrating, that such a interpretation\\nleads to new practical methods for the original problem. In particular we\\ncharacterise a novel class of iterative solutions to the stochastic optimal\\ncontrol problem based on a natural relaxation of the exact dual formulation.\\nThese theoretical insights are applied to the Reinforcement Learning problem\\nwhere they lead to new model free, off policy methods for discrete and\\ncontinuous problems.\\n',\n",
              " '  We describe a fast method to eliminate features (variables) in l1 -penalized\\nleast-square regression (or LASSO) problems. The elimination of features leads\\nto a potentially substantial reduction in running time, specially for large\\nvalues of the penalty parameter. Our method is not heuristic: it only\\neliminates features that are guaranteed to be absent after solving the LASSO\\nproblem. The feature elimination step is easy to parallelize and can test each\\nfeature for elimination independently. Moreover, the computational effort of\\nour method is negligible compared to that of solving the LASSO problem -\\nroughly it is the same as single gradient step. Our method extends the scope of\\nexisting LASSO algorithms to treat larger data sets, previously out of their\\nreach. We show how our method can be extended to general l1 -penalized convex\\nproblems and present preliminary results for the Sparse Support Vector Machine\\nand Logistic Regression problems.\\n',\n",
              " '  Text classification is the process of classifying documents into predefined\\ncategories based on their content. Existing supervised learning algorithms to\\nautomatically classify text need sufficient documents to learn accurately. This\\npaper presents a new algorithm for text classification that requires fewer\\ndocuments for training. Instead of using words, word relation i.e association\\nrules from these words is used to derive feature set from preclassified text\\ndocuments. The concept of Naive Bayes classifier is then used on derived\\nfeatures and finally only a single concept of Genetic Algorithm has been added\\nfor final classification. Experimental results show that the classifier build\\nthis way is more accurate than the existing text classification systems.\\n',\n",
              " '  As the amount of online text increases, the demand for text classification to\\naid the analysis and management of text is increasing. Text is cheap, but\\ninformation, in the form of knowing what classes a text belongs to, is\\nexpensive. Automatic classification of text can provide this information at low\\ncost, but the classifiers themselves must be built with expensive human effort,\\nor trained from texts which have themselves been manually classified. In this\\npaper we will discuss a procedure of classifying text using the concept of\\nassociation rule of data mining. Association rule mining technique has been\\nused to derive feature set from pre-classified text documents. Naive Bayes\\nclassifier is then used on derived features for final classification.\\n',\n",
              " '  This paper describes an effective unsupervised speaker indexing approach. We\\nsuggest a two stage algorithm to speed-up the state-of-the-art algorithm based\\non the Bayesian Information Criterion (BIC). In the first stage of the merging\\nprocess a computationally cheap method based on the vector quantization (VQ) is\\nused. Then in the second stage a more computational expensive technique based\\non the BIC is applied. In the speaker indexing task a turning parameter or a\\nthreshold is used. We suggest an on-line procedure to define the value of a\\nturning parameter without using development data. The results are evaluated\\nusing 10 hours of audio data.\\n',\n",
              " '  Sparse learning has recently received increasing attention in many areas\\nincluding machine learning, statistics, and applied mathematics. The mixed-norm\\nregularization based on the L1/Lq norm with q > 1 is attractive in many\\napplications of regression and classification in that it facilitates group\\nsparsity in the model. The resulting optimization problem is, however,\\nchallenging to solve due to the structure of the L1/Lq -regularization.\\nExisting work deals with special cases including q = 2,infinity, and they\\ncannot be easily extended to the general case. In this paper, we propose an\\nefficient algorithm based on the accelerated gradient method for solving the\\nL1/Lq -regularized problem, which is applicable for all values of q larger than\\n1, thus significantly extending existing work. One key building block of the\\nproposed algorithm is the L1/Lq -regularized Euclidean projection (EP1q). Our\\ntheoretical analysis reveals the key properties of EP1q and illustrates why\\nEP1q for the general q is significantly more challenging to solve than the\\nspecial cases. Based on our theoretical analysis, we develop an efficient\\nalgorithm for EP1q by solving two zero finding problems. Experimental results\\ndemonstrate the efficiency of the proposed algorithm.\\n',\n",
              " '  An instance-weighted variant of the support vector machine (SVM) has\\nattracted considerable attention recently since they are useful in various\\nmachine learning tasks such as non-stationary data analysis, heteroscedastic\\ndata modeling, transfer learning, learning to rank, and transduction. An\\nimportant challenge in these scenarios is to overcome the computational\\nbottleneck---instance weights often change dynamically or adaptively, and thus\\nthe weighted SVM solutions must be repeatedly computed. In this paper, we\\ndevelop an algorithm that can efficiently and exactly update the weighted SVM\\nsolutions for arbitrary change of instance weights. Technically, this\\ncontribution can be regarded as an extension of the conventional solution-path\\nalgorithm for a single regularization parameter to multiple instance-weight\\nparameters. However, this extension gives rise to a significant problem that\\nbreakpoints (at which the solution path turns) have to be identified in\\nhigh-dimensional space. To facilitate this, we introduce a parametric\\nrepresentation of instance weights. We also provide a geometric interpretation\\nin weight space using a notion of critical region: a polyhedron in which the\\ncurrent affine solution remains to be optimal. Then we find breakpoints at\\nintersections of the solution path and boundaries of polyhedrons. Through\\nextensive experiments on various practical applications, we demonstrate the\\nusefulness of the proposed algorithm.\\n',\n",
              " '  Speech recognition and speaker identification are important for\\nauthentication and verification in security purpose, but they are difficult to\\nachieve. Speaker identification methods can be divided into text-independent\\nand text-dependent. This paper presents a technique of text-dependent speaker\\nidentification using MFCC-domain support vector machine (SVM). In this work,\\nmelfrequency cepstrum coefficients (MFCCs) and their statistical distribution\\nproperties are used as features, which will be inputs to the neural network.\\nThis work firstly used sequential minimum optimization (SMO) learning technique\\nfor SVM that improve performance over traditional techniques Chunking, Osuna.\\nThe cepstrum coefficients representing the speaker characteristics of a speech\\nsegment are computed by nonlinear filter bank analysis and discrete cosine\\ntransform. The speaker identification ability and convergence speed of the SVMs\\nare investigated for different combinations of features. Extensive experimental\\nresults on several samples show the effectiveness of the proposed approach.\\n',\n",
              " '  Text classification is the automated assignment of natural language texts to\\npredefined categories based on their content. Text classification is the\\nprimary requirement of text retrieval systems, which retrieve texts in response\\nto a user query, and text understanding systems, which transform text in some\\nway such as producing summaries, answering questions or extracting data. Now a\\nday the demand of text classification is increasing tremendously. Keeping this\\ndemand into consideration, new and updated techniques are being developed for\\nthe purpose of automated text classification. This paper presents a new\\nalgorithm for text classification. Instead of using words, word relation i.e.\\nassociation rules is used to derive feature set from pre-classified text\\ndocuments. The concept of Naive Bayes Classifier is then used on derived\\nfeatures and finally a concept of Genetic Algorithm has been added for final\\nclassification. A system based on the proposed algorithm has been implemented\\nand tested. The experimental results show that the proposed system works as a\\nsuccessful text classifier.\\n',\n",
              " \"  Bayesian optimization with Gaussian processes has become an increasingly\\npopular tool in the machine learning community. It is efficient and can be used\\nwhen very little is known about the objective function, making it popular in\\nexpensive black-box optimization scenarios. It uses Bayesian methods to sample\\nthe objective efficiently using an acquisition function which incorporates the\\nmodel's estimate of the objective and the uncertainty at any given point.\\nHowever, there are several different parameterized acquisition functions in the\\nliterature, and it is often unclear which one to use. Instead of using a single\\nacquisition function, we adopt a portfolio of acquisition functions governed by\\nan online multi-armed bandit strategy. We propose several portfolio strategies,\\nthe best of which we call GP-Hedge, and show that this method outperforms the\\nbest individual acquisition function. We also provide a theoretical bound on\\nthe algorithm's performance.\\n\",\n",
              " '  In certain applications it is useful to fit multinomial distributions to\\nobserved data with a penalty term that encourages sparsity. For example, in\\nprobabilistic latent audio source decomposition one may wish to encode the\\nassumption that only a few latent sources are active at any given time. The\\nstandard heuristic of applying an L1 penalty is not an option when fitting the\\nparameters to a multinomial distribution, which are constrained to sum to 1. An\\nalternative is to use a penalty term that encourages low-entropy solutions,\\nwhich corresponds to maximum a posteriori (MAP) parameter estimation with an\\nentropic prior. The lack of conjugacy between the entropic prior and the\\nmultinomial distribution complicates this approach. In this report I propose a\\nsimple iterative algorithm for MAP estimation of multinomial distributions with\\nsparsity-inducing entropic priors.\\n',\n",
              " '  We consider the problem of energy-efficient point-to-point transmission of\\ndelay-sensitive data (e.g. multimedia data) over a fading channel. Existing\\nresearch on this topic utilizes either physical-layer centric solutions, namely\\npower-control and adaptive modulation and coding (AMC), or system-level\\nsolutions based on dynamic power management (DPM); however, there is currently\\nno rigorous and unified framework for simultaneously utilizing both\\nphysical-layer centric and system-level techniques to achieve the minimum\\npossible energy consumption, under delay constraints, in the presence of\\nstochastic and a priori unknown traffic and channel conditions. In this report,\\nwe propose such a framework. We formulate the stochastic optimization problem\\nas a Markov decision process (MDP) and solve it online using reinforcement\\nlearning. The advantages of the proposed online method are that (i) it does not\\nrequire a priori knowledge of the traffic arrival and channel statistics to\\ndetermine the jointly optimal power-control, AMC, and DPM policies; (ii) it\\nexploits partial information about the system so that less information needs to\\nbe learned than when using conventional reinforcement learning algorithms; and\\n(iii) it obviates the need for action exploration, which severely limits the\\nadaptation speed and run-time performance of conventional reinforcement\\nlearning algorithms. Our results show that the proposed learning algorithms can\\nconverge up to two orders of magnitude faster than a state-of-the-art learning\\nalgorithm for physical layer power-control and up to three orders of magnitude\\nfaster than conventional reinforcement learning algorithms.\\n',\n",
              " '  We propose a focus of attention mechanism to speed up the Perceptron\\nalgorithm. Focus of attention speeds up the Perceptron algorithm by lowering\\nthe number of features evaluated throughout training and prediction. Whereas\\nthe traditional Perceptron evaluates all the features of each example, the\\nAttentive Perceptron evaluates less features for easy to classify examples,\\nthereby achieving significant speedups and small losses in prediction accuracy.\\nFocus of attention allows the Attentive Perceptron to stop the evaluation of\\nfeatures at any interim point and filter the example. This creates an attentive\\nfilter which concentrates computation at examples that are hard to classify,\\nand quickly filters examples that are easy to classify.\\n',\n",
              " \"  We consider an opportunistic spectrum access (OSA) problem where the\\ntime-varying condition of each channel (e.g., as a result of random fading or\\ncertain primary users' activities) is modeled as an arbitrary finite-state\\nMarkov chain. At each instance of time, a (secondary) user probes a channel and\\ncollects a certain reward as a function of the state of the channel (e.g., good\\nchannel condition results in higher data rate for the user). Each channel has\\npotentially different state space and statistics, both unknown to the user, who\\ntries to learn which one is the best as it goes and maximizes its usage of the\\nbest channel. The objective is to construct a good online learning algorithm so\\nas to minimize the difference between the user's performance in total rewards\\nand that of using the best channel (on average) had it known which one is the\\nbest from a priori knowledge of the channel statistics (also known as the\\nregret). This is a classic exploration and exploitation problem and results\\nabound when the reward processes are assumed to be iid. Compared to prior work,\\nthe biggest difference is that in our case the reward process is assumed to be\\nMarkovian, of which iid is a special case. In addition, the reward processes\\nare restless in that the channel conditions will continue to evolve independent\\nof the user's actions. This leads to a restless bandit problem, for which there\\nexists little result on either algorithms or performance bounds in this\\nlearning context to the best of our knowledge. In this paper we introduce an\\nalgorithm that utilizes regenerative cycles of a Markov chain and computes a\\nsample-mean based index policy, and show that under mild conditions on the\\nstate transition probabilities of the Markov chains this algorithm achieves\\nlogarithmic regret uniformly over time, and that this regret bound is also\\noptimal.\\n\",\n",
              " '  In this paper, we consider a queue-aware distributive resource control\\nalgorithm for two-hop MIMO cooperative systems. We shall illustrate that relay\\nbuffering is an effective way to reduce the intrinsic half-duplex penalty in\\ncooperative systems. The complex interactions of the queues at the source node\\nand the relays are modeled as an average-cost infinite horizon Markov Decision\\nProcess (MDP). The traditional approach solving this MDP problem involves\\ncentralized control with huge complexity. To obtain a distributive and low\\ncomplexity solution, we introduce a linear structure which approximates the\\nvalue function of the associated Bellman equation by the sum of per-node value\\nfunctions. We derive a distributive two-stage two-winner auction-based control\\npolicy which is a function of the local CSI and local QSI only. Furthermore, to\\nestimate the best fit approximation parameter, we propose a distributive online\\nstochastic learning algorithm using stochastic approximation theory. Finally,\\nwe establish technical conditions for almost-sure convergence and show that\\nunder heavy traffic, the proposed low complexity distributive control is global\\noptimal.\\n',\n",
              " '  We consider a hidden Markov model with multiple observation processes, one of\\nwhich is chosen at each point in time by a policy---a deterministic function of\\nthe information state---and attempt to determine which policy minimises the\\nlimiting expected entropy of the information state. Focusing on a special case,\\nwe prove analytically that the information state always converges in\\ndistribution, and derive a formula for the limiting entropy which can be used\\nfor calculations with high precision. Using this fomula, we find\\ncomputationally that the optimal policy is always a threshold policy, allowing\\nit to be easily found. We also find that the greedy policy is almost optimal.\\n',\n",
              " '  To classify time series by nearest neighbors, we need to specify or learn one\\nor several distance measures. We consider variations of the Mahalanobis\\ndistance measures which rely on the inverse covariance matrix of the data.\\nUnfortunately --- for time series data --- the covariance matrix has often low\\nrank. To alleviate this problem we can either use a pseudoinverse, covariance\\nshrinking or limit the matrix to its diagonal. We review these alternatives and\\nbenchmark them against competitive methods such as the related Large Margin\\nNearest Neighbor Classification (LMNN) and the Dynamic Time Warping (DTW)\\ndistance. As we expected, we find that the DTW is superior, but the Mahalanobis\\ndistance measures are one to two orders of magnitude faster. To get best\\nresults with Mahalanobis distance measures, we recommend learning one distance\\nmeasure per class using either covariance shrinking or the diagonal approach.\\n',\n",
              " '  This paper describes algorithms for nonnegative matrix factorization (NMF)\\nwith the beta-divergence (beta-NMF). The beta-divergence is a family of cost\\nfunctions parametrized by a single shape parameter beta that takes the\\nEuclidean distance, the Kullback-Leibler divergence and the Itakura-Saito\\ndivergence as special cases (beta = 2,1,0, respectively). The proposed\\nalgorithms are based on a surrogate auxiliary function (a local majorization of\\nthe criterion function). We first describe a majorization-minimization (MM)\\nalgorithm that leads to multiplicative updates, which differ from standard\\nheuristic multiplicative updates by a beta-dependent power exponent. The\\nmonotonicity of the heuristic algorithm can however be proven for beta in (0,1)\\nusing the proposed auxiliary function. Then we introduce the concept of\\nmajorization-equalization (ME) algorithm which produces updates that move along\\nconstant level sets of the auxiliary function and lead to larger steps than MM.\\nSimulations on synthetic and real data illustrate the faster convergence of the\\nME approach. The paper also describes how the proposed algorithms can be\\nadapted to two common variants of NMF : penalized NMF (i.e., when a penalty\\nfunction of the factors is added to the criterion function) and convex-NMF\\n(when the dictionary is assumed to belong to a known subspace).\\n',\n",
              " '  For classification problems, feature extraction is a crucial process which\\naims to find a suitable data representation that increases the performance of\\nthe machine learning algorithm. According to the curse of dimensionality\\ntheorem, the number of samples needed for a classification task increases\\nexponentially as the number of dimensions (variables, features) increases. On\\nthe other hand, it is costly to collect, store and process data. Moreover,\\nirrelevant and redundant features might hinder classifier performance. In\\nexploratory analysis settings, high dimensionality prevents the users from\\nexploring the data visually. Feature extraction is a two-step process: feature\\nconstruction and feature selection. Feature construction creates new features\\nbased on the original features and feature selection is the process of\\nselecting the best features as in filter, wrapper and embedded methods.\\n  In this work, we focus on feature construction methods that aim to decrease\\ndata dimensionality for visualization tasks. Various linear (such as principal\\ncomponents analysis (PCA), multiple discriminants analysis (MDA), exploratory\\nprojection pursuit) and non-linear (such as multidimensional scaling (MDS),\\nmanifold learning, kernel PCA/LDA, evolutionary constructive induction)\\ntechniques have been proposed for dimensionality reduction. Our algorithm is an\\nadaptive feature extraction method which consists of evolutionary constructive\\ninduction for feature construction and a hybrid filter/wrapper method for\\nfeature selection.\\n',\n",
              " '  In this work we address the subspace recovery problem. Given a set of data\\nsamples (vectors) approximately drawn from a union of multiple subspaces, our\\ngoal is to segment the samples into their respective subspaces and correct the\\npossible errors as well. To this end, we propose a novel method termed Low-Rank\\nRepresentation (LRR), which seeks the lowest-rank representation among all the\\ncandidates that can represent the data samples as linear combinations of the\\nbases in a given dictionary. It is shown that LRR well solves the subspace\\nrecovery problem: when the data is clean, we prove that LRR exactly captures\\nthe true subspace structures; for the data contaminated by outliers, we prove\\nthat under certain conditions LRR can exactly recover the row space of the\\noriginal data and detect the outlier as well; for the data corrupted by\\narbitrary errors, LRR can also approximately recover the row space with\\ntheoretical guarantees. Since the subspace membership is provably determined by\\nthe row space, these further imply that LRR can perform robust subspace\\nsegmentation and error correction, in an efficient way.\\n',\n",
              " '  We tackle the fundamental problem of Bayesian active learning with noise,\\nwhere we need to adaptively select from a number of expensive tests in order to\\nidentify an unknown hypothesis sampled from a known prior distribution. In the\\ncase of noise-free observations, a greedy algorithm called generalized binary\\nsearch (GBS) is known to perform near-optimally. We show that if the\\nobservations are noisy, perhaps surprisingly, GBS can perform very poorly. We\\ndevelop EC2, a novel, greedy active learning algorithm and prove that it is\\ncompetitive with the optimal policy, thus obtaining the first competitiveness\\nguarantees for Bayesian active learning with noisy observations. Our bounds\\nrely on a recently discovered diminishing returns property called adaptive\\nsubmodularity, generalizing the classical notion of submodular set functions to\\nadaptive policies. Our results hold even if the tests have non-uniform cost and\\ntheir noise is correlated. We also propose EffECXtive, a particularly fast\\napproximation of EC2, and evaluate it on a Bayesian experimental design problem\\ninvolving human subjects, intended to tease apart competing economic theories\\nof how people make decisions under uncertainty.\\n',\n",
              " '  Adaptive sparse coding methods learn a possibly overcomplete set of basis\\nfunctions, such that natural image patches can be reconstructed by linearly\\ncombining a small subset of these bases. The applicability of these methods to\\nvisual object recognition tasks has been limited because of the prohibitive\\ncost of the optimization algorithms required to compute the sparse\\nrepresentation. In this work we propose a simple and efficient algorithm to\\nlearn basis functions. After training, this model also provides a fast and\\nsmooth approximator to the optimal representation, achieving even better\\naccuracy than exact sparse coding algorithms on visual object recognition\\ntasks.\\n',\n",
              " '  Hardness results for maximum agreement problems have close connections to\\nhardness results for proper learning in computational learning theory. In this\\npaper we prove two hardness results for the problem of finding a low degree\\npolynomial threshold function (PTF) which has the maximum possible agreement\\nwith a given set of labeled examples in $\\\\R^n \\\\times \\\\{-1,1\\\\}.$ We prove that\\nfor any constants $d\\\\geq 1, \\\\eps > 0$,\\n  {itemize}\\n  Assuming the Unique Games Conjecture, no polynomial-time algorithm can find a\\ndegree-$d$ PTF that is consistent with a $(\\\\half + \\\\eps)$ fraction of a given\\nset of labeled examples in $\\\\R^n \\\\times \\\\{-1,1\\\\}$, even if there exists a\\ndegree-$d$ PTF that is consistent with a $1-\\\\eps$ fraction of the examples.\\n  It is $\\\\NP$-hard to find a degree-2 PTF that is consistent with a $(\\\\half +\\n\\\\eps)$ fraction of a given set of labeled examples in $\\\\R^n \\\\times \\\\{-1,1\\\\}$,\\neven if there exists a halfspace (degree-1 PTF) that is consistent with a $1 -\\n\\\\eps$ fraction of the examples.\\n  {itemize}\\n  These results immediately imply the following hardness of learning results:\\n(i) Assuming the Unique Games Conjecture, there is no better-than-trivial\\nproper learning algorithm that agnostically learns degree-$d$ PTFs under\\narbitrary distributions; (ii) There is no better-than-trivial learning\\nalgorithm that outputs degree-2 PTFs and agnostically learns halfspaces (i.e.\\ndegree-1 PTFs) under arbitrary distributions.\\n',\n",
              " '  A general framework based on Gaussian models and a MAP-EM algorithm is\\nintroduced in this paper for solving matrix/table completion problems. The\\nnumerical experiments with the standard and challenging movie ratings data show\\nthat the proposed approach, based on probably one of the simplest probabilistic\\nmodels, leads to the results in the same ballpark as the state-of-the-art, at a\\nlower computational cost.\\n',\n",
              " '  Set-functions appear in many areas of computer science and applied\\nmathematics, such as machine learning, computer vision, operations research or\\nelectrical networks. Among these set-functions, submodular functions play an\\nimportant role, similar to convex functions on vector spaces. In this tutorial,\\nthe theory of submodular functions is presented, in a self-contained way, with\\nall results shown from first principles. A good knowledge of convex analysis is\\nassumed.\\n',\n",
              " '  Singular Value Decomposition (and Principal Component Analysis) is one of the\\nmost widely used techniques for dimensionality reduction: successful and\\nefficiently computable, it is nevertheless plagued by a well-known,\\nwell-documented sensitivity to outliers. Recent work has considered the setting\\nwhere each point has a few arbitrarily corrupted components. Yet, in\\napplications of SVD or PCA such as robust collaborative filtering or\\nbioinformatics, malicious agents, defective genes, or simply corrupted or\\ncontaminated experiments may effectively yield entire points that are\\ncompletely corrupted.\\n  We present an efficient convex optimization-based algorithm we call Outlier\\nPursuit, that under some mild assumptions on the uncorrupted points (satisfied,\\ne.g., by the standard generative assumption in PCA problems) recovers the exact\\noptimal low-dimensional subspace, and identifies the corrupted points. Such\\nidentification of corrupted points that do not conform to the low-dimensional\\napproximation, is of paramount interest in bioinformatics and financial\\napplications, and beyond. Our techniques involve matrix decomposition using\\nnuclear norm minimization, however, our results, setup, and approach,\\nnecessarily differ considerably from the existing line of work in matrix\\ncompletion and matrix decomposition, since we develop an approach to recover\\nthe correct column space of the uncorrupted matrix, rather than the exact\\nmatrix itself. In any problem where one seeks to recover a structure rather\\nthan the exact initial matrices, techniques developed thus far relying on\\ncertificates of optimality, will fail. We present an important extension of\\nthese methods, that allows the treatment of such problems.\\n',\n",
              " '  This paper considers the clustering problem for large data sets. We propose\\nan approach based on distributed optimization. The clustering problem is\\nformulated as an optimization problem of maximizing the classification gain. We\\nshow that the optimization problem can be reformulated and decomposed into\\nsmall-scale sub optimization problems by using the Dantzig-Wolfe decomposition\\nmethod. Generally speaking, the Dantzig-Wolfe method can only be used for\\nconvex optimization problems, where the duality gaps are zero. Even though, the\\nconsidered optimization problem in this paper is non-convex, we prove that the\\nduality gap goes to zero, as the problem size goes to infinity. Therefore, the\\nDantzig-Wolfe method can be applied here. In the proposed approach, the\\nclustering problem is iteratively solved by a group of computers coordinated by\\none center processor, where each computer solves one independent small-scale\\nsub optimization problem during each iteration, and only a small amount of data\\ncommunication is needed between the computers and center processor. Numerical\\nresults show that the proposed approach is effective and efficient.\\n',\n",
              " '  We give sublinear-time approximation algorithms for some optimization\\nproblems arising in machine learning, such as training linear classifiers and\\nfinding minimum enclosing balls. Our algorithms can be extended to some\\nkernelized versions of these problems, such as SVDD, hard margin SVM, and\\nL2-SVM, for which sublinear-time algorithms were not known before. These new\\nalgorithms use a combination of a novel sampling techniques and a new\\nmultiplicative update algorithm. We give lower bounds which show the running\\ntimes of many of our algorithms to be nearly best possible in the unit-cost RAM\\nmodel. We also give implementations of our algorithms in the semi-streaming\\nsetting, obtaining the first low pass polylogarithmic space and sublinear time\\nalgorithms achieving arbitrary approximation factor.\\n',\n",
              " '  Motivated by authentication, intrusion and spam detection applications we\\nconsider single-class classification (SCC) as a two-person game between the\\nlearner and an adversary. In this game the learner has a sample from a target\\ndistribution and the goal is to construct a classifier capable of\\ndistinguishing observations from the target distribution from observations\\nemitted from an unknown other distribution. The ideal SCC classifier must\\nguarantee a given tolerance for the false-positive error (false alarm rate)\\nwhile minimizing the false negative error (intruder pass rate). Viewing SCC as\\na two-person zero-sum game we identify both deterministic and randomized\\noptimal classification strategies for different game variants. We demonstrate\\nthat randomized classification can provide a significant advantage. In the\\ndeterministic setting we show how to reduce SCC to two-class classification\\nwhere in the two-class problem the other class is a synthetically generated\\ndistribution. We provide an efficient and practical algorithm for constructing\\nand solving the two class problem. The algorithm distinguishes low density\\nregions of the target distribution and is shown to be consistent.\\n',\n",
              " '  The decision boundaries of Bayes classifier are optimal because they lead to\\nmaximum probability of correct decision. It means if we knew the prior\\nprobabilities and the class-conditional densities, we could design a classifier\\nwhich gives the lowest probability of error. However, in classification based\\non nonparametric density estimation methods such as Parzen windows, the\\ndecision regions depend on the choice of parameters such as window width.\\nMoreover, these methods suffer from curse of dimensionality of the feature\\nspace and small sample size problem which severely restricts their practical\\napplications. In this paper, we address these problems by introducing a novel\\ndimension reduction and classification method based on local component\\nanalysis. In this method, by adopting an iterative cross-validation algorithm,\\nwe simultaneously estimate the optimal transformation matrices (for dimension\\nreduction) and classifier parameters based on local information. The proposed\\nmethod can classify the data with complicated boundary and also alleviate the\\ncourse of dimensionality dilemma. Experiments on real data show the superiority\\nof the proposed algorithm in term of classification accuracies for pattern\\nclassification applications like age, facial expression and character\\nrecognition. Keywords: Bayes classifier, curse of dimensionality dilemma,\\nParzen window, pattern classification, subspace learning.\\n',\n",
              " '  This paper proposes uni-orthogonal and bi-orthogonal nonnegative matrix\\nfactorization algorithms with robust convergence proofs. We design the\\nalgorithms based on the work of Lee and Seung [1], and derive the converged\\nversions by utilizing ideas from the work of Lin [2]. The experimental results\\nconfirm the theoretical guarantees of the convergences.\\n',\n",
              " '  This paper focuses on the relation between computational learning theory and\\nresource-bounded dimension. We intend to establish close connections between\\nthe learnability/nonlearnability of a concept class and its corresponding size\\nin terms of effective dimension, which will allow the use of powerful dimension\\ntechniques in computational learning and viceversa, the import of learning\\nresults into complexity via dimension. Firstly, we obtain a tight result on the\\ndimension of online mistake-bound learnable classes. Secondly, in relation with\\nPAC learning, we show that the polynomial-space dimension of PAC learnable\\nclasses of concepts is zero. This provides a hypothesis on effective dimension\\nthat implies the inherent unpredictability of concept classes (the classes that\\nverify this property are classes not efficiently PAC learnable using any\\nhypothesis). Thirdly, in relation to space dimension of classes that are\\nlearnable by membership query algorithms, the main result proves that\\npolynomial-space dimension of concept classes learnable by a membership-query\\nalgorithm is zero.\\n',\n",
              " '  Many combinatorial problems arising in machine learning can be reduced to the\\nproblem of minimizing a submodular function. Submodular functions are a natural\\ndiscrete analog of convex functions, and can be minimized in strongly\\npolynomial time. Unfortunately, state-of-the-art algorithms for general\\nsubmodular minimization are intractable for larger problems. In this paper, we\\nintroduce a novel subclass of submodular minimization problems that we call\\ndecomposable. Decomposable submodular functions are those that can be\\nrepresented as sums of concave functions applied to modular functions. We\\ndevelop an algorithm, SLG, that can efficiently minimize decomposable\\nsubmodular functions with tens of thousands of variables. Our algorithm\\nexploits recent results in smoothed convex minimization. We apply SLG to\\nsynthetic benchmarks and a joint classification-and-segmentation task, and show\\nthat it outperforms the state-of-the-art general purpose submodular\\nminimization algorithms by several orders of magnitude.\\n',\n",
              " \"  This report outlines the use of a relational representation in a Multi-Agent\\ndomain to model the behaviour of the whole system. A desired property in this\\nsystems is the ability of the team members to work together to achieve a common\\ngoal in a cooperative manner. The aim is to define a systematic method to\\nverify the effective collaboration among the members of a team and comparing\\nthe different multi-agent behaviours. Using external observations of a\\nMulti-Agent System to analyse, model, recognize agent behaviour could be very\\nuseful to direct team actions. In particular, this report focuses on the\\nchallenge of autonomous unsupervised sequential learning of the team's\\nbehaviour from observations. Our approach allows to learn a symbolic sequence\\n(a relational representation) to translate raw multi-agent, multi-variate\\nobservations of a dynamic, complex environment, into a set of sequential\\nbehaviours that are characteristic of the team in question, represented by a\\nset of sequences expressed in first-order logic atoms. We propose to use a\\nrelational learning algorithm to mine meaningful frequent patterns among the\\nrelational sequences to characterise team behaviours. We compared the\\nperformance of two teams in the RoboCup four-legged league environment, that\\nhave a very different approach to the game. One uses a Case Based Reasoning\\napproach, the other uses a pure reactive behaviour.\\n\",\n",
              " '  We propose a new approach to value function approximation which combines\\nlinear temporal difference reinforcement learning with subspace identification.\\nIn practical applications, reinforcement learning (RL) is complicated by the\\nfact that state is either high-dimensional or partially observable. Therefore,\\nRL methods are designed to work with features of state rather than state\\nitself, and the success or failure of learning is often determined by the\\nsuitability of the selected features. By comparison, subspace identification\\n(SSID) methods are designed to select a feature set which preserves as much\\ninformation as possible about state. In this paper we connect the two\\napproaches, looking at the problem of reinforcement learning with a large set\\nof features, each of which may only be marginally useful for value function\\napproximation. We introduce a new algorithm for this situation, called\\nPredictive State Temporal Difference (PSTD) learning. As in SSID for predictive\\nstate representations, PSTD finds a linear compression operator that projects a\\nlarge set of features down to a small set that preserves the maximum amount of\\npredictive information. As in RL, PSTD then uses a Bellman recursion to\\nestimate a value function. We discuss the connection between PSTD and prior\\napproaches in RL and SSID. We prove that PSTD is statistically consistent,\\nperform several experiments that illustrate its properties, and demonstrate its\\npotential on a difficult optimal stopping problem.\\n',\n",
              " \"  Gaussian graphical models are of great interest in statistical learning.\\nBecause the conditional independencies between different nodes correspond to\\nzero entries in the inverse covariance matrix of the Gaussian distribution, one\\ncan learn the structure of the graph by estimating a sparse inverse covariance\\nmatrix from sample data, by solving a convex maximum likelihood problem with an\\n$\\\\ell_1$-regularization term. In this paper, we propose a first-order method\\nbased on an alternating linearization technique that exploits the problem's\\nspecial structure; in particular, the subproblems solved in each iteration have\\nclosed-form solutions. Moreover, our algorithm obtains an $\\\\epsilon$-optimal\\nsolution in $O(1/\\\\epsilon)$ iterations. Numerical experiments on both synthetic\\nand real data from gene association networks show that a practical version of\\nthis algorithm outperforms other competitive algorithms.\\n\",\n",
              " '  However utilizing rich, interactive solutions can make learning more\\neffective and attractive, scenario- and game-based educational resources on the\\nweb are not widely used. Creating these applications is a complex, expensive\\nand challenging process. Development frameworks and authoring tools hardly\\nsupport reusable components, teamwork and learning management\\nsystem-independent courseware architecture. In this article we initiate the\\nconcept of a low-level, thick-client solution addressing these problems. With\\nsome example applications we try to demonstrate, how a framework, based on this\\nconcept can be useful for developing scenario- and game-based e-learning\\nenvironments.\\n',\n",
              " \"  We consider linear models for stochastic dynamics. To any such model can be\\nassociated a network (namely a directed graph) describing which degrees of\\nfreedom interact under the dynamics. We tackle the problem of learning such a\\nnetwork from observation of the system trajectory over a time interval $T$.\\n  We analyze the $\\\\ell_1$-regularized least squares algorithm and, in the\\nsetting in which the underlying network is sparse, we prove performance\\nguarantees that are \\\\emph{uniform in the sampling rate} as long as this is\\nsufficiently high. This result substantiates the notion of a well defined `time\\ncomplexity' for the network inference problem.\\n\",\n",
              " '  One of the key challenges in sensor networks is the extraction of information\\nby fusing data from a multitude of distinct, but possibly unreliable sensors.\\nRecovering information from the maximum number of dependable sensors while\\nspecifying the unreliable ones is critical for robust sensing. This sensing\\ntask is formulated here as that of finding the maximum number of feasible\\nsubsystems of linear equations, and proved to be NP-hard. Useful links are\\nestablished with compressive sampling, which aims at recovering vectors that\\nare sparse. In contrast, the signals here are not sparse, but give rise to\\nsparse residuals. Capitalizing on this form of sparsity, four sensing schemes\\nwith complementary strengths are developed. The first scheme is a convex\\nrelaxation of the original problem expressed as a second-order cone program\\n(SOCP). It is shown that when the involved sensing matrices are Gaussian and\\nthe reliable measurements are sufficiently many, the SOCP can recover the\\noptimal solution with overwhelming probability. The second scheme is obtained\\nby replacing the initial objective function with a concave one. The third and\\nfourth schemes are tailored for noisy sensor data. The noisy case is cast as a\\ncombinatorial problem that is subsequently surrogated by a (weighted) SOCP.\\nInterestingly, the derived cost functions fall into the framework of robust\\nmultivariate linear regression, while an efficient block-coordinate descent\\nalgorithm is developed for their minimization. The robust sensing capabilities\\nof all schemes are verified by simulated tests.\\n',\n",
              " \"  Nesterov's accelerated gradient methods (AGM) have been successfully applied\\nin many machine learning areas. However, their empirical performance on\\ntraining max-margin models has been inferior to existing specialized solvers.\\nIn this paper, we first extend AGM to strongly convex and composite objective\\nfunctions with Bregman style prox-functions. Our unifying framework covers both\\nthe $\\\\infty$-memory and 1-memory styles of AGM, tunes the Lipschiz constant\\nadaptively, and bounds the duality gap. Then we demonstrate various ways to\\napply this framework of methods to a wide range of machine learning problems.\\nEmphasis will be given on their rate of convergence and how to efficiently\\ncompute the gradient and optimize the models. The experimental results show\\nthat with our extensions AGM outperforms state-of-the-art solvers on max-margin\\nmodels.\\n\",\n",
              " '  Sequential prediction problems such as imitation learning, where future\\nobservations depend on previous predictions (actions), violate the common\\ni.i.d. assumptions made in statistical learning. This leads to poor performance\\nin theory and often in practice. Some recent approaches provide stronger\\nguarantees in this setting, but remain somewhat unsatisfactory as they train\\neither non-stationary or stochastic policies and require a large number of\\niterations. In this paper, we propose a new iterative algorithm, which trains a\\nstationary deterministic policy, that can be seen as a no regret algorithm in\\nan online learning setting. We show that any such no regret algorithm, combined\\nwith additional reduction assumptions, must find a policy with good performance\\nunder the distribution of observations it induces in such sequential settings.\\nWe demonstrate that this new approach outperforms previous approaches on two\\nchallenging imitation learning problems and a benchmark sequence labeling\\nproblem.\\n',\n",
              " '  In this paper we initiate the study of optimization of bandit type problems\\nin scenarios where the feedback of a play is not immediately known. This arises\\nnaturally in allocation problems which have been studied extensively in the\\nliterature, albeit in the absence of delays in the feedback. We study this\\nproblem in the Bayesian setting. In presence of delays, no solution with\\nprovable guarantees is known to exist with sub-exponential running time.\\n  We show that bandit problems with delayed feedback that arise in allocation\\nsettings can be forced to have significant structure, with a slight loss in\\noptimality. This structure gives us the ability to reason about the\\nrelationship of single arm policies to the entangled optimum policy, and\\neventually leads to a O(1) approximation for a significantly general class of\\npriors. The structural insights we develop are of key interest and carry over\\nto the setting where the feedback of an action is available instantaneously,\\nand we improve all previous results in this setting as well.\\n',\n",
              " \"  Suppose we would like to know all answers to a set of statistical queries C\\non a data set up to small error, but we can only access the data itself using\\nstatistical queries. A trivial solution is to exhaustively ask all queries in\\nC. Can we do any better?\\n  + We show that the number of statistical queries necessary and sufficient for\\nthis task is---up to polynomial factors---equal to the agnostic learning\\ncomplexity of C in Kearns' statistical query (SQ) model. This gives a complete\\nanswer to the question when running time is not a concern.\\n  + We then show that the problem can be solved efficiently (allowing arbitrary\\nerror on a small fraction of queries) whenever the answers to C can be\\ndescribed by a submodular function. This includes many natural concept classes,\\nsuch as graph cuts and Boolean disjunctions and conjunctions.\\n  While interesting from a learning theoretic point of view, our main\\napplications are in privacy-preserving data analysis:\\n  Here, our second result leads to the first algorithm that efficiently\\nreleases differentially private answers to of all Boolean conjunctions with 1%\\naverage error. This presents significant progress on a key open problem in\\nprivacy-preserving data analysis.\\n  Our first result on the other hand gives unconditional lower bounds on any\\ndifferentially private algorithm that admits a (potentially\\nnon-privacy-preserving) implementation using only statistical queries. Not only\\nour algorithms, but also most known private algorithms can be implemented using\\nonly statistical queries, and hence are constrained by these lower bounds. Our\\nresult therefore isolates the complexity of agnostic learning in the SQ-model\\nas a new barrier in the design of differentially private algorithms.\\n\",\n",
              " '  Suppose a given observation matrix can be decomposed as the sum of a low-rank\\nmatrix and a sparse matrix (outliers), and the goal is to recover these\\nindividual components from the observed sum. Such additive decompositions have\\napplications in a variety of numerical problems including system\\nidentification, latent variable graphical modeling, and principal components\\nanalysis. We study conditions under which recovering such a decomposition is\\npossible via a combination of $\\\\ell_1$ norm and trace norm minimization. We are\\nspecifically interested in the question of how many outliers are allowed so\\nthat convex programming can still achieve accurate recovery, and we obtain\\nstronger recovery guarantees than previous studies. Moreover, we do not assume\\nthat the spatial pattern of outliers is random, which stands in contrast to\\nrelated analyses under such assumptions via matrix completion.\\n',\n",
              " '  An importance weight quantifies the relative importance of one example over\\nanother, coming up in applications of boosting, asymmetric classification\\ncosts, reductions, and active learning. The standard approach for dealing with\\nimportance weights in gradient descent is via multiplication of the gradient.\\nWe first demonstrate the problems of this approach when importance weights are\\nlarge, and argue in favor of more sophisticated ways for dealing with them. We\\nthen develop an approach which enjoys an invariance property: that updating\\ntwice with importance weight $h$ is equivalent to updating once with importance\\nweight $2h$. For many important losses this has a closed form update which\\nsatisfies standard regret guarantees when all examples have $h=1$. We also\\nbriefly discuss two other reasonable approaches for handling large importance\\nweights. Empirically, these approaches yield substantially superior prediction\\nwith similar computational performance while reducing the sensitivity of the\\nalgorithm to the exact setting of the learning rate. We apply these to online\\nactive learning yielding an extraordinarily fast active learning algorithm that\\nworks even in the presence of adversarial noise.\\n',\n",
              " \"  Given a set of alternatives to be ranked, and some pairwise comparison data,\\nranking is a least squares computation on a graph. The vertices are the\\nalternatives, and the edge values comprise the comparison data. The basic idea\\nis very simple and old: come up with values on vertices such that their\\ndifferences match the given edge data. Since an exact match will usually be\\nimpossible, one settles for matching in a least squares sense. This formulation\\nwas first described by Leake in 1976 for rankingfootball teams and appears as\\nan example in Professor Gilbert Strang's classic linear algebra textbook. If\\none is willing to look into the residual a little further, then the problem\\nreally comes alive, as shown effectively by the remarkable recent paper of\\nJiang et al. With or without this twist, the humble least squares problem on\\ngraphs has far-reaching connections with many current areas ofresearch. These\\nconnections are to theoretical computer science (spectral graph theory, and\\nmultilevel methods for graph Laplacian systems); numerical analysis (algebraic\\nmultigrid, and finite element exterior calculus); other mathematics (Hodge\\ndecomposition, and random clique complexes); and applications (arbitrage, and\\nranking of sports teams). Not all of these connections are explored in this\\npaper, but many are. The underlying ideas are easy to explain, requiring only\\nthe four fundamental subspaces from elementary linear algebra. One of our aims\\nis to explain these basic ideas and connections, to get researchers in many\\nfields interested in this topic. Another aim is to use our numerical\\nexperiments for guidance on selecting methods and exposing the need for further\\ndevelopment.\\n\",\n",
              " '  We consider the celebrated Blackwell Approachability Theorem for two-player\\ngames with vector payoffs. We show that Blackwell\\'s result is equivalent, via\\nefficient reductions, to the existence of \"no-regret\" algorithms for Online\\nLinear Optimization. Indeed, we show that any algorithm for one such problem\\ncan be efficiently converted into an algorithm for the other. We provide a\\nuseful application of this reduction: the first efficient algorithm for\\ncalibrated forecasting.\\n',\n",
              " '  Active Learning Method (ALM) is a soft computing method which is used for\\nmodeling and control, based on fuzzy logic. Although ALM has shown that it acts\\nwell in dynamic environments, its operators cannot support it very well in\\ncomplex situations due to losing data. Thus ALM can find better membership\\nfunctions if more appropriate operators be chosen for it. This paper\\nsubstituted two new operators instead of ALM original ones; which consequently\\nrenewed finding membership functions in a way superior to conventional ALM.\\nThis new method is called Extended Active Learning Method (EALM).\\n',\n",
              " '  We herein introduce a new method of interpretable clustering that uses\\nunsupervised binary trees. It is a three-stage procedure, the first stage of\\nwhich entails a series of recursive binary splits to reduce the heterogeneity\\nof the data within the new subsamples. During the second stage (pruning),\\nconsideration is given to whether adjacent nodes can be aggregated. Finally,\\nduring the third stage (joining), similar clusters are joined together, even if\\nthey do not share the same parent originally. Consistency results are obtained,\\nand the procedure is used on simulated and real data sets.\\n',\n",
              " '  Multiple kernel learning (MKL), structured sparsity, and multi-task learning\\nhave recently received considerable attention. In this paper, we show how\\ndifferent MKL algorithms can be understood as applications of either\\nregularization on the kernel weights or block-norm-based regularization, which\\nis more common in structured sparsity and multi-task learning. We show that\\nthese two regularization strategies can be systematically mapped to each other\\nthrough a concave conjugate operation. When the kernel-weight-based regularizer\\nis separable into components, we can naturally consider a generative\\nprobabilistic model behind MKL. Based on this model, we propose learning\\nalgorithms for the kernel weights through the maximization of marginal\\nlikelihood. We show through numerical experiments that $\\\\ell_2$-norm MKL and\\nElastic-net MKL achieve comparable accuracy to uniform kernel combination.\\nAlthough uniform kernel combination might be preferable from its simplicity,\\n$\\\\ell_2$-norm MKL and Elastic-net MKL can learn the usefulness of the\\ninformation sources represented as kernels. In particular, Elastic-net MKL\\nachieves sparsity in the kernel weights.\\n',\n",
              " \"  We study online learnability of a wide class of problems, extending the\\nresults of (Rakhlin, Sridharan, Tewari, 2010) to general notions of performance\\nmeasure well beyond external regret. Our framework simultaneously captures such\\nwell-known notions as internal and general Phi-regret, learning with\\nnon-additive global cost functions, Blackwell's approachability, calibration of\\nforecasters, adaptive regret, and more. We show that learnability in all these\\nsituations is due to control of the same three quantities: a martingale\\nconvergence term, a term describing the ability to perform well if future is\\nknown, and a generalization of sequential Rademacher complexity, studied in\\n(Rakhlin, Sridharan, Tewari, 2010). Since we directly study complexity of the\\nproblem instead of focusing on efficient algorithms, we are able to improve and\\nextend many known results which have been previously derived via an algorithmic\\nconstruction.\\n\",\n",
              " '  Learning structured representations has emerged as an important problem in\\nmany domains, including document and Web data mining, bioinformatics, and image\\nanalysis. One approach to learning complex structures is to integrate many\\nsmaller, incomplete and noisy structure fragments. In this work, we present an\\nunsupervised probabilistic approach that extends affinity propagation to\\ncombine the small ontological fragments into a collection of integrated,\\nconsistent, and larger folksonomies. This is a challenging task because the\\nmethod must aggregate similar structures while avoiding structural\\ninconsistencies and handling noise. We validate the approach on a real-world\\nsocial media dataset, comprised of shallow personal hierarchies specified by\\nmany individual users, collected from the photosharing website Flickr. Our\\nempirical results show that our proposed approach is able to construct deeper\\nand denser structures, compared to an approach using only the standard affinity\\npropagation algorithm. Additionally, the approach yields better overall\\nintegration quality than a state-of-the-art approach based on incremental\\nrelational clustering.\\n',\n",
              " '  Recently, considerable research efforts have been devoted to the design of\\nmethods to learn from data overcomplete dictionaries for sparse coding.\\nHowever, learned dictionaries require the solution of an optimization problem\\nfor coding new data. In order to overcome this drawback, we propose an\\nalgorithm aimed at learning both a dictionary and its dual: a linear mapping\\ndirectly performing the coding. By leveraging on proximal methods, our\\nalgorithm jointly minimizes the reconstruction error of the dictionary and the\\ncoding error of its dual; the sparsity of the representation is induced by an\\n$\\\\ell_1$-based penalty on its coefficients. The results obtained on synthetic\\ndata and real images show that the algorithm is capable of recovering the\\nexpected dictionaries. Furthermore, on a benchmark dataset, we show that the\\nimage features obtained from the dual matrix yield state-of-the-art\\nclassification performance while being much less computational intensive.\\n',\n",
              " \"  This paper discusses clustering and latent semantic indexing (LSI) aspects of\\nthe singular value decomposition (SVD). The purpose of this paper is twofold.\\nThe first is to give an explanation on how and why the singular vectors can be\\nused in clustering. And the second is to show that the two seemingly unrelated\\nSVD aspects actually originate from the same source: related vertices tend to\\nbe more clustered in the graph representation of lower rank approximate matrix\\nusing the SVD than in the original semantic graph. Accordingly, the SVD can\\nimprove retrieval performance of an information retrieval system since queries\\nmade to the approximate matrix can retrieve more relevant documents and filter\\nout more irrelevant documents than the same queries made to the original\\nmatrix. By utilizing this fact, we will devise an LSI algorithm that mimicks\\nSVD capability in clustering related vertices. Convergence analysis shows that\\nthe algorithm is convergent and produces a unique solution for each input.\\nExperimental results using some standard datasets in LSI research show that\\nretrieval performances of the algorithm are comparable to the SVD's. In\\naddition, the algorithm is more practical and easier to use because there is no\\nneed to determine decomposition rank which is crucial in driving retrieval\\nperformance of the SVD.\\n\",\n",
              " '  In the classic multi-armed bandits problem, the goal is to have a policy for\\ndynamically operating arms that each yield stochastic rewards with unknown\\nmeans. The key metric of interest is regret, defined as the gap between the\\nexpected total reward accumulated by an omniscient player that knows the reward\\nmeans for each arm, and the expected total reward accumulated by the given\\npolicy. The policies presented in prior work have storage, computation and\\nregret all growing linearly with the number of arms, which is not scalable when\\nthe number of arms is large. We consider in this work a broad class of\\nmulti-armed bandits with dependent arms that yield rewards as a linear\\ncombination of a set of unknown parameters. For this general framework, we\\npresent efficient policies that are shown to achieve regret that grows\\nlogarithmically with time, and polynomially in the number of unknown parameters\\n(even though the number of dependent arms may grow exponentially). Furthermore,\\nthese policies only require storage that grows linearly in the number of\\nunknown parameters. We show that this generalization is broadly applicable and\\nuseful for many interesting tasks in networks that can be formulated as\\ntractable combinatorial optimization problems with linear objective functions,\\nsuch as maximum weight matching, shortest path, and minimum spanning tree\\ncomputations.\\n',\n",
              " '  In the classic Bayesian restless multi-armed bandit (RMAB) problem, there are\\n$N$ arms, with rewards on all arms evolving at each time as Markov chains with\\nknown parameters. A player seeks to activate $K \\\\geq 1$ arms at each time in\\norder to maximize the expected total reward obtained over multiple plays. RMAB\\nis a challenging problem that is known to be PSPACE-hard in general. We\\nconsider in this work the even harder non-Bayesian RMAB, in which the\\nparameters of the Markov chain are assumed to be unknown \\\\emph{a priori}. We\\ndevelop an original approach to this problem that is applicable when the\\ncorresponding Bayesian problem has the structure that, depending on the known\\nparameter values, the optimal solution is one of a prescribed finite set of\\npolicies. In such settings, we propose to learn the optimal policy for the\\nnon-Bayesian RMAB by employing a suitable meta-policy which treats each policy\\nfrom this finite set as an arm in a different non-Bayesian multi-armed bandit\\nproblem for which a single-arm selection policy is optimal. We demonstrate this\\napproach by developing a novel sensing policy for opportunistic spectrum access\\nover unknown dynamic channels. We prove that our policy achieves\\nnear-logarithmic regret (the difference in expected reward compared to a\\nmodel-aware genie), which leads to the same average reward that can be achieved\\nby the optimal policy under a known model. This is the first such result in the\\nliterature for a non-Bayesian RMAB.\\n',\n",
              " '  We consider the restless multi-armed bandit (RMAB) problem with unknown\\ndynamics in which a player chooses M out of N arms to play at each time. The\\nreward state of each arm transits according to an unknown Markovian rule when\\nit is played and evolves according to an arbitrary unknown random process when\\nit is passive. The performance of an arm selection policy is measured by\\nregret, defined as the reward loss with respect to the case where the player\\nknows which M arms are the most rewarding and always plays the M best arms. We\\nconstruct a policy with an interleaving exploration and exploitation epoch\\nstructure that achieves a regret with logarithmic order when arbitrary (but\\nnontrivial) bounds on certain system parameters are known. When no knowledge\\nabout the system is available, we show that the proposed policy achieves a\\nregret arbitrarily close to the logarithmic order. We further extend the\\nproblem to a decentralized setting where multiple distributed players share the\\narms without information exchange. Under both an exogenous restless model and\\nan endogenous restless model, we show that a decentralized extension of the\\nproposed policy preserves the logarithmic regret order as in the centralized\\nsetting. The results apply to adaptive learning in various dynamic systems and\\ncommunication networks, as well as financial investment.\\n',\n",
              " \"  We obtain a tight distribution-specific characterization of the sample\\ncomplexity of large-margin classification with L_2 regularization: We introduce\\nthe \\\\gamma-adapted-dimension, which is a simple function of the spectrum of a\\ndistribution's covariance matrix, and show distribution-specific upper and\\nlower bounds on the sample complexity, both governed by the\\n\\\\gamma-adapted-dimension of the source distribution. We conclude that this new\\nquantity tightly characterizes the true sample complexity of large-margin\\nclassification. The bounds hold for a rich family of sub-Gaussian\\ndistributions.\\n\",\n",
              " '  Many clustering schemes are defined by optimizing an objective function\\ndefined on the partitions of the underlying set of a finite metric space. In\\nthis paper, we construct a framework for studying what happens when we instead\\nimpose various structural conditions on the clustering schemes, under the\\ngeneral heading of functoriality. Functoriality refers to the idea that one\\nshould be able to compare the results of clustering algorithms as one varies\\nthe data set, for example by adding points or by applying functions to it. We\\nshow that within this framework, one can prove a theorems analogous to one of\\nJ. Kleinberg, in which for example one obtains an existence and uniqueness\\ntheorem instead of a non-existence result.\\n  We obtain a full classification of all clustering schemes satisfying a\\ncondition we refer to as excisiveness. The classification can be changed by\\nvarying the notion of maps of finite metric spaces. The conditions occur\\nnaturally when one considers clustering as the statistical version of the\\ngeometric notion of connected components. By varying the degree of\\nfunctoriality that one requires from the schemes it is possible to construct\\nricher families of clustering schemes that exhibit sensitivity to density.\\n',\n",
              " '  A large set of signals can sometimes be described sparsely using a\\ndictionary, that is, every element can be represented as a linear combination\\nof few elements from the dictionary. Algorithms for various signal processing\\napplications, including classification, denoising and signal separation, learn\\na dictionary from a set of signals to be represented. Can we expect that the\\nrepresentation found by such a dictionary for a previously unseen example from\\nthe same source will have L_2 error of the same magnitude as those for the\\ngiven examples? We assume signals are generated from a fixed distribution, and\\nstudy this questions from a statistical learning theory perspective.\\n  We develop generalization bounds on the quality of the learned dictionary for\\ntwo types of constraints on the coefficient selection, as measured by the\\nexpected L_2 error in representation when the dictionary is used. For the case\\nof l_1 regularized coefficient selection we provide a generalization bound of\\nthe order of O(sqrt(np log(m lambda)/m)), where n is the dimension, p is the\\nnumber of elements in the dictionary, lambda is a bound on the l_1 norm of the\\ncoefficient vector and m is the number of samples, which complements existing\\nresults. For the case of representing a new signal as a combination of at most\\nk dictionary elements, we provide a bound of the order O(sqrt(np log(m k)/m))\\nunder an assumption on the level of orthogonality of the dictionary (low Babel\\nfunction). We further show that this assumption holds for most dictionaries in\\nhigh dimensions in a strong probabilistic sense. Our results further yield fast\\nrates of order 1/m as opposed to 1/sqrt(m) using localized Rademacher\\ncomplexity. We provide similar results in a general setting using kernels with\\nweak smoothness requirements.\\n',\n",
              " '  The note presents a modified proof of a loss bound for the exponentially\\nweighted average forecaster with time-varying potential. The regret term of the\\nalgorithm is upper-bounded by sqrt{n ln(N)} (uniformly in n), where N is the\\nnumber of experts and n is the number of steps.\\n',\n",
              " '  Statistical models of natural stimuli provide an important tool for\\nresearchers in the fields of machine learning and computational neuroscience. A\\ncanonical way to quantitatively assess and compare the performance of\\nstatistical models is given by the likelihood. One class of statistical models\\nwhich has recently gained increasing popularity and has been applied to a\\nvariety of complex data are deep belief networks. Analyses of these models,\\nhowever, have been typically limited to qualitative analyses based on samples\\ndue to the computationally intractable nature of the model likelihood.\\nMotivated by these circumstances, the present article provides a consistent\\nestimator for the likelihood that is both computationally tractable and simple\\nto apply in practice. Using this estimator, a deep belief network which has\\nbeen suggested for the modeling of natural image patches is quantitatively\\ninvestigated and compared to other models of natural image patches. Contrary to\\nearlier claims based on qualitative results, the results presented in this\\narticle provide evidence that the model under investigation is not a\\nparticularly good model for natural images\\n',\n",
              " '  Imbalanced data sets containing much more background than signal instances\\nare very common in particle physics, and will also be characteristic for the\\nupcoming analyses of LHC data. Following up the work presented at ACAT 2008, we\\nuse the multivariate technique presented there (a rule growing algorithm with\\nthe meta-methods bagging and instance weighting) on much more imbalanced data\\nsets, especially a selection of D0 decays without the use of particle\\nidentification. It turns out that the quality of the result strongly depends on\\nthe number of background instances used for training. We discuss methods to\\nexploit this in order to improve the results significantly, and how to handle\\nand reduce the size of large training sets without loss of result quality in\\ngeneral. We will also comment on how to take into account statistical\\nfluctuation in receiver operation characteristic curves (ROC) for comparing\\nclassifier methods.\\n',\n",
              " \"  Recommendation systems are emerging as an important business application with\\nsignificant economic impact. Currently popular systems include Amazon's book\\nrecommendations, Netflix's movie recommendations, and Pandora's music\\nrecommendations. In this paper we address the problem of estimating\\nprobabilities associated with recommendation system data using non-parametric\\nkernel smoothing. In our estimation we interpret missing items as randomly\\ncensored observations and obtain efficient computation schemes using\\ncombinatorial properties of generating functions. We demonstrate our approach\\nwith several case studies involving real world movie recommendation data. The\\nresults are comparable with state-of-the-art techniques while also providing\\nprobabilistic preference estimates outside the scope of traditional recommender\\nsystems.\\n\",\n",
              " \"  We prove the following strong hardness result for learning: Given a\\ndistribution of labeled examples from the hypercube such that there exists a\\nmonomial consistent with $(1-\\\\eps)$ of the examples, it is NP-hard to find a\\nhalfspace that is correct on $(1/2+\\\\eps)$ of the examples, for arbitrary\\nconstants $\\\\eps > 0$. In learning theory terms, weak agnostic learning of\\nmonomials is hard, even if one is allowed to output a hypothesis from the much\\nbigger concept class of halfspaces. This hardness result subsumes a long line\\nof previous results, including two recent hardness results for the proper\\nlearning of monomials and halfspaces. As an immediate corollary of our result\\nwe show that weak agnostic learning of decision lists is NP-hard.\\n  Our techniques are quite different from previous hardness proofs for\\nlearning. We define distributions on positive and negative examples for\\nmonomials whose first few moments match. We use the invariance principle to\\nargue that regular halfspaces (all of whose coefficients have small absolute\\nvalue relative to the total $\\\\ell_2$ norm) cannot distinguish between\\ndistributions whose first few moments match. For highly non-regular subspaces,\\nwe use a structural lemma from recent work on fooling halfspaces to argue that\\nthey are ``junta-like'' and one can zero out all but the top few coefficients\\nwithout affecting the performance of the halfspace. The top few coefficients\\nform the natural list decoding of a halfspace in the context of dictatorship\\ntests/Label Cover reductions.\\n  We note that unlike previous invariance principle based proofs which are only\\nknown to give Unique-Games hardness, we are able to reduce from a version of\\nLabel Cover problem that is known to be NP-hard. This has inspired follow-up\\nwork on bypassing the Unique Games conjecture in some optimal geometric\\ninapproximability results.\\n\",\n",
              " '  The output of an association rule miner is often huge in practice. This is\\nwhy several concise lossless representations have been proposed, such as the\\n\"essential\" or \"representative\" rules. We revisit the algorithm given by\\nKryszkiewicz (Int. Symp. Intelligent Data Analysis 2001, Springer-Verlag LNCS\\n2189, 350-359) for mining representative rules. We show that its output is\\nsometimes incomplete, due to an oversight in its mathematical validation. We\\npropose alternative complete generators and we extend the approach to an\\nexisting closure-aware basis similar to, and often smaller than, the\\nrepresentative rules, namely the basis B*.\\n',\n",
              " '  The Border algorithm and the iPred algorithm find the Hasse diagrams of FCA\\nlattices. We show that they can be generalized to arbitrary lattices. In the\\ncase of iPred, this requires the identification of a join-semilattice\\nhomomorphism into a distributive lattice.\\n',\n",
              " '  Many problems in machine learning and statistics can be formulated as\\n(generalized) eigenproblems. In terms of the associated optimization problem,\\ncomputing linear eigenvectors amounts to finding critical points of a quadratic\\nfunction subject to quadratic constraints. In this paper we show that a certain\\nclass of constrained optimization problems with nonquadratic objective and\\nconstraints can be understood as nonlinear eigenproblems. We derive a\\ngeneralization of the inverse power method which is guaranteed to converge to a\\nnonlinear eigenvector. We apply the inverse power method to 1-spectral\\nclustering and sparse PCA which can naturally be formulated as nonlinear\\neigenproblems. In both applications we achieve state-of-the-art results in\\nterms of solution quality and runtime. Moving beyond the standard eigenproblem\\nshould be useful also in many other applications and our inverse power method\\ncan be easily adapted to new problems.\\n',\n",
              " '  Most of the existing information retrieval systems are based on bag of words\\nmodel and are not equipped with common world knowledge. Work has been done\\ntowards improving the efficiency of such systems by using intelligent\\nalgorithms to generate search queries, however, not much research has been done\\nin the direction of incorporating human-and-society level knowledge in the\\nqueries. This paper is one of the first attempts where such information is\\nincorporated into the search queries using Wikipedia semantics. The paper\\npresents an essential shift from conventional token based queries to concept\\nbased queries, leading to an enhanced efficiency of information retrieval\\nsystems. To efficiently handle the automated query learning problem, we propose\\nWikipedia-based Evolutionary Semantics (Wiki-ES) framework where concept based\\nqueries are learnt using a co-evolving evolutionary procedure. Learning concept\\nbased queries using an intelligent evolutionary procedure yields significant\\nimprovement in performance which is shown through an extensive study using\\nReuters newswire documents. Comparison of the proposed framework is performed\\nwith other information retrieval systems. Concept based approach has also been\\nimplemented on other information retrieval systems to justify the effectiveness\\nof a transition from token based queries to concept based queries.\\n',\n",
              " '  Many popular Bayesian nonparametric priors can be characterized in terms of\\nexchangeable species sampling sequences. However, in some applications,\\nexchangeability may not be appropriate. We introduce a {novel and\\nprobabilistically coherent family of non-exchangeable species sampling\\nsequences characterized by a tractable predictive probability function with\\nweights driven by a sequence of independent Beta random variables. We compare\\ntheir theoretical clustering properties with those of the Dirichlet Process and\\nthe two parameters Poisson-Dirichlet process. The proposed construction\\nprovides a complete characterization of the joint process, differently from\\nexisting work. We then propose the use of such process as prior distribution in\\na hierarchical Bayes modeling framework, and we describe a Markov Chain Monte\\nCarlo sampler for posterior inference. We evaluate the performance of the prior\\nand the robustness of the resulting inference in a simulation study, providing\\na comparison with popular Dirichlet Processes mixtures and Hidden Markov\\nModels. Finally, we develop an application to the detection of chromosomal\\naberrations in breast cancer by leveraging array CGH data.\\n',\n",
              " '  In practical applications, machine learning algorithms are often needed to\\nlearn classifiers that optimize domain specific performance measures.\\nPreviously, the research has focused on learning the needed classifier in\\nisolation, yet learning nonlinear classifier for nonlinear and nonsmooth\\nperformance measures is still hard. In this paper, rather than learning the\\nneeded classifier by optimizing specific performance measure directly, we\\ncircumvent this problem by proposing a novel two-step approach called as CAPO,\\nnamely to first train nonlinear auxiliary classifiers with existing learning\\nmethods, and then to adapt auxiliary classifiers for specific performance\\nmeasures. In the first step, auxiliary classifiers can be obtained efficiently\\nby taking off-the-shelf learning algorithms. For the second step, we show that\\nthe classifier adaptation problem can be reduced to a quadratic program\\nproblem, which is similar to linear SVMperf and can be efficiently solved. By\\nexploiting nonlinear auxiliary classifiers, CAPO can generate nonlinear\\nclassifier which optimizes a large variety of performance measures including\\nall the performance measure based on the contingency table and AUC, whilst\\nkeeping high computational efficiency. Empirical studies show that CAPO is\\neffective and of high computational efficiency, and even it is more efficient\\nthan linear SVMperf.\\n',\n",
              " '  We consider the problem of estimating the inverse covariance matrix by\\nmaximizing the likelihood function with a penalty added to encourage the\\nsparsity of the resulting matrix. We propose a new approach based on the split\\nBregman method to solve the regularized maximum likelihood estimation problem.\\nWe show that our method is significantly faster than the widely used graphical\\nlasso method, which is based on blockwise coordinate descent, on both\\nartificial and real-world data. More importantly, different from the graphical\\nlasso, the split Bregman based method is much more general, and can be applied\\nto a class of regularization terms other than the $\\\\ell_1$ norm\\n',\n",
              " '  Online prediction methods are typically presented as serial algorithms\\nrunning on a single processor. However, in the age of web-scale prediction\\nproblems, it is increasingly common to encounter situations where a single\\nprocessor cannot keep up with the high rate at which inputs arrive. In this\\nwork, we present the \\\\emph{distributed mini-batch} algorithm, a method of\\nconverting many serial gradient-based online prediction algorithms into\\ndistributed algorithms. We prove a regret bound for this method that is\\nasymptotically optimal for smooth convex loss functions and stochastic inputs.\\nMoreover, our analysis explicitly takes into account communication latencies\\nbetween nodes in the distributed environment. We show how our method can be\\nused to solve the closely-related distributed stochastic optimization problem,\\nachieving an asymptotically linear speed-up over multiple processors. Finally,\\nwe demonstrate the merits of our approach on a web-scale online prediction\\nproblem.\\n',\n",
              " '  The standard model of online prediction deals with serial processing of\\ninputs by a single processor. However, in large-scale online prediction\\nproblems, where inputs arrive at a high rate, an increasingly common necessity\\nis to distribute the computation across several processors. A non-trivial\\nchallenge is to design distributed algorithms for online prediction, which\\nmaintain good regret guarantees. In \\\\cite{DMB}, we presented the DMB algorithm,\\nwhich is a generic framework to convert any serial gradient-based online\\nprediction algorithm into a distributed algorithm. Moreover, its regret\\nguarantee is asymptotically optimal for smooth convex loss functions and\\nstochastic inputs. On the flip side, it is fragile to many types of failures\\nthat are common in distributed environments. In this companion paper, we\\npresent variants of the DMB algorithm, which are resilient to many types of\\nnetwork failures, and tolerant to varying performance of the computing nodes.\\n',\n",
              " '  We consider a class of sparsity-inducing regularization terms based on\\nsubmodular functions. While previous work has focused on non-decreasing\\nfunctions, we explore symmetric submodular functions and their \\\\lova\\nextensions. We show that the Lovasz extension may be seen as the convex\\nenvelope of a function that depends on level sets (i.e., the set of indices\\nwhose corresponding components of the underlying predictor are greater than a\\ngiven constant): this leads to a class of convex structured regularization\\nterms that impose prior knowledge on the level sets, and not only on the\\nsupports of the underlying predictors. We provide a unified set of optimization\\nalgorithms, such as proximal operators, and theoretical guarantees (allowed\\nlevel sets and recovery conditions). By selecting specific submodular\\nfunctions, we give a new interpretation to known norms, such as the total\\nvariation; we also define new norms, in particular ones that are based on order\\nstatistics with application to clustering and outlier detection, and on noisy\\ncuts in graphs with application to change point detection in the presence of\\noutliers.\\n',\n",
              " '  Knowledge Representation is important issue in reinforcement learning. In\\nthis paper, we bridge the gap between reinforcement learning and knowledge\\nrepresentation, by providing a rich knowledge representation framework, based\\non normal logic programs with answer set semantics, that is capable of solving\\nmodel-free reinforcement learning problems for more complex do-mains and\\nexploits the domain-specific knowledge. We prove the correctness of our\\napproach. We show that the complexity of finding an offline and online policy\\nfor a model-free reinforcement learning problem in our approach is NP-complete.\\nMoreover, we show that any model-free reinforcement learning problem in MDP\\nenvironment can be encoded as a SAT problem. The importance of that is\\nmodel-free reinforcement\\n',\n",
              " '  Recovering intrinsic data structure from corrupted observations plays an\\nimportant role in various tasks in the communities of machine learning and\\nsignal processing. In this paper, we propose a novel model, named log-sum\\nheuristic recovery (LHR), to learn the essential low-rank structure from\\ncorrupted data. Different from traditional approaches, which directly utilize\\n$\\\\ell_1$ norm to measure the sparseness, LHR introduces a more reasonable\\nlog-sum measurement to enhance the sparsity in both the intrinsic low-rank\\nstructure and in the sparse corruptions. Although the proposed LHR optimization\\nis no longer convex, it still can be effectively solved by a\\nmajorization-minimization (MM) type algorithm, with which the non-convex\\nobjective function is iteratively replaced by its convex surrogate and LHR\\nfinally falls into the general framework of reweighed approaches. We prove that\\nthe MM-type algorithm can converge to a stationary point after successive\\niteration. We test the performance of our proposed model by applying it to\\nsolve two typical problems: robust principal component analysis (RPCA) and\\nlow-rank representation (LRR).\\n  For RPCA, we compare LHR with the benchmark Principal Component Pursuit (PCP)\\nmethod from both the perspectives of simulations and practical applications.\\nFor LRR, we apply LHR to compute the low-rank representation matrix for motion\\nsegmentation and stock clustering. Experimental results on low rank structure\\nlearning demonstrate that the proposed Log-sum based model performs much better\\nthan the $\\\\ell_1$-based method on for data with higher rank and with denser\\ncorruptions.\\n',\n",
              " '  In a dynamic heterogeneous environment, such as pervasive and ubiquitous\\ncomputing, context-aware adaptation is a key concept to meet the varying\\nrequirements of different users. Connectivity is an important context source\\nthat can be utilized for optimal management of diverse networking resources.\\nApplication QoS (Quality of service) is another important issue that should be\\ntaken into consideration for design of a context-aware system. This paper\\npresents connectivity from the view point of context awareness, identifies\\nvarious relevant raw connectivity contexts, and discusses how high-level\\ncontext information can be abstracted from the raw context information.\\nFurther, rich context information is utilized in various policy representation\\nwith respect to user profile and preference, application characteristics,\\ndevice capability, and network QoS conditions. Finally, a context-aware\\nend-to-end evaluation algorithm is presented for adaptive connectivity\\nmanagement in a multi-access wireless network. Unlike the currently existing\\nalgorithms, the proposed algorithm takes into account user QoS parameters, and\\ntherefore, it is more practical.\\n',\n",
              " '  We present a tutorial on Bayesian optimization, a method of finding the\\nmaximum of expensive cost functions. Bayesian optimization employs the Bayesian\\ntechnique of setting a prior over the objective function and combining it with\\nevidence to get a posterior function. This permits a utility-based selection of\\nthe next observation to make on the objective function, which must take into\\naccount both exploration (sampling from areas of high uncertainty) and\\nexploitation (sampling areas likely to offer improvement over the current best\\nobservation). We also present two detailed extensions of Bayesian optimization,\\nwith experiments---active user modelling with preferences, and hierarchical\\nreinforcement learning---and a discussion of the pros and cons of Bayesian\\noptimization based on our experiences.\\n',\n",
              " '  Term weighting schemes often dominate the performance of many classifiers,\\nsuch as kNN, centroid-based classifier and SVMs. The widely used term weighting\\nscheme in text categorization, i.e., tf.idf, is originated from information\\nretrieval (IR) field. The intuition behind idf for text categorization seems\\nless reasonable than IR. In this paper, we introduce inverse category frequency\\n(icf) into term weighting scheme and propose two novel approaches, i.e., tf.icf\\nand icf-based supervised term weighting schemes. The tf.icf adopts icf to\\nsubstitute idf factor and favors terms occurring in fewer categories, rather\\nthan fewer documents. And the icf-based approach combines icf and relevance\\nfrequency (rf) to weight terms in a supervised way. Our cross-classifier and\\ncross-corpus experiments have shown that our proposed approaches are superior\\nor comparable to six supervised term weighting schemes and three traditional\\nschemes in terms of macro-F1 and micro-F1.\\n',\n",
              " '  We consider a combinatorial generalization of the classical multi-armed\\nbandit problem that is defined as follows. There is a given bipartite graph of\\n$M$ users and $N \\\\geq M$ resources. For each user-resource pair $(i,j)$, there\\nis an associated state that evolves as an aperiodic irreducible finite-state\\nMarkov chain with unknown parameters, with transitions occurring each time the\\nparticular user $i$ is allocated resource $j$. The user $i$ receives a reward\\nthat depends on the corresponding state each time it is allocated the resource\\n$j$. The system objective is to learn the best matching of users to resources\\nso that the long-term sum of the rewards received by all users is maximized.\\nThis corresponds to minimizing regret, defined here as the gap between the\\nexpected total reward that can be obtained by the best-possible static matching\\nand the expected total reward that can be achieved by a given algorithm. We\\npresent a polynomial-storage and polynomial-complexity-per-step\\nmatching-learning algorithm for this problem. We show that this algorithm can\\nachieve a regret that is uniformly arbitrarily close to logarithmic in time and\\npolynomial in the number of users and resources. This formulation is broadly\\napplicable to scheduling and switching problems in networks and significantly\\nextends prior results in the area.\\n',\n",
              " '  The diameter $k$-clustering problem is the problem of partitioning a finite\\nsubset of $\\\\mathbb{R}^d$ into $k$ subsets called clusters such that the maximum\\ndiameter of the clusters is minimized. One early clustering algorithm that\\ncomputes a hierarchy of approximate solutions to this problem (for all values\\nof $k$) is the agglomerative clustering algorithm with the complete linkage\\nstrategy. For decades, this algorithm has been widely used by practitioners.\\nHowever, it is not well studied theoretically. In this paper, we analyze the\\nagglomerative complete linkage clustering algorithm. Assuming that the\\ndimension $d$ is a constant, we show that for any $k$ the solution computed by\\nthis algorithm is an $O(\\\\log k)$-approximation to the diameter $k$-clustering\\nproblem. Our analysis does not only hold for the Euclidean distance but for any\\nmetric that is based on a norm. Furthermore, we analyze the closely related\\n$k$-center and discrete $k$-center problem. For the corresponding agglomerative\\nalgorithms, we deduce an approximation factor of $O(\\\\log k)$ as well.\\n',\n",
              " '  In this paper, we propose a two-timescale delay-optimal dynamic clustering\\nand power allocation design for downlink network MIMO systems. The dynamic\\nclustering control is adaptive to the global queue state information (GQSI)\\nonly and computed at the base station controller (BSC) over a longer time\\nscale. On the other hand, the power allocations of all the BSs in one cluster\\nare adaptive to both intra-cluster channel state information (CCSI) and\\nintra-cluster queue state information (CQSI), and computed at the cluster\\nmanager (CM) over a shorter time scale. We show that the two-timescale\\ndelay-optimal control can be formulated as an infinite-horizon average cost\\nConstrained Partially Observed Markov Decision Process (CPOMDP). By exploiting\\nthe special problem structure, we shall derive an equivalent Bellman equation\\nin terms of Pattern Selection Q-factor to solve the CPOMDP. To address the\\ndistributive requirement and the issue of exponential memory requirement and\\ncomputational complexity, we approximate the Pattern Selection Q-factor by the\\nsum of Per-cluster Potential functions and propose a novel distributive online\\nlearning algorithm to estimate the Per-cluster Potential functions (at each CM)\\nas well as the Lagrange multipliers (LM) (at each BS). We show that the\\nproposed distributive online learning algorithm converges almost surely (with\\nprobability 1). By exploiting the birth-death structure of the queue dynamics,\\nwe further decompose the Per-cluster Potential function into sum of Per-cluster\\nPer-user Potential functions and formulate the instantaneous power allocation\\nas a Per-stage QSI-aware Interference Game played among all the CMs. We also\\npropose a QSI-aware Simultaneous Iterative Water-filling Algorithm (QSIWFA) and\\nshow that it can achieve the Nash Equilibrium (NE).\\n',\n",
              " '  To attain the best learning accuracy, people move on with difficulties and\\nfrustrations. Though one can optimize the empirical objective using a given set\\nof samples, its generalization ability to the entire sample distribution\\nremains questionable. Even if a fair generalization guarantee is offered, one\\nstill wants to know what is to happen if the regularizer is removed, and/or how\\nwell the artificial loss (like the hinge loss) relates to the accuracy.\\n  For such reason, this report surveys four different trials towards the\\nlearning accuracy, embracing the major advances in supervised learning theory\\nin the past four years. Starting from the generic setting of learning, the\\nfirst two trials introduce the best optimization and generalization bounds for\\nconvex learning, and the third trial gets rid of the regularizer. As an\\ninnovative attempt, the fourth trial studies the optimization when the\\nobjective is exactly the accuracy, in the special case of binary\\nclassification. This report also analyzes the last trial through experiments.\\n',\n",
              " '  This report explores the use of machine learning techniques to accurately\\npredict travel times in city streets and highways using floating car data\\n(location information of user vehicles on a road network). The aim of this\\nreport is twofold, first we present a general architecture of solving this\\nproblem, then present and evaluate few techniques on real floating car data\\ngathered over a month on a 5 Km highway in New Delhi.\\n',\n",
              " '  This article discusses in detail the rating system that won the kaggle\\ncompetition \"Chess Ratings: Elo vs the rest of the world\". The competition\\nprovided a historical dataset of outcomes for chess games, and aimed to\\ndiscover whether novel approaches can predict the outcomes of future games,\\nmore accurately than the well-known Elo rating system. The winning rating\\nsystem, called Elo++ in the rest of the article, builds upon the Elo rating\\nsystem. Like Elo, Elo++ uses a single rating per player and predicts the\\noutcome of a game, by using a logistic curve over the difference in ratings of\\nthe players. The major component of Elo++ is a regularization technique that\\navoids overfitting these ratings. The dataset of chess games and outcomes is\\nrelatively small and one has to be careful not to draw \"too many conclusions\"\\nout of the limited data. Many approaches tested in the competition showed signs\\nof such an overfitting. The leader-board was dominated by attempts that did a\\nvery good job on a small test dataset, but couldn\\'t generalize well on the\\nprivate hold-out dataset. The Elo++ regularization takes into account the\\nnumber of games per player, the recency of these games and the ratings of the\\nopponents. Finally, Elo++ employs a stochastic gradient descent scheme for\\ntraining the ratings, and uses only two global parameters (white\\'s advantage\\nand regularization constant) that are optimized using cross-validation.\\n',\n",
              " '  We study the calibration process in circular ultrasound tomography devices\\nwhere the sensor positions deviate from the circumference of a perfect circle.\\nThis problem arises in a variety of applications in signal processing ranging\\nfrom breast imaging to sensor network localization. We introduce a novel method\\nof calibration/localization based on the time-of-flight (ToF) measurements\\nbetween sensors when the enclosed medium is homogeneous. In the presence of all\\nthe pairwise ToFs, one can easily estimate the sensor positions using\\nmulti-dimensional scaling (MDS) method. In practice however, due to the\\ntransitional behaviour of the sensors and the beam form of the transducers, the\\nToF measurements for close-by sensors are unavailable. Further, random\\nmalfunctioning of the sensors leads to random missing ToF measurements. On top\\nof the missing entries, in practice an unknown time delay is also added to the\\nmeasurements. In this work, we incorporate the fact that a matrix defined from\\nall the ToF measurements is of rank at most four. In order to estimate the\\nmissing ToFs, we apply a state-of-the-art low-rank matrix completion algorithm,\\nOPTSPACE . To find the correct positions of the sensors (our ultimate goal) we\\nthen apply MDS. We show analytic bounds on the overall error of the whole\\nprocess in the presence of noise and hence deduce its robustness. Finally, we\\nconfirm the functionality of our method in practice by simulations mimicking\\nthe measurements of a circular ultrasound tomography device.\\n',\n",
              " '  We show that the definition of neighbor in Markov random fields as defined by\\nBesag (1974) when the joint distribution of the sites is not positive is not\\nwell-defined. In a random field with finite number of sites we study the\\nconditions under which giving the value at extra sites will change the belief\\nof an agent about one site. Also the conditions under which the information\\nfrom some sites is equivalent to giving the value at all other sites is\\nstudied. These concepts provide an alternative to the concept of neighbor for\\ngeneral case where the positivity condition of the joint does not hold.\\n',\n",
              " '  In this theoretical paper we are concerned with the problem of learning a\\nvalue function by a smooth general function approximator, to solve a\\ndeterministic episodic control problem in a large continuous state space. It is\\nshown that learning the gradient of the value-function at every point along a\\ntrajectory generated by a greedy policy is a sufficient condition for the\\ntrajectory to be locally extremal, and often locally optimal, and we argue that\\nthis brings greater efficiency to value-function learning. This contrasts to\\ntraditional value-function learning in which the value-function must be learnt\\nover the whole of state space.\\n  It is also proven that policy-gradient learning applied to a greedy policy on\\na value-function produces a weight update equivalent to a value-gradient weight\\nupdate, which provides a surprising connection between these two alternative\\nparadigms of reinforcement learning, and a convergence proof for control\\nproblems with a value function represented by a general smooth function\\napproximator.\\n',\n",
              " '  We consider the problem of online linear regression on arbitrary\\ndeterministic sequences when the ambient dimension d can be much larger than\\nthe number of time rounds T. We introduce the notion of sparsity regret bound,\\nwhich is a deterministic online counterpart of recent risk bounds derived in\\nthe stochastic setting under a sparsity scenario. We prove such regret bounds\\nfor an online-learning algorithm called SeqSEW and based on exponential\\nweighting and data-driven truncation. In a second part we apply a\\nparameter-free version of this algorithm to the stochastic setting (regression\\nmodel with random design). This yields risk bounds of the same flavor as in\\nDalalyan and Tsybakov (2011) but which solve two questions left open therein.\\nIn particular our risk bounds are adaptive (up to a logarithmic factor) to the\\nunknown variance of the noise if the latter is Gaussian. We also address the\\nregression model with fixed design.\\n',\n",
              " '  The main purpose of Feature Subset Selection is to find a reduced subset of\\nattributes from a data set described by a feature set. The task of a feature\\nselection algorithm (FSA) is to provide with a computational solution motivated\\nby a certain definition of relevance or by a reliable evaluation measure. In\\nthis paper several fundamental algorithms are studied to assess their\\nperformance in a controlled experimental scenario. A measure to evaluate FSAs\\nis devised that computes the degree of matching between the output given by a\\nFSA and the known optimal solutions. An extensive experimental study on\\nsynthetic problems is carried out to assess the behaviour of the algorithms in\\nterms of solution accuracy and size as a function of the relevance,\\nirrelevance, redundancy and size of the data samples. The controlled\\nexperimental conditions facilitate the derivation of better-supported and\\nmeaningful conclusions.\\n',\n",
              " '  Kernel-based machine learning algorithms are based on mapping data from the\\noriginal input feature space to a kernel feature space of higher dimensionality\\nto solve a linear problem in that space. Over the last decade, kernel based\\nclassification and regression approaches such as support vector machines have\\nwidely been used in remote sensing as well as in various civil engineering\\napplications. In spite of their better performance with different datasets,\\nsupport vector machines still suffer from shortcomings such as\\nvisualization/interpretation of model, choice of kernel and kernel specific\\nparameter as well as the regularization parameter. Relevance vector machines\\nare another kernel based approach being explored for classification and\\nregression with in last few years. The advantages of the relevance vector\\nmachines over the support vector machines is the availability of probabilistic\\npredictions, using arbitrary kernel functions and not requiring setting of the\\nregularization parameter. This paper presents a state-of-the-art review of SVM\\nand RVM in remote sensing and provides some details of their use in other civil\\nengineering application also.\\n',\n",
              " '  This work is motivated by the problem of image mis-registration in remote\\nsensing and we are interested in determining the resulting loss in the accuracy\\nof pattern classification. A statistical formulation is given where we propose\\nto use data contamination to model and understand the phenomenon of image\\nmis-registration. This model is widely applicable to many other types of errors\\nas well, for example, measurement errors and gross errors etc. The impact of\\ndata contamination on classification is studied under a statistical learning\\ntheoretical framework. A closed-form asymptotic bound is established for the\\nresulting loss in classification accuracy, which is less than\\n$\\\\epsilon/(1-\\\\epsilon)$ for data contamination of an amount of $\\\\epsilon$. Our\\nbound is sharper than similar bounds in the domain adaptation literature and,\\nunlike such bounds, it applies to classifiers with an infinite\\nVapnik-Chervonekis (VC) dimension. Extensive simulations have been conducted on\\nboth synthetic and real datasets under various types of data contamination,\\nincluding label flipping, feature swapping and the replacement of feature\\nvalues with data generated from a random source such as a Gaussian or Cauchy\\ndistribution. Our simulation results show that the bound we derive is fairly\\ntight.\\n',\n",
              " '  In a Role-Playing Game, finding optimal trajectories is one of the most\\nimportant tasks. In fact, the strategy decision system becomes a key component\\nof a game engine. Determining the way in which decisions are taken (online,\\nbatch or simulated) and the consumed resources in decision making (e.g.\\nexecution time, memory) will influence, in mayor degree, the game performance.\\nWhen classical search algorithms such as A* can be used, they are the very\\nfirst option. Nevertheless, such methods rely on precise and complete models of\\nthe search space, and there are many interesting scenarios where their\\napplication is not possible. Then, model free methods for sequential decision\\nmaking under uncertainty are the best choice. In this paper, we propose a\\nheuristic planning strategy to incorporate the ability of heuristic-search in\\npath-finding into a Dyna agent. The proposed Dyna-H algorithm, as A* does,\\nselects branches more likely to produce outcomes than other branches. Besides,\\nit has the advantages of being a model-free online reinforcement learning\\nalgorithm. The proposal was evaluated against the one-step Q-Learning and\\nDyna-Q algorithms obtaining excellent experimental results: Dyna-H\\nsignificantly overcomes both methods in all experiments. We suggest also, a\\nfunctional analogy between the proposed sampling from worst trajectories\\nheuristic and the role of dreams (e.g. nightmares) in human behavior.\\n',\n",
              " '  An important part of problems in statistical physics and computer science can\\nbe expressed as the computation of marginal probabilities over a Markov Random\\nField. The belief propagation algorithm, which is an exact procedure to compute\\nthese marginals when the underlying graph is a tree, has gained its popularity\\nas an efficient way to approximate them in the more general case. In this\\npaper, we focus on an aspect of the algorithm that did not get that much\\nattention in the literature, which is the effect of the normalization of the\\nmessages. We show in particular that, for a large class of normalization\\nstrategies, it is possible to focus only on belief convergence. Following this,\\nwe express the necessary and sufficient conditions for local stability of a\\nfixed point in terms of the graph structure and the beliefs values at the fixed\\npoint. We also explicit some connexion between the normalization constants and\\nthe underlying Bethe Free Energy.\\n',\n",
              " '  We theoretically study semi-supervised clustering in sparse graphs in the\\npresence of pairwise constraints on the cluster assignments of nodes. We focus\\non bi-cluster graphs, and study the impact of semi-supervision for varying\\nconstraint density and overlap between the clusters. Recent results for\\nunsupervised clustering in sparse graphs indicate that there is a critical\\nratio of within-cluster and between-cluster connectivities below which clusters\\ncannot be recovered with better than random accuracy. The goal of this paper is\\nto examine the impact of pairwise constraints on the clustering accuracy. Our\\nresults suggests that the addition of constraints does not provide automatic\\nimprovement over the unsupervised case. When the density of the constraints is\\nsufficiently small, their only impact is to shift the detection threshold while\\npreserving the criticality. Conversely, if the density of (hard) constraints is\\nabove the percolation threshold, the criticality is suppressed and the\\ndetection threshold disappears.\\n',\n",
              " '  Targeting at sparse learning, we construct Banach spaces B of functions on an\\ninput space X with the properties that (1) B possesses an l1 norm in the sense\\nthat it is isometrically isomorphic to the Banach space of integrable functions\\non X with respect to the counting measure; (2) point evaluations are continuous\\nlinear functionals on B and are representable through a bilinear form with a\\nkernel function; (3) regularized learning schemes on B satisfy the linear\\nrepresenter theorem. Examples of kernel functions admissible for the\\nconstruction of such spaces are given.\\n',\n",
              " '  A typical approach in estimating the learning rate of a regularized learning\\nscheme is to bound the approximation error by the sum of the sampling error,\\nthe hypothesis error and the regularization error. Using a reproducing kernel\\nspace that satisfies the linear representer theorem brings the advantage of\\ndiscarding the hypothesis error from the sum automatically. Following this\\ndirection, we illustrate how reproducing kernel Banach spaces with the l1 norm\\ncan be applied to improve the learning rate estimate of l1-regularization in\\nmachine learning.\\n',\n",
              " '  We consider a retailer selling a single product with limited on-hand\\ninventory over a finite selling season. Customer demand arrives according to a\\nPoisson process, the rate of which is influenced by a single action taken by\\nthe retailer (such as price adjustment, sales commission, advertisement\\nintensity, etc.). The relationship between the action and the demand rate is\\nnot known in advance. However, the retailer is able to learn the optimal action\\n\"on the fly\" as she maximizes her total expected revenue based on the observed\\ndemand reactions.\\n  Using the pricing problem as an example, we propose a dynamic\\n\"learning-while-doing\" algorithm that only involves function value estimation\\nto achieve a near-optimal performance. Our algorithm employs a series of\\nshrinking price intervals and iteratively tests prices within that interval\\nusing a set of carefully chosen parameters. We prove that the convergence rate\\nof our algorithm is among the fastest of all possible algorithms in terms of\\nasymptotic \"regret\" (the relative loss comparing to the full information\\noptimal solution). Our result closes the performance gaps between parametric\\nand non-parametric learning and between a post-price mechanism and a\\ncustomer-bidding mechanism. Important managerial insight from this research is\\nthat the values of information on both the parametric form of the demand\\nfunction as well as each customer\\'s exact reservation price are less important\\nthan prior literature suggests. Our results also suggest that firms would be\\nbetter off to perform dynamic learning and action concurrently rather than\\nsequentially.\\n',\n",
              " '  In this paper, an Entropy functional based online Adaptive Decision Fusion\\n(EADF) framework is developed for image analysis and computer vision\\napplications. In this framework, it is assumed that the compound algorithm\\nconsists of several sub-algorithms each of which yielding its own decision as a\\nreal number centered around zero, representing the confidence level of that\\nparticular sub-algorithm. Decision values are linearly combined with weights\\nwhich are updated online according to an active fusion method based on\\nperforming entropic projections onto convex sets describing sub-algorithms. It\\nis assumed that there is an oracle, who is usually a human operator, providing\\nfeedback to the decision fusion method. A video based wildfire detection system\\nis developed to evaluate the performance of the algorithm in handling the\\nproblems where data arrives sequentially. In this case, the oracle is the\\nsecurity guard of the forest lookout tower verifying the decision of the\\ncombined algorithm. Simulation results are presented. The EADF framework is\\nalso tested with a standard dataset.\\n',\n",
              " '  Boosting combines weak learners into a predictor with low empirical risk. Its\\ndual constructs a high entropy distribution upon which weak learners and\\ntraining labels are uncorrelated. This manuscript studies this primal-dual\\nrelationship under a broad family of losses, including the exponential loss of\\nAdaBoost and the logistic loss, revealing:\\n  - Weak learnability aids the whole loss family: for any {\\\\epsilon}>0,\\nO(ln(1/{\\\\epsilon})) iterations suffice to produce a predictor with empirical\\nrisk {\\\\epsilon}-close to the infimum;\\n  - The circumstances granting the existence of an empirical risk minimizer may\\nbe characterized in terms of the primal and dual problems, yielding a new proof\\nof the known rate O(ln(1/{\\\\epsilon}));\\n  - Arbitrary instances may be decomposed into the above two, granting rate\\nO(1/{\\\\epsilon}), with a matching lower bound provided for the logistic loss.\\n',\n",
              " '  Different features have different relevance to a particular learning problem.\\nSome features are less relevant; while some very important. Instead of\\nselecting the most relevant features using feature selection, an algorithm can\\nbe given this knowledge of feature importance based on expert opinion or prior\\nlearning. Learning can be faster and more accurate if learners take feature\\nimportance into account. Correlation aided Neural Networks (CANN) is presented\\nwhich is such an algorithm. CANN treats feature importance as the correlation\\ncoefficient between the target attribute and the features. CANN modifies normal\\nfeed-forward Neural Network to fit both correlation values and training data.\\nEmpirical evaluation shows that CANN is faster and more accurate than applying\\nthe two step approach of feature selection and then using normal learning\\nalgorithms.\\n',\n",
              " '  Hybrid learning methods use theoretical knowledge of a domain and a set of\\nclassified examples to develop a method for classification. Methods that use\\ndomain knowledge have been shown to perform better than inductive learners.\\nHowever, there is no general method to include domain knowledge into all\\ninductive learning algorithms as all hybrid methods are highly specialized for\\na particular algorithm. We present an algorithm that will take domain knowledge\\nin the form of propositional rules, generate artificial examples from the rules\\nand also remove instances likely to be flawed. This enriched dataset then can\\nbe used by any learning algorithm. Experimental results of different scenarios\\nare shown that demonstrate this method to be more effective than simple\\ninductive learning.\\n',\n",
              " '  This article presents a model which is capable of learning and abstracting\\nnew concepts based on comparing observations and finding the resemblance\\nbetween the observations. In the model, the new observations are compared with\\nthe templates which have been derived from the previous experiences. In the\\nfirst stage, the objects are first represented through a geometric description\\nwhich is used for finding the object boundaries and a descriptor which is\\ninspired by the human visual system and then they are fed into the model. Next,\\nthe new observations are identified through comparing them with the\\npreviously-learned templates and are used for producing new templates. The\\ncomparisons are made based on measures like Euclidean or correlation distance.\\nThe new template is created by applying onion-pealing algorithm. The algorithm\\nconsecutively uses convex hulls which are made by the points representing the\\nobjects. If the new observation is remarkably similar to one of the observed\\ncategories, it is no longer utilized in creating a new template. The existing\\ntemplates are used to provide a description of the new observation. This\\ndescription is provided in the templates space. Each template represents a\\ndimension of the feature space. The degree of the resemblance each template\\nbears to each object indicates the value associated with the object in that\\ndimension of the templates space. In this way, the description of the new\\nobservation becomes more accurate and detailed as the time passes and the\\nexperiences increase. We have used this model for learning and recognizing the\\nnew polygons in the polygon space. Representing the polygons was made possible\\nthrough employing a geometric method and a method inspired by human visual\\nsystem. Various implementations of the model have been compared. The evaluation\\nresults of the model prove its efficiency in learning and deriving new\\ntemplates.\\n',\n",
              " '  Learning latent structure in complex networks has become an important problem\\nfueled by many types of networked data originating from practically all fields\\nof science. In this paper, we propose a new non-parametric Bayesian\\nmultiple-membership latent feature model for networks. Contrary to existing\\nmultiple-membership models that scale quadratically in the number of vertices\\nthe proposed model scales linearly in the number of links admitting\\nmultiple-membership analysis in large scale networks. We demonstrate a\\nconnection between the single membership relational model and multiple\\nmembership models and show on \"real\" size benchmark network data that\\naccounting for multiple memberships improves the learning of latent structure\\nas measured by link prediction while explicitly accounting for multiple\\nmembership result in a more compact representation of the latent structure of\\nnetworks.\\n',\n",
              " '  Many methods have been developed for data clustering, such as k-means,\\nexpectation maximization and algorithms based on graph theory. In this latter\\ncase, graphs are generally constructed by taking into account the Euclidian\\ndistance as a similarity measure, and partitioned using spectral methods.\\nHowever, these methods are not accurate when the clusters are not well\\nseparated. In addition, it is not possible to automatically determine the\\nnumber of clusters. These limitations can be overcome by taking into account\\nnetwork community identification algorithms. In this work, we propose a\\nmethodology for data clustering based on complex networks theory. We compare\\ndifferent metrics for quantifying the similarity between objects and take into\\naccount three community finding techniques. This approach is applied to two\\nreal-world databases and to two sets of artificially generated data. By\\ncomparing our method with traditional clustering approaches, we verify that the\\nproximity measures given by the Chebyshev and Manhattan distances are the most\\nsuitable metrics to quantify the similarity between objects. In addition, the\\ncommunity identification method based on the greedy optimization provides the\\nsmallest misclassification rates.\\n',\n",
              " '  Recent research in multi-robot exploration and mapping has focused on\\nsampling environmental fields, which are typically modeled using the Gaussian\\nprocess (GP). Existing information-theoretic exploration strategies for\\nlearning GP-based environmental field maps adopt the non-Markovian problem\\nstructure and consequently scale poorly with the length of history of\\nobservations. Hence, it becomes computationally impractical to use these\\nstrategies for in situ, real-time active sampling. To ease this computational\\nburden, this paper presents a Markov-based approach to efficient\\ninformation-theoretic path planning for active sampling of GP-based fields. We\\nanalyze the time complexity of solving the Markov-based path planning problem,\\nand demonstrate analytically that it scales better than that of deriving the\\nnon-Markovian strategies with increasing length of planning horizon. For a\\nclass of exploration tasks called the transect sampling task, we provide\\ntheoretical guarantees on the active sampling performance of our Markov-based\\npolicy, from which ideal environmental field conditions and sampling task\\nsettings can be established to limit its performance degradation due to\\nviolation of the Markov assumption. Empirical evaluation on real-world\\ntemperature and plankton density field data shows that our Markov-based policy\\ncan generally achieve active sampling performance comparable to that of the\\nwidely-used non-Markovian greedy policies under less favorable realistic field\\nconditions and task settings while enjoying significant computational gain over\\nthem.\\n',\n",
              " \"  The idea that many important classes of signals can be well-represented by\\nlinear combinations of a small set of atoms selected from a given dictionary\\nhas had dramatic impact on the theory and practice of signal processing. For\\npractical problems in which an appropriate sparsifying dictionary is not known\\nahead of time, a very popular and successful heuristic is to search for a\\ndictionary that minimizes an appropriate sparsity surrogate over a given set of\\nsample data. While this idea is appealing, the behavior of these algorithms is\\nlargely a mystery; although there is a body of empirical evidence suggesting\\nthey do learn very effective representations, there is little theory to\\nguarantee when they will behave correctly, or when the learned dictionary can\\nbe expected to generalize. In this paper, we take a step towards such a theory.\\nWe show that under mild hypotheses, the dictionary learning problem is locally\\nwell-posed: the desired solution is indeed a local minimum of the $\\\\ell^1$\\nnorm. Namely, if $\\\\mb A \\\\in \\\\Re^{m \\\\times n}$ is an incoherent (and possibly\\novercomplete) dictionary, and the coefficients $\\\\mb X \\\\in \\\\Re^{n \\\\times p}$\\nfollow a random sparse model, then with high probability $(\\\\mb A,\\\\mb X)$ is a\\nlocal minimum of the $\\\\ell^1$ norm over the manifold of factorizations $(\\\\mb\\nA',\\\\mb X')$ satisfying $\\\\mb A' \\\\mb X' = \\\\mb Y$, provided the number of samples\\n$p = \\\\Omega(n^3 k)$. For overcomplete $\\\\mb A$, this is the first result showing\\nthat the dictionary learning problem is locally solvable. Our analysis draws on\\ntools developed for the problem of completing a low-rank matrix from a small\\nsubset of its entries, which allow us to overcome a number of technical\\nobstacles; in particular, the absence of the restricted isometry property.\\n\",\n",
              " '  A novel framework of compressed sensing, namely statistical compressed\\nsensing (SCS), that aims at efficiently sampling a collection of signals that\\nfollow a statistical distribution, and achieving accurate reconstruction on\\naverage, is introduced. SCS based on Gaussian models is investigated in depth.\\nFor signals that follow a single Gaussian model, with Gaussian or Bernoulli\\nsensing matrices of O(k) measurements, considerably smaller than the O(k\\nlog(N/k)) required by conventional CS based on sparse models, where N is the\\nsignal dimension, and with an optimal decoder implemented via linear filtering,\\nsignificantly faster than the pursuit decoders applied in conventional CS, the\\nerror of SCS is shown tightly upper bounded by a constant times the best k-term\\napproximation error, with overwhelming probability. The failure probability is\\nalso significantly smaller than that of conventional sparsity-oriented CS.\\nStronger yet simpler results further show that for any sensing matrix, the\\nerror of Gaussian SCS is upper bounded by a constant times the best k-term\\napproximation with probability one, and the bound constant can be efficiently\\ncalculated. For Gaussian mixture models (GMMs), that assume multiple Gaussian\\ndistributions and that each signal follows one of them with an unknown index, a\\npiecewise linear estimator is introduced to decode SCS. The accuracy of model\\nselection, at the heart of the piecewise linear decoder, is analyzed in terms\\nof the properties of the Gaussian distributions and the number of sensing\\nmeasurements. A maximum a posteriori expectation-maximization algorithm that\\niteratively estimates the Gaussian models parameters, the signals model\\nselection, and decodes the signals, is presented for GMM-based SCS. In real\\nimage sensing applications, GMM-based SCS is shown to lead to improved results\\ncompared to conventional CS, at a considerably lower computational cost.\\n',\n",
              " '  We develop a novel method, based on the statistical concept of the\\nVapnik-Chervonenkis dimension, to evaluate the selectivity (output cardinality)\\nof SQL queries - a crucial step in optimizing the execution of large scale\\ndatabase and data-mining operations. The major theoretical contribution of this\\nwork, which is of independent interest, is an explicit bound to the\\nVC-dimension of a range space defined by all possible outcomes of a collection\\n(class) of queries. We prove that the VC-dimension is a function of the maximum\\nnumber of Boolean operations in the selection predicate and of the maximum\\nnumber of select and join operations in any individual query in the collection,\\nbut it is neither a function of the number of queries in the collection nor of\\nthe size (number of tuples) of the database. We leverage on this result and\\ndevelop a method that, given a class of queries, builds a concise random sample\\nof a database, such that with high probability the execution of any query in\\nthe class on the sample provides an accurate estimate for the selectivity of\\nthe query on the original large database. The error probability holds\\nsimultaneously for the selectivity estimates of all queries in the collection,\\nthus the same sample can be used to evaluate the selectivity of multiple\\nqueries, and the sample needs to be refreshed only following major changes in\\nthe database. The sample representation computed by our method is typically\\nsufficiently small to be stored in main memory. We present extensive\\nexperimental results, validating our theoretical analysis and demonstrating the\\nadvantage of our technique when compared to complex selectivity estimation\\ntechniques used in PostgreSQL and the Microsoft SQL Server.\\n',\n",
              " '  This paper proposes a new distance metric between clusterings that\\nincorporates information about the spatial distribution of points and clusters.\\nOur approach builds on the idea of a Hilbert space-based representation of\\nclusters as a combination of the representations of their constituent points.\\nWe use this representation and the underlying metric to design a\\nspatially-aware consensus clustering procedure. This consensus procedure is\\nimplemented via a novel reduction to Euclidean clustering, and is both simple\\nand efficient. All of our results apply to both soft and hard clusterings. We\\naccompany these algorithms with a detailed experimental evaluation that\\ndemonstrates the efficiency and quality of our techniques.\\n',\n",
              " '  Recent advances in tissue microarray technology have allowed\\nimmunohistochemistry to become a powerful medium-to-high throughput analysis\\ntool, particularly for the validation of diagnostic and prognostic biomarkers.\\nHowever, as study size grows, the manual evaluation of these assays becomes a\\nprohibitive limitation; it vastly reduces throughput and greatly increases\\nvariability and expense. We propose an algorithm - Tissue Array Co-Occurrence\\nMatrix Analysis (TACOMA) - for quantifying cellular phenotypes based on\\ntextural regularity summarized by local inter-pixel relationships. The\\nalgorithm can be easily trained for any staining pattern, is absent of\\nsensitive tuning parameters and has the ability to report salient pixels in an\\nimage that contribute to its score. Pathologists\\' input via informative\\ntraining patches is an important aspect of the algorithm that allows the\\ntraining for any specific marker or cell type. With co-training, the error rate\\nof TACOMA can be reduced substantially for a very small training sample (e.g.,\\nwith size 30). We give theoretical insights into the success of co-training via\\nthinning of the feature set in a high-dimensional setting when there is\\n\"sufficient\" redundancy among the features. TACOMA is flexible, transparent and\\nprovides a scoring process that can be evaluated with clarity and confidence.\\nIn a study based on an estrogen receptor (ER) marker, we show that TACOMA is\\ncomparable to, or outperforms, pathologists\\' performance in terms of accuracy\\nand repeatability.\\n',\n",
              " '  It is a challenging task to select correlated variables in a high dimensional\\nspace. To address this challenge, the elastic net has been developed and\\nsuccessfully applied to many applications. Despite its great success, the\\nelastic net does not explicitly use correlation information embedded in data to\\nselect correlated variables. To overcome this limitation, we present a novel\\nBayesian hybrid model, the EigenNet, that uses the eigenstructures of data to\\nguide variable selection. Specifically, it integrates a sparse conditional\\nclassification model with a generative model capturing variable correlations in\\na principled Bayesian framework. We reparameterize the hybrid model in the\\neigenspace to avoid overfiting and to increase the computational efficiency of\\nits MCMC sampler. Furthermore, we provide an alternative view to the EigenNet\\nfrom a regularization perspective: the EigenNet has an adaptive\\neigenspace-based composite regularizer, which naturally generalizes the\\n$l_{1/2}$ regularizer used by the elastic net. Experiments on synthetic and\\nreal data show that the EigenNet significantly outperforms the lasso, the\\nelastic net, and the Bayesian lasso in terms of prediction accuracy, especially\\nwhen the number of training samples is smaller than the number of variables.\\n',\n",
              " '  The ability to predict the intentions of people based solely on their visual\\nactions is a skill only performed by humans and animals. The intelligence of\\ncurrent computer algorithms has not reached this level of complexity, but there\\nare several research efforts that are working towards it. With the number of\\nclassification algorithms available, it is hard to determine which algorithm\\nworks best for a particular situation. In classification of visual human intent\\ndata, Hidden Markov Models (HMM), and their variants, are leading candidates.\\n  The inability of HMMs to provide a probability in the observation to\\nobservation linkages is a big downfall in this classification technique. If a\\nperson is visually identifying an action of another person, they monitor\\npatterns in the observations. By estimating the next observation, people have\\nthe ability to summarize the actions, and thus determine, with pretty good\\naccuracy, the intention of the person performing the action. These visual cues\\nand linkages are important in creating intelligent algorithms for determining\\nhuman actions based on visual observations.\\n  The Evidence Feed Forward Hidden Markov Model is a newly developed algorithm\\nwhich provides observation to observation linkages. The following research\\naddresses the theory behind Evidence Feed Forward HMMs, provides mathematical\\nproofs of their learning of these parameters to optimize the likelihood of\\nobservations with a Evidence Feed Forwards HMM, which is important in all\\ncomputational intelligence algorithm, and gives comparative examples with\\nstandard HMMs in classification of both visual action data and measurement\\ndata; thus providing a strong base for Evidence Feed Forward HMMs in\\nclassification of many types of problems.\\n',\n",
              " \"  We present and study an agent-based model of T-Cell cross-regulation in the\\nadaptive immune system, which we apply to binary classification. Our method\\nexpands an existing analytical model of T-cell cross-regulation (Carneiro et\\nal. in Immunol Rev 216(1):48-68, 2007) that was used to study the\\nself-organizing dynamics of a single population of T-Cells in interaction with\\nan idealized antigen presenting cell capable of presenting a single antigen.\\nWith agent-based modeling we are able to study the self-organizing dynamics of\\nmultiple populations of distinct T-cells which interact via antigen presenting\\ncells that present hundreds of distinct antigens. Moreover, we show that such\\nself-organizing dynamics can be guided to produce an effective binary\\nclassification of antigens, which is competitive with existing machine learning\\nmethods when applied to biomedical text classification. More specifically, here\\nwe test our model on a dataset of publicly available full-text biomedical\\narticles provided by the BioCreative challenge (Krallinger in The biocreative\\nii. 5 challenge overview, p 19, 2009). We study the robustness of our model's\\nparameter configurations, and show that it leads to encouraging results\\ncomparable to state-of-the-art classifiers. Our results help us understand both\\nT-cell cross-regulation as a general principle of guided self-organization, as\\nwell as its applicability to document classification. Therefore, we show that\\nour bio-inspired algorithm is a promising novel method for biomedical article\\nclassification and for binary document classification in general.\\n\",\n",
              " '  We present an asymptotically exact analysis of the problem of detecting\\ncommunities in sparse random networks. Our results are also applicable to\\ndetection of functional modules, partitions, and colorings in noisy planted\\nmodels. Using a cavity method analysis, we unveil a phase transition from a\\nregion where the original group assignment is undetectable to one where\\ndetection is possible. In some cases, the detectable region splits into an\\nalgorithmically hard region and an easy one. Our approach naturally translates\\ninto a practical algorithm for detecting modules in sparse networks, and\\nlearning the parameters of the underlying model.\\n',\n",
              " '  This paper studies the construction of a refinement kernel for a given\\noperator-valued reproducing kernel such that the vector-valued reproducing\\nkernel Hilbert space of the refinement kernel contains that of the given one as\\na subspace. The study is motivated from the need of updating the current\\noperator-valued reproducing kernel in multi-task learning when underfitting or\\noverfitting occurs. Numerical simulations confirm that the established\\nrefinement kernel method is able to meet this need. Various characterizations\\nare provided based on feature maps and vector-valued integral representations\\nof operator-valued reproducing kernels. Concrete examples of refining\\ntranslation invariant and finite Hilbert-Schmidt operator-valued reproducing\\nkernels are provided. Other examples include refinement of Hessian of\\nscalar-valued translation-invariant kernels and transformation kernels.\\nExistence and properties of operator-valued reproducing kernels preserved\\nduring the refinement process are also investigated.\\n',\n",
              " \"  Prediction markets are used in real life to predict outcomes of interest such\\nas presidential elections. This paper presents a mathematical theory of\\nartificial prediction markets for supervised learning of conditional\\nprobability estimators. The artificial prediction market is a novel method for\\nfusing the prediction information of features or trained classifiers, where the\\nfusion result is the contract price on the possible outcomes. The market can be\\ntrained online by updating the participants' budgets using training examples.\\nInspired by the real prediction markets, the equations that govern the market\\nare derived from simple and reasonable assumptions. Efficient numerical\\nalgorithms are presented for solving these equations. The obtained artificial\\nprediction market is shown to be a maximum likelihood estimator. It generalizes\\nlinear aggregation, existent in boosting and random forest, as well as logistic\\nregression and some kernel methods. Furthermore, the market mechanism allows\\nthe aggregation of specialized classifiers that participate only on specific\\ninstances. Experimental comparisons show that the artificial prediction markets\\noften outperform random forest and implicit online learning on synthetic data\\nand real UCI datasets. Moreover, an extensive evaluation for pelvic and\\nabdominal lymph node detection in CT data shows that the prediction market\\nimproves adaboost's detection rate from 79.6% to 81.2% at 3 false\\npositives/volume.\\n\",\n",
              " '  A plausible definition of \"reasoning\" could be \"algebraically manipulating\\npreviously acquired knowledge in order to answer a new question\". This\\ndefinition covers first-order logical inference or probabilistic inference. It\\nalso includes much simpler manipulations commonly used to build large learning\\nsystems. For instance, we can build an optical character recognition system by\\nfirst training a character segmenter, an isolated character recognizer, and a\\nlanguage model, using appropriate labeled training sets. Adequately\\nconcatenating these modules and fine tuning the resulting system can be viewed\\nas an algebraic operation in a space of models. The resulting model answers a\\nnew question, that is, converting the image of a text page into a computer\\nreadable text.\\n  This observation suggests a conceptual continuity between algebraically rich\\ninference systems, such as logical or probabilistic inference, and simple\\nmanipulations, such as the mere concatenation of trainable learning systems.\\nTherefore, instead of trying to bridge the gap between machine learning systems\\nand sophisticated \"all-purpose\" inference mechanisms, we can instead\\nalgebraically enrich the set of manipulations applicable to training systems,\\nand build reasoning capabilities from the ground up.\\n',\n",
              " '  This encyclopedic article gives a mini-introduction into the theory of\\nuniversal learning, founded by Ray Solomonoff in the 1960s and significantly\\ndeveloped and extended in the last decade. It explains the spirit of universal\\nlearning, but necessarily glosses over technical subtleties.\\n',\n",
              " '  This paper presents a finite-time analysis of the KL-UCB algorithm, an\\nonline, horizon-free index policy for stochastic bandit problems. We prove two\\ndistinct results: first, for arbitrary bounded rewards, the KL-UCB algorithm\\nsatisfies a uniformly better regret bound than UCB or UCB2; second, in the\\nspecial case of Bernoulli rewards, it reaches the lower bound of Lai and\\nRobbins. Furthermore, we show that simple adaptations of the KL-UCB algorithm\\nare also optimal for specific classes of (possibly unbounded) rewards,\\nincluding those generated from exponential families of distributions. A\\nlarge-scale numerical study comparing KL-UCB with its main competitors (UCB,\\nUCB2, UCB-Tuned, UCB-V, DMED) shows that KL-UCB is remarkably efficient and\\nstable, including for short time horizons. KL-UCB is also the only method that\\nalways performs better than the basic UCB policy. Our regret bounds rely on\\ndeviations results of independent interest which are stated and proved in the\\nAppendix. As a by-product, we also obtain an improved regret bound for the\\nstandard UCB algorithm.\\n',\n",
              " '  This study is focused on the development of the cortex-like visual object\\nrecognition system. We propose a general framework, which consists of three\\nhierarchical levels (modules). These modules functionally correspond to the V1,\\nV4 and IT areas. Both bottom-up and top-down connections between the\\nhierarchical levels V4 and IT are employed. The higher the degree of matching\\nbetween the input and the preferred stimulus, the shorter the response time of\\nthe neuron. Therefore information about a single stimulus is distributed in\\ntime and is transmitted by the waves of spikes. The reciprocal connections and\\nwaves of spikes implement predictive coding: an initial hypothesis is generated\\non the basis of information delivered by the first wave of spikes and is tested\\nwith the information carried by the consecutive waves. The development is\\nconsidered as extraction and accumulation of features in V4 and objects in IT.\\nOnce stored a feature can be disposed, if rarely activated. This cause update\\nof feature repository. Consequently, objects in IT are also updated. This\\nillustrates the growing process and dynamical change of topological structures\\nof V4, IT and connections between these areas.\\n',\n",
              " '  Ordinal regression is commonly formulated as a multi-class problem with\\nordinal constraints. The challenge of designing accurate classifiers for\\nordinal regression generally increases with the number of classes involved, due\\nto the large number of labeled patterns that are needed. The availability of\\nordinal class labels, however, is often costly to calibrate or difficult to\\nobtain. Unlabeled patterns, on the other hand, often exist in much greater\\nabundance and are freely available. To take benefits from the abundance of\\nunlabeled patterns, we present a novel transductive learning paradigm for\\nordinal regression in this paper, namely Transductive Ordinal Regression (TOR).\\nThe key challenge of the present study lies in the precise estimation of both\\nthe ordinal class label of the unlabeled data and the decision functions of the\\nordinal classes, simultaneously. The core elements of the proposed TOR include\\nan objective function that caters to several commonly used loss functions\\ncasted in transductive settings, for general ordinal regression. A label\\nswapping scheme that facilitates a strictly monotonic decrease in the objective\\nfunction value is also introduced. Extensive numerical studies on commonly used\\nbenchmark datasets including the real world sentiment prediction problem are\\nthen presented to showcase the characteristics and efficacies of the proposed\\ntransductive ordinal regression. Further, comparisons to recent\\nstate-of-the-art ordinal regression methods demonstrate the introduced\\ntransductive learning paradigm for ordinal regression led to the robust and\\nimproved performance.\\n',\n",
              " '  We consider decentralized restless multi-armed bandit problems with unknown\\ndynamics and multiple players. The reward state of each arm transits according\\nto an unknown Markovian rule when it is played and evolves according to an\\narbitrary unknown random process when it is passive. Players activating the\\nsame arm at the same time collide and suffer from reward loss. The objective is\\nto maximize the long-term reward by designing a decentralized arm selection\\npolicy to address unknown reward models and collisions among players. A\\ndecentralized policy is constructed that achieves a regret with logarithmic\\norder when an arbitrary nontrivial bound on certain system parameters is known.\\nWhen no knowledge about the system is available, we extend the policy to\\nachieve a regret arbitrarily close to the logarithmic order. The result finds\\napplications in communication networks, financial investment, and industrial\\nengineering.\\n',\n",
              " '  Truncated Singular Value Decomposition (SVD) calculates the closest rank-$k$\\napproximation of a given input matrix. Selecting the appropriate rank $k$\\ndefines a critical model order choice in most applications of SVD. To obtain a\\nprincipled cut-off criterion for the spectrum, we convert the underlying\\noptimization problem into a noisy channel coding problem. The optimal\\napproximation capacity of this channel controls the appropriate strength of\\nregularization to suppress noise. In simulation experiments, this information\\ntheoretic method to determine the optimal rank competes with state-of-the art\\nmodel selection techniques.\\n',\n",
              " '  We introduce a procedure to infer the interactions among a set of binary\\nvariables, based on their sampled frequencies and pairwise correlations. The\\nalgorithm builds the clusters of variables contributing most to the entropy of\\nthe inferred Ising model, and rejects the small contributions due to the\\nsampling noise. Our procedure successfully recovers benchmark Ising models even\\nat criticality and in the low temperature phase, and is applied to\\nneurobiological data.\\n',\n",
              " \"  In this paper we study the online learning problem involving rested and\\nrestless multiarmed bandits with multiple plays. The system consists of a\\nsingle player/user and a set of K finite-state discrete-time Markov chains\\n(arms) with unknown state spaces and statistics. At each time step the player\\ncan play M arms. The objective of the user is to decide for each step which M\\nof the K arms to play over a sequence of trials so as to maximize its long term\\nreward. The restless multiarmed bandit is particularly relevant to the\\napplication of opportunistic spectrum access (OSA), where a (secondary) user\\nhas access to a set of K channels, each of time-varying condition as a result\\nof random fading and/or certain primary users' activities.\\n\",\n",
              " '  Hierarchical clustering based on pairwise similarities is a common tool used\\nin a broad range of scientific applications. However, in many problems it may\\nbe expensive to obtain or compute similarities between the items to be\\nclustered. This paper investigates the hierarchical clustering of N items based\\non a small subset of pairwise similarities, significantly less than the\\ncomplete set of N(N-1)/2 similarities. First, we show that if the intracluster\\nsimilarities exceed intercluster similarities, then it is possible to correctly\\ndetermine the hierarchical clustering from as few as 3N log N similarities. We\\ndemonstrate this order of magnitude savings in the number of pairwise\\nsimilarities necessitates sequentially selecting which similarities to obtain\\nin an adaptive fashion, rather than picking them at random. We then propose an\\nactive clustering method that is robust to a limited fraction of anomalous\\nsimilarities, and show how even in the presence of these noisy similarity\\nvalues we can resolve the hierarchical clustering using only O(N log^2 N)\\npairwise similarities.\\n',\n",
              " '  A computational challenge to validate the candidate disease genes identified\\nin a high-throughput genomic study is to elucidate the associations between the\\nset of candidate genes and disease phenotypes. The conventional gene set\\nenrichment analysis often fails to reveal associations between disease\\nphenotypes and the gene sets with a short list of poorly annotated genes,\\nbecause the existing annotations of disease causative genes are incomplete. We\\npropose a network-based computational approach called rcNet to discover the\\nassociations between gene sets and disease phenotypes. Assuming coherent\\nassociations between the genes ranked by their relevance to the query gene set,\\nand the disease phenotypes ranked by their relevance to the hidden target\\ndisease phenotypes of the query gene set, we formulate a learning framework\\nmaximizing the rank coherence with respect to the known disease phenotype-gene\\nassociations. An efficient algorithm coupling ridge regression with label\\npropagation, and two variants are introduced to find the optimal solution of\\nthe framework. We evaluated the rcNet algorithms and existing baseline methods\\nwith both leave-one-out cross-validation and a task of predicting recently\\ndiscovered disease-gene associations in OMIM. The experiments demonstrated that\\nthe rcNet algorithms achieved the best overall rankings compared to the\\nbaselines. To further validate the reproducibility of the performance, we\\napplied the algorithms to identify the target diseases of novel candidate\\ndisease genes obtained from recent studies of GWAS, DNA copy number variation\\nanalysis, and gene expression profiling. The algorithms ranked the target\\ndisease of the candidate genes at the top of the rank list in many cases across\\nall the three case studies. The rcNet algorithms are available as a webtool for\\ndisease and gene set association analysis at\\nhttp://compbio.cs.umn.edu/dgsa_rcNet.\\n',\n",
              " '  We consider the problem of approximately reconstructing a partially-observed,\\napproximately low-rank matrix. This problem has received much attention lately,\\nmostly using the trace-norm as a surrogate to the rank. Here we study low-rank\\nmatrix reconstruction using both the trace-norm, as well as the less-studied\\nmax-norm, and present reconstruction guarantees based on existing analysis on\\nthe Rademacher complexity of the unit balls of these norms. We show how these\\nare superior in several ways to recently published guarantees based on\\nspecialized analysis.\\n',\n",
              " '  We address the sparse signal recovery problem in the context of multiple\\nmeasurement vectors (MMV) when elements in each nonzero row of the solution\\nmatrix are temporally correlated. Existing algorithms do not consider such\\ntemporal correlations and thus their performance degrades significantly with\\nthe correlations. In this work, we propose a block sparse Bayesian learning\\nframework which models the temporal correlations. In this framework we derive\\ntwo sparse Bayesian learning (SBL) algorithms, which have superior recovery\\nperformance compared to existing algorithms, especially in the presence of high\\ntemporal correlations. Furthermore, our algorithms are better at handling\\nhighly underdetermined problems and require less row-sparsity on the solution\\nmatrix. We also provide analysis of the global and local minima of their cost\\nfunction, and show that the SBL cost function has the very desirable property\\nthat the global minimum is at the sparsest solution to the MMV problem.\\nExtensive experiments also provide some interesting results that motivate\\nfuture theoretical research on the MMV model.\\n',\n",
              " '  Email is a private medium of communication, and the inherent privacy\\nconstraints form a major obstacle in developing effective spam filtering\\nmethods which require access to a large amount of email data belonging to\\nmultiple users. To mitigate this problem, we envision a privacy preserving spam\\nfiltering system, where the server is able to train and evaluate a logistic\\nregression based spam classifier on the combined email data of all users\\nwithout being able to observe any emails using primitives such as homomorphic\\nencryption and randomization. We analyze the protocols for correctness and\\nsecurity, and perform experiments of a prototype system on a large scale spam\\nfiltering task.\\n  State of the art spam filters often use character n-grams as features which\\nresult in large sparse data representation, which is not feasible to be used\\ndirectly with our training and evaluation protocols. We explore various data\\nindependent dimensionality reduction which decrease the running time of the\\nprotocol making it feasible to use in practice while achieving high accuracy.\\n',\n",
              " '  Coded recurrent neural networks with three levels of sparsity are introduced.\\nThe first level is related to the size of messages, much smaller than the\\nnumber of available neurons. The second one is provided by a particular coding\\nrule, acting as a local constraint in the neural activity. The third one is a\\ncharacteristic of the low final connection density of the network after the\\nlearning phase. Though the proposed network is very simple since it is based on\\nbinary neurons and binary connections, it is able to learn a large number of\\nmessages and recall them, even in presence of strong erasures. The performance\\nof the network is assessed as a classifier and as an associative memory.\\n',\n",
              " '  This paper describes the winning entry to the IJCNN 2011 Social Network\\nChallenge run by Kaggle.com. The goal of the contest was to promote research on\\nreal-world link prediction, and the dataset was a graph obtained by crawling\\nthe popular Flickr social photo sharing website, with user identities scrubbed.\\nBy de-anonymizing much of the competition test set using our own Flickr crawl,\\nwe were able to effectively game the competition. Our attack represents a new\\napplication of de-anonymization to gaming machine learning contests, suggesting\\nchanges in how future competitions should be run.\\n  We introduce a new simulated annealing-based weighted graph matching\\nalgorithm for the seeding step of de-anonymization. We also show how to combine\\nde-anonymization with link prediction---the latter is required to achieve good\\nperformance on the portion of the test set not de-anonymized---for example by\\ntraining the predictor on the de-anonymized portion of the test set, and\\ncombining probabilistic predictions from de-anonymization and link prediction.\\n',\n",
              " '  We provide consistent random algorithms for sequential decision under partial\\nmonitoring, i.e. when the decision maker does not observe the outcomes but\\nreceives instead random feedback signals. Those algorithms have no internal\\nregret in the sense that, on the set of stages where the decision maker chose\\nhis action according to a given law, the average payoff could not have been\\nimproved in average by using any other fixed law.\\n  They are based on a generalization of calibration, no longer defined in terms\\nof a Voronoi diagram but instead of a Laguerre diagram (a more general\\nconcept). This allows us to bound, for the first time in this general\\nframework, the expected average internal -- as well as the usual external --\\nregret at stage $n$ by $O(n^{-1/3})$, which is known to be optimal.\\n',\n",
              " '  We analyze a class of estimators based on convex relaxation for solving\\nhigh-dimensional matrix decomposition problems. The observations are noisy\\nrealizations of a linear transformation $\\\\mathfrak{X}$ of the sum of an\\napproximately) low rank matrix $\\\\Theta^\\\\star$ with a second matrix\\n$\\\\Gamma^\\\\star$ endowed with a complementary form of low-dimensional structure;\\nthis set-up includes many statistical models of interest, including factor\\nanalysis, multi-task regression, and robust covariance estimation. We derive a\\ngeneral theorem that bounds the Frobenius norm error for an estimate of the\\npair $(\\\\Theta^\\\\star, \\\\Gamma^\\\\star)$ obtained by solving a convex optimization\\nproblem that combines the nuclear norm with a general decomposable regularizer.\\nOur results utilize a \"spikiness\" condition that is related to but milder than\\nsingular vector incoherence. We specialize our general result to two cases that\\nhave been studied in past work: low rank plus an entrywise sparse matrix, and\\nlow rank plus a columnwise sparse matrix. For both models, our theory yields\\nnon-asymptotic Frobenius error bounds for both deterministic and stochastic\\nnoise matrices, and applies to matrices $\\\\Theta^\\\\star$ that can be exactly or\\napproximately low rank, and matrices $\\\\Gamma^\\\\star$ that can be exactly or\\napproximately sparse. Moreover, for the case of stochastic noise matrices and\\nthe identity observation operator, we establish matching lower bounds on the\\nminimax error. The sharpness of our predictions is confirmed by numerical\\nsimulations.\\n',\n",
              " '  Recovery of low-rank matrices has recently seen significant activity in many\\nareas of science and engineering, motivated by recent theoretical results for\\nexact reconstruction guarantees and interesting practical applications. A\\nnumber of methods have been developed for this recovery problem. However, a\\nprincipled method for choosing the unknown target rank is generally not\\nprovided. In this paper, we present novel recovery algorithms for estimating\\nlow-rank matrices in matrix completion and robust principal component analysis\\nbased on sparse Bayesian learning (SBL) principles. Starting from a matrix\\nfactorization formulation and enforcing the low-rank constraint in the\\nestimates as a sparsity constraint, we develop an approach that is very\\neffective in determining the correct rank while providing high recovery\\nperformance. We provide connections with existing methods in other similar\\nproblems and empirical results and comparisons with current state-of-the-art\\nmethods that illustrate the effectiveness of this approach.\\n',\n",
              " \"  A generalized-statistics variational principle for source separation is\\nformulated by recourse to Tsallis' entropy subjected to the additive duality\\nand employing constraints described by normal averages. The variational\\nprinciple is amalgamated with Hopfield-like learning rules resulting in an\\nunsupervised learning model. The update rules are formulated with the aid of\\nq-deformed calculus. Numerical examples exemplify the efficacy of this model.\\n\",\n",
              " '  Reinforcement learning has solid foundations, but becomes inefficient in\\npartially observed (non-Markovian) environments. Thus, a learning agent -born\\nwith a representation and a policy- might wish to investigate to what extent\\nthe Markov property holds. We propose a learning architecture that utilizes\\ncombinatorial policy optimization to overcome non-Markovity and to develop\\nefficient behaviors, which are easy to inherit, tests the Markov property of\\nthe behavioral states, and corrects against non-Markovity by running a\\ndeterministic factored Finite State Model, which can be learned. We illustrate\\nthe properties of architecture in the near deterministic Ms. Pac-Man game. We\\nanalyze the architecture from the point of view of evolutionary, individual,\\nand social learning.\\n',\n",
              " '  Kolmogorov-Smirnov (K-S) test-a non-parametric method to measure the goodness\\nof fit, is applied for automatic modulation classification (AMC) in this paper.\\nThe basic procedure involves computing the empirical cumulative distribution\\nfunction (ECDF) of some decision statistic derived from the received signal,\\nand comparing it with the CDFs of the signal under each candidate modulation\\nformat. The K-S-based modulation classifier is first developed for AWGN\\nchannel, then it is applied to OFDM-SDMA systems to cancel multiuser\\ninterference. Regarding the complexity issue of K-S modulation classification,\\nwe propose a low-complexity method based on the robustness of the K-S\\nclassifier. Extensive simulation results demonstrate that compared with the\\ntraditional cumulant-based classifiers, the proposed K-S classifier offers\\nsuperior classification performance and requires less number of signal samples\\n(thus is fast).\\n',\n",
              " \"  With the explosion of the size of digital dataset, the limiting factor for\\ndecomposition algorithms is the \\\\emph{number of passes} over the input, as the\\ninput is often stored out-of-core or even off-site. Moreover, we're only\\ninterested in algorithms that operate in \\\\emph{constant memory} w.r.t. to the\\ninput size, so that arbitrarily large input can be processed. In this paper, we\\npresent a practical comparison of two such algorithms: a distributed method\\nthat operates in a single pass over the input vs. a streamed two-pass\\nstochastic algorithm. The experiments track the effect of distributed\\ncomputing, oversampling and memory trade-offs on the accuracy and performance\\nof the two algorithms. To ensure meaningful results, we choose the input to be\\na real dataset, namely the whole of the English Wikipedia, in the application\\nsettings of Latent Semantic Analysis.\\n\",\n",
              " '  This paper introduces a named entity recognition approach in textual corpus.\\nThis Named Entity (NE) can be a named: location, person, organization, date,\\ntime, etc., characterized by instances. A NE is found in texts accompanied by\\ncontexts: words that are left or right of the NE. The work mainly aims at\\nidentifying contexts inducing the NE\\'s nature. As such, The occurrence of the\\nword \"President\" in a text, means that this word or context may be followed by\\nthe name of a president as President \"Obama\". Likewise, a word preceded by the\\nstring \"footballer\" induces that this is the name of a footballer. NE\\nrecognition may be viewed as a classification method, where every word is\\nassigned to a NE class, regarding the context. The aim of this study is then to\\nidentify and classify the contexts that are most relevant to recognize a NE,\\nthose which are frequently found with the NE. A learning approach using\\ntraining corpus: web documents, constructed from learning examples is then\\nsuggested. Frequency representations and modified tf-idf representations are\\nused to calculate the context weights associated to context frequency, learning\\nexample frequency, and document frequency in the corpus.\\n',\n",
              " '  Motivated by problems of anomaly detection, this paper implements the\\nNeyman-Pearson paradigm to deal with asymmetric errors in binary classification\\nwith a convex loss. Given a finite collection of classifiers, we combine them\\nand obtain a new classifier that satisfies simultaneously the two following\\nproperties with high probability: (i) its probability of type I error is below\\na pre-specified level and (ii), it has probability of type II error close to\\nthe minimum possible. The proposed classifier is obtained by solving an\\noptimization problem with an empirical objective and an empirical constraint.\\nNew techniques to handle such problems are developed and have consequences on\\nchance constrained programming.\\n',\n",
              " '  In many large scale distributed systems and on the web, agents need to\\ninteract with other unknown agents to carry out some tasks or transactions. The\\nability to reason about and assess the potential risks in carrying out such\\ntransactions is essential for providing a safe and reliable environment. A\\ntraditional approach to reason about the trustworthiness of a transaction is to\\ndetermine the trustworthiness of the specific agent involved, derived from the\\nhistory of its behavior. As a departure from such traditional trust models, we\\npropose a generic, machine learning approach based trust framework where an\\nagent uses its own previous transactions (with other agents) to build a\\nknowledge base, and utilize this to assess the trustworthiness of a transaction\\nbased on associated features, which are capable of distinguishing successful\\ntransactions from unsuccessful ones. These features are harnessed using\\nappropriate machine learning algorithms to extract relationships between the\\npotential transaction and previous transactions. The trace driven experiments\\nusing real auction dataset show that this approach provides good accuracy and\\nis highly efficient compared to other trust mechanisms, especially when\\nhistorical information of the specific agent is rare, incomplete or inaccurate.\\n',\n",
              " '  In multi-label learning, each sample is associated with several labels.\\nExisting works indicate that exploring correlations between labels improve the\\nprediction performance. However, embedding the label correlations into the\\ntraining process significantly increases the problem size. Moreover, the\\nmapping of the label structure in the feature space is not clear. In this\\npaper, we propose a novel multi-label learning method \"Structured Decomposition\\n+ Group Sparsity (SDGS)\". In SDGS, we learn a feature subspace for each label\\nfrom the structured decomposition of the training data, and predict the labels\\nof a new sample from its group sparse representation on the multi-subspace\\nobtained from the structured decomposition. In particular, in the training\\nstage, we decompose the data matrix $X\\\\in R^{n\\\\times p}$ as\\n$X=\\\\sum_{i=1}^kL^i+S$, wherein the rows of $L^i$ associated with samples that\\nbelong to label $i$ are nonzero and consist a low-rank matrix, while the other\\nrows are all-zeros, the residual $S$ is a sparse matrix. The row space of $L_i$\\nis the feature subspace corresponding to label $i$. This decomposition can be\\nefficiently obtained via randomized optimization. In the prediction stage, we\\nestimate the group sparse representation of a new sample on the multi-subspace\\nvia group \\\\emph{lasso}. The nonzero representation coefficients tend to\\nconcentrate on the subspaces of labels that the sample belongs to, and thus an\\neffective prediction can be obtained. We evaluate SDGS on several real datasets\\nand compare it with popular methods. Results verify the effectiveness and\\nefficiency of SDGS.\\n',\n",
              " '  We propose a unified neural network architecture and learning algorithm that\\ncan be applied to various natural language processing tasks including:\\npart-of-speech tagging, chunking, named entity recognition, and semantic role\\nlabeling. This versatility is achieved by trying to avoid task-specific\\nengineering and therefore disregarding a lot of prior knowledge. Instead of\\nexploiting man-made input features carefully optimized for each task, our\\nsystem learns internal representations on the basis of vast amounts of mostly\\nunlabeled training data. This work is then used as a basis for building a\\nfreely available tagging system with good performance and minimal computational\\nrequirements.\\n',\n",
              " '  We consider the problem of learning an unknown product distribution $X$ over\\n$\\\\{0,1\\\\}^n$ using samples $f(X)$ where $f$ is a \\\\emph{known} transformation\\nfunction. Each choice of a transformation function $f$ specifies a learning\\nproblem in this framework.\\n  Information-theoretic arguments show that for every transformation function\\n$f$ the corresponding learning problem can be solved to accuracy $\\\\eps$, using\\n$\\\\tilde{O}(n/\\\\eps^2)$ examples, by a generic algorithm whose running time may\\nbe exponential in $n.$ We show that this learning problem can be\\ncomputationally intractable even for constant $\\\\eps$ and rather simple\\ntransformation functions. Moreover, the above sample complexity bound is nearly\\noptimal for the general problem, as we give a simple explicit linear\\ntransformation function $f(x)=w \\\\cdot x$ with integer weights $w_i \\\\leq n$ and\\nprove that the corresponding learning problem requires $\\\\Omega(n)$ samples.\\n  As our main positive result we give a highly efficient algorithm for learning\\na sum of independent unknown Bernoulli random variables, corresponding to the\\ntransformation function $f(x)= \\\\sum_{i=1}^n x_i$. Our algorithm learns to\\n$\\\\eps$-accuracy in poly$(n)$ time, using a surprising poly$(1/\\\\eps)$ number of\\nsamples that is independent of $n.$ We also give an efficient algorithm that\\nuses $\\\\log n \\\\cdot \\\\poly(1/\\\\eps)$ samples but has running time that is only\\n$\\\\poly(\\\\log n, 1/\\\\eps).$\\n',\n",
              " '  Volterra and polynomial regression models play a major role in nonlinear\\nsystem identification and inference tasks. Exciting applications ranging from\\nneuroscience to genome-wide association analysis build on these models with the\\nadditional requirement of parsimony. This requirement has high interpretative\\nvalue, but unfortunately cannot be met by least-squares based or kernel\\nregression methods. To this end, compressed sampling (CS) approaches, already\\nsuccessful in linear regression settings, can offer a viable alternative. The\\nviability of CS for sparse Volterra and polynomial models is the core theme of\\nthis work. A common sparse regression task is initially posed for the two\\nmodels. Building on (weighted) Lasso-based schemes, an adaptive RLS-type\\nalgorithm is developed for sparse polynomial regressions. The identifiability\\nof polynomial models is critically challenged by dimensionality. However,\\nfollowing the CS principle, when these models are sparse, they could be\\nrecovered by far fewer measurements. To quantify the sufficient number of\\nmeasurements for a given level of sparsity, restricted isometry properties\\n(RIP) are investigated in commonly met polynomial regression settings,\\ngeneralizing known results for their linear counterparts. The merits of the\\nnovel (weighted) adaptive CS algorithms to sparse polynomial modeling are\\nverified through synthetic as well as real data tests for genotype-phenotype\\nanalysis.\\n',\n",
              " '  Conditional random field (CRF) and Structural Support Vector Machine\\n(Structural SVM) are two state-of-the-art methods for structured prediction\\nwhich captures the interdependencies among output variables. The success of\\nthese methods is attributed to the fact that their discriminative models are\\nable to account for overlapping features on the whole input observations. These\\nfeatures are usually generated by applying a given set of templates on labeled\\ndata, but improper templates may lead to degraded performance. To alleviate\\nthis issue, in this paper, we propose a novel multiple template learning\\nparadigm to learn structured prediction and the importance of each template\\nsimultaneously, so that hundreds of arbitrary templates could be added into the\\nlearning model without caution. This paradigm can be formulated as a special\\nmultiple kernel learning problem with exponential number of constraints. Then\\nwe introduce an efficient cutting plane algorithm to solve this problem in the\\nprimal, and its convergence is presented. We also evaluate the proposed\\nlearning paradigm on two widely-studied structured prediction tasks,\\n\\\\emph{i.e.} sequence labeling and dependency parsing. Extensive experimental\\nresults show that the proposed method outperforms CRFs and Structural SVMs due\\nto exploiting the importance of each template. Our complexity analysis and\\nempirical results also show that our proposed method is more efficient than\\nOnlineMKL on very sparse and high-dimensional data. We further extend this\\nparadigm for structured prediction using generalized $p$-block norm\\nregularization with $p>1$, and experiments show competitive performances when\\n$p \\\\in [1,2)$.\\n',\n",
              " \"  The literature on statistical learning for time series assumes the asymptotic\\nindependence or ``mixing' of the data-generating process. These mixing\\nassumptions are never tested, nor are there methods for estimating mixing rates\\nfrom data. We give an estimator for the $\\\\beta$-mixing rate based on a single\\nstationary sample path and show it is $L_1$-risk consistent.\\n\",\n",
              " '  We derive generalization error bounds for stationary univariate\\nautoregressive (AR) models. We show that imposing stationarity is enough to\\ncontrol the Gaussian complexity without further regularization. This lets us\\nuse structural risk minimization for model selection. We demonstrate our\\nmethods by predicting interest rate movements.\\n',\n",
              " \"  When dealing with time series with complex non-stationarities, low\\nretrospective regret on individual realizations is a more appropriate goal than\\nlow prospective risk in expectation. Online learning algorithms provide\\npowerful guarantees of this form, and have often been proposed for use with\\nnon-stationary processes because of their ability to switch between different\\nforecasters or ``experts''. However, existing methods assume that the set of\\nexperts whose forecasts are to be combined are all given at the start, which is\\nnot plausible when dealing with a genuinely historical or evolutionary system.\\nWe show how to modify the ``fixed shares'' algorithm for tracking the best\\nexpert to cope with a steadily growing set of experts, obtained by fitting new\\nmodels to new data as it becomes available, and obtain regret bounds for the\\ngrowing ensemble.\\n\",\n",
              " '  Feature selection with specific multivariate performance measures is the key\\nto the success of many applications, such as image retrieval and text\\nclassification. The existing feature selection methods are usually designed for\\nclassification error. In this paper, we propose a generalized sparse\\nregularizer. Based on the proposed regularizer, we present a unified feature\\nselection framework for general loss functions. In particular, we study the\\nnovel feature selection paradigm by optimizing multivariate performance\\nmeasures. The resultant formulation is a challenging problem for\\nhigh-dimensional data. Hence, a two-layer cutting plane algorithm is proposed\\nto solve this problem, and the convergence is presented. In addition, we adapt\\nthe proposed method to optimize multivariate measures for multiple instance\\nlearning problems. The analyses by comparing with the state-of-the-art feature\\nselection methods show that the proposed method is superior to others.\\nExtensive experiments on large-scale and high-dimensional real world datasets\\nshow that the proposed method outperforms $l_1$-SVM and SVM-RFE when choosing a\\nsmall subset of features, and achieves significantly improved performances over\\nSVM$^{perf}$ in terms of $F_1$-score.\\n',\n",
              " \"  We consider the problem of positioning a cloud of points in the Euclidean\\nspace $\\\\mathbb{R}^d$, using noisy measurements of a subset of pairwise\\ndistances. This task has applications in various areas, such as sensor network\\nlocalization and reconstruction of protein conformations from NMR measurements.\\nAlso, it is closely related to dimensionality reduction problems and manifold\\nlearning, where the goal is to learn the underlying global geometry of a data\\nset using local (or partial) metric information. Here we propose a\\nreconstruction algorithm based on semidefinite programming. For a random\\ngeometric graph model and uniformly bounded noise, we provide a precise\\ncharacterization of the algorithm's performance: In the noiseless case, we find\\na radius $r_0$ beyond which the algorithm reconstructs the exact positions (up\\nto rigid transformations). In the presence of noise, we obtain upper and lower\\nbounds on the reconstruction error that match up to a factor that depends only\\non the dimension $d$, and the average degree of the nodes in the graph.\\n\",\n",
              " '  This document reviews the definition of the kernel distance, providing a\\ngentle introduction tailored to a reader with background in theoretical\\ncomputer science, but limited exposure to technology more common to machine\\nlearning, functional analysis and geometric measure theory. The key aspect of\\nthe kernel distance developed here is its interpretation as an L_2 distance\\nbetween probability measures or various shapes (e.g. point sets, curves,\\nsurfaces) embedded in a vector space (specifically an RKHS). This structure\\nenables several elegant and efficient solutions to data analysis problems. We\\nconclude with a glimpse into the mathematical underpinnings of this measure,\\nhighlighting its recent independent evolution in two separate fields.\\n',\n",
              " '  Consider the problem of learning the drift coefficient of a stochastic\\ndifferential equation from a sample path. In this paper, we assume that the\\ndrift is parametrized by a high dimensional vector. We address the question of\\nhow long the system needs to be observed in order to learn this vector of\\nparameters. We prove a general lower bound on this time complexity by using a\\ncharacterization of mutual information as time integral of conditional\\nvariance, due to Kadota, Zakai, and Ziv. This general lower bound is applied to\\nspecific classes of linear and non-linear stochastic differential equations. In\\nthe linear case, the problem under consideration is the one of learning a\\nmatrix of interaction coefficients. We evaluate our lower bound for ensembles\\nof sparse and dense random matrices. The resulting estimates match the\\nqualitative behavior of upper bounds achieved by computationally efficient\\nprocedures.\\n',\n",
              " '  COMET is a single-pass MapReduce algorithm for learning on large-scale data.\\nIt builds multiple random forest ensembles on distributed blocks of data and\\nmerges them into a mega-ensemble. This approach is appropriate when learning\\nfrom massive-scale data that is too large to fit on a single machine. To get\\nthe best accuracy, IVoting should be used instead of bagging to generate the\\ntraining subset for each decision tree in the random forest. Experiments with\\ntwo large datasets (5GB and 50GB compressed) show that COMET compares favorably\\n(in both accuracy and training time) to learning on a subsample of data using a\\nserial algorithm. Finally, we propose a new Gaussian approach for lazy ensemble\\nevaluation which dynamically decides how many ensemble members to evaluate per\\ndata point; this can reduce evaluation cost by 100X or more.\\n',\n",
              " '  Learning algorithms are essential for the applications of game theory in a\\nnetworking environment. In dynamic and decentralized settings where the\\ntraffic, topology and channel states may vary over time and the communication\\nbetween agents is impractical, it is important to formulate and study games of\\nincomplete information and fully distributed learning algorithms which for each\\nagent requires a minimal amount of information regarding the remaining agents.\\nIn this paper, we address this major challenge and introduce heterogeneous\\nlearning schemes in which each agent adopts a distinct learning pattern in the\\ncontext of games with incomplete information. We use stochastic approximation\\ntechniques to show that the heterogeneous learning schemes can be studied in\\nterms of their deterministic ordinary differential equation (ODE) counterparts.\\nDepending on the learning rates of the players, these ODEs could be different\\nfrom the standard replicator dynamics, (myopic) best response (BR) dynamics,\\nlogit dynamics, and fictitious play dynamics. We apply the results to a class\\nof security games in which the attacker and the defender adopt different\\nlearning schemes due to differences in their rationality levels and the\\ninformation they acquire.\\n',\n",
              " '  This paper describes two applications of conditional restricted Boltzmann\\nmachines (CRBMs) to the task of autotagging music. The first consists of\\ntraining a CRBM to predict tags that a user would apply to a clip of a song\\nbased on tags already applied by other users. By learning the relationships\\nbetween tags, this model is able to pre-process training data to significantly\\nimprove the performance of a support vector machine (SVM) autotagging. The\\nsecond is the use of a discriminative RBM, a type of CRBM, to autotag music. By\\nsimultaneously exploiting the relationships among tags and between tags and\\naudio-based features, this model is able to significantly outperform SVMs,\\nlogistic regression, and multi-layer perceptrons. In order to be applied to\\nthis problem, the discriminative RBM was generalized to the multi-label setting\\nand four different learning algorithms for it were evaluated, the first such\\nin-depth analysis of which we are aware.\\n',\n",
              " '  We show that the disagreement coefficient of certain smooth hypothesis\\nclasses is $O(m)$, where $m$ is the dimension of the hypothesis space, thereby\\nanswering a question posed in \\\\cite{friedman09}.\\n',\n",
              " \"  We analyze the problem of distributed power allocation for orthogonal\\nmultiple access channels by considering a continuous non-cooperative game whose\\nstrategy space represents the users' distribution of transmission power over\\nthe network's channels. When the channels are static, we find that this game\\nadmits an exact potential function and this allows us to show that it has a\\nunique equilibrium almost surely. Furthermore, using the game's potential\\nproperty, we derive a modified version of the replicator dynamics of\\nevolutionary game theory which applies to this continuous game, and we show\\nthat if the network's users employ a distributed learning scheme based on these\\ndynamics, then they converge to equilibrium exponentially quickly. On the other\\nhand, a major challenge occurs if the channels do not remain static but\\nfluctuate stochastically over time, following a stationary ergodic process. In\\nthat case, the associated ergodic game still admits a unique equilibrium, but\\nthe learning analysis becomes much more complicated because the replicator\\ndynamics are no longer deterministic. Nonetheless, by employing results from\\nthe theory of stochastic approximation, we show that users still converge to\\nthe game's unique equilibrium.\\n  Our analysis hinges on a game-theoretical result which is of independent\\ninterest: in finite player games which admit a (possibly nonlinear) convex\\npotential function, the replicator dynamics (suitably modified to account for\\nnonlinear payoffs) converge to an eps-neighborhood of an equilibrium at time of\\norder O(log(1/eps)).\\n\",\n",
              " '  Traditional machine-learned ranking systems for web search are often trained\\nto capture stationary relevance of documents to queries, which has limited\\nability to track non-stationary user intention in a timely manner. In recency\\nsearch, for instance, the relevance of documents to a query on breaking news\\noften changes significantly over time, requiring effective adaptation to user\\nintention. In this paper, we focus on recency search and study a number of\\nalgorithms to improve ranking results by leveraging user click feedback. Our\\ncontributions are three-fold. First, we use real search sessions collected in a\\nrandom exploration bucket for \\\\emph{reliable} offline evaluation of these\\nalgorithms, which provides an unbiased comparison across algorithms without\\nonline bucket tests. Second, we propose a re-ranking approach to improve search\\nresults for recency queries using user clicks. Third, our empirical comparison\\nof a dozen algorithms on real-life search data suggests importance of a few\\nalgorithmic choices in these applications, including generalization across\\ndifferent query-document pairs, specialization to popular queries, and\\nreal-time adaptation of user clicks.\\n',\n",
              " '  As a mathematical model of associative memories, the Hopfield model was now\\nwell-established and a lot of studies to reveal the pattern-recalling process\\nhave been done from various different approaches. As well-known, a single\\nneuron is itself an uncertain, noisy unit with a finite unnegligible error in\\nthe input-output relation. To model the situation artificially, a kind of \\'heat\\nbath\\' that surrounds neurons is introduced. The heat bath, which is a source of\\nnoise, is specified by the \\'temperature\\'. Several studies concerning the\\npattern-recalling processes of the Hopfield model governed by the\\nGlauber-dynamics at finite temperature were already reported. However, we might\\nextend the \\'thermal noise\\' to the quantum-mechanical variant. In this paper, in\\nterms of the stochastic process of quantum-mechanical Markov chain Monte Carlo\\nmethod (the quantum MCMC), we analytically derive macroscopically deterministic\\nequations of order parameters such as \\'overlap\\' in a quantum-mechanical variant\\nof the Hopfield neural networks (let us call \"quantum Hopfield model\" or\\n\"quantum Hopfield networks\"). For the case in which non-extensive number $p$ of\\npatterns are embedded via asymmetric Hebbian connections, namely, $p/N \\\\to 0$\\nfor the number of neuron $N \\\\to \\\\infty$ (\\'far from saturation\\'), we evaluate\\nthe recalling processes for one of the built-in patterns under the influence of\\nquantum-mechanical noise.\\n',\n",
              " '  We participated, in the Article Classification and the Interaction Method\\nsubtasks (ACT and IMT, respectively) of the Protein-Protein Interaction task of\\nthe BioCreative III Challenge. For the ACT, we pursued an extensive testing of\\navailable Named Entity Recognition and dictionary tools, and used the most\\npromising ones to extend our Variable Trigonometric Threshold linear\\nclassifier. For the IMT, we experimented with a primarily statistical approach,\\nas opposed to employing a deeper natural language processing strategy. Finally,\\nwe also studied the benefits of integrating the method extraction approach that\\nwe have used for the IMT into the ACT pipeline. For the ACT, our linear article\\nclassifier leads to a ranking and classification performance significantly\\nhigher than all the reported submissions. For the IMT, our results are\\ncomparable to those of other systems, which took very different approaches. For\\nthe ACT, we show that the use of named entity recognition tools leads to a\\nsubstantial improvement in the ranking and classification of articles relevant\\nto protein-protein interaction. Thus, we show that our substantially expanded\\nlinear classifier is a very competitive classifier in this domain. Moreover,\\nthis classifier produces interpretable surfaces that can be understood as\\n\"rules\" for human understanding of the classification. In terms of the IMT\\ntask, in contrast to other participants, our approach focused on identifying\\nsentences that are likely to bear evidence for the application of a PPI\\ndetection method, rather than on classifying a document as relevant to a\\nmethod. As BioCreative III did not perform an evaluation of the evidence\\nprovided by the system, we have conducted a separate assessment; the evaluators\\nagree that our tool is indeed effective in detecting relevant evidence for PPI\\ndetection methods.\\n',\n",
              " '  In this work we study parallelization of online learning, a core primitive in\\nmachine learning. In a parallel environment all known approaches for parallel\\nonline learning lead to delayed updates, where the model is updated using\\nout-of-date information. In the worst case, or when examples are temporally\\ncorrelated, delay can have a very adverse effect on the learning algorithm.\\nHere, we analyze and present preliminary empirical results on a set of learning\\narchitectures based on a feature sharding approach that present various\\ntradeoffs between delay, degree of parallelism, representation power and\\nempirical performance.\\n',\n",
              " '  We consider a collection of prediction experiments, which are clustered in\\nthe sense that groups of experiments ex- hibit similar relationship between the\\npredictor and response variables. The experiment clusters as well as the\\nregres- sion relationships are unknown. The regression relation- ships define\\nthe experiment clusters, and in general, the predictor and response variables\\nmay not exhibit any clus- tering. We call this prediction problem clustered\\nregres- sion with unknown clusters (CRUC) and in this paper we focus on linear\\nregression. We study and compare several methods for CRUC, demonstrate their\\napplicability to the Yahoo Learning-to-rank Challenge (YLRC) dataset, and in-\\nvestigate an associated mathematical model. CRUC is at the crossroads of many\\nprior works and we study several prediction algorithms with diverse origins: an\\nadaptation of the expectation-maximization algorithm, an approach in- spired by\\nK-means clustering, the singular value threshold- ing approach to matrix rank\\nminimization under quadratic constraints, an adaptation of the Curds and Whey\\nmethod in multiple regression, and a local regression (LoR) scheme reminiscent\\nof neighborhood methods in collaborative filter- ing. Based on empirical\\nevaluation on the YLRC dataset as well as simulated data, we identify the LoR\\nmethod as a good practical choice: it yields best or near-best prediction\\nperformance at a reasonable computational load, and it is less sensitive to the\\nchoice of the algorithm parameter. We also provide some analysis of the LoR\\nmethod for an asso- ciated mathematical model, which sheds light on optimal\\nparameter choice and prediction performance.\\n',\n",
              " '  The competitive MNIST handwritten digit recognition benchmark has a long\\nhistory of broken records since 1998. The most recent substantial improvement\\nby others dates back 7 years (error rate 0.4%) . Recently we were able to\\nsignificantly improve this result, using graphics cards to greatly speed up\\ntraining of simple but deep MLPs, which achieved 0.35%, outperforming all the\\nprevious more complex methods. Here we report another substantial improvement:\\n0.31% obtained using a committee of MLPs.\\n',\n",
              " '  We study decision making in environments where the reward is only partially\\nobserved, but can be modeled as a function of an action and an observed\\ncontext. This setting, known as contextual bandits, encompasses a wide variety\\nof applications including health-care policy and Internet advertising. A\\ncentral task is evaluation of a new policy given historic data consisting of\\ncontexts, actions and received rewards. The key challenge is that the past data\\ntypically does not faithfully represent proportions of actions taken by a new\\npolicy. Previous approaches rely either on models of rewards or models of the\\npast policy. The former are plagued by a large bias whereas the latter have a\\nlarge variance.\\n  In this work, we leverage the strength and overcome the weaknesses of the two\\napproaches by applying the doubly robust technique to the problems of policy\\nevaluation and optimization. We prove that this approach yields accurate value\\nestimates when we have either a good (but not necessarily consistent) model of\\nrewards or a good (but not necessarily consistent) model of past policy.\\nExtensive empirical comparison demonstrates that the doubly robust approach\\nuniformly improves over existing techniques, achieving both lower variance in\\nvalue estimation and better policies. As such, we expect the doubly robust\\napproach to become common practice.\\n',\n",
              " '  We consider the problem of classification when inputs correspond to sets of\\nvectors. This setting occurs in many problems such as the classification of\\npieces of mail containing several pages, of web sites with several sections or\\nof images that have been pre-segmented into smaller regions. We propose\\ngeneralizations of the restricted Boltzmann machine (RBM) that are appropriate\\nin this context and explore how to incorporate different assumptions about the\\nrelationship between the input sets and the target class within the RBM. In\\nexperiments on standard multiple-instance learning datasets, we demonstrate the\\ncompetitiveness of approaches based on RBMs and apply the proposed variants to\\nthe problem of incoming mail classification.\\n',\n",
              " \"  Valiant's (2007) model of evolvability models the evolutionary process of\\nacquiring useful functionality as a restricted form of learning from random\\nexamples. Linear threshold functions and their various subclasses, such as\\nconjunctions and decision lists, play a fundamental role in learning theory and\\nhence their evolvability has been the primary focus of research on Valiant's\\nframework (2007). One of the main open problems regarding the model is whether\\nconjunctions are evolvable distribution-independently (Feldman and Valiant,\\n2008). We show that the answer is negative. Our proof is based on a new\\ncombinatorial parameter of a concept class that lower-bounds the complexity of\\nlearning from correlations.\\n  We contrast the lower bound with a proof that linear threshold functions\\nhaving a non-negligible margin on the data points are evolvable\\ndistribution-independently via a simple mutation algorithm. Our algorithm\\nrelies on a non-linear loss function being used to select the hypotheses\\ninstead of 0-1 loss in Valiant's (2007) original definition. The proof of\\nevolvability requires that the loss function satisfies several mild conditions\\nthat are, for example, satisfied by the quadratic loss function studied in\\nseveral other works (Michael, 2007; Feldman, 2009; Valiant, 2010). An important\\nproperty of our evolution algorithm is monotonicity, that is the algorithm\\nguarantees evolvability without any decreases in performance. Previously,\\nmonotone evolvability was only shown for conjunctions with quadratic loss\\n(Feldman, 2009) or when the distribution on the domain is severely restricted\\n(Michael, 2007; Feldman, 2009; Kanade et al., 2010)\\n\",\n",
              " \"  We propose a compression-based version of the empirical entropy of a finite\\nstring over a finite alphabet. Whereas previously one considers the naked\\nentropy of (possibly higher order) Markov processes, we consider the sum of the\\ndescription of the random variable involved plus the entropy it induces. We\\nassume only that the distribution involved is computable. To test the new\\nnotion we compare the Normalized Information Distance (the similarity metric)\\nwith a related measure based on Mutual Information in Shannon's framework. This\\nway the similarities and differences of the last two concepts are exposed.\\n\",\n",
              " '  The fundamental problem of multiple secondary users contending for\\nopportunistic spectrum access over multiple channels in cognitive radio\\nnetworks has been formulated recently as a decentralized multi-armed bandit\\n(D-MAB) problem. In a D-MAB problem there are $M$ users and $N$ arms (channels)\\nthat each offer i.i.d. stochastic rewards with unknown means so long as they\\nare accessed without collision. The goal is to design a decentralized online\\nlearning policy that incurs minimal regret, defined as the difference between\\nthe total expected rewards accumulated by a model-aware genie, and that\\nobtained by all users applying the policy. We make two contributions in this\\npaper. First, we consider the setting where the users have a prioritized\\nranking, such that it is desired for the $K$-th-ranked user to learn to access\\nthe arm offering the $K$-th highest mean reward. For this problem, we present\\nthe first distributed policy that yields regret that is uniformly logarithmic\\nover time without requiring any prior assumption about the mean rewards.\\nSecond, we consider the case when a fair access policy is required, i.e., it is\\ndesired for all users to experience the same mean reward. For this problem, we\\npresent a distributed policy that yields order-optimal regret scaling with\\nrespect to the number of users and arms, better than previously proposed\\npolicies in the literature. Both of our distributed policies make use of an\\ninnovative modification of the well known UCB1 policy for the classic\\nmulti-armed bandit problem that allows a single user to learn how to play the\\narm that yields the $K$-th largest mean reward.\\n',\n",
              " '  Supervised learning is all about the ability to generalize knowledge.\\nSpecifically, the goal of the learning is to train a classifier using training\\ndata, in such a way that it will be capable of classifying new unseen data\\ncorrectly. In order to acheive this goal, it is important to carefully design\\nthe learner, so it will not overfit the training data. The later can is done\\nusually by adding a regularization term. The statistical learning theory\\nexplains the success of this method by claiming that it restricts the\\ncomplexity of the learned model. This explanation, however, is rather abstract\\nand does not have a geometric intuition. The generalization error of a\\nclassifier may be thought of as correlated with its robustness to perturbations\\nof the data: a classifier that copes with disturbance is expected to generalize\\nwell. Indeed, Xu et al. [2009] have shown that the SVM formulation is\\nequivalent to a robust optimization (RO) formulation, in which an adversary\\ndisplaces the training and testing points within a ball of pre-determined\\nradius. In this work we explore a different kind of robustness, namely changing\\neach data point with a Gaussian cloud centered at the sample. Loss is evaluated\\nas the expectation of an underlying loss function on the cloud. This setup fits\\nthe fact that in many applications, the data is sampled along with noise. We\\ndevelop an RO framework, in which the adversary chooses the covariance of the\\nnoise. In our algorithm named GURU, the tuning parameter is a spectral bound on\\nthe noise, thus it can be estimated using physical or applicative\\nconsiderations. Our experiments show that this framework performs as well as\\nSVM and even slightly better in some cases. Generalizations for Mercer kernels\\nand for the multiclass case are presented as well. We also show that our\\nframework may be further generalized, using the technique of convex perspective\\nfunctions.\\n',\n",
              " '  We propose a new clustering technique that can be regarded as a numerical\\nmethod to compute the proximity gestalt. The method analyzes edge length\\nstatistics in the MST of the dataset and provides an a contrario cluster\\ndetection criterion. The approach is fully parametric on the chosen distance\\nand can detect arbitrarily shaped clusters. The method is also automatic, in\\nthe sense that only a single parameter is left to the user. This parameter has\\nan intuitive interpretation as it controls the expected number of false\\ndetections. We show that the iterative application of our method can (1)\\nprovide robustness to noise and (2) solve a masking phenomenon in which a\\nhighly populated and salient cluster dominates the scene and inhibits the\\ndetection of less-populated, but still salient, clusters.\\n',\n",
              " '  We introduce new online and batch algorithms that are robust to data with\\nmissing features, a situation that arises in many practical applications. In\\nthe online setup, we allow for the comparison hypothesis to change as a\\nfunction of the subset of features that is observed on any given round,\\nextending the standard setting where the comparison hypothesis is fixed\\nthroughout. In the batch setup, we present a convex relation of a non-convex\\nproblem to jointly estimate an imputation function, used to fill in the values\\nof missing features, along with the classification hypothesis. We prove regret\\nbounds in the online setting and Rademacher complexity bounds for the batch\\ni.i.d. setting. The algorithms are tested on several UCI datasets, showing\\nsuperior performance over baselines.\\n',\n",
              " '  A wide class of regularization problems in machine learning and statistics\\nemploy a regularization term which is obtained by composing a simple convex\\nfunction \\\\omega with a linear transformation. This setting includes Group Lasso\\nmethods, the Fused Lasso and other total variation methods, multi-task learning\\nmethods and many more. In this paper, we present a general approach for\\ncomputing the proximity operator of this class of regularizers, under the\\nassumption that the proximity operator of the function \\\\omega is known in\\nadvance. Our approach builds on a recent line of research on optimal first\\norder optimization methods and uses fixed point iterations for numerically\\ncomputing the proximity operator. It is more general than current approaches\\nand, as we show with numerical simulations, computationally more efficient than\\navailable first order methods which do not achieve the optimal rate. In\\nparticular, our method outperforms state of the art O(1/T) methods for\\noverlapping Group Lasso and matches optimal O(1/T^2) methods for the Fused\\nLasso and tree structured Group Lasso.\\n',\n",
              " '  We present a new active learning algorithm based on nonparametric estimators\\nof the regression function. Our investigation provides probabilistic bounds for\\nthe rates of convergence of the generalization error achievable by proposed\\nmethod over a broad class of underlying distributions. We also prove minimax\\nlower bounds which show that the obtained rates are almost tight.\\n',\n",
              " '  We derive exponential tail inequalities for sums of random matrices with no\\ndependence on the explicit matrix dimensions. These are similar to the matrix\\nversions of the Chernoff bound and Bernstein inequality except with the\\nexplicit matrix dimensions replaced by a trace quantity that can be small even\\nwhen the dimension is large or infinite. Some applications to principal\\ncomponent analysis and approximate matrix multiplication are given to\\nillustrate the utility of the new bounds.\\n',\n",
              " '  We consider a class of learning problems regularized by a structured\\nsparsity-inducing norm defined as the sum of l_2- or l_infinity-norms over\\ngroups of variables. Whereas much effort has been put in developing fast\\noptimization techniques when the groups are disjoint or embedded in a\\nhierarchy, we address here the case of general overlapping groups. To this end,\\nwe present two different strategies: On the one hand, we show that the proximal\\noperator associated with a sum of l_infinity-norms can be computed exactly in\\npolynomial time by solving a quadratic min-cost flow problem, allowing the use\\nof accelerated proximal gradient methods. On the other hand, we use proximal\\nsplitting techniques, and address an equivalent formulation with\\nnon-overlapping groups, but in higher dimension and with additional\\nconstraints. We propose efficient and scalable algorithms exploiting these two\\nstrategies, which are significantly faster than alternative approaches. We\\nillustrate these methods with several problems such as CUR matrix\\nfactorization, multi-task learning of tree-structured dictionaries, background\\nsubtraction in video sequences, image denoising with wavelets, and topographic\\ndictionary learning of natural image patches.\\n',\n",
              " '  In many practical applications of clustering, the objects to be clustered\\nevolve over time, and a clustering result is desired at each time step. In such\\napplications, evolutionary clustering typically outperforms traditional static\\nclustering by producing clustering results that reflect long-term trends while\\nbeing robust to short-term variations. Several evolutionary clustering\\nalgorithms have recently been proposed, often by adding a temporal smoothness\\npenalty to the cost function of a static clustering method. In this paper, we\\nintroduce a different approach to evolutionary clustering by accurately\\ntracking the time-varying proximities between objects followed by static\\nclustering. We present an evolutionary clustering framework that adaptively\\nestimates the optimal smoothing parameter using shrinkage estimation, a\\nstatistical approach that improves a naive estimate using additional\\ninformation. The proposed framework can be used to extend a variety of static\\nclustering algorithms, including hierarchical, k-means, and spectral\\nclustering, into evolutionary clustering algorithms. Experiments on synthetic\\nand real data sets indicate that the proposed framework outperforms static\\nclustering and existing evolutionary clustering algorithms in many scenarios.\\n',\n",
              " '  Generalized Linear Models (GLMs) and Single Index Models (SIMs) provide\\npowerful generalizations of linear regression, where the target variable is\\nassumed to be a (possibly unknown) 1-dimensional function of a linear\\npredictor. In general, these problems entail non-convex estimation procedures,\\nand, in practice, iterative local search heuristics are often used. Kalai and\\nSastry (2009) recently provided the first provably efficient method for\\nlearning SIMs and GLMs, under the assumptions that the data are in fact\\ngenerated under a GLM and under certain monotonicity and Lipschitz constraints.\\nHowever, to obtain provable performance, the method requires a fresh sample\\nevery iteration. In this paper, we provide algorithms for learning GLMs and\\nSIMs, which are both computationally and statistically efficient. We also\\nprovide an empirical study, demonstrating their feasibility in practice.\\n',\n",
              " \"  A fundamental result of statistical learnig theory states that a concept\\nclass is PAC learnable if and only if it is a uniform Glivenko-Cantelli class\\nif and only if the VC dimension of the class is finite. However, the theorem is\\nonly valid under special assumptions of measurability of the class, in which\\ncase the PAC learnability even becomes consistent. Otherwise, there is a\\nclassical example, constructed under the Continuum Hypothesis by Dudley and\\nDurst and further adapted by Blumer, Ehrenfeucht, Haussler, and Warmuth, of a\\nconcept class of VC dimension one which is neither uniform Glivenko-Cantelli\\nnor consistently PAC learnable. We show that, rather surprisingly, under an\\nadditional set-theoretic hypothesis which is much milder than the Continuum\\nHypothesis (Martin's Axiom), PAC learnability is equivalent to finite VC\\ndimension for every concept class.\\n\",\n",
              " '  Given the ever increasing bandwidth of the visual information available to\\nmany intelligent systems, it is becoming essential to endow them with a sense\\nof what is worthwhile their attention and what can be safely disregarded. This\\narticle presents a general mathematical framework to efficiently allocate the\\navailable computational resources to process the parts of the input that are\\nrelevant to solve a given perceptual problem. By this we mean to find the\\nhypothesis H (i.e., the state of the world) that maximizes a function L(H),\\nrepresenting how well each hypothesis \"explains\" the input. Given the large\\nbandwidth of the sensory input, fully evaluating L(H) for each hypothesis H is\\ncomputationally infeasible (e.g., because it would imply checking a large\\nnumber of pixels). To address this problem we propose a mathematical framework\\nwith two key ingredients. The first one is a Bounding Mechanism (BM) to compute\\nlower and upper bounds of L(H), for a given computational budget. These bounds\\nare much cheaper to compute than L(H) itself, can be refined at any time by\\nincreasing the budget allocated to a hypothesis, and are frequently enough to\\ndiscard a hypothesis. To compute these bounds, we develop a novel theory of\\nshapes and shape priors. The second ingredient is a Focus of Attention\\nMechanism (FoAM) to select which hypothesis\\' bounds should be refined next,\\nwith the goal of discarding non-optimal hypotheses with the least amount of\\ncomputation. The proposed framework: 1) is very efficient since most hypotheses\\nare discarded with minimal computation; 2) is parallelizable; 3) is guaranteed\\nto find the globally optimal hypothesis; and 4) its running time depends on the\\nproblem at hand, not on the bandwidth of the input. We instantiate the proposed\\nframework for the problem of simultaneously estimating the class, pose, and a\\nnoiseless version of a 2D shape in a 2D image.\\n',\n",
              " '  With inspiration from Random Forests (RF) in the context of classification, a\\nnew clustering ensemble method---Cluster Forests (CF) is proposed.\\nGeometrically, CF randomly probes a high-dimensional data cloud to obtain \"good\\nlocal clusterings\" and then aggregates via spectral clustering to obtain\\ncluster assignments for the whole dataset. The search for good local\\nclusterings is guided by a cluster quality measure kappa. CF progressively\\nimproves each local clustering in a fashion that resembles the tree growth in\\nRF. Empirical studies on several real-world datasets under two different\\nperformance metrics show that CF compares favorably to its competitors.\\nTheoretical analysis reveals that the kappa measure makes it possible to grow\\nthe local clustering in a desirable way---it is \"noise-resistant\". A\\nclosed-form expression is obtained for the mis-clustering rate of spectral\\nclustering under a perturbation model, which yields new insights into some\\naspects of spectral clustering.\\n',\n",
              " '  This article focuses on signal classification for deep-sea acoustic neutrino\\ndetection. In the deep sea, the background of transient signals is very\\ndiverse. Approaches like matched filtering are not sufficient to distinguish\\nbetween neutrino-like signals and other transient signals with similar\\nsignature, which are forming the acoustic background for neutrino detection in\\nthe deep-sea environment. A classification system based on machine learning\\nalgorithms is analysed with the goal to find a robust and effective way to\\nperform this task. For a well-trained model, a testing error on the level of\\none percent is achieved for strong classifiers like Random Forest and Boosting\\nTrees using the extracted features of the signal as input and utilising dense\\nclusters of sensors instead of single sensors.\\n',\n",
              " \"  The $\\\\ell$-1 norm based optimization is widely used in signal processing,\\nespecially in recent compressed sensing theory. This paper studies the solution\\npath of the $\\\\ell$-1 norm penalized least-square problem, whose constrained\\nform is known as Least Absolute Shrinkage and Selection Operator (LASSO). A\\nsolution path is the set of all the optimizers with respect to the evolution of\\nthe hyperparameter (Lagrange multiplier). The study of the solution path is of\\ngreat significance in viewing and understanding the profile of the tradeoff\\nbetween the approximation and regularization terms. If the solution path of a\\ngiven problem is known, it can help us to find the optimal hyperparameter under\\na given criterion such as the Akaike Information Criterion. In this paper we\\npresent a sufficient condition on $\\\\ell$-1 norm penalized least-square problem.\\nUnder this sufficient condition, the number of nonzero entries in the optimizer\\nor solution vector increases monotonically when the hyperparameter decreases.\\nWe also generalize the result to the often used total variation case, where the\\n$\\\\ell$-1 norm is taken over the first order derivative of the solution vector.\\nWe prove that the proposed condition has intrinsic connections with the\\ncondition given by Donoho, et al \\\\cite{Donoho08} and the positive cone\\ncondition by Efron {\\\\it el al} \\\\cite{Efron04}. However, the proposed condition\\ndoes not need to assume the sparsity level of the signal as required by Donoho\\net al's condition, and is easier to verify than Efron, et al's positive cone\\ncondition when being used for practical applications.\\n\",\n",
              " '  Pattern learning in an important problem in Natural Language Processing\\n(NLP). Some exhaustive pattern learning (EPL) methods (Bod, 1992) were proved\\nto be flawed (Johnson, 2002), while similar algorithms (Och and Ney, 2004)\\nshowed great advantages on other tasks, such as machine translation. In this\\narticle, we first formalize EPL, and then show that the probability given by an\\nEPL model is constant-factor approximation of the probability given by an\\nensemble method that integrates exponential number of models obtained with\\nvarious segmentations of the training data. This work for the first time\\nprovides theoretical justification for the widely used EPL algorithm in NLP,\\nwhich was previously viewed as a flawed heuristic method. Better understanding\\nof EPL may lead to improved pattern learning algorithms in future.\\n',\n",
              " \"  In conventional target tracking systems, human operators use the estimated\\ntarget tracks to make higher level inference of the target behaviour/intent.\\nThis paper develops syntactic filtering algorithms that assist human operators\\nby extracting spatial patterns from target tracks to identify\\nsuspicious/anomalous spatial trajectories. The targets' spatial trajectories\\nare modeled by a stochastic context free grammar (SCFG) and a switched mode\\nstate space model. Bayesian filtering algorithms for stochastic context free\\ngrammars are presented for extracting the syntactic structure and illustrated\\nfor a ground moving target indicator (GMTI) radar example. The performance of\\nthe algorithms is tested with the experimental data collected using DRDC\\nOttawa's X-band Wideband Experimental Airborne Radar (XWEAR).\\n\",\n",
              " '  Notwithstanding the popularity of conventional clustering algorithms such as\\nK-means and probabilistic clustering, their clustering results are sensitive to\\nthe presence of outliers in the data. Even a few outliers can compromise the\\nability of these algorithms to identify meaningful hidden structures rendering\\ntheir outcome unreliable. This paper develops robust clustering algorithms that\\nnot only aim to cluster the data, but also to identify the outliers. The novel\\napproaches rely on the infrequent presence of outliers in the data which\\ntranslates to sparsity in a judiciously chosen domain. Capitalizing on the\\nsparsity in the outlier domain, outlier-aware robust K-means and probabilistic\\nclustering approaches are proposed. Their novelty lies on identifying outliers\\nwhile effecting sparsity in the outlier domain through carefully chosen\\nregularization. A block coordinate descent approach is developed to obtain\\niterative algorithms with convergence guarantees and small excess computational\\ncomplexity with respect to their non-robust counterparts. Kernelized versions\\nof the robust clustering algorithms are also developed to efficiently handle\\nhigh-dimensional data, identify nonlinearly separable clusters, or even cluster\\nobjects that are not represented by vectors. Numerical tests on both synthetic\\nand real datasets validate the performance and applicability of the novel\\nalgorithms.\\n',\n",
              " '  Modern data acquisition routinely produces massive amounts of network data.\\nThough many methods and models have been proposed to analyze such data, the\\nresearch of network data is largely disconnected with the classical theory of\\nstatistical learning and signal processing. In this paper, we present a new\\nframework for modeling network data, which connects two seemingly different\\nareas: network data analysis and compressed sensing. From a nonparametric\\nperspective, we model an observed network using a large dictionary. In\\nparticular, we consider the network clique detection problem and show\\nconnections between our formulation with a new algebraic tool, namely Randon\\nbasis pursuit in homogeneous spaces. Such a connection allows us to identify\\nrigorous recovery conditions for clique detection problems. Though this paper\\nis mainly conceptual, we also develop practical approximation algorithms for\\nsolving empirical problems and demonstrate their usefulness on real-world\\ndatasets.\\n',\n",
              " \"  Q-learning is a reliable but inefficient off-policy temporal-difference\\nmethod, backing up reward only one step at a time. Replacing traces, using a\\nrecency heuristic, are more efficient but less reliable. In this work, we\\nintroduce model-free, off-policy temporal difference methods that make better\\nuse of experience than Watkins' Q(\\\\lambda). We introduce both Optimistic\\nQ(\\\\lambda) and the temporal second difference trace (TSDT). TSDT is\\nparticularly powerful in deterministic domains. TSDT uses neither recency nor\\nfrequency heuristics, storing (s,a,r,s',\\\\delta) so that off-policy updates can\\nbe performed after apparently suboptimal actions have been taken. There are\\nadditional advantages when using state abstraction, as in MAXQ. We demonstrate\\nthat TSDT does significantly better than both Q-learning and Watkins'\\nQ(\\\\lambda) in a deterministic cliff-walking domain. Results in a noisy\\ncliff-walking domain are less advantageous for TSDT, but demonstrate the\\nefficacy of Optimistic Q(\\\\lambda), a replacing trace with some of the\\nadvantages of TSDT.\\n\",\n",
              " '  This paper considers the problem of clustering a partially observed\\nunweighted graph---i.e., one where for some node pairs we know there is an edge\\nbetween them, for some others we know there is no edge, and for the remaining\\nwe do not know whether or not there is an edge. We want to organize the nodes\\ninto disjoint clusters so that there is relatively dense (observed)\\nconnectivity within clusters, and sparse across clusters.\\n  We take a novel yet natural approach to this problem, by focusing on finding\\nthe clustering that minimizes the number of \"disagreements\"---i.e., the sum of\\nthe number of (observed) missing edges within clusters, and (observed) present\\nedges across clusters. Our algorithm uses convex optimization; its basis is a\\nreduction of disagreement minimization to the problem of recovering an\\n(unknown) low-rank matrix and an (unknown) sparse matrix from their partially\\nobserved sum. We evaluate the performance of our algorithm on the classical\\nPlanted Partition/Stochastic Block Model. Our main theorem provides sufficient\\nconditions for the success of our algorithm as a function of the minimum\\ncluster size, edge density and observation probability; in particular, the\\nresults characterize the tradeoff between the observation probability and the\\nedge density gap. When there are a constant number of clusters of equal size,\\nour results are optimal up to logarithmic factors.\\n',\n",
              " '  In experimenting with off-policy temporal difference (TD) methods in\\nhierarchical reinforcement learning (HRL) systems, we have observed unwanted\\non-policy learning under reproducible conditions. Here we present modifications\\nto several TD methods that prevent unintentional on-policy learning from\\noccurring. These modifications create a tension between exploration and\\nlearning. Traditional TD methods require commitment to finishing subtasks\\nwithout exploration in order to update Q-values for early actions with high\\nprobability. One-step intra-option learning and temporal second difference\\ntraces (TSDT) do not suffer from this limitation. We demonstrate that our HRL\\nsystem is efficient without commitment to completion of subtasks in a\\ncliff-walking domain, contrary to a widespread claim in the literature that it\\nis critical for efficiency of learning. Furthermore, decreasing commitment as\\nexploration progresses is shown to improve both online performance and the\\nresultant policy in the taxicab domain, opening a new avenue for research into\\nwhen it is more beneficial to continue with the current subtask or to replan.\\n',\n",
              " '  We present a new application and covering number bound for the framework of\\n\"Machine Learning with Operational Costs (MLOC),\" which is an exploratory form\\nof decision theory. The MLOC framework incorporates knowledge about how a\\npredictive model will be used for a subsequent task, thus combining machine\\nlearning with the decision that is made afterwards. In this work, we use the\\nMLOC framework to study a problem that has implications for power grid\\nreliability and maintenance, called the Machine Learning and Traveling\\nRepairman Problem ML&TRP. The goal of the ML&TRP is to determine a route for a\\n\"repair crew,\" which repairs nodes on a graph. The repair crew aims to minimize\\nthe cost of failures at the nodes, but as in many real situations, the failure\\nprobabilities are not known and must be estimated. The MLOC framework allows us\\nto understand how this uncertainty influences the repair route. We also present\\nnew covering number generalization bounds for the MLOC framework.\\n',\n",
              " \"  Learning theory has largely focused on two main learning scenarios. The first\\nis the classical statistical setting where instances are drawn i.i.d. from a\\nfixed distribution and the second scenario is the online learning, completely\\nadversarial scenario where adversary at every time step picks the worst\\ninstance to provide the learner with. It can be argued that in the real world\\nneither of these assumptions are reasonable. It is therefore important to study\\nproblems with a range of assumptions on data. Unfortunately, theoretical\\nresults in this area are scarce, possibly due to absence of general tools for\\nanalysis. Focusing on the regret formulation, we define the minimax value of a\\ngame where the adversary is restricted in his moves. The framework captures\\nstochastic and non-stochastic assumptions on data. Building on the sequential\\nsymmetrization approach, we define a notion of distribution-dependent\\nRademacher complexity for the spectrum of problems ranging from i.i.d. to\\nworst-case. The bounds let us immediately deduce variation-type bounds. We then\\nconsider the i.i.d. adversary and show equivalence of online and batch\\nlearnability. In the supervised setting, we consider various hybrid assumptions\\non the way that x and y variables are chosen. Finally, we consider smoothed\\nlearning problems and show that half-spaces are online learnable in the\\nsmoothed model. In fact, exponentially small noise added to adversary's\\ndecisions turns this problem with infinite Littlestone's dimension into a\\nlearnable problem.\\n\",\n",
              " '  In this paper we present methods for attacking and defending $k$-gram\\nstatistical analysis techniques that are used, for example, in network traffic\\nanalysis and covert channel detection. The main new result is our demonstration\\nof how to use a behavior\\'s or process\\' $k$-order statistics to build a\\nstochastic process that has those same $k$-order stationary statistics but\\npossesses different, deliberately designed, $(k+1)$-order statistics if\\ndesired. Such a model realizes a \"complexification\" of the process or behavior\\nwhich a defender can use to monitor whether an attacker is shaping the\\nbehavior. By deliberately introducing designed $(k+1)$-order behaviors, the\\ndefender can check to see if those behaviors are present in the data. We also\\ndevelop constructs for source codes that respect the $k$-order statistics of a\\nprocess while encoding covert information. One fundamental consequence of these\\nresults is that certain types of behavior analyses techniques come down to an\\n{\\\\em arms race} in the sense that the advantage goes to the party that has more\\ncomputing resources applied to the problem.\\n',\n",
              " \"  In wireless access network optimization, today's main challenges reside in\\ntraffic offload and in the improvement of both capacity and coverage networks.\\nThe operators are interested in solving their localized coverage and capacity\\nproblems in areas where the macro network signal is not able to serve the\\ndemand for mobile data. Thus, the major issue for operators is to find the best\\nsolution at reasonable expanses. The femto cell seems to be the answer to this\\nproblematic. In this work (This work is supported by the COMET project AWARE.\\nhttp://www.ftw.at/news/project-start-for-aware-ftw), we focus on the problem of\\nsharing femto access between a same mobile operator's customers. This problem\\ncan be modeled as a game where service requesters customers (SRCs) and service\\nproviders customers (SPCs) are the players.\\n  This work addresses the sharing femto access problem considering only one SPC\\nusing game theory tools. We consider that SRCs are static and have some similar\\nand regular connection behavior. We also note that the SPC and each SRC have a\\nsoftware embedded respectively on its femto access, user equipment (UE).\\n  After each connection requested by a SRC, its software will learn the\\nstrategy increasing its gain knowing that no information about the other SRCs\\nstrategies is given. The following article presents a distributed learning\\nalgorithm with incomplete information running in SRCs software. We will then\\nanswer the following questions for a game with $N$ SRCs and one SPC: how many\\nconnections are necessary for each SRC in order to learn the strategy\\nmaximizing its gain? Does this algorithm converge to a stable state? If yes,\\ndoes this state a Nash Equilibrium and is there any way to optimize the\\nlearning process duration time triggered by SRCs software?\\n\",\n",
              " '  In undirected graphical models, learning the graph structure and learning the\\nfunctions that relate the predictive variables (features) to the responses\\ngiven the structure are two topics that have been widely investigated in\\nmachine learning and statistics. Learning graphical models in two stages will\\nhave problems because graph structure may change after considering the\\nfeatures. The main contribution of this paper is the proposed method that\\nlearns the graph structure and functions on the graph at the same time. General\\ngraphical models with binary outcomes conditioned on predictive variables are\\nproved to be equivalent to multivariate Bernoulli model. The reparameterization\\nof the potential functions in graphical model by conditional log odds ratios in\\nmultivariate Bernoulli model offers advantage in the representation of the\\nconditional independence structure in the model. Additionally, we impose a\\nstructure penalty on groups of conditional log odds ratios to learn the graph\\nstructure. These groups of functions are designed with overlaps to enforce\\nhierarchical function selection. In this way, we are able to shrink higher\\norder interactions to obtain a sparse graph structure. Simulation studies show\\nthat the method is able to recover the graph structure. The analysis of county\\ndata from Census Bureau gives interesting relations between unemployment rate,\\ncrime and others discovered by the model.\\n',\n",
              " '  In this paper,we consider the restless bandit problem, which is one of the\\nmost well-studied generalizations of the celebrated stochastic multi-armed\\nbandit problem in decision theory. However, it is known be PSPACE-Hard to\\napproximate to any non-trivial factor. Thus the optimality is very difficult to\\nobtain due to its high complexity. A natural method is to obtain the greedy\\npolicy considering its stability and simplicity. However, the greedy policy\\nwill result in the optimality loss for its intrinsic myopic behavior generally.\\nIn this paper, by analyzing one class of so-called standard reward function, we\\nestablish the closed-form condition about the discounted factor \\\\beta such that\\nthe optimality of the greedy policy is guaranteed under the discounted expected\\nreward criterion, especially, the condition \\\\beta = 1 indicating the optimality\\nof the greedy policy under the average accumulative reward criterion. Thus, the\\nstandard form of reward function can easily be used to judge the optimality of\\nthe greedy policy without any complicated calculation. Some examples in\\ncognitive radio networks are presented to verify the effectiveness of the\\nmathematical result in judging the optimality of the greedy policy.\\n',\n",
              " '  This book presents a methodology and philosophy of empirical science based on\\nlarge scale lossless data compression. In this view a theory is scientific if\\nit can be used to build a data compression program, and it is valuable if it\\ncan compress a standard benchmark database to a small size, taking into account\\nthe length of the compressor itself. This methodology therefore includes an\\nOccam principle as well as a solution to the problem of demarcation. Because of\\nthe fundamental difficulty of lossless compression, this type of research must\\nbe empirical in nature: compression can only be achieved by discovering and\\ncharacterizing empirical regularities in the data. Because of this, the\\nphilosophy provides a way to reformulate fields such as computer vision and\\ncomputational linguistics as empirical sciences: the former by attempting to\\ncompress databases of natural images, the latter by attempting to compress\\nlarge text databases. The book argues that the rigor and objectivity of the\\ncompression principle should set the stage for systematic progress in these\\nfields. The argument is especially strong in the context of computer vision,\\nwhich is plagued by chronic problems of evaluation.\\n  The book also considers the field of machine learning. Here the traditional\\napproach requires that the models proposed to solve learning problems be\\nextremely simple, in order to avoid overfitting. However, the world may contain\\nintrinsically complex phenomena, which would require complex models to\\nunderstand. The compression philosophy can justify complex models because of\\nthe large quantity of data being modeled (if the target database is 100 Gb, it\\nis easy to justify a 10 Mb model). The complex models and abstractions learned\\non the basis of the raw data (images, language, etc) can then be reused to\\nsolve any specific learning problem, such as face recognition or machine\\ntranslation.\\n',\n",
              " '  We consider finite horizon Markov decision processes under performance\\nmeasures that involve both the mean and the variance of the cumulative reward.\\nWe show that either randomized or history-based policies can improve\\nperformance. We prove that the complexity of computing a policy that maximizes\\nthe mean reward under a variance constraint is NP-hard for some cases, and\\nstrongly NP-hard for others. We finally offer pseudopolynomial exact and\\napproximation algorithms.\\n',\n",
              " '  We consider the problem of learning causal information between random\\nvariables in directed acyclic graphs (DAGs) when allowing arbitrarily many\\nlatent and selection variables. The FCI (Fast Causal Inference) algorithm has\\nbeen explicitly designed to infer conditional independence and causal\\ninformation in such settings. However, FCI is computationally infeasible for\\nlarge graphs. We therefore propose the new RFCI algorithm, which is much faster\\nthan FCI. In some situations the output of RFCI is slightly less informative,\\nin particular with respect to conditional independence information. However, we\\nprove that any causal information in the output of RFCI is correct in the\\nasymptotic limit. We also define a class of graphs on which the outputs of FCI\\nand RFCI are identical. We prove consistency of FCI and RFCI in sparse\\nhigh-dimensional settings, and demonstrate in simulations that the estimation\\nperformances of the algorithms are very similar. All software is implemented in\\nthe R-package pcalg.\\n',\n",
              " \"  We state the problem of inverse reinforcement learning in terms of preference\\nelicitation, resulting in a principled (Bayesian) statistical formulation. This\\ngeneralises previous work on Bayesian inverse reinforcement learning and allows\\nus to obtain a posterior distribution on the agent's preferences, policy and\\noptionally, the obtained reward sequence, from observations. We examine the\\nrelation of the resulting approach to other statistical methods for inverse\\nreinforcement learning via analysis and experimental results. We show that\\npreferences can be determined accurately, even if the observed agent's policy\\nis sub-optimal with respect to its own preferences. In that case, significantly\\nimproved policies with respect to the agent's preferences are obtained,\\ncompared to both other methods and to the performance of the demonstrated\\npolicy.\\n\",\n",
              " '  We present a method to stop the evaluation of a decision making process when\\nthe result of the full evaluation is obvious. This trait is highly desirable\\nfor online margin-based machine learning algorithms where a classifier\\ntraditionally evaluates all the features for every example. We observe that\\nsome examples are easier to classify than others, a phenomenon which is\\ncharacterized by the event when most of the features agree on the class of an\\nexample. By stopping the feature evaluation when encountering an easy to\\nclassify example, the learning algorithm can achieve substantial gains in\\ncomputation. Our method provides a natural attention mechanism for learning\\nalgorithms. By modifying Pegasos, a margin-based online learning algorithm, to\\ninclude our attentive method we lower the number of attributes computed from\\n$n$ to an average of $O(\\\\sqrt{n})$ features without loss in prediction\\naccuracy. We demonstrate the effectiveness of Attentive Pegasos on MNIST data.\\n',\n",
              " '  We consider a suboptimal solution path algorithm for the Support Vector\\nMachine. The solution path algorithm is an effective tool for solving a\\nsequence of a parametrized optimization problems in machine learning. The path\\nof the solutions provided by this algorithm are very accurate and they satisfy\\nthe optimality conditions more strictly than other SVM optimization algorithms.\\nIn many machine learning application, however, this strict optimality is often\\nunnecessary, and it adversely affects the computational efficiency. Our\\nalgorithm can generate the path of suboptimal solutions within an arbitrary\\nuser-specified tolerance level. It allows us to control the trade-off between\\nthe accuracy of the solution and the computational cost. Moreover, We also show\\nthat our suboptimal solutions can be interpreted as the solution of a\\n\\\\emph{perturbed optimization problem} from the original one. We provide some\\ntheoretical analyses of our algorithm based on this novel interpretation. The\\nexperimental results also demonstrate the effectiveness of our algorithm.\\n',\n",
              " '  Nearest neighbor (k-NN) graphs are widely used in machine learning and data\\nmining applications, and our aim is to better understand what they reveal about\\nthe cluster structure of the unknown underlying distribution of points.\\nMoreover, is it possible to identify spurious structures that might arise due\\nto sampling variability?\\n  Our first contribution is a statistical analysis that reveals how certain\\nsubgraphs of a k-NN graph form a consistent estimator of the cluster tree of\\nthe underlying distribution of points. Our second and perhaps most important\\ncontribution is the following finite sample guarantee. We carefully work out\\nthe tradeoff between aggressive and conservative pruning and are able to\\nguarantee the removal of all spurious cluster structures at all levels of the\\ntree while at the same time guaranteeing the recovery of salient clusters. This\\nis the first such finite sample result in the context of clustering.\\n',\n",
              " '  We study the prevalent problem when a test distribution differs from the\\ntraining distribution. We consider a setting where our training set consists of\\na small number of sample domains, but where we have many samples in each\\ndomain. Our goal is to generalize to a new domain. For example, we may want to\\nlearn a similarity function using only certain classes of objects, but we\\ndesire that this similarity function be applicable to object classes not\\npresent in our training sample (e.g. we might seek to learn that \"dogs are\\nsimilar to dogs\" even though images of dogs were absent from our training set).\\nOur theoretical analysis shows that we can select many more features than\\ndomains while avoiding overfitting by utilizing data-dependent variance\\nproperties. We present a greedy feature selection algorithm based on using\\nT-statistics. Our experiments validate this theory showing that our T-statistic\\nbased greedy feature selection is more robust at avoiding overfitting than the\\nclassical greedy procedure.\\n',\n",
              " '  We investigate unsupervised pre-training of deep architectures as feature\\ngenerators for \"shallow\" classifiers. Stacked Denoising Autoencoders (SdA),\\nwhen used as feature pre-processing tools for SVM classification, can lead to\\nsignificant improvements in accuracy - however, at the price of a substantial\\nincrease in computational cost. In this paper we create a simple algorithm\\nwhich mimics the layer by layer training of SdAs. However, in contrast to SdAs,\\nour algorithm requires no training through gradient descent as the parameters\\ncan be computed in closed-form. It can be implemented in less than 20 lines of\\nMATLABTMand reduces the computation time from several hours to mere seconds. We\\nshow that our feature transformation reliably improves the results of SVM\\nclassification significantly on all our data sets - often outperforming SdAs\\nand even deep neural networks in three out of four deep learning benchmarks.\\n',\n",
              " '  We introduce an algorithm that, given n objects, learns a similarity matrix\\nover all n^2 pairs, from crowdsourced data alone. The algorithm samples\\nresponses to adaptively chosen triplet-based relative-similarity queries. Each\\nquery has the form \"is object \\'a\\' more similar to \\'b\\' or to \\'c\\'?\" and is chosen\\nto be maximally informative given the preceding responses. The output is an\\nembedding of the objects into Euclidean space (like MDS); we refer to this as\\nthe \"crowd kernel.\" SVMs reveal that the crowd kernel captures prominent and\\nsubtle features across a number of domains, such as \"is striped\" among neckties\\nand \"vowel vs. consonant\" among letters.\\n',\n",
              " '  The maximum a posteriori (MAP) configuration of binary variable models with\\nsubmodular graph-structured energy functions can be found efficiently and\\nexactly by graph cuts. Max-product belief propagation (MP) has been shown to be\\nsuboptimal on this class of energy functions by a canonical counterexample\\nwhere MP converges to a suboptimal fixed point (Kulesza & Pereira, 2008).\\n  In this work, we show that under a particular scheduling and damping scheme,\\nMP is equivalent to graph cuts, and thus optimal. We explain the apparent\\ncontradiction by showing that with proper scheduling and damping, MP always\\nconverges to an optimal fixed point. Thus, the canonical counterexample only\\nshows the suboptimality of MP with a particular suboptimal choice of schedule\\nand damping. With proper choices, MP is optimal.\\n',\n",
              " '  The goal of machine learning is to provide solutions which are trained by\\ndata or by experience coming from the environment. Many training algorithms\\nexist and some brilliant successes were achieved. But even in structured\\nenvironments for machine learning (e.g. data mining or board games), most\\napplications beyond the level of toy problems need careful hand-tuning or human\\ningenuity (i.e. detection of interesting patterns) or both. We discuss several\\naspects how self-configuration can help to alleviate these problems. One aspect\\nis the self-configuration by tuning of algorithms, where recent advances have\\nbeen made in the area of SPO (Sequen- tial Parameter Optimization). Another\\naspect is the self-configuration by pattern detection or feature construction.\\nForming multiple features (e.g. random boolean functions) and using algorithms\\n(e.g. random forests) which easily digest many fea- tures can largely increase\\nlearning speed. However, a full-fledged theory of feature construction is not\\nyet available and forms a current barrier in machine learning. We discuss\\nseveral ideas for systematic inclusion of feature construction. This may lead\\nto partly self-configuring machine learning solutions which show robustness,\\nflexibility, and fast learning in potentially changing environments.\\n',\n",
              " '  Boosting is a popular way to derive powerful learners from simpler hypothesis\\nclasses. Following previous work (Mason et al., 1999; Friedman, 2000) on\\ngeneral boosting frameworks, we analyze gradient-based descent algorithms for\\nboosting with respect to any convex objective and introduce a new measure of\\nweak learner performance into this setting which generalizes existing work. We\\npresent the weak to strong learning guarantees for the existing gradient\\nboosting work for strongly-smooth, strongly-convex objectives under this new\\nmeasure of performance, and also demonstrate that this work fails for\\nnon-smooth objectives. To address this issue, we present new algorithms which\\nextend this boosting approach to arbitrary convex loss functions and give\\ncorresponding weak to strong convergence results. In addition, we demonstrate\\nexperimental results that support our analysis and demonstrate the need for the\\nnew algorithms we present.\\n',\n",
              " '  In many real world problems, optimization decisions have to be made with\\nlimited information. The decision maker may have no a priori or posteriori data\\nabout the often nonconvex objective function except from on a limited number of\\npoints that are obtained over time through costly observations. This paper\\npresents an optimization framework that takes into account the information\\ncollection (observation), estimation (regression), and optimization\\n(maximization) aspects in a holistic and structured manner. Explicitly\\nquantifying the information acquired at each optimization step using the\\nentropy measure from information theory, the (nonconvex) objective function to\\nbe optimized (maximized) is modeled and estimated by adopting a Bayesian\\napproach and using Gaussian processes as a state-of-the-art regression method.\\nThe resulting iterative scheme allows the decision maker to solve the problem\\nby expressing preferences for each aspect quantitatively and concurrently.\\n',\n",
              " '  In many real world problems, control decisions have to be made with limited\\ninformation. The controller may have no a priori (or even posteriori) data on\\nthe nonlinear system, except from a limited number of points that are obtained\\nover time. This is either due to high cost of observation or the highly\\nnon-stationary nature of the system. The resulting conflict between information\\ncollection (identification, exploration) and control (optimization,\\nexploitation) necessitates an active learning approach for iteratively\\nselecting the control actions which concurrently provide the data points for\\nsystem identification. This paper presents a dual control approach where the\\ninformation acquired at each control step is quantified using the entropy\\nmeasure from information theory and serves as the training input to a\\nstate-of-the-art Gaussian process regression (Bayesian learning) method. The\\nexplicit quantification of the information obtained from each data point allows\\nfor iterative optimization of both identification and control objectives. The\\napproach developed is illustrated with two examples: control of logistic map as\\na chaotic system and position control of a cart with inverted pendulum.\\n',\n",
              " '  In this paper, we focus on the question of the extent to which online\\nlearning can benefit from distributed computing. We focus on the setting in\\nwhich $N$ agents online-learn cooperatively, where each agent only has access\\nto its own data. We propose a generic data-distributed online learning\\nmeta-algorithm. We then introduce the Distributed Weighted Majority and\\nDistributed Online Mirror Descent algorithms, as special cases. We show, using\\nboth theoretical analysis and experiments, that compared to a single agent:\\ngiven the same computation time, these distributed algorithms achieve smaller\\ngeneralization errors; and given the same generalization errors, they can be\\n$N$ times faster.\\n',\n",
              " '  We present two alternative ways to apply PAC-Bayesian analysis to sequences\\nof dependent random variables. The first is based on a new lemma that enables\\nto bound expectations of convex functions of certain dependent random variables\\nby expectations of the same functions of independent Bernoulli random\\nvariables. This lemma provides an alternative tool to Hoeffding-Azuma\\ninequality to bound concentration of martingale values. Our second approach is\\nbased on integration of Hoeffding-Azuma inequality with PAC-Bayesian analysis.\\nWe also introduce a way to apply PAC-Bayesian analysis in situation of limited\\nfeedback. We combine the new tools to derive PAC-Bayesian generalization and\\nregret bounds for the multiarmed bandit problem. Although our regret bound is\\nnot yet as tight as state-of-the-art regret bounds based on other\\nwell-established techniques, our results significantly expand the range of\\npotential applications of PAC-Bayesian analysis and introduce a new analysis\\ntool to reinforcement learning and many other fields, where martingales and\\nlimited feedback are encountered.\\n',\n",
              " '  In this short note we prove a maximal concentration lemma for sub-Gaussian\\nrandom variables stating that for independent sub-Gaussian random variables we\\nhave \\\\[P<(\\\\max_{1\\\\le i\\\\le N}S_{i}>\\\\epsilon>)\\n\\\\le\\\\exp<(-\\\\frac{1}{N^2}\\\\sum_{i=1}^{N}\\\\frac{\\\\epsilon^{2}}{2\\\\sigma_{i}^{2}}>), \\\\]\\nwhere $S_i$ is the sum of $i$ zero mean independent sub-Gaussian random\\nvariables and $\\\\sigma_i$ is the variance of the $i$th random variable.\\n',\n",
              " '  The entropy/influence conjecture, raised by Friedgut and Kalai in 1996, seeks\\nto relate two different measures of concentration of the Fourier coefficients\\nof a Boolean function. Roughly saying, it claims that if the Fourier spectrum\\nis \"smeared out\", then the Fourier coefficients are concentrated on \"high\"\\nlevels. In this note we generalize the conjecture to biased product measures on\\nthe discrete cube, and prove a variant of the conjecture for functions with an\\nextremely low Fourier weight on the \"high\" levels.\\n',\n",
              " '  We first present our work in machine translation, during which we used\\naligned sentences to train a neural network to embed n-grams of different\\nlanguages into an $d$-dimensional space, such that n-grams that are the\\ntranslation of each other are close with respect to some metric. Good n-grams\\nto n-grams translation results were achieved, but full sentences translation is\\nstill problematic. We realized that learning semantics of sentences and\\ndocuments was the key for solving a lot of natural language processing\\nproblems, and thus moved to the second part of our work: sentence compression.\\nWe introduce a flexible neural network architecture for learning embeddings of\\nwords and sentences that extract their semantics, propose an efficient\\nimplementation in the Torch framework and present embedding results comparable\\nto the ones obtained with classical neural language models, while being more\\npowerful.\\n',\n",
              " '  Feature selection is an important pre-processing step for many pattern\\nclassification tasks. Traditionally, feature selection methods are designed to\\nobtain a feature subset that can lead to high classification accuracy. However,\\nclassification accuracy has recently been shown to be an inappropriate\\nperformance metric of classification systems in many cases. Instead, the Area\\nUnder the receiver operating characteristic Curve (AUC) and its multi-class\\nextension, MAUC, have been proved to be better alternatives. Hence, the target\\nof classification system design is gradually shifting from seeking a system\\nwith the maximum classification accuracy to obtaining a system with the maximum\\nAUC/MAUC. Previous investigations have shown that traditional feature selection\\nmethods need to be modified to cope with this new objective. These methods most\\noften are restricted to binary classification problems only. In this study, a\\nfilter feature selection method, namely MAUC Decomposition based Feature\\nSelection (MDFS), is proposed for multi-class classification problems. To the\\nbest of our knowledge, MDFS is the first method specifically designed to select\\nfeatures for building classification systems with maximum MAUC. Extensive\\nempirical results demonstrate the advantage of MDFS over several compared\\nfeature selection methods.\\n',\n",
              " \"  Many common probability distributions in statistics like the Gaussian,\\nmultinomial, Beta or Gamma distributions can be studied under the unified\\nframework of exponential families. In this paper, we prove that both R\\\\'enyi\\nand Tsallis divergences of distributions belonging to the same exponential\\nfamily admit a generic closed form expression. Furthermore, we show that\\nR\\\\'enyi and Tsallis entropies can also be calculated in closed-form for\\nsub-families including the Gaussian or exponential distributions, among others.\\n\",\n",
              " '  In manifold learning, algorithms based on graph Laplacians constructed from\\ndata have received considerable attention both in practical applications and\\ntheoretical analysis. In particular, the convergence of graph Laplacians\\nobtained from sampled data to certain continuous operators has become an active\\nresearch topic recently. Most of the existing work has been done under the\\nassumption that the data is sampled from a manifold without boundary or that\\nthe functions of interests are evaluated at a point away from the boundary.\\nHowever, the question of boundary behavior is of considerable practical and\\ntheoretical interest. In this paper we provide an analysis of the behavior of\\ngraph Laplacians at a point near or on the boundary, discuss their convergence\\nrates and their implications and provide some numerical results. It turns out\\nthat while points near the boundary occupy only a small part of the total\\nvolume of a manifold, the behavior of graph Laplacian there has different\\nscaling properties from its behavior elsewhere on the manifold, with global\\neffects on the whole manifold, an observation with potentially important\\nimplications for the general problem of learning on manifolds.\\n',\n",
              " '  We consider the problem of online linear regression on individual sequences.\\nThe goal in this paper is for the forecaster to output sequential predictions\\nwhich are, after $T$ time rounds, almost as good as the ones output by the best\\nlinear predictor in a given $\\\\ell^1$-ball in $\\\\\\\\R^d$. We consider both the\\ncases where the dimension~$d$ is small and large relative to the time horizon\\n$T$. We first present regret bounds with optimal dependencies on $d$, $T$, and\\non the sizes $U$, $X$ and $Y$ of the $\\\\ell^1$-ball, the input data and the\\nobservations. The minimax regret is shown to exhibit a regime transition around\\nthe point $d = \\\\sqrt{T} U X / (2 Y)$. Furthermore, we present efficient\\nalgorithms that are adaptive, \\\\ie, that do not require the knowledge of $U$,\\n$X$, $Y$, and $T$, but still achieve nearly optimal regret bounds.\\n',\n",
              " \"  We provide a natural learning process in which a financial trader without a\\nrisk receives a gain in case when Stock Market is inefficient. In this process,\\nthe trader rationally choose his gambles using a prediction made by a\\nrandomized calibrated algorithm. Our strategy is based on Dawid's notion of\\ncalibration with more general changing checking rules and on some modification\\nof Kakade and Foster's randomized algorithm for computing calibrated forecasts.\\n\",\n",
              " '  In this paper, we propose to (seamlessly) integrate b-bit minwise hashing\\nwith linear SVM to substantially improve the training (and testing) efficiency\\nusing much smaller memory, with essentially no loss of accuracy. Theoretically,\\nwe prove that the resemblance matrix, the minwise hashing matrix, and the b-bit\\nminwise hashing matrix are all positive definite matrices (kernels).\\nInterestingly, our proof for the positive definiteness of the b-bit minwise\\nhashing kernel naturally suggests a simple strategy to integrate b-bit hashing\\nwith linear SVM. Our technique is particularly useful when the data can not fit\\nin memory, which is an increasingly critical issue in large-scale machine\\nlearning. Our preliminary experimental results on a publicly available webspam\\ndataset (350K samples and 16 million dimensions) verified the effectiveness of\\nour algorithm. For example, the training time was reduced to merely a few\\nseconds. In addition, our technique can be easily extended to many other linear\\nand nonlinear machine learning applications such as logistic regression.\\n',\n",
              " '  We develop a coherent framework for integrative simultaneous analysis of the\\nexploration-exploitation and model order selection trade-offs. We improve over\\nour preceding results on the same subject (Seldin et al., 2011) by combining\\nPAC-Bayesian analysis with Bernstein-type inequality for martingales. Such a\\ncombination is also of independent interest for studies of multiple\\nsimultaneously evolving martingales.\\n',\n",
              " \"  We begin this report by describing the Probably Approximately Correct (PAC)\\nmodel for learning a concept class, consisting of subsets of a domain, and a\\nfunction class, consisting of functions from the domain to the unit interval.\\nTwo combinatorial parameters, the Vapnik-Chervonenkis (VC) dimension and its\\ngeneralization, the Fat Shattering dimension of scale e, are explained and a\\nfew examples of their calculations are given with proofs. We then explain\\nSauer's Lemma, which involves the VC dimension and is used to prove the\\nequivalence of a concept class being distribution-free PAC learnable and it\\nhaving finite VC dimension.\\n  As the main new result of our research, we explore the construction of a new\\nfunction class, obtained by forming compositions with a continuous logic\\nconnective, a uniformly continuous function from the unit hypercube to the unit\\ninterval, from a collection of function classes. Vidyasagar had proved that\\nsuch a composition function class has finite Fat Shattering dimension of all\\nscales if the classes in the original collection do; however, no estimates of\\nthe dimension were known. Using results by Mendelson-Vershynin and Talagrand,\\nwe bound the Fat Shattering dimension of scale e of this new function class in\\nterms of the Fat Shattering dimensions of the collection's classes.\\n  We conclude this report by providing a few open questions and future research\\ntopics involving the PAC learning model.\\n\",\n",
              " '  In batch learning, stability together with existence and uniqueness of the\\nsolution corresponds to well-posedness of Empirical Risk Minimization (ERM)\\nmethods; recently, it was proved that CV_loo stability is necessary and\\nsufficient for generalization and consistency of ERM. In this note, we\\nintroduce CV_on stability, which plays a similar note in online learning. We\\nshow that stochastic gradient descent (SDG) with the usual hypotheses is CVon\\nstable and we then discuss the implications of CV_on stability for convergence\\nof SGD.\\n',\n",
              " '  Approachability has become a standard tool in analyzing earning algorithms in\\nthe adversarial online learning setup. We develop a variant of approachability\\nfor games where there is ambiguity in the obtained reward that belongs to a\\nset, rather than being a single vector. Using this variant we tackle the\\nproblem of approachability in games with partial monitoring and develop simple\\nand efficient algorithms (i.e., with constant per-step complexity) for this\\nsetup. We finally consider external regret and internal regret in repeated\\ngames with partial monitoring and derive regret-minimizing strategies based on\\napproachability theory.\\n',\n",
              " '  Music prediction tasks range from predicting tags given a song or clip of\\naudio, predicting the name of the artist, or predicting related songs given a\\nsong, clip, artist name or tag. That is, we are interested in every semantic\\nrelationship between the different musical concepts in our database. In\\nrealistically sized databases, the number of songs is measured in the hundreds\\nof thousands or more, and the number of artists in the tens of thousands or\\nmore, providing a considerable challenge to standard machine learning\\ntechniques. In this work, we propose a method that scales to such datasets\\nwhich attempts to capture the semantic similarities between the database items\\nby modeling audio, artist names, and tags in a single low-dimensional semantic\\nspace. This choice of space is learnt by optimizing the set of prediction tasks\\nof interest jointly using multi-task learning. Our method both outperforms\\nbaseline methods and, in comparison to them, is faster and consumes less\\nmemory. We then demonstrate how our method learns an interpretable model, where\\nthe semantic space captures well the similarities of interest.\\n',\n",
              " '  We propose Shotgun, a parallel coordinate descent algorithm for minimizing\\nL1-regularized losses. Though coordinate descent seems inherently sequential,\\nwe prove convergence bounds for Shotgun which predict linear speedups, up to a\\nproblem-dependent limit. We present a comprehensive empirical study of Shotgun\\nfor Lasso and sparse logistic regression. Our theoretical predictions on the\\npotential for parallelism closely match behavior on real data. Shotgun\\noutperforms other published solvers on a range of large problems, proving to be\\none of the most scalable algorithms for L1.\\n',\n",
              " \"  There are many applications in which it is desirable to order rather than\\nclassify instances. Here we consider the problem of learning how to order\\ninstances given feedback in the form of preference judgments, i.e., statements\\nto the effect that one instance should be ranked ahead of another. We outline a\\ntwo-stage approach in which one first learns by conventional means a binary\\npreference function indicating whether it is advisable to rank one instance\\nbefore another. Here we consider an on-line algorithm for learning preference\\nfunctions that is based on Freund and Schapire's 'Hedge' algorithm. In the\\nsecond stage, new instances are ordered so as to maximize agreement with the\\nlearned preference function. We show that the problem of finding the ordering\\nthat agrees best with a learned preference function is NP-complete.\\nNevertheless, we describe simple greedy algorithms that are guaranteed to find\\na good approximation. Finally, we show how metasearch can be formulated as an\\nordering problem, and present experimental results on learning a combination of\\n'search experts', each of which is a domain-specific query expansion strategy\\nfor a web search engine.\\n\",\n",
              " '  We propose a nonparametric generalization of belief propagation, Kernel\\nBelief Propagation (KBP), for pairwise Markov random fields. Messages are\\nrepresented as functions in a reproducing kernel Hilbert space (RKHS), and\\nmessage updates are simple linear operations in the RKHS. KBP makes none of the\\nassumptions commonly required in classical BP algorithms: the variables need\\nnot arise from a finite domain or a Gaussian distribution, nor must their\\nrelations take any particular parametric form. Rather, the relations between\\nvariables are represented implicitly, and are learned nonparametrically from\\ntraining data. KBP has the advantage that it may be used on any domain where\\nkernels are defined (Rd, strings, groups), even where explicit parametric\\nmodels are not known, or closed form expressions for the BP updates do not\\nexist. The computational cost of message updates in KBP is polynomial in the\\ntraining data size. We also propose a constant time approximate message update\\nprocedure by representing messages using a small number of basis functions. In\\nexperiments, we apply KBP to image denoising, depth prediction from still\\nimages, and protein configuration prediction: KBP is faster than competing\\nclassical and nonparametric approaches (by orders of magnitude, in some cases),\\nwhile providing significantly more accurate results.\\n',\n",
              " '  Understanding inductive reasoning is a problem that has engaged mankind for\\nthousands of years. This problem is relevant to a wide range of fields and is\\nintegral to the philosophy of science. It has been tackled by many great minds\\nranging from philosophers to scientists to mathematicians, and more recently\\ncomputer scientists. In this article we argue the case for Solomonoff\\nInduction, a formal inductive framework which combines algorithmic information\\ntheory with the Bayesian framework. Although it achieves excellent theoretical\\nresults and is based on solid philosophical foundations, the requisite\\ntechnical knowledge necessary for understanding this framework has caused it to\\nremain largely unknown and unappreciated in the wider scientific community. The\\nmain contribution of this article is to convey Solomonoff induction and its\\nrelated concepts in a generally accessible form with the aim of bridging this\\ncurrent technical gap. In the process we examine the major historical\\ncontributions that have led to the formulation of Solomonoff Induction as well\\nas criticisms of Solomonoff and induction in general. In particular we examine\\nhow Solomonoff induction addresses many issues that have plagued other\\ninductive systems, such as the black ravens paradox and the confirmation\\nproblem, and compare this approach with other recent approaches.\\n',\n",
              " '  This paper is devoted to the problem of sampling Gaussian fields in high\\ndimension. Solutions exist for two specific structures of inverse covariance :\\nsparse and circulant. The proposed approach is valid in a more general case and\\nespecially as it emerges in inverse problems. It relies on a\\nperturbation-optimization principle: adequate stochastic perturbation of a\\ncriterion and optimization of the perturbed criterion. It is shown that the\\ncriterion minimizer is a sample of the target density. The motivation in\\ninverse problems is related to general (non-convolutive) linear observation\\nmodels and their resolution in a Bayesian framework implemented through\\nsampling algorithms when existing samplers are not feasible. It finds a direct\\napplication in myopic and/or unsupervised inversion as well as in some\\nnon-Gaussian inversion. An illustration focused on hyperparameter estimation\\nfor super-resolution problems assesses the effectiveness of the proposed\\napproach.\\n',\n",
              " '  The classical perceptron rule provides a varying upper bound on the maximum\\nmargin, namely the length of the current weight vector divided by the total\\nnumber of updates up to that time. Requiring that the perceptron updates its\\ninternal state whenever the normalized margin of a pattern is found not to\\nexceed a certain fraction of this dynamic upper bound we construct a new\\napproximate maximum margin classifier called the perceptron with dynamic margin\\n(PDM). We demonstrate that PDM converges in a finite number of steps and derive\\nan upper bound on them. We also compare experimentally PDM with other\\nperceptron-like algorithms and support vector machines on hard margin tasks\\ninvolving linear kernels which are equivalent to 2-norm soft margin.\\n',\n",
              " '  There are two distinct approaches to solving reinforcement learning problems,\\nnamely, searching in value function space and searching in policy space.\\nTemporal difference methods and evolutionary algorithms are well-known examples\\nof these approaches. Kaelbling, Littman and Moore recently provided an\\ninformative survey of temporal difference methods. This article focuses on the\\napplication of evolutionary algorithms to the reinforcement learning problem,\\nemphasizing alternative policy representations, credit assignment methods, and\\nproblem-specific genetic operators. Strengths and weaknesses of the\\nevolutionary approach to reinforcement learning are presented, along with a\\nsurvey of representative applications.\\n',\n",
              " '  This paper introduces an elemental building block which combines Dictionary\\nLearning and Dimension Reduction (DRDL). We show how this foundational element\\ncan be used to iteratively construct a Hierarchical Sparse Representation (HSR)\\nof a sensory stream. We compare our approach to existing models showing the\\ngenerality of our simple prescription. We then perform preliminary experiments\\nusing this framework, illustrating with the example of an object recognition\\ntask using standard datasets. This work introduces the very first steps towards\\nan integrated framework for designing and analyzing various computational tasks\\nfrom learning to attention to action. The ultimate goal is building a\\nmathematically rigorous, integrated theory of intelligence.\\n',\n",
              " \"  Loopy belief propagation performs approximate inference on graphical models\\nwith loops. One might hope to compensate for the approximation by adjusting\\nmodel parameters. Learning algorithms for this purpose have been explored\\npreviously, and the claim has been made that every set of locally consistent\\nmarginals can arise from belief propagation run on a graphical model. On the\\ncontrary, here we show that many probability distributions have marginals that\\ncannot be reached by belief propagation using any set of model parameters or\\nany learning algorithm. We call such marginals `unbelievable.' This problem\\noccurs whenever the Hessian of the Bethe free energy is not positive-definite\\nat the target marginals. All learning algorithms for belief propagation\\nnecessarily fail in these cases, producing beliefs or sets of beliefs that may\\neven be worse than the pre-learning approximation. We then show that averaging\\ninaccurate beliefs, each obtained from belief propagation using model\\nparameters perturbed about some learned mean values, can achieve the\\nunbelievable marginals.\\n\",\n",
              " '  We show that all non-negative submodular functions have high {\\\\em\\nnoise-stability}. As a consequence, we obtain a polynomial-time learning\\nalgorithm for this class with respect to any product distribution on\\n$\\\\{-1,1\\\\}^n$ (for any constant accuracy parameter $\\\\epsilon$). Our algorithm\\nalso succeeds in the agnostic setting. Previous work on learning submodular\\nfunctions required either query access or strong assumptions about the types of\\nsubmodular functions to be learned (and did not hold in the agnostic setting).\\n',\n",
              " \"  In this paper, we present algorithms that perform gradient ascent of the\\naverage reward in a partially observable Markov decision process (POMDP). These\\nalgorithms are based on GPOMDP, an algorithm introduced in a companion paper\\n(Baxter and Bartlett, this volume), which computes biased estimates of the\\nperformance gradient in POMDPs. The algorithm's chief advantages are that it\\nuses only one free parameter beta, which has a natural interpretation in terms\\nof bias-variance trade-off, it requires no knowledge of the underlying state,\\nand it can be applied to infinite state, control and observation spaces. We\\nshow how the gradient estimates produced by GPOMDP can be used to perform\\ngradient ascent, both with a traditional stochastic-gradient algorithm, and\\nwith an algorithm based on conjugate-gradients that utilizes gradient\\ninformation to bracket maxima in line searches. Experimental results are\\npresented illustrating both the theoretical results of (Baxter and Bartlett,\\nthis volume) on a toy problem, and practical aspects of the algorithms on a\\nnumber of more realistic problems.\\n\",\n",
              " '  Designing the dialogue policy of a spoken dialogue system involves many\\nnontrivial choices. This paper presents a reinforcement learning approach for\\nautomatically optimizing a dialogue policy, which addresses the technical\\nchallenges in applying reinforcement learning to a working dialogue system with\\nhuman users. We report on the design, construction and empirical evaluation of\\nNJFun, an experimental spoken dialogue system that provides users with access\\nto information about fun things to do in New Jersey. Our results show that by\\noptimizing its performance via reinforcement learning, NJFun measurably\\nimproves system performance.\\n',\n",
              " \"  Imitation can be viewed as a means of enhancing learning in multiagent\\nenvironments. It augments an agent's ability to learn useful behaviors by\\nmaking intelligent use of the knowledge implicit in behaviors demonstrated by\\ncooperative teachers or other more experienced agents. We propose and study a\\nformal model of implicit imitation that can accelerate reinforcement learning\\ndramatically in certain cases. Roughly, by observing a mentor, a\\nreinforcement-learning agent can extract information about its own capabilities\\nin, and the relative value of, unvisited parts of the state space. We study two\\nspecific instantiations of this model, one in which the learning agent and the\\nmentor have identical abilities, and one designed to deal with agents and\\nmentors with different action sets. We illustrate the benefits of implicit\\nimitation by integrating it with prioritized sweeping, and demonstrating\\nimproved performance and convergence through observation of single and multiple\\nmentors. Though we make some stringent assumptions regarding observability and\\npossible interactions, we briefly comment on extensions of the model that relax\\nthese restricitions.\\n\",\n",
              " '  The recursive least-squares (RLS) algorithm is one of the most well-known\\nalgorithms used in adaptive filtering, system identification and adaptive\\ncontrol. Its popularity is mainly due to its fast convergence speed, which is\\nconsidered to be optimal in practice. In this paper, RLS methods are used to\\nsolve reinforcement learning problems, where two new reinforcement learning\\nalgorithms using linear value function approximators are proposed and analyzed.\\nThe two algorithms are called RLS-TD(lambda) and Fast-AHC (Fast Adaptive\\nHeuristic Critic), respectively. RLS-TD(lambda) can be viewed as the extension\\nof RLS-TD(0) from lambda=0 to general lambda within interval [0,1], so it is a\\nmulti-step temporal-difference (TD) learning algorithm using RLS methods. The\\nconvergence with probability one and the limit of convergence of RLS-TD(lambda)\\nare proved for ergodic Markov chains. Compared to the existing LS-TD(lambda)\\nalgorithm, RLS-TD(lambda) has advantages in computation and is more suitable\\nfor online learning. The effectiveness of RLS-TD(lambda) is analyzed and\\nverified by learning prediction experiments of Markov chains with a wide range\\nof parameter settings. The Fast-AHC algorithm is derived by applying the\\nproposed RLS-TD(lambda) algorithm in the critic network of the adaptive\\nheuristic critic method. Unlike conventional AHC algorithm, Fast-AHC makes use\\nof RLS methods to improve the learning-prediction efficiency in the critic.\\nLearning control experiments of the cart-pole balancing and the acrobot\\nswing-up problems are conducted to compare the data efficiency of Fast-AHC with\\nconventional AHC. From the experimental results, it is shown that the data\\nefficiency of learning control can also be improved by using RLS methods in the\\nlearning-prediction process of the critic. The performance of Fast-AHC is also\\ncompared with that of the AHC method using LS-TD(lambda). Furthermore, it is\\ndemonstrated in the experiments that different initial values of the variance\\nmatrix in RLS-TD(lambda) are required to get better performance not only in\\nlearning prediction but also in learning control. The experimental results are\\nanalyzed based on the existing theoretical work on the transient phase of\\nforgetting factor RLS methods.\\n',\n",
              " '  We show how to control the generalization error of time series models wherein\\npast values of the outcome are used to predict future values. The results are\\nbased on a generalization of standard i.i.d. concentration inequalities to\\ndependent data without the mixing assumptions common in the time series\\nsetting. Our proof and the result are simpler than previous analyses with\\ndependent data or stochastic adversaries which use sequential Rademacher\\ncomplexities rather than the expected Rademacher complexity for i.i.d.\\nprocesses. We also derive empirical Rademacher results without mixing\\nassumptions resulting in fully calculable upper bounds.\\n',\n",
              " '  The exploration-exploitation trade-off is among the central challenges of\\nreinforcement learning. The optimal Bayesian solution is intractable in\\ngeneral. This paper studies to what extent analytic statements about optimal\\nlearning are possible if all beliefs are Gaussian processes. A first order\\napproximation of learning of both loss and dynamics, for nonlinear,\\ntime-varying systems in continuous time and space, subject to a relatively weak\\nrestriction on the dynamics, is described by an infinite-dimensional partial\\ndifferential equation. An approximate finite-dimensional projection gives an\\nimpression for how this result may be helpful.\\n',\n",
              " '  In this paper, we first demonstrate that b-bit minwise hashing, whose\\nestimators are positive definite kernels, can be naturally integrated with\\nlearning algorithms such as SVM and logistic regression. We adopt a simple\\nscheme to transform the nonlinear (resemblance) kernel into linear (inner\\nproduct) kernel; and hence large-scale problems can be solved extremely\\nefficiently. Our method provides a simple effective solution to large-scale\\nlearning in massive and extremely high-dimensional datasets, especially when\\ndata do not fit in memory.\\n  We then compare b-bit minwise hashing with the Vowpal Wabbit (VW) algorithm\\n(which is related the Count-Min (CM) sketch). Interestingly, VW has the same\\nvariances as random projections. Our theoretical and empirical comparisons\\nillustrate that usually $b$-bit minwise hashing is significantly more accurate\\n(at the same storage) than VW (and random projections) in binary data.\\nFurthermore, $b$-bit minwise hashing can be combined with VW to achieve further\\nimprovements in terms of training speed, especially when $b$ is large.\\n',\n",
              " '  The structure representation of data distribution plays an important role in\\nunderstanding the underlying mechanism of generating data. In this paper, we\\npropose nearest prime simplicial complex approaches (NSC) by utilizing\\npersistent homology to capture such structures. Assuming that each class is\\nrepresented with a prime simplicial complex, we classify unlabeled samples\\nbased on the nearest projection distances from the samples to the simplicial\\ncomplexes. We also extend the extrapolation ability of these complexes with a\\nprojection constraint term. Experiments in simulated and practical datasets\\nindicate that compared with several published algorithms, the proposed NSC\\napproaches achieve promising performance without losing the structure\\nrepresentation.\\n',\n",
              " '  Graph-based representations of images have recently acquired an important\\nrole for classification purposes within the context of machine learning\\napproaches. The underlying idea is to consider that relevant information of an\\nimage is implicitly encoded into the relationships between more basic entities\\nthat compose by themselves the whole image. The classification problem is then\\nreformulated in terms of an optimization problem usually solved by a\\ngradient-based search procedure. Vario-eta through structure is an approximate\\nsecond order stochastic optimization technique that achieves a good trade-off\\nbetween speed of convergence and the computational effort required. However,\\nthe robustness of this technique for large scale problems has not been yet\\nassessed. In this paper we firstly provide a theoretical justification of the\\nassumptions made by this optimization procedure. Secondly, a complexity\\nanalysis of the algorithm is performed to prove its suitability for large scale\\nlearning problems.\\n',\n",
              " '  The use of L1 regularisation for sparse learning has generated immense\\nresearch interest, with successful application in such diverse areas as signal\\nacquisition, image coding, genomics and collaborative filtering. While existing\\nwork highlights the many advantages of L1 methods, in this paper we find that\\nL1 regularisation often dramatically underperforms in terms of predictive\\nperformance when compared with other methods for inferring sparsity. We focus\\non unsupervised latent variable models, and develop L1 minimising factor\\nmodels, Bayesian variants of \"L1\", and Bayesian models with a stronger L0-like\\nsparsity induced through spike-and-slab distributions. These spike-and-slab\\nBayesian factor models encourage sparsity while accounting for uncertainty in a\\nprincipled manner and avoiding unnecessary shrinkage of non-zero values. We\\ndemonstrate on a number of data sets that in practice spike-and-slab Bayesian\\nmethods outperform L1 minimisation, even on a computational budget. We thus\\nhighlight the need to re-assess the wide use of L1 methods in sparsity-reliant\\napplications, particularly when we care about generalising to previously unseen\\ndata, and provide an alternative that, over many varying conditions, provides\\nimproved generalisation performance.\\n',\n",
              " '  In many recent applications, data is plentiful. By now, we have a rather\\nclear understanding of how more data can be used to improve the accuracy of\\nlearning algorithms. Recently, there has been a growing interest in\\nunderstanding how more data can be leveraged to reduce the required training\\nruntime. In this paper, we study the runtime of learning as a function of the\\nnumber of available training examples, and underscore the main high-level\\ntechniques. We provide some initial positive results showing that the runtime\\ncan decrease exponentially while only requiring a polynomial growth of the\\nnumber of examples, and spell-out several interesting open problems.\\n',\n",
              " '  Given a set $F$ of $n$ positive functions over a ground set $X$, we consider\\nthe problem of computing $x^*$ that minimizes the expression $\\\\sum_{f\\\\in\\nF}f(x)$, over $x\\\\in X$. A typical application is \\\\emph{shape fitting}, where we\\nwish to approximate a set $P$ of $n$ elements (say, points) by a shape $x$ from\\na (possibly infinite) family $X$ of shapes. Here, each point $p\\\\in P$\\ncorresponds to a function $f$ such that $f(x)$ is the distance from $p$ to $x$,\\nand we seek a shape $x$ that minimizes the sum of distances from each point in\\n$P$. In the $k$-clustering variant, each $x\\\\in X$ is a tuple of $k$ shapes, and\\n$f(x)$ is the distance from $p$ to its closest shape in $x$.\\n  Our main result is a unified framework for constructing {\\\\em coresets} and\\n{\\\\em approximate clustering} for such general sets of functions. To achieve our\\nresults, we forge a link between the classic and well defined notion of\\n$\\\\varepsilon$-approximations from the theory of PAC Learning and VC dimension,\\nto the relatively new (and not so consistent) paradigm of coresets, which are\\nsome kind of \"compressed representation\" of the input set $F$. Using\\ntraditional techniques, a coreset usually implies an LTAS (linear time\\napproximation scheme) for the corresponding optimization problem, which can be\\ncomputed in parallel, via one pass over the data, and using only\\npolylogarithmic space (i.e, in the streaming model).\\n  We show how to generalize the results of our framework for squared distances\\n(as in $k$-mean), distances to the $q$th power, and deterministic\\nconstructions.\\n',\n",
              " '  We address the problem of minimizing a convex function over the space of\\nlarge matrices with low rank. While this optimization problem is hard in\\ngeneral, we propose an efficient greedy algorithm and derive its formal\\napproximation guarantees. Each iteration of the algorithm involves\\n(approximately) finding the left and right singular vectors corresponding to\\nthe largest singular value of a certain matrix, which can be calculated in\\nlinear time. This leads to an algorithm which can scale to large matrices\\narising in several applications such as matrix completion for collaborative\\nfiltering and robust low rank matrix approximation.\\n',\n",
              " '  We consider the problem of identifying the sparse principal component of a\\nrank-deficient matrix. We introduce auxiliary spherical variables and prove\\nthat there exists a set of candidate index-sets (that is, sets of indices to\\nthe nonzero elements of the vector argument) whose size is polynomially\\nbounded, in terms of rank, and contains the optimal index-set, i.e. the\\nindex-set of the nonzero elements of the optimal solution. Finally, we develop\\nan algorithm that computes the optimal sparse principal component in polynomial\\ntime for any sparsity degree.\\n',\n",
              " '  The main principle of stacked generalization (or Stacking) is using a\\nsecond-level generalizer to combine the outputs of base classifiers in an\\nensemble. In this paper, we investigate different combination types under the\\nstacking framework; namely weighted sum (WS), class-dependent weighted sum\\n(CWS) and linear stacked generalization (LSG). For learning the weights, we\\npropose using regularized empirical risk minimization with the hinge loss. In\\naddition, we propose using group sparsity for regularization to facilitate\\nclassifier selection. We performed experiments using two different ensemble\\nsetups with differing diversities on 8 real-world datasets. Results show the\\npower of regularized learning with the hinge loss function. Using sparse\\nregularization, we are able to reduce the number of selected classifiers of the\\ndiverse ensemble without sacrificing accuracy. With the non-diverse ensembles,\\nwe even gain accuracy on average by using sparse regularization.\\n',\n",
              " '  This paper introduces a machine learning based collaborative multi-band\\nspectrum sensing policy for cognitive radios. The proposed sensing policy\\nguides secondary users to focus the search of unused radio spectrum to those\\nfrequencies that persistently provide them high data rate. The proposed policy\\nis based on machine learning, which makes it adaptive with the temporally and\\nspatially varying radio spectrum. Furthermore, there is no need for dynamic\\nmodeling of the primary activity since it is implicitly learned over time.\\nEnergy efficiency is achieved by minimizing the number of assigned sensors per\\neach subband under a constraint on miss detection probability. It is important\\nto control the missed detections because they cause collisions with primary\\ntransmissions and lead to retransmissions at both the primary and secondary\\nuser. Simulations show that the proposed machine learning based sensing policy\\nimproves the overall throughput of the secondary network and improves the\\nenergy efficiency while controlling the miss detection probability.\\n',\n",
              " \"  This paper considers the problem of learning, from samples, the dependency\\nstructure of a system of linear stochastic differential equations, when some of\\nthe variables are latent. In particular, we observe the time evolution of some\\nvariables, and never observe other variables; from this, we would like to find\\nthe dependency structure between the observed variables - separating out the\\nspurious interactions caused by the (marginalizing out of the) latent\\nvariables' time series. We develop a new method, based on convex optimization,\\nto do so in the case when the number of latent variables is smaller than the\\nnumber of observed ones. For the case when the dependency structure between the\\nobserved variables is sparse, we theoretically establish a high-dimensional\\nscaling result for structure recovery. We verify our theoretical result with\\nboth synthetic and real data (from the stock market).\\n\",\n",
              " '  It is of increasing importance to develop learning methods for ranking. In\\ncontrast to many learning objectives, however, the ranking problem presents\\ndifficulties due to the fact that the space of permutations is not smooth. In\\nthis paper, we examine the class of rank-linear objective functions, which\\nincludes popular metrics such as precision and discounted cumulative gain. In\\nparticular, we observe that expectations of these gains are completely\\ncharacterized by the marginals of the corresponding distribution over\\npermutation matrices. Thus, the expectations of rank-linear objectives can\\nalways be described through locations in the Birkhoff polytope, i.e.,\\ndoubly-stochastic matrices (DSMs). We propose a technique for learning\\nDSM-based ranking functions using an iterative projection operator known as\\nSinkhorn normalization. Gradients of this operator can be computed via\\nbackpropagation, resulting in an algorithm we call Sinkhorn propagation, or\\nSinkProp. This approach can be combined with a wide range of gradient-based\\napproaches to rank learning. We demonstrate the utility of SinkProp on several\\ninformation retrieval data sets.\\n',\n",
              " \"  This paper considers a dynamic game with transferable utilities (TU), where\\nthe characteristic function is a continuous-time bounded mean ergodic process.\\nA central planner interacts continuously over time with the players by choosing\\nthe instantaneous allocations subject to budget constraints. Before the game\\nstarts, the central planner knows the nature of the process (bounded mean\\nergodic), the bounded set from which the coalitions' values are sampled, and\\nthe long run average coalitions' values. On the other hand, he has no knowledge\\nof the underlying probability function generating the coalitions' values. Our\\ngoal is to find allocation rules that use a measure of the extra reward that a\\ncoalition has received up to the current time by re-distributing the budget\\namong the players. The objective is two-fold: i) guaranteeing convergence of\\nthe average allocations to the core (or a specific point in the core) of the\\naverage game, ii) driving the coalitions' excesses to an a priori given cone.\\nThe resulting allocation rules are robust as they guarantee the aforementioned\\nconvergence properties despite the uncertain and time-varying nature of the\\ncoaltions' values. We highlight three main contributions. First, we design an\\nallocation rule based on full observation of the extra reward so that the\\naverage allocation approaches a specific point in the core of the average game,\\nwhile the coalitions' excesses converge to an a priori given direction. Second,\\nwe design a new allocation rule based on partial observation on the extra\\nreward so that the average allocation converges to the core of the average\\ngame, while the coalitions' excesses converge to an a priori given cone. And\\nthird, we establish connections to approachability theory and attainability\\ntheory.\\n\",\n",
              " '  Observational data usually comes with a multimodal nature, which means that\\nit can be naturally represented by a multi-layer graph whose layers share the\\nsame set of vertices (users) with different edges (pairwise relationships). In\\nthis paper, we address the problem of combining different layers of the\\nmulti-layer graph for improved clustering of the vertices compared to using\\nlayers independently. We propose two novel methods, which are based on joint\\nmatrix factorization and graph regularization framework respectively, to\\nefficiently combine the spectrum of the multiple graph layers, namely the\\neigenvectors of the graph Laplacian matrices. In each case, the resulting\\ncombination, which we call a \"joint spectrum\" of multiple graphs, is used for\\nclustering the vertices. We evaluate our approaches by simulations with several\\nreal world social network datasets. Results demonstrate the superior or\\ncompetitive performance of the proposed methods over state-of-the-art technique\\nand common baseline methods, such as co-regularization and summation of\\ninformation from individual graphs.\\n',\n",
              " \"  This work gives a simultaneous analysis of both the ordinary least squares\\nestimator and the ridge regression estimator in the random design setting under\\nmild assumptions on the covariate/response distributions. In particular, the\\nanalysis provides sharp results on the ``out-of-sample'' prediction error, as\\nopposed to the ``in-sample'' (fixed design) error. The analysis also reveals\\nthe effect of errors in the estimated covariance structure, as well as the\\neffect of modeling errors, neither of which effects are present in the fixed\\ndesign setting. The proofs of the main results are based on a simple\\ndecomposition lemma combined with concentration inequalities for random vectors\\nand matrices.\\n\",\n",
              " '  We address the problem of learning in an online setting where the learner\\nrepeatedly observes features, selects among a set of actions, and receives\\nreward for the action taken. We provide the first efficient algorithm with an\\noptimal regret. Our algorithm uses a cost sensitive classification learner as\\nan oracle and has a running time $\\\\mathrm{polylog}(N)$, where $N$ is the number\\nof classification rules among which the oracle might choose. This is\\nexponentially faster than all previous algorithms that achieve optimal regret\\nin this setting. Our formulation also enables us to create an algorithm with\\nregret that is additive rather than multiplicative in feedback delay as in all\\nprevious work.\\n',\n",
              " '  Most traditional online learning algorithms are based on variants of mirror\\ndescent or follow-the-leader. In this paper, we present an online algorithm\\nbased on a completely different approach, tailored for transductive settings,\\nwhich combines \"random playout\" and randomized rounding of loss subgradients.\\nAs an application of our approach, we present the first computationally\\nefficient online algorithm for collaborative filtering with trace-norm\\nconstrained matrices. As a second application, we solve an open question\\nlinking batch learning and transductive online learning\\n',\n",
              " '  We consider an adversarial online learning setting where a decision maker can\\nchoose an action in every stage of the game. In addition to observing the\\nreward of the chosen action, the decision maker gets side observations on the\\nreward he would have obtained had he chosen some of the other actions. The\\nobservation structure is encoded as a graph, where node i is linked to node j\\nif sampling i provides information on the reward of j. This setting naturally\\ninterpolates between the well-known \"experts\" setting, where the decision maker\\ncan view all rewards, and the multi-armed bandits setting, where the decision\\nmaker can only view the reward of the chosen action. We develop practical\\nalgorithms with provable regret guarantees, which depend on non-trivial\\ngraph-theoretic properties of the information feedback structure. We also\\nprovide partially-matching lower bounds.\\n',\n",
              " '  In this article, a survey of several important equilibrium concepts for\\ndecentralized networks is presented. The term decentralized is used here to\\nrefer to scenarios where decisions (e.g., choosing a power allocation policy)\\nare taken autonomously by devices interacting with each other (e.g., through\\nmutual interference). The iterative long-term interaction is characterized by\\nstable points of the wireless network called equilibria. The interest in these\\nequilibria stems from the relevance of network stability and the fact that they\\ncan be achieved by letting radio devices to repeatedly interact over time. To\\nachieve these equilibria, several learning techniques, namely, the best\\nresponse dynamics, fictitious play, smoothed fictitious play, reinforcement\\nlearning algorithms, and regret matching, are discussed in terms of information\\nrequirements and convergence properties. Most of the notions introduced here,\\nfor both equilibria and learning schemes, are illustrated by a simple case\\nstudy, namely, an interference channel with two transmitter-receiver pairs.\\n',\n",
              " '  The recent crisis and the following flight to simplicity put most derivative\\nbusinesses around the world under considerable pressure. We argue that the\\ntraditional modeling techniques must be extended to include product design. We\\npropose a quantitative framework for creating products which meet the challenge\\nof being optimal from the investors point of view while remaining relatively\\nsimple and transparent.\\n',\n",
              " '  Estimator algorithms in learning automata are useful tools for adaptive,\\nreal-time optimization in computer science and engineering applications. This\\npaper investigates theoretical convergence properties for a special case of\\nestimator algorithms: the pursuit learning algorithm. In this note, we identify\\nand fill a gap in existing proofs of probabilistic convergence for pursuit\\nlearning. It is tradition to take the pursuit learning tuning parameter to be\\nfixed in practical applications, but our proof sheds light on the importance of\\na vanishing sequence of tuning parameters in a theoretical convergence\\nanalysis.\\n',\n",
              " '  One of the major challenges of ECoG-based Brain-Machine Interfaces is the\\nmovement prediction of a human subject. Several methods exist to predict an arm\\n2-D trajectory. The fourth BCI Competition gives a dataset in which the aim is\\nto predict individual finger movements (5-D trajectory). The difficulty lies in\\nthe fact that there is no simple relation between ECoG signals and finger\\nmovement. We propose in this paper to decode finger flexions using switching\\nmodels. This method permits to simplify the system as it is now described as an\\nensemble of linear models depending on an internal state. We show that an\\ninteresting accuracy prediction can be obtained by such a model.\\n',\n",
              " '  Signal Sequence Labeling consists in predicting a sequence of labels given an\\nobserved sequence of samples. A naive way is to filter the signal in order to\\nreduce the noise and to apply a classification algorithm on the filtered\\nsamples. We propose in this paper to jointly learn the filter with the\\nclassifier leading to a large margin filtering for classification. This method\\nallows to learn the optimal cutoff frequency and phase of the filter that may\\nbe different from zero. Two methods are proposed and tested on a toy dataset\\nand on a real life BCI dataset from BCI Competition III.\\n',\n",
              " '  This paper addresses the pattern classification problem arising when\\navailable target data include some uncertainty information. Target data\\nconsidered here is either qualitative (a class label) or quantitative (an\\nestimation of the posterior probability). Our main contribution is a SVM\\ninspired formulation of this problem allowing to take into account class label\\nthrough a hinge loss as well as probability estimates using epsilon-insensitive\\ncost function together with a minimum norm (maximum margin) objective. This\\nformulation shows a dual form leading to a quadratic problem and allows the use\\nof a representer theorem and associated kernel. The solution provided can be\\nused for both decision and posterior probability estimation. Based on empirical\\nevidence our method outperforms regular SVM in terms of probability predictions\\nand classification performances.\\n',\n",
              " '  In the Bayesian approach to sequential decision making, exact calculation of\\nthe (subjective) utility is intractable. This extends to most special cases of\\ninterest, such as reinforcement learning problems. While utility bounds are\\nknown to exist for this problem, so far none of them were particularly tight.\\nIn this paper, we show how to efficiently calculate a lower bound, which\\ncorresponds to the utility of a near-optimal memoryless policy for the decision\\nproblem, which is generally different from both the Bayes-optimal policy and\\nthe policy which is optimal for the expected MDP under the current belief. We\\nthen show how these can be applied to obtain robust exploration policies in a\\nBayesian reinforcement learning setting.\\n',\n",
              " '  Identifying and understanding modular organizations is centrally important in\\nthe study of complex systems. Several approaches to this problem have been\\nadvanced, many framed in information-theoretic terms. Our treatment starts from\\nthe complementary point of view of statistical modeling and prediction of\\ndynamical systems. It is known that for finite amounts of training data,\\nsimpler models can have greater predictive power than more complex ones. We use\\nthe trade-off between model simplicity and predictive accuracy to generate\\noptimal multiscale decompositions of dynamical networks into weakly-coupled,\\nsimple modules. State-dependent and causal versions of our method are also\\nproposed.\\n',\n",
              " '  We investigate the problem of learning XML queries, path queries and tree\\npattern queries, from examples given by the user. A learning algorithm takes on\\nthe input a set of XML documents with nodes annotated by the user and returns a\\nquery that selects the nodes in a manner consistent with the annotation. We\\nstudy two learning settings that differ with the types of annotations. In the\\nfirst setting the user may only indicate required nodes that the query must\\nreturn. In the second, more general, setting, the user may also indicate\\nforbidden nodes that the query must not return. The query may or may not return\\nany node with no annotation. We formalize what it means for a class of queries\\nto be \\\\emph{learnable}. One requirement is the existence of a learning\\nalgorithm that is sound i.e., always returns a query consistent with the\\nexamples given by the user. Furthermore, the learning algorithm should be\\ncomplete i.e., able to produce every query with a sufficiently rich example.\\nOther requirements involve tractability of learning and its robustness to\\nnonessential examples. We show that the classes of simple path queries and\\npath-subsumption-free tree queries are learnable from positive examples. The\\nlearnability of the full class of tree pattern queries (and the full class of\\npath queries) remains an open question. We show also that adding negative\\nexamples to the picture renders the learning unfeasible.\\n  Published in ICDT 2012, Berlin.\\n',\n",
              " '  Motivated by the amount of code that goes unidentified on the web, we\\nintroduce a practical method for algorithmically identifying the programming\\nlanguage of source code. Our work is based on supervised learning and\\nintelligent statistical features. We also explored, but abandoned, a\\ngrammatical approach. In testing, our implementation greatly outperforms that\\nof an existing tool that relies on a Bayesian classifier. Code is written in\\nPython and available under an MIT license.\\n',\n",
              " '  To help understand various reproducing kernels used in applied sciences, we\\ninvestigate the inclusion relation of two reproducing kernel Hilbert spaces.\\nCharacterizations in terms of feature maps of the corresponding reproducing\\nkernels are established. A full table of inclusion relations among widely-used\\ntranslation invariant kernels is given. Concrete examples for Hilbert-Schmidt\\nkernels are presented as well. We also discuss the preservation of such a\\nrelation under various operations of reproducing kernels. Finally, we briefly\\ndiscuss the special inclusion with a norm equivalence.\\n',\n",
              " '  We provide rigorous guarantees on learning with the weighted trace-norm under\\narbitrary sampling distributions. We show that the standard weighted trace-norm\\nmight fail when the sampling distribution is not a product distribution (i.e.\\nwhen row and column indexes are not selected independently), present a\\ncorrected variant for which we establish strong learning guarantees, and\\ndemonstrate that it works better in practice. We provide guarantees when\\nweighting by either the true or empirical sampling distribution, and suggest\\nthat even if the true distribution is known (or is uniform), weighting by the\\nempirical distribution may be beneficial.\\n',\n",
              " '  Standard compressive sensing results state that to exactly recover an s\\nsparse signal in R^p, one requires O(s. log(p)) measurements. While this bound\\nis extremely useful in practice, often real world signals are not only sparse,\\nbut also exhibit structure in the sparsity pattern. We focus on\\ngroup-structured patterns in this paper. Under this model, groups of signal\\ncoefficients are active (or inactive) together. The groups are predefined, but\\nthe particular set of groups that are active (i.e., in the signal support) must\\nbe learned from measurements. We show that exploiting knowledge of groups can\\nfurther reduce the number of measurements required for exact signal recovery,\\nand derive universal bounds for the number of measurements needed. The bound is\\nuniversal in the sense that it only depends on the number of groups under\\nconsideration, and not the particulars of the groups (e.g., compositions,\\nsizes, extents, overlaps, etc.). Experiments show that our result holds for a\\nvariety of overlapping group configurations.\\n',\n",
              " \"  We develop, analyze, and evaluate a novel, supervised, specific-to-general\\nlearner for a simple temporal logic and use the resulting algorithm to learn\\nvisual event definitions from video sequences. First, we introduce a simple,\\npropositional, temporal, event-description language called AMA that is\\nsufficiently expressive to represent many events yet sufficiently restrictive\\nto support learning. We then give algorithms, along with lower and upper\\ncomplexity bounds, for the subsumption and generalization problems for AMA\\nformulas. We present a positive-examples--only specific-to-general learning\\nmethod based on these algorithms. We also present a polynomial-time--computable\\n``syntactic'' subsumption test that implies semantic subsumption without being\\nequivalent to it. A generalization algorithm based on syntactic subsumption can\\nbe used in place of semantic generalization to improve the asymptotic\\ncomplexity of the resulting learning algorithm. Finally, we apply this\\nalgorithm to the task of learning relational event definitions from video and\\nshow that it yields definitions that are competitive with hand-coded ones.\\n\",\n",
              " '  Mini-batch algorithms have been proposed as a way to speed-up stochastic\\nconvex optimization problems. We study how such algorithms can be improved\\nusing accelerated gradient methods. We provide a novel analysis, which shows\\nhow standard gradient methods may sometimes be insufficient to obtain a\\nsignificant speed-up and propose a novel accelerated gradient algorithm, which\\ndeals with this deficiency, enjoys a uniformly superior guarantee and works\\nwell in practice.\\n',\n",
              " '  We study a generalized framework for structured sparsity. It extends the\\nwell-known methods of Lasso and Group Lasso by incorporating additional\\nconstraints on the variables as part of a convex optimization problem. This\\nframework provides a straightforward way of favouring prescribed sparsity\\npatterns, such as orderings, contiguous regions and overlapping groups, among\\nothers. Existing optimization methods are limited to specific constraint sets\\nand tend to not scale well with sample size and dimensionality. We propose a\\nnovel first order proximal method, which builds upon results on fixed points\\nand successive approximations. The algorithm can be applied to a general class\\nof conic and norm constraints sets and relies on a proximity operator\\nsubproblem which can be computed explicitly. Experiments on different\\nregression problems demonstrate the efficiency of the optimization algorithm\\nand its scalability with the size of the problem. They also demonstrate state\\nof the art statistical performance, which improves over Lasso and StructOMP.\\n',\n",
              " \"  Shaping has proven to be a powerful but precarious means of improving\\nreinforcement learning performance. Ng, Harada, and Russell (1999) proposed the\\npotential-based shaping algorithm for adding shaping rewards in a way that\\nguarantees the learner will learn optimal behavior. In this note, we prove\\ncertain similarities between this shaping algorithm and the initialization step\\nrequired for several reinforcement learning algorithms. More specifically, we\\nprove that a reinforcement learner with initial Q-values based on the shaping\\nalgorithm's potential function make the same updates throughout learning as a\\nlearner receiving potential-based shaping rewards. We further prove that under\\na broad category of policies, the behavior of these two learners are\\nindistinguishable. The comparison provides intuition on the theoretical\\nproperties of the shaping algorithm as well as a suggestion for a simpler\\nmethod for capturing the algorithm's benefit. In addition, the equivalence\\nraises previously unaddressed issues concerning the efficiency of learning with\\npotential-based shaping.\\n\",\n",
              " \"  By reformulating a learning process of a set system L as a game between\\nTeacher and Learner, we define the order type of L to be the order type of the\\ngame tree, if the tree is well-founded. The features of the order type of L\\n(dim L in symbol) are (1) We can represent any well-quasi-order (wqo for short)\\nby the set system L of the upper-closed sets of the wqo such that the maximal\\norder type of the wqo is equal to dim L. (2) dim L is an upper bound of the\\nmind-change complexity of L. dim L is defined iff L has a finite elasticity (fe\\nfor short), where, according to computational learning theory, if an indexed\\nfamily of recursive languages has fe then it is learnable by an algorithm from\\npositive data. Regarding set systems as subspaces of Cantor spaces, we prove\\nthat fe of set systems is preserved by any continuous function which is\\nmonotone with respect to the set-inclusion. By it, we prove that finite\\nelasticity is preserved by various (nondeterministic) language operators\\n(Kleene-closure, shuffle-closure, union, product, intersection,. . ..) The\\nmonotone continuous functions represent nondeterministic computations. If a\\nmonotone continuous function has a computation tree with each node followed by\\nat most n immediate successors and the order type of a set system L is\\n{\\\\alpha}, then the direct image of L is a set system of order type at most\\nn-adic diagonal Ramsey number of {\\\\alpha}. Furthermore, we provide an\\norder-type-preserving contravariant embedding from the category of quasi-orders\\nand finitely branching simulations between them, into the complete category of\\nsubspaces of Cantor spaces and monotone continuous functions having Girard's\\nlinearity between them. Keyword: finite elasticity, shuffle-closure\\n\",\n",
              " '  We present a method for estimating pose information from a single depth image\\ngiven an arbitrary kinematic structure without prior training. For an arbitrary\\nskeleton and depth image, an evolutionary algorithm is used to find the optimal\\nkinematic configuration to explain the observed image. Results show that our\\napproach can correctly estimate poses of 39 and 78 degree-of-freedom models\\nfrom a single depth image, even in cases of significant self-occlusion.\\n',\n",
              " \"  Stochastic Gradient Descent (SGD) is a popular algorithm that can achieve\\nstate-of-the-art performance on a variety of machine learning tasks. Several\\nresearchers have recently proposed schemes to parallelize SGD, but all require\\nperformance-destroying memory locking and synchronization. This work aims to\\nshow using novel theoretical analysis, algorithms, and implementation that SGD\\ncan be implemented without any locking. We present an update scheme called\\nHOGWILD! which allows processors access to shared memory with the possibility\\nof overwriting each other's work. We show that when the associated optimization\\nproblem is sparse, meaning most gradient updates only modify small parts of the\\ndecision variable, then HOGWILD! achieves a nearly optimal rate of convergence.\\nWe demonstrate experimentally that HOGWILD! outperforms alternative schemes\\nthat use locking by an order of magnitude.\\n\",\n",
              " '  Sparse linear regression -- finding an unknown vector from linear\\nmeasurements -- is now known to be possible with fewer samples than variables,\\nvia methods like the LASSO. We consider the multiple sparse linear regression\\nproblem, where several related vectors -- with partially shared support sets --\\nhave to be recovered. A natural question in this setting is whether one can use\\nthe sharing to further decrease the overall number of samples required. A line\\nof recent research has studied the use of \\\\ell_1/\\\\ell_q norm\\nblock-regularizations with q>1 for such problems; however these could actually\\nperform worse in sample complexity -- vis a vis solving each problem separately\\nignoring sharing -- depending on the level of sharing.\\n  We present a new method for multiple sparse linear regression that can\\nleverage support and parameter overlap when it exists, but not pay a penalty\\nwhen it does not. A very simple idea: we decompose the parameters into two\\ncomponents and regularize these differently. We show both theoretically and\\nempirically, our method strictly and noticeably outperforms both \\\\ell_1 or\\n\\\\ell_1/\\\\ell_q methods, over the entire range of possible overlaps (except at\\nboundary cases, where we match the best method). We also provide theoretical\\nguarantees that the method performs well under high-dimensional scaling.\\n',\n",
              " '  In the Multi-Armed Bandit (MAB) problem, there is a given set of arms with\\nunknown reward models. At each time, a player selects one arm to play, aiming\\nto maximize the total expected reward over a horizon of length T. An approach\\nbased on a Deterministic Sequencing of Exploration and Exploitation (DSEE) is\\ndeveloped for constructing sequential arm selection policies. It is shown that\\nfor all light-tailed reward distributions, DSEE achieves the optimal\\nlogarithmic order of the regret, where regret is defined as the total expected\\nreward loss against the ideal case with known reward models. For heavy-tailed\\nreward distributions, DSEE achieves O(T^1/p) regret when the moments of the\\nreward distributions exist up to the pth order for 1<p<=2 and O(T^1/(1+p/2))\\nfor p>2. With the knowledge of an upperbound on a finite moment of the\\nheavy-tailed reward distributions, DSEE offers the optimal logarithmic regret\\norder. The proposed DSEE approach complements existing work on MAB by providing\\ncorresponding results for general reward distributions. Furthermore, with a\\nclearly defined tunable parameter-the cardinality of the exploration sequence,\\nthe DSEE approach is easily extendable to variations of MAB, including MAB with\\nvarious objectives, decentralized MAB with multiple players and incomplete\\nreward observations under collisions, MAB with unknown Markov dynamics, and\\ncombinatorial MAB with dependent arms that often arise in network optimization\\nproblems such as the shortest path, the minimum spanning, and the dominating\\nset problems under unknown random weights.\\n',\n",
              " '  We present IBSEAD or distributed autonomous entity systems based Interaction\\n- a learning algorithm for the computer to self-evolve in a self-obsessed\\nmanner. This learning algorithm will present the computer to look at the\\ninternal and external environment in series of independent entities, which will\\ninteract with each other, with and/or without knowledge of the computer\\'s\\nbrain. When a learning algorithm interacts, it does so by detecting and\\nunderstanding the entities in the human algorithm. However, the problem with\\nthis approach is that the algorithm does not consider the interaction of the\\nthird party or unknown entities, which may be interacting with each other.\\nThese unknown entities in their interaction with the non-computer entities make\\nan effect in the environment that influences the information and the behaviour\\nof the computer brain. Such details and the ability to process the dynamic and\\nunsettling nature of these interactions are absent in the current learning\\nalgorithm such as the decision tree learning algorithm. IBSEAD is able to\\nevaluate and consider such algorithms and thus give us a better accuracy in\\nsimulation of the highly evolved nature of the human brain. Processes such as\\ndreams, imagination and novelty, that exist in humans are not fully simulated\\nby the existing learning algorithms. Also, Hidden Markov models (HMM) are\\nuseful in finding \"hidden\" entities, which may be known or unknown. However,\\nthis model fails to consider the case of unknown entities which maybe unclear\\nor unknown. IBSEAD is better because it considers three types of entities-\\nknown, unknown and invisible. We present our case with a comparison of existing\\nalgorithms in known environments and cases and present the results of the\\nexperiments using dry run of the simulated runs of the existing machine\\nlearning algorithms versus IBSEAD.\\n',\n",
              " '  In this paper, we correct an upper bound, presented in~\\\\cite{hs-11}, on the\\ngeneralisation error of classifiers learned through multiple kernel learning.\\nThe bound in~\\\\cite{hs-11} uses Rademacher complexity and has an\\\\emph{additive}\\ndependence on the logarithm of the number of kernels and the margin achieved by\\nthe classifier. However, there are some errors in parts of the proof which are\\ncorrected in this paper. Unfortunately, the final result turns out to be a risk\\nbound which has a \\\\emph{multiplicative} dependence on the logarithm of the\\nnumber of kernels and the margin achieved by the classifier.\\n',\n",
              " '  Induction is the process by which we obtain predictive laws or theories or\\nmodels of the world. We consider the structural aspect of induction. We answer\\nthe question as to whether we can find a finite and minmalistic set of\\noperations on structural elements in terms of which any theory can be\\nexpressed. We identify abstraction (grouping similar entities) and\\nsuper-structuring (combining topologically e.g., spatio-temporally close\\nentities) as the essential structural operations in the induction process. We\\nshow that only two more structural operations, namely, reverse abstraction and\\nreverse super-structuring (the duals of abstraction and super-structuring\\nrespectively) suffice in order to exploit the full power of Turing-equivalent\\ngenerative grammars in induction. We explore the implications of this theorem\\nwith respect to the nature of hidden variables, radical positivism and the\\n2-century old claim of David Hume about the principles of connexion among\\nideas.\\n',\n",
              " '  We propose an alternative approach to construct an artificial learning\\nsystem, which naturally learns in an unsupervised manner. Its mathematical\\nprototype is a dynamical system, which automatically shapes its vector field in\\nresponse to the input signal. The vector field converges to a gradient of a\\nmulti-dimensional probability density distribution of the input process, taken\\nwith negative sign. The most probable patterns are represented by the stable\\nfixed points, whose basins of attraction are formed automatically. The\\nperformance of this system is illustrated with musical signals.\\n',\n",
              " '  If learning methods are to scale to the massive sizes of modern datasets, it\\nis essential for the field of machine learning to embrace parallel and\\ndistributed computing. Inspired by the recent development of matrix\\nfactorization methods with rich theory but poor computational complexity and by\\nthe relative ease of mapping matrices onto distributed architectures, we\\nintroduce a scalable divide-and-conquer framework for noisy matrix\\nfactorization. We present a thorough theoretical analysis of this framework in\\nwhich we characterize the statistical errors introduced by the \"divide\" step\\nand control their magnitude in the \"conquer\" step, so that the overall\\nalgorithm enjoys high-probability estimation guarantees comparable to those of\\nits base algorithm. We also present experiments in collaborative filtering and\\nvideo background modeling that demonstrate the near-linear to superlinear\\nspeed-ups attainable with this approach.\\n',\n",
              " '  Machine Learning (ML) techniques are indispensable in a wide range of fields.\\nUnfortunately, the exponential increase of dataset sizes are rapidly extending\\nthe runtime of sequential algorithms and threatening to slow future progress in\\nML. With the promise of affordable large-scale parallel computing, Cloud\\nsystems offer a viable platform to resolve the computational challenges in ML.\\nHowever, designing and implementing efficient, provably correct distributed ML\\nalgorithms is often prohibitively challenging. To enable ML researchers to\\neasily and efficiently use parallel systems, we introduced the GraphLab\\nabstraction which is designed to represent the computational patterns in ML\\nalgorithms while permitting efficient parallel and distributed implementations.\\nIn this paper we provide a formal description of the GraphLab parallel\\nabstraction and present an efficient distributed implementation. We conduct a\\ncomprehensive evaluation of GraphLab on three state-of-the-art ML algorithms\\nusing real large-scale data and a 64 node EC2 cluster of 512 processors. We\\nfind that GraphLab achieves orders of magnitude performance gains over Hadoop\\nwhile performing comparably or superior to hand-tuned MPI implementations.\\n',\n",
              " '  We consider the problem of high-dimensional Gaussian graphical model\\nselection. We identify a set of graphs for which an efficient estimation\\nalgorithm exists, and this algorithm is based on thresholding of empirical\\nconditional covariances. Under a set of transparent conditions, we establish\\nstructural consistency (or sparsistency) for the proposed algorithm, when the\\nnumber of samples n=omega(J_{min}^{-2} log p), where p is the number of\\nvariables and J_{min} is the minimum (absolute) edge potential of the graphical\\nmodel. The sufficient conditions for sparsistency are based on the notion of\\nwalk-summability of the model and the presence of sparse local vertex\\nseparators in the underlying graph. We also derive novel non-asymptotic\\nnecessary conditions on the number of samples required for sparsistency.\\n',\n",
              " '  This work considers the problem of learning the structure of multivariate\\nlinear tree models, which include a variety of directed tree graphical models\\nwith continuous, discrete, and mixed latent variables such as linear-Gaussian\\nmodels, hidden Markov models, Gaussian mixture models, and Markov evolutionary\\ntrees. The setting is one where we only have samples from certain observed\\nvariables in the tree, and our goal is to estimate the tree structure (i.e.,\\nthe graph of how the underlying hidden variables are connected to each other\\nand to the observed variables). We propose the Spectral Recursive Grouping\\nalgorithm, an efficient and simple bottom-up procedure for recovering the tree\\nstructure from independent samples of the observed variables. Our finite sample\\nsize bounds for exact recovery of the tree structure reveal certain natural\\ndependencies on underlying statistical and structural properties of the\\nunderlying joint distribution. Furthermore, our sample complexity guarantees\\nhave no explicit dependence on the dimensionality of the observed variables,\\nmaking the algorithm applicable to many high-dimensional settings. At the heart\\nof our algorithm is a spectral quartet test for determining the relative\\ntopology of a quartet of variables from second-order statistics.\\n',\n",
              " '  We propose to model the text classification process as a sequential decision\\nprocess. In this process, an agent learns to classify documents into topics\\nwhile reading the document sentences sequentially and learns to stop as soon as\\nenough information was read for deciding. The proposed algorithm is based on a\\nmodelisation of Text Classification as a Markov Decision Process and learns by\\nusing Reinforcement Learning. Experiments on four different classical\\nmono-label corpora show that the proposed approach performs comparably to\\nclassical SVM approaches for large training sets, and better for small training\\nsets. In addition, the model automatically adapts its reading process to the\\nquantity of training information provided.\\n',\n",
              " '  This paper introduces the Furthest Hyperplane Problem (FHP), which is an\\nunsupervised counterpart of Support Vector Machines. Given a set of n points in\\nRd, the objective is to produce the hyperplane (passing through the origin)\\nwhich maximizes the separation margin, that is, the minimal distance between\\nthe hyperplane and any input point. To the best of our knowledge, this is the\\nfirst paper achieving provable results regarding FHP. We provide both lower and\\nupper bounds to this NP-hard problem. First, we give a simple randomized\\nalgorithm whose running time is n^O(1/{\\\\theta}^2) where {\\\\theta} is the optimal\\nseparation margin. We show that its exponential dependency on 1/{\\\\theta}^2 is\\ntight, up to sub-polynomial factors, assuming SAT cannot be solved in\\nsub-exponential time. Next, we give an efficient approxima- tion algorithm. For\\nany {\\\\alpha} \\\\in [0, 1], the algorithm produces a hyperplane whose distance\\nfrom at least 1 - 5{\\\\alpha} fraction of the points is at least {\\\\alpha} times\\nthe optimal separation margin. Finally, we show that FHP does not admit a PTAS\\nby presenting a gap preserving reduction from a particular version of the PCP\\ntheorem.\\n',\n",
              " '  In this paper we propose a new algorithm for learning polyhedral classifiers\\nwhich we call as Polyceptron. It is a Perception like algorithm which updates\\nthe parameters only when the current classifier misclassifies any training\\ndata. We give both batch and online version of Polyceptron algorithm. Finally\\nwe give experimental results to show the effectiveness of our approach.\\n',\n",
              " '  We consider the problem of high-dimensional Ising (graphical) model\\nselection. We propose a simple algorithm for structure estimation based on the\\nthresholding of the empirical conditional variation distances. We introduce a\\nnovel criterion for tractable graph families, where this method is efficient,\\nbased on the presence of sparse local separators between node pairs in the\\nunderlying graph. For such graphs, the proposed algorithm has a sample\\ncomplexity of $n=\\\\Omega(J_{\\\\min}^{-2}\\\\log p)$, where $p$ is the number of\\nvariables, and $J_{\\\\min}$ is the minimum (absolute) edge potential in the\\nmodel. We also establish nonasymptotic necessary and sufficient conditions for\\nstructure estimation.\\n',\n",
              " \"  This paper addresses the problem of minimizing a convex, Lipschitz function\\n$f$ over a convex, compact set $\\\\xset$ under a stochastic bandit feedback\\nmodel. In this model, the algorithm is allowed to observe noisy realizations of\\nthe function value $f(x)$ at any query point $x \\\\in \\\\xset$. The quantity of\\ninterest is the regret of the algorithm, which is the sum of the function\\nvalues at algorithm's query points minus the optimal function value. We\\ndemonstrate a generalization of the ellipsoid algorithm that incurs\\n$\\\\otil(\\\\poly(d)\\\\sqrt{T})$ regret. Since any algorithm has regret at least\\n$\\\\Omega(\\\\sqrt{T})$ on this problem, our algorithm is optimal in terms of the\\nscaling with $T$.\\n\",\n",
              " '  In the supervised learning setting termed Multiple-Instance Learning (MIL),\\nthe examples are bags of instances, and the bag label is a function of the\\nlabels of its instances. Typically, this function is the Boolean OR. The\\nlearner observes a sample of bags and the bag labels, but not the instance\\nlabels that determine the bag labels. The learner is then required to emit a\\nclassification rule for bags based on the sample. MIL has numerous\\napplications, and many heuristic algorithms have been used successfully on this\\nproblem, each adapted to specific settings or applications. In this work we\\nprovide a unified theoretical analysis for MIL, which holds for any underlying\\nhypothesis class, regardless of a specific application or problem domain. We\\nshow that the sample complexity of MIL is only poly-logarithmically dependent\\non the size of the bag, for any underlying hypothesis class. In addition, we\\nintroduce a new PAC-learning algorithm for MIL, which uses a regular supervised\\nlearning algorithm as an oracle. We prove that efficient PAC-learning for MIL\\ncan be generated from any efficient non-MIL supervised learning algorithm that\\nhandles one-sided error. The computational complexity of the resulting\\nalgorithm is only polynomially dependent on the bag size.\\n',\n",
              " '  We consider the model introduced by Bilu and Linial (2010), who study\\nproblems for which the optimal clustering does not change when distances are\\nperturbed. They show that even when a problem is NP-hard, it is sometimes\\npossible to obtain efficient algorithms for instances resilient to certain\\nmultiplicative perturbations, e.g. on the order of $O(\\\\sqrt{n})$ for max-cut\\nclustering. Awasthi et al. (2010) consider center-based objectives, and Balcan\\nand Liang (2011) analyze the $k$-median and min-sum objectives, giving\\nefficient algorithms for instances resilient to certain constant multiplicative\\nperturbations.\\n  Here, we are motivated by the question of to what extent these assumptions\\ncan be relaxed while allowing for efficient algorithms. We show there is little\\nroom to improve these results by giving NP-hardness lower bounds for both the\\n$k$-median and min-sum objectives. On the other hand, we show that constant\\nmultiplicative resilience parameters can be so strong as to make the clustering\\nproblem trivial, leaving only a narrow range of resilience parameters for which\\nclustering is interesting. We also consider a model of additive perturbations\\nand give a correspondence between additive and multiplicative notions of\\nstability. Our results provide a close examination of the consequences of\\nassuming stability in data.\\n',\n",
              " \"  This work considers computationally efficient privacy-preserving data\\nrelease. We study the task of analyzing a database containing sensitive\\ninformation about individual participants. Given a set of statistical queries\\non the data, we want to release approximate answers to the queries while also\\nguaranteeing differential privacy---protecting each participant's sensitive\\ndata.\\n  Our focus is on computationally efficient data release algorithms; we seek\\nalgorithms whose running time is polynomial, or at least sub-exponential, in\\nthe data dimensionality. Our primary contribution is a computationally\\nefficient reduction from differentially private data release for a class of\\ncounting queries, to learning thresholded sums of predicates from a related\\nclass.\\n  We instantiate this general reduction with a variety of algorithms for\\nlearning thresholds. These instantiations yield several new results for\\ndifferentially private data release. As two examples, taking {0,1}^d to be the\\ndata domain (of dimension d), we obtain differentially private algorithms for:\\n  (*) Releasing all k-way conjunctions. For any given k, the resulting data\\nrelease algorithm has bounded error as long as the database is of size at least\\nd^{O(\\\\sqrt{k\\\\log(k\\\\log d)})}. The running time is polynomial in the database\\nsize.\\n  (*) Releasing a (1-\\\\gamma)-fraction of all parity queries. For any \\\\gamma\\n\\\\geq \\\\poly(1/d), the algorithm has bounded error as long as the database is of\\nsize at least \\\\poly(d). The running time is polynomial in the database size.\\n  Several other instantiations yield further results for privacy-preserving\\ndata release. Of the two results highlighted above, the first learning\\nalgorithm uses techniques for representing thresholded sums of predicates as\\nlow-degree polynomial threshold functions. The second learning algorithm is\\nbased on Jackson's Harmonic Sieve algorithm [Jackson 1997].\\n\",\n",
              " '  Machine learning approaches to multi-label document classification have to\\ndate largely relied on discriminative modeling techniques such as support\\nvector machines. A drawback of these approaches is that performance rapidly\\ndrops off as the total number of labels and the number of labels per document\\nincrease. This problem is amplified when the label frequencies exhibit the type\\nof highly skewed distributions that are often observed in real-world datasets.\\nIn this paper we investigate a class of generative statistical topic models for\\nmulti-label documents that associate individual word tokens with different\\nlabels. We investigate the advantages of this approach relative to\\ndiscriminative models, particularly with respect to classification problems\\ninvolving large numbers of relatively rare labels. We compare the performance\\nof generative and discriminative approaches on document labeling tasks ranging\\nfrom datasets with several thousand labels to datasets with tens of labels. The\\nexperimental results indicate that probabilistic generative models can achieve\\ncompetitive multi-label classification performance compared to discriminative\\nmethods, and have advantages for datasets with many labels and skewed label\\nfrequencies.\\n',\n",
              " '  Controller design faces a trade-off between robustness and performance, and\\nthe reliability of linear controllers has caused many practitioners to focus on\\nthe former. However, there is renewed interest in improving system performance\\nto deal with growing energy constraints. This paper describes a learning-based\\nmodel predictive control (LBMPC) scheme that provides deterministic guarantees\\non robustness, while statistical identification tools are used to identify\\nricher models of the system in order to improve performance; the benefits of\\nthis framework are that it handles state and input constraints, optimizes\\nsystem performance with respect to a cost function, and can be designed to use\\na wide variety of parametric or nonparametric statistical tools. The main\\ninsight of LBMPC is that safety and performance can be decoupled under\\nreasonable conditions in an optimization framework by maintaining two models of\\nthe system. The first is an approximate model with bounds on its uncertainty,\\nand the second model is updated by statistical methods. LBMPC improves\\nperformance by choosing inputs that minimize a cost subject to the learned\\ndynamics, and it ensures safety and robustness by checking whether these same\\ninputs keep the approximate model stable when it is subject to uncertainty.\\nFurthermore, we show that if the system is sufficiently excited, then the LBMPC\\ncontrol action probabilistically converges to that of an MPC computed using the\\ntrue dynamics.\\n',\n",
              " '  For large scale learning problems, it is desirable if we can obtain the\\noptimal model parameters by going through the data in only one pass. Polyak and\\nJuditsky (1992) showed that asymptotically the test performance of the simple\\naverage of the parameters obtained by stochastic gradient descent (SGD) is as\\ngood as that of the parameters which minimize the empirical cost. However, to\\nour knowledge, despite its optimal asymptotic convergence rate, averaged SGD\\n(ASGD) received little attention in recent research on large scale learning.\\nOne possible reason is that it may take a prohibitively large number of\\ntraining samples for ASGD to reach its asymptotic region for most real\\nproblems. In this paper, we present a finite sample analysis for the method of\\nPolyak and Juditsky (1992). Our analysis shows that it indeed usually takes a\\nhuge number of samples for ASGD to reach its asymptotic region for improperly\\nchosen learning rate. More importantly, based on our analysis, we propose a\\nsimple way to properly set learning rate so that it takes a reasonable amount\\nof data for ASGD to reach its asymptotic region. We compare ASGD using our\\nproposed learning rate with other well known algorithms for training large\\nscale linear classifiers. The experiments clearly show the superiority of ASGD.\\n',\n",
              " '  A $k$-modal probability distribution over the discrete domain $\\\\{1,...,n\\\\}$\\nis one whose histogram has at most $k$ \"peaks\" and \"valleys.\" Such\\ndistributions are natural generalizations of monotone ($k=0$) and unimodal\\n($k=1$) probability distributions, which have been intensively studied in\\nprobability theory and statistics.\\n  In this paper we consider the problem of \\\\emph{learning} (i.e., performing\\ndensity estimation of) an unknown $k$-modal distribution with respect to the\\n$L_1$ distance. The learning algorithm is given access to independent samples\\ndrawn from an unknown $k$-modal distribution $p$, and it must output a\\nhypothesis distribution $\\\\widehat{p}$ such that with high probability the total\\nvariation distance between $p$ and $\\\\widehat{p}$ is at most $\\\\epsilon.$ Our\\nmain goal is to obtain \\\\emph{computationally efficient} algorithms for this\\nproblem that use (close to) an information-theoretically optimal number of\\nsamples.\\n  We give an efficient algorithm for this problem that runs in time\\n$\\\\mathrm{poly}(k,\\\\log(n),1/\\\\epsilon)$. For $k \\\\leq \\\\tilde{O}(\\\\log n)$, the\\nnumber of samples used by our algorithm is very close (within an\\n$\\\\tilde{O}(\\\\log(1/\\\\epsilon))$ factor) to being information-theoretically\\noptimal. Prior to this work computationally efficient algorithms were known\\nonly for the cases $k=0,1$ \\\\cite{Birge:87b,Birge:97}.\\n  A novel feature of our approach is that our learning algorithm crucially uses\\na new algorithm for \\\\emph{property testing of probability distributions} as a\\nkey subroutine. The learning algorithm uses the property tester to efficiently\\ndecompose the $k$-modal distribution into $k$ (near-)monotone distributions,\\nwhich are easier to learn.\\n',\n",
              " '  We consider a basic problem in unsupervised learning: learning an unknown\\n\\\\emph{Poisson Binomial Distribution}. A Poisson Binomial Distribution (PBD)\\nover $\\\\{0,1,\\\\dots,n\\\\}$ is the distribution of a sum of $n$ independent\\nBernoulli random variables which may have arbitrary, potentially non-equal,\\nexpectations. These distributions were first studied by S. Poisson in 1837\\n\\\\cite{Poisson:37} and are a natural $n$-parameter generalization of the\\nfamiliar Binomial Distribution. Surprisingly, prior to our work this basic\\nlearning problem was poorly understood, and known results for it were far from\\noptimal.\\n  We essentially settle the complexity of the learning problem for this basic\\nclass of distributions. As our first main result we give a highly efficient\\nalgorithm which learns to $\\\\eps$-accuracy (with respect to the total variation\\ndistance) using $\\\\tilde{O}(1/\\\\eps^3)$ samples \\\\emph{independent of $n$}. The\\nrunning time of the algorithm is \\\\emph{quasilinear} in the size of its input\\ndata, i.e., $\\\\tilde{O}(\\\\log(n)/\\\\eps^3)$ bit-operations. (Observe that each draw\\nfrom the distribution is a $\\\\log(n)$-bit string.) Our second main result is a\\n{\\\\em proper} learning algorithm that learns to $\\\\eps$-accuracy using\\n$\\\\tilde{O}(1/\\\\eps^2)$ samples, and runs in time $(1/\\\\eps)^{\\\\poly (\\\\log\\n(1/\\\\eps))} \\\\cdot \\\\log n$. This is nearly optimal, since any algorithm {for this\\nproblem} must use $\\\\Omega(1/\\\\eps^2)$ samples. We also give positive and\\nnegative results for some extensions of this learning problem to weighted sums\\nof independent Bernoulli random variables.\\n',\n",
              " '  We analyse the potential of Gibbs Random Fields for shape prior modelling. We\\nshow that the expressive power of second order GRFs is already sufficient to\\nexpress simple shapes and spatial relations between them simultaneously. This\\nallows to model and recognise complex shapes as spatial compositions of simpler\\nparts.\\n',\n",
              " '  The problem of content search through comparisons has recently received\\nconsiderable attention. In short, a user searching for a target object\\nnavigates through a database in the following manner: the user is asked to\\nselect the object most similar to her target from a small list of objects. A\\nnew object list is then presented to the user based on her earlier selection.\\nThis process is repeated until the target is included in the list presented, at\\nwhich point the search terminates. This problem is known to be strongly related\\nto the small-world network design problem.\\n  However, contrary to prior work, which focuses on cases where objects in the\\ndatabase are equally popular, we consider here the case where the demand for\\nobjects may be heterogeneous. We show that, under heterogeneous demand, the\\nsmall-world network design problem is NP-hard. Given the above negative result,\\nwe propose a novel mechanism for small-world design and provide an upper bound\\non its performance under heterogeneous demand. The above mechanism has a\\nnatural equivalent in the context of content search through comparisons, and we\\nestablish both an upper bound and a lower bound for the performance of this\\nmechanism. These bounds are intuitively appealing, as they depend on the\\nentropy of the demand as well as its doubling constant, a quantity capturing\\nthe topology of the set of target objects. They also illustrate interesting\\nconnections between comparison-based search to classic results from information\\ntheory. Finally, we propose an adaptive learning algorithm for content search\\nthat meets the performance guarantees achieved by the above mechanisms.\\n',\n",
              " \"  We show that the problem of finding an optimal stochastic 'blind' controller\\nin a Markov decision process is an NP-hard problem. The corresponding decision\\nproblem is NP-hard, in PSPACE, and SQRT-SUM-hard, hence placing it in NP would\\nimply breakthroughs in long-standing open problems in computer science. Our\\nresult establishes that the more general problem of stochastic controller\\noptimization in POMDPs is also NP-hard. Nonetheless, we outline a special case\\nthat is convex and admits efficient global solutions.\\n\",\n",
              " '  We propose a method for nonparametric density estimation that exhibits\\nrobustness to contamination of the training sample. This method achieves\\nrobustness by combining a traditional kernel density estimator (KDE) with ideas\\nfrom classical $M$-estimation. We interpret the KDE based on a radial, positive\\nsemi-definite kernel as a sample mean in the associated reproducing kernel\\nHilbert space. Since the sample mean is sensitive to outliers, we estimate it\\nrobustly via $M$-estimation, yielding a robust kernel density estimator (RKDE).\\n  An RKDE can be computed efficiently via a kernelized iteratively re-weighted\\nleast squares (IRWLS) algorithm. Necessary and sufficient conditions are given\\nfor kernelized IRWLS to converge to the global minimizer of the $M$-estimator\\nobjective function. The robustness of the RKDE is demonstrated with a\\nrepresenter theorem, the influence function, and experimental results for\\ndensity estimation and anomaly detection.\\n',\n",
              " '  In this paper, we address the problem of learning the structure of a pairwise\\ngraphical model from samples in a high-dimensional setting. Our first main\\nresult studies the sparsistency, or consistency in sparsity pattern recovery,\\nproperties of a forward-backward greedy algorithm as applied to general\\nstatistical models. As a special case, we then apply this algorithm to learn\\nthe structure of a discrete graphical model via neighborhood estimation. As a\\ncorollary of our general result, we derive sufficient conditions on the number\\nof samples n, the maximum node-degree d and the problem size p, as well as\\nother conditions on the model parameters, so that the algorithm recovers all\\nthe edges with high probability. Our result guarantees graph selection for\\nsamples scaling as n = Omega(d^2 log(p)), in contrast to existing\\nconvex-optimization based algorithms that require a sample complexity of\\n\\\\Omega(d^3 log(p)). Further, the greedy algorithm only requires a restricted\\nstrong convexity condition which is typically milder than irrepresentability\\nassumptions. We corroborate these results using numerical simulations at the\\nend.\\n',\n",
              " '  Discovering pattern sets or global patterns is an attractive issue from the\\npattern mining community in order to provide useful information. By combining\\nlocal patterns satisfying a joint meaning, this approach produces patterns of\\nhigher level and thus more useful for the data analyst than the usual local\\npatterns, while reducing the number of patterns. In parallel, recent works\\ninvestigating relationships between data mining and constraint programming (CP)\\nshow that the CP paradigm is a nice framework to model and mine such patterns\\nin a declarative and generic way. We present a constraint-based language which\\nenables us to define queries addressing patterns sets and global patterns. The\\nusefulness of such a declarative approach is highlighted by several examples\\ncoming from the clustering based on associations. This language has been\\nimplemented in the CP framework.\\n',\n",
              " '  In many scientific disciplines structures in high-dimensional data have to be\\nfound, e.g., in stellar spectra, in genome data, or in face recognition tasks.\\nIn this work we present a novel approach to non-linear dimensionality\\nreduction. It is based on fitting K-nearest neighbor regression to the\\nunsupervised regression framework for learning of low-dimensional manifolds.\\nSimilar to related approaches that are mostly based on kernel methods,\\nunsupervised K-nearest neighbor (UNN) regression optimizes latent variables\\nw.r.t. the data space reconstruction error employing the K-nearest neighbor\\nheuristic. The problem of optimizing latent neighborhoods is difficult to\\nsolve, but the UNN formulation allows the design of efficient strategies that\\niteratively embed latent points to fixed neighborhood topologies. UNN is well\\nappropriate for sorting of high-dimensional data. The iterative variants are\\nanalyzed experimentally.\\n',\n",
              " '  We propose an extension of the Restricted Boltzmann Machine (RBM) that allows\\nthe joint shape and appearance of foreground objects in cluttered images to be\\nmodeled independently of the background. We present a learning scheme that\\nlearns this representation directly from cluttered images with only very weak\\nsupervision. The model generates plausible samples and performs\\nforeground-background segmentation. We demonstrate that representing foreground\\nobjects independently of the background can be beneficial in recognition tasks.\\n',\n",
              " '  In this paper we consider the problem of learning the optimal policy for\\nuncontrolled restless bandit problems. In an uncontrolled restless bandit\\nproblem, there is a finite set of arms, each of which when pulled yields a\\npositive reward. There is a player who sequentially selects one of the arms at\\neach time step. The goal of the player is to maximize its undiscounted reward\\nover a time horizon T. The reward process of each arm is a finite state Markov\\nchain, whose transition probabilities are unknown by the player. State\\ntransitions of each arm is independent of the selection of the player. We\\npropose a learning algorithm with logarithmic regret uniformly over time with\\nrespect to the optimal finite horizon policy. Our results extend the optimal\\nadaptive learning of MDPs to POMDPs.\\n',\n",
              " '  We show that for a general class of convex online learning problems, Mirror\\nDescent can always achieve a (nearly) optimal regret guarantee.\\n',\n",
              " '  We study the problem of allocating multiple users to a set of wireless\\nchannels in a decentralized manner when the channel quali- ties are\\ntime-varying and unknown to the users, and accessing the same channel by\\nmultiple users leads to reduced quality due to interference. In such a setting\\nthe users not only need to learn the inherent channel quality and at the same\\ntime the best allocations of users to channels so as to maximize the social\\nwelfare. Assuming that the users adopt a certain online learning algorithm, we\\ninvestigate under what conditions the socially optimal allocation is\\nachievable. In particular we examine the effect of different levels of\\nknowledge the users may have and the amount of communications and cooperation.\\nThe general conclusion is that when the cooperation of users decreases and the\\nuncertainty about channel payoffs increases it becomes harder to achieve the\\nsocially opti- mal allocation.\\n',\n",
              " '  It has been argued that analogy is the core of cognition. In AI research,\\nalgorithms for analogy are often limited by the need for hand-coded high-level\\nrepresentations as input. An alternative approach is to use high-level\\nperception, in which high-level representations are automatically generated\\nfrom raw data. Analogy perception is the process of recognizing analogies using\\nhigh-level perception. We present PairClass, an algorithm for analogy\\nperception that recognizes lexical proportional analogies using representations\\nthat are automatically generated from a large corpus of raw textual data. A\\nproportional analogy is an analogy of the form A:B::C:D, meaning \"A is to B as\\nC is to D\". A lexical proportional analogy is a proportional analogy with\\nwords, such as carpenter:wood::mason:stone. PairClass represents the semantic\\nrelations between two words using a high-dimensional feature vector, in which\\nthe elements are based on frequencies of patterns in the corpus. PairClass\\nrecognizes analogies by applying standard supervised machine learning\\ntechniques to the feature vectors. We show how seven different tests of word\\ncomprehension can be framed as problems of analogy perception and we then apply\\nPairClass to the seven resulting sets of analogy perception problems. We\\nachieve competitive results on all seven tests. This is the first time a\\nuniform approach has handled such a range of tests of word comprehension.\\n',\n",
              " '  This paper gives specific divergence examples of value-iteration for several\\nmajor Reinforcement Learning and Adaptive Dynamic Programming algorithms, when\\nusing a function approximator for the value function. These divergence examples\\ndiffer from previous divergence examples in the literature, in that they are\\napplicable for a greedy policy, i.e. in a \"value iteration\" scenario. Perhaps\\nsurprisingly, with a greedy policy, it is also possible to get divergence for\\nthe algorithms TD(1) and Sarsa(1). In addition to these divergences, we also\\nachieve divergence for the Adaptive Dynamic Programming algorithms HDP, DHP and\\nGDHP.\\n',\n",
              " ...]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g7dXXjmY9Um"
      },
      "source": [
        "# ðŸ¦™ **Quantized LLM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs6EjDTALfpB"
      },
      "source": [
        "To use a quantized LLMs, we make use of the `GGUF` format together with `llama-cpp-python`. When you access any of [TheBloke's quantized models](https://huggingface.co/TheBloke), you can click on files and find specific quantized formats. We are going with a 4-bit quantized model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnqgCvHkiXzx",
        "outputId": "fabf4f93-a066-407d-dc76-707aac0e2707"
      },
      "outputs": [],
      "source": [
        "#!wget https://huggingface.co/TheBloke/OpenHermes-2.5-Mistral-7B-GGUF/resolve/main/openhermes-2.5-mistral-7b.Q4_K_M.gguf\n",
        "# !wget https://huggingface.co/TheBloke/dolphin-2.7-mixtral-8x7b-GGUF/resolve/main/dolphin-2.7-mixtral-8x7b.Q3_K_M.gguf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkzOVBHJLhLr"
      },
      "source": [
        "Next, we load the model using `llama-cpp-python`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJHF-D4hKyvo",
        "outputId": "58ee6cd6-f4e8-40de-d905-ccc3eb35a823"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ggml_init_cublas: GGML_CUDA_FORCE_MMQ:   no\n",
            "ggml_init_cublas: CUDA_USE_TENSOR_CORES: yes\n",
            "ggml_init_cublas: found 1 CUDA devices:\n",
            "  Device 0: NVIDIA GeForce RTX 3090, compute capability 8.6, VMM: yes\n",
            "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from /home/maitre/Documents/Development/text-generation-webui/models/openhermes-2.5-mistral-7b.Q4_K_M.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = teknium_openhermes-2.5-mistral-7b\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32002]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32002]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32002]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.padding_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 261/32002 ).\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32002\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 32768\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 8\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
            "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 14336\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
            "llm_load_print_meta: model params     = 7.24 B\n",
            "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
            "llm_load_print_meta: general.name     = teknium_openhermes-2.5-mistral-7b\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 32000 '<|im_end|>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.22 MiB\n",
            "llm_load_tensors: offloading 32 repeating layers to GPU\n",
            "llm_load_tensors: offloading non-repeating layers to GPU\n",
            "llm_load_tensors: offloaded 33/33 layers to GPU\n",
            "llm_load_tensors:        CPU buffer size =    70.32 MiB\n",
            "llm_load_tensors:      CUDA0 buffer size =  4095.06 MiB\n",
            ".........."
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ".......................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 4096\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:      CUDA0 KV buffer size =   512.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  512.00 MiB, K (f16):  256.00 MiB, V (f16):  256.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host input buffer size   =    17.04 MiB\n",
            "llama_new_context_with_model:      CUDA0 compute buffer size =   296.02 MiB\n",
            "llama_new_context_with_model:  CUDA_Host compute buffer size =     8.00 MiB\n",
            "llama_new_context_with_model: graph splits (measure): 3\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
            "Model metadata: {'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.eos_token_id': '32000', 'general.architecture': 'llama', 'llama.rope.freq_base': '10000.000000', 'llama.context_length': '32768', 'general.name': 'teknium_openhermes-2.5-mistral-7b', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n"
          ]
        }
      ],
      "source": [
        "from llama_cpp import Llama\n",
        "\n",
        "# Use llama.cpp to load in a Quantized LLM\n",
        "model_path=\"/home/maitre/Documents/Development/text-generation-webui/models/openhermes-2.5-mistral-7b.Q4_K_M.gguf\"\n",
        "llm = Llama(model_path=model_path, n_gpu_layers=-1, n_ctx=4096, stop=[\"Q:\", \"\\n\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdsdtT2G6pk3"
      },
      "source": [
        "We pass the LLM to BERTopic with a custom prompt. Let's add `KeyBERTInspired` representations to compare the LLM representations with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JRH6OpQr6z2v"
      },
      "outputs": [],
      "source": [
        "from bertopic.representation import KeyBERTInspired, LlamaCPP\n",
        "\n",
        "prompt = \"\"\" Q:\n",
        "I have a topic that contains the following documents:\n",
        "[DOCUMENTS]\n",
        "\n",
        "The topic is described by the following keywords: '[KEYWORDS]'.\n",
        "\n",
        "Based on the above information, can you give a short label of the topic of at most 5 words?\n",
        "A:\n",
        "\"\"\"\n",
        "\n",
        "representation_model = {\n",
        "    \"KeyBERT\": KeyBERTInspired(),\n",
        "    \"LLM\": LlamaCPP(llm, prompt=prompt),\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mDfAxLbYaeU"
      },
      "source": [
        "# ðŸ—¨ï¸ **BERTopic**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HSPV-N9Ydp1"
      },
      "source": [
        "By pre-calculating the embeddings for each document, we can speed-up additional exploration steps and use the embeddings to quickly iterate over BERTopic's hyperparameters if needed.\n",
        "\n",
        "ðŸ”¥ **TIP**: You can find a great overview of good embeddings for clustering on the [MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465,
          "referenced_widgets": [
            "32b3e320c6394311ba48773db9e9b22b",
            "ecba0505794e4312a8c6eddfd6563058",
            "d44050c3f35842a58b6158aec48b20e1",
            "668d08eef527446ca16ab8e7c41c788b",
            "c5fc9a8da64b48c8ad1e1cccbc00b7a7",
            "ca5f02626ce14220af769957b8729fd6",
            "adaf28e7e7f44b55a39319aa1911c5af",
            "eba5cfcc6796421b906625f898c736a0",
            "9f1a759cfa9848dfaab4a4579cd4edca",
            "dfc7002e8ad0487ca27a002c906f0a91",
            "86a3358c8192420cb03bf26f5aa82a55",
            "2911473810814cf2a701fb7c664535d7",
            "c068a62e89514493b6892902b07588ca",
            "8ed574479d084302903a187f742d37dd",
            "57ff32efde8b46b4b8446f9f8ad3124c",
            "3ab6e3c02835479c952c1ff94cf2d11d",
            "e3e0c7959c9d452a92d1f6331577ef0b",
            "cefba38a83524e25ba11a8afe51d7a4a",
            "cf1d7fd7cd774a7082bd131c385771f0",
            "909aefbb4913407cbfcca69367bf12c9",
            "c536190d16a94bee9040b3e30e0e7a42",
            "bf432b718c9e45c1aec79c343a2a961b",
            "dcafd9390a4145b2ba60291d992e8a99",
            "990f4fea07194fd5963b040e38033198",
            "3dc13a513ab54716ac6652de82c2c6e1",
            "5aa1c93e38f84e1682e0da8916f23570",
            "93442b807f2d406eb9e8253318176a8c",
            "0c3b3798b81e4518b37a193c8a2cf8e5",
            "e1c0ac8457bd4dc6ad76a6682c9c9294",
            "d28ee359eca1443ba2e8843a5cc87634",
            "7e000ee95b1941d4b85556cc55a7cb7a",
            "3b8bc05023784477ac20e075c1511783",
            "c19f084191a349a48daa49580cbf9a22",
            "8a7ee59f41a548808479b4482282d803",
            "f85952f39f6247f2b308477082723642",
            "97bdf1b1b19147d1932a8057d5f81dd2",
            "6a760553da3a4cf4af57314f70ecca12",
            "47995cace7734f1db0013b2d52b5a33b",
            "bef1768f438044ea98e36913c123d378",
            "efd44195239945aaaef40fa4290105df",
            "e3278f12f0da4a73bd3589ff9908ba45",
            "7747d146a0e44cf69b2c97c4e0a7a6e2",
            "750c0b4ead7b4a4b87f21ea1af774912",
            "13d0f64fbd2242df842b5ee24e62c713",
            "1786b6f50554429e9a05e4afd159eec9",
            "ef67fa67939e4101bd14109bc86012ee",
            "4f9cd48c6a544edfb76db48c38475a95",
            "a13cfeb6c4cf4a6db46f70615fcbfdbb",
            "1c9f9da220244c2bb5cb3b8ea26fefd1",
            "35b4e41692ea44e08648722c0ffeb5ec",
            "39534b0ad5154390959f44ea29dfbe0a",
            "7a8c442cba3442afaf74dd9e1a867cc9",
            "9b91f4bc6b624f5ab927e1938b2b2e1b",
            "5e097d4a966a41d497cc7998197a3a1b",
            "c893c283bd6f4c5094498870881554ab",
            "1b0acf777e1e40d99b5c33e0f8e543a6",
            "484449cc5f214722bee84bdaf3e0bb62",
            "da644207a0fe482fa7e7801d146743b9",
            "27816c1794c04a31b850cab640690984",
            "da11831b9b64409ebb221c5696d4df00",
            "a581cb88aa744e959667dea384a4d67d",
            "dd3775f1c6da4690b6d4bb0d4c05faa3",
            "25a509713da94079a3d732b3640b45f1",
            "b788043339374e3caece51aee331fc8e",
            "99f5f91417b347679eab2084dc3a173c",
            "6f071c1778514eb19cfd7e1c591bad3b",
            "1f27a38fceaf435aa129c9105088cad3",
            "50a57b619b2a48c4a8eb5305e92edacf",
            "a2886173497d446d8c33718541dd2f86",
            "d51117191e3f464d908bdaf9af40d416",
            "ef3c40dc8acf4c7f998af622ee487f32",
            "513b6ef2d1f24fb09b35da7508cf677b",
            "926f81d57f8c44728f7ab2ce23045a1e",
            "29dfb020240b4e2082ebd415e9bebae1",
            "f4082a051e9040c3a275b9c327255ccc",
            "ef4e004652c749609ef7d4f8fb5b38d7",
            "d5e24ec20e544f2fa2bc90355e24bc9e",
            "ccaae9ff77ce4393baca81c3235e6512",
            "7eaf5817d3d844cc83f0d22249877c2c",
            "ddea2dbed8d244a08eb34fbdd51fd4ff",
            "2baa14a4ade84861a04c2cb39626a3f8",
            "4537ca1a93ff459ea91a1971febc3240",
            "e81c7b65f15646db923f2b757663a390",
            "bc772c27481e4e3fadd74a76008a718f",
            "95aeff88d4454d6997ded27932add286",
            "db6096a4006548f18a1768e1a7b56ed0",
            "cf29105419e14ab6bb3812c67091db3a",
            "a4229c528f004d89af576a9eb55a4af0",
            "bbe2f12d1a81462bb8cf22be9f0b619c",
            "49d7ea3e683c4c1d9bbdec9a0a50def2",
            "4e075b9251ba4851993ffa2134cfda30",
            "ce368f69663c47a9bc62f42a87a4b9a4",
            "53ddd2c0ee5844dc96961c63f7cf357a",
            "cdb633688620485e833e894b0690b624",
            "ef40bb8746e24b0bba4c9b86f0e71366",
            "b105bd9d8489494bb2fcfd6dc12e9940",
            "e420443a8f094a088158c922a067ab92",
            "ca814d3d1d1e463696a87e6af616c725",
            "38497928129048929cf8a4a6fa040f75",
            "31eafc989e3f4355afd8cc39c2a308d3",
            "7cddcdb41f8c48d48d9688118a3df1f4",
            "77dc6643ecec446a85b1c10527cc97ed",
            "373af9df368b47a9ab45b05702c23377",
            "daf244afa867435ea9c46964d7730c21",
            "53f7e33194f04fab8b16f175c8446cfd",
            "549cfd8542c947efac340054c6fecdad",
            "b71af597c449404b81f871ed31bf853d",
            "66d7fcd2e1c147fdafff192c2379d192",
            "38e695c7b2c04dff86521c2ae0bfa7cd",
            "8c348e604699440385a58eedb6320b37",
            "e4b9a48b2b634aac89dd82905a96fca4",
            "e2afa0054bc24ca1a48b214a0558c281",
            "afa8767a74a243cb8248b05bccc47d1c",
            "504f359e12bc4d7abec3432b613b2b57",
            "9a0fc4fa6be34d3fb4773c6ffdef365c",
            "bcfe91d3a22045a7add3deb099fd641a",
            "99d3f153e4b04d4087112ecb5ab36cb2",
            "856d9c2c3ea7412fbf3ff6c846d853c1",
            "5f81bfbdf539477095bf1d9cd1fb44e0",
            "896ed32e621449ff8a0bb9ef65fe241f",
            "e7b6b060966b468ca3bda23b744590c5",
            "c68875f2a5c9423d8ad572e930759826",
            "d3c875bed4e04774a32f9503c63c8e66",
            "f4ec9b1bbf89426fbc515e0d2b291d90",
            "0261126af0bf47d490b40ebc8f8f73c5",
            "4872a46c8ada479ca62ee8a362135399",
            "1ff5a36868a04ee1a2a70520e4004cce",
            "f07049851cbd47819466c7f5b9be3db5",
            "d8bf6d6dc49f403bb5c1b7a2eaf9c5ae",
            "74fc148c1fa3428382acbcd43b747472",
            "28e9406ec1404eb0bfb3ebba01c5e04f",
            "80495805c2a448a6a4405d2f223dc95b",
            "89c5eff824b44a67ba29f8a51b6519d1",
            "2def6630a8c64e768e38c0cecf7b4a19",
            "1537d3486fcf4ec683be254e3f9af7f2",
            "9670404c09bc4781aa10fd4e2d06ad2e",
            "67e7fa0df2d34f78b6545ff9fdcd5eb6",
            "ca959e8e38e14764bc1e046ce1b241c1",
            "9c64ba4c52d24c42ac2a1cc3e3e0a77f",
            "90ea70019c8842079d7ff919f3af843a",
            "e1eca1748c8c4055a43d97492d078879",
            "b4b6c986d05c4957885e39f1f93a6355",
            "b113de801dc24911bec0f2c09ef0540c",
            "a89dd48f19f74c669de84b78b9158908",
            "d9d90d474012467b8a23c8c59ee4fba6",
            "c2e95cca9f7c40949cc88addf207069a",
            "9446d53d57724a4caf06e344ea21df78",
            "0da7331c8f0f446fb916f148beab9877",
            "bb912639a55846f39ffad8a4b0f3c9bc",
            "e3e175e11dff4ffc9345fceffdaf4ad0",
            "003f1df5815f4907a0ece85edad574ca",
            "eac4daaeefc944c1b3c90323e4953242",
            "59edec96719244ee8844c4c00b586665",
            "56b77e38f86a4a81a1e091d8426aeebf"
          ]
        },
        "id": "hqhLlG8_YhtB",
        "outputId": "f9c2b62a-98c3-4487-9a49-3249689f147a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d0b6b73eb9946d9bfa628fd7bf6c673",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3675 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from cuml.manifold import UMAP\n",
        "from cuml.cluster import HDBSCAN\n",
        "# from umap import UMAP\n",
        "# from hdbscan import HDBSCAN\n",
        "\n",
        "# Pre-calculate embeddings\n",
        "embedding_model = SentenceTransformer(\"BAAI/bge-small-en\")\n",
        "embeddings = embedding_model.encode(docs, show_progress_bar=True)\n",
        "\n",
        "# Pre-reduce embeddings for visualization purposes\n",
        "reduced_embeddings = UMAP(n_neighbors=15, n_components=2, min_dist=0.0, metric='cosine', random_state=42).fit_transform(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NUbjxSQ3NAt-"
      },
      "outputs": [],
      "source": [
        "# Define sub-models\n",
        "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', random_state=42)\n",
        "hdbscan_model = HDBSCAN(min_cluster_size=400, metric='euclidean', cluster_selection_method='eom', prediction_data=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLVYJQf2aegN"
      },
      "source": [
        "# ðŸ”¥ **Training**\n",
        "\n",
        "Now that we have our models prepared, we can start training our topic model! We supply BERTopic with the sub-models of interest, run `.fit_transform`, and see what kind of topics we get."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdokcXzW6C1g",
        "outputId": "cc9ef408-1809-46ae-fc3a-e591c7b1e115"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-10 16:27:03,492 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
            "2024-03-10 16:27:05,599 - BERTopic - Dimensionality - Completed âœ“\n",
            "2024-03-10 16:27:05,601 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
            "2024-03-10 16:27:11,421 - BERTopic - Cluster - Completed âœ“\n",
            "2024-03-10 16:27:11,436 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
            "  0%|          | 0/33 [00:00<?, ?it/s]\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       2.48 ms /     9 runs   (    0.28 ms per token,  3621.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     411.46 ms /  1140 tokens (    0.36 ms per token,  2770.59 tokens per second)\n",
            "llama_print_timings:        eval time =      79.33 ms /     8 runs   (    9.92 ms per token,   100.85 tokens per second)\n",
            "llama_print_timings:       total time =     513.66 ms /  1148 tokens\n",
            "  3%|â–Ž         | 1/33 [00:00<00:16,  1.92it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       3.76 ms /    14 runs   (    0.27 ms per token,  3723.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     510.48 ms /  1539 tokens (    0.33 ms per token,  3014.83 tokens per second)\n",
            "llama_print_timings:        eval time =     127.20 ms /    13 runs   (    9.78 ms per token,   102.20 tokens per second)\n",
            "llama_print_timings:       total time =     671.81 ms /  1552 tokens\n",
            "  6%|â–Œ         | 2/33 [00:01<00:19,  1.63it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       1.98 ms /     7 runs   (    0.28 ms per token,  3535.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     538.14 ms /  1574 tokens (    0.34 ms per token,  2924.88 tokens per second)\n",
            "llama_print_timings:        eval time =      59.85 ms /     6 runs   (    9.98 ms per token,   100.25 tokens per second)\n",
            "llama_print_timings:       total time =     617.34 ms /  1580 tokens\n",
            "  9%|â–‰         | 3/33 [00:01<00:18,  1.62it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       2.01 ms /     7 runs   (    0.29 ms per token,  3480.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     402.81 ms /  1249 tokens (    0.32 ms per token,  3100.76 tokens per second)\n",
            "llama_print_timings:        eval time =      61.20 ms /     6 runs   (   10.20 ms per token,    98.04 tokens per second)\n",
            "llama_print_timings:       total time =     482.18 ms /  1255 tokens\n",
            " 12%|â–ˆâ–        | 4/33 [00:02<00:16,  1.76it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       2.47 ms /     9 runs   (    0.27 ms per token,  3642.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     397.73 ms /  1244 tokens (    0.32 ms per token,  3127.79 tokens per second)\n",
            "llama_print_timings:        eval time =      78.22 ms /     8 runs   (    9.78 ms per token,   102.28 tokens per second)\n",
            "llama_print_timings:       total time =     496.69 ms /  1252 tokens\n",
            " 15%|â–ˆâ–Œ        | 5/33 [00:02<00:15,  1.83it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       4.42 ms /    16 runs   (    0.28 ms per token,  3624.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =     388.23 ms /  1185 tokens (    0.33 ms per token,  3052.31 tokens per second)\n",
            "llama_print_timings:        eval time =     150.29 ms /    15 runs   (   10.02 ms per token,    99.81 tokens per second)\n",
            "llama_print_timings:       total time =     575.50 ms /  1200 tokens\n",
            " 18%|â–ˆâ–Š        | 6/33 [00:03<00:15,  1.79it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       4.34 ms /    16 runs   (    0.27 ms per token,  3689.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     452.63 ms /  1411 tokens (    0.32 ms per token,  3117.34 tokens per second)\n",
            "llama_print_timings:        eval time =     153.65 ms /    15 runs   (   10.24 ms per token,    97.62 tokens per second)\n",
            "llama_print_timings:       total time =     642.89 ms /  1426 tokens\n",
            " 21%|â–ˆâ–ˆ        | 7/33 [00:04<00:15,  1.70it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       4.45 ms /    16 runs   (    0.28 ms per token,  3592.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     375.63 ms /  1128 tokens (    0.33 ms per token,  3002.96 tokens per second)\n",
            "llama_print_timings:        eval time =     146.34 ms /    15 runs   (    9.76 ms per token,   102.50 tokens per second)\n",
            "llama_print_timings:       total time =     556.34 ms /  1143 tokens\n",
            " 24%|â–ˆâ–ˆâ–       | 8/33 [00:04<00:14,  1.72it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       2.90 ms /    10 runs   (    0.29 ms per token,  3447.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     423.89 ms /  1293 tokens (    0.33 ms per token,  3050.35 tokens per second)\n",
            "llama_print_timings:        eval time =      87.79 ms /     9 runs   (    9.75 ms per token,   102.52 tokens per second)\n",
            "llama_print_timings:       total time =     536.82 ms /  1302 tokens\n",
            " 27%|â–ˆâ–ˆâ–‹       | 9/33 [00:05<00:13,  1.76it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       1.91 ms /     7 runs   (    0.27 ms per token,  3659.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     379.58 ms /  1151 tokens (    0.33 ms per token,  3032.31 tokens per second)\n",
            "llama_print_timings:        eval time =      62.30 ms /     6 runs   (   10.38 ms per token,    96.32 tokens per second)\n",
            "llama_print_timings:       total time =     461.02 ms /  1157 tokens\n",
            " 30%|â–ˆâ–ˆâ–ˆ       | 10/33 [00:05<00:12,  1.86it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /    15 runs   (    0.26 ms per token,  3838.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     403.60 ms /  1268 tokens (    0.32 ms per token,  3141.73 tokens per second)\n",
            "llama_print_timings:        eval time =     130.95 ms /    14 runs   (    9.35 ms per token,   106.91 tokens per second)\n",
            "llama_print_timings:       total time =     566.44 ms /  1282 tokens\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 11/33 [00:06<00:12,  1.82it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       2.70 ms /    10 runs   (    0.27 ms per token,  3699.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     371.79 ms /  1123 tokens (    0.33 ms per token,  3020.56 tokens per second)\n",
            "llama_print_timings:        eval time =      88.25 ms /     9 runs   (    9.81 ms per token,   101.99 tokens per second)\n",
            "llama_print_timings:       total time =     482.81 ms /  1132 tokens\n",
            " 36%|â–ˆâ–ˆâ–ˆâ–‹      | 12/33 [00:06<00:11,  1.88it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       4.43 ms /    16 runs   (    0.28 ms per token,  3610.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     465.84 ms /  1438 tokens (    0.32 ms per token,  3086.92 tokens per second)\n",
            "llama_print_timings:        eval time =     155.12 ms /    15 runs   (   10.34 ms per token,    96.70 tokens per second)\n",
            "llama_print_timings:       total time =     657.49 ms /  1453 tokens\n",
            " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 13/33 [00:07<00:11,  1.75it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       2.77 ms /    10 runs   (    0.28 ms per token,  3612.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     464.21 ms /  1419 tokens (    0.33 ms per token,  3056.81 tokens per second)\n",
            "llama_print_timings:        eval time =      94.68 ms /     9 runs   (   10.52 ms per token,    95.06 tokens per second)\n",
            "llama_print_timings:       total time =     585.90 ms /  1428 tokens\n",
            " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/33 [00:07<00:10,  1.73it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       3.43 ms /    12 runs   (    0.29 ms per token,  3499.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     407.93 ms /  1280 tokens (    0.32 ms per token,  3137.77 tokens per second)\n",
            "llama_print_timings:        eval time =     105.70 ms /    11 runs   (    9.61 ms per token,   104.07 tokens per second)\n",
            "llama_print_timings:       total time =     542.98 ms /  1291 tokens\n",
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 15/33 [00:08<00:10,  1.75it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       2.47 ms /     9 runs   (    0.27 ms per token,  3642.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     400.84 ms /  1237 tokens (    0.32 ms per token,  3086.03 tokens per second)\n",
            "llama_print_timings:        eval time =      80.27 ms /     8 runs   (   10.03 ms per token,    99.67 tokens per second)\n",
            "llama_print_timings:       total time =     502.49 ms /  1245 tokens\n",
            " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 16/33 [00:09<00:09,  1.81it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       4.52 ms /    16 runs   (    0.28 ms per token,  3536.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     400.60 ms /  1278 tokens (    0.31 ms per token,  3190.20 tokens per second)\n",
            "llama_print_timings:        eval time =     144.55 ms /    15 runs   (    9.64 ms per token,   103.77 tokens per second)\n",
            "llama_print_timings:       total time =     579.39 ms /  1293 tokens\n",
            " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:09<00:09,  1.78it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       4.42 ms /    16 runs   (    0.28 ms per token,  3616.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =     456.97 ms /  1413 tokens (    0.32 ms per token,  3092.14 tokens per second)\n",
            "llama_print_timings:        eval time =     152.22 ms /    15 runs   (   10.15 ms per token,    98.54 tokens per second)\n",
            "llama_print_timings:       total time =     644.03 ms /  1428 tokens\n",
            " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 18/33 [00:10<00:08,  1.70it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       2.81 ms /    10 runs   (    0.28 ms per token,  3565.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =     402.44 ms /  1277 tokens (    0.32 ms per token,  3173.16 tokens per second)\n",
            "llama_print_timings:        eval time =      87.81 ms /     9 runs   (    9.76 ms per token,   102.49 tokens per second)\n",
            "llama_print_timings:       total time =     514.53 ms /  1286 tokens\n",
            " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 19/33 [00:10<00:07,  1.76it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       2.25 ms /     8 runs   (    0.28 ms per token,  3549.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     321.13 ms /  1027 tokens (    0.31 ms per token,  3198.10 tokens per second)\n",
            "llama_print_timings:        eval time =      69.83 ms /     7 runs   (    9.98 ms per token,   100.24 tokens per second)\n",
            "llama_print_timings:       total time =     410.99 ms /  1034 tokens\n",
            " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 20/33 [00:11<00:06,  1.91it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       3.06 ms /    11 runs   (    0.28 ms per token,  3592.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     468.55 ms /  1481 tokens (    0.32 ms per token,  3160.80 tokens per second)\n",
            "llama_print_timings:        eval time =     103.63 ms /    10 runs   (   10.36 ms per token,    96.50 tokens per second)\n",
            "llama_print_timings:       total time =     599.54 ms /  1491 tokens\n",
            " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 21/33 [00:11<00:06,  1.82it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       3.40 ms /    12 runs   (    0.28 ms per token,  3528.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     433.73 ms /  1391 tokens (    0.31 ms per token,  3207.06 tokens per second)\n",
            "llama_print_timings:        eval time =     113.52 ms /    11 runs   (   10.32 ms per token,    96.90 tokens per second)\n",
            "llama_print_timings:       total time =     575.32 ms /  1402 tokens\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 22/33 [00:12<00:06,  1.79it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       4.31 ms /    16 runs   (    0.27 ms per token,  3711.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     348.61 ms /  1057 tokens (    0.33 ms per token,  3032.09 tokens per second)\n",
            "llama_print_timings:        eval time =     140.26 ms /    15 runs   (    9.35 ms per token,   106.94 tokens per second)\n",
            "llama_print_timings:       total time =     524.22 ms /  1072 tokens\n",
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:12<00:05,  1.82it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       4.56 ms /    16 runs   (    0.29 ms per token,  3508.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =     380.40 ms /  1258 tokens (    0.30 ms per token,  3307.05 tokens per second)\n",
            "llama_print_timings:        eval time =     138.71 ms /    15 runs   (    9.25 ms per token,   108.14 tokens per second)\n",
            "llama_print_timings:       total time =     554.77 ms /  1273 tokens\n",
            " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:13<00:04,  1.81it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       1.48 ms /     5 runs   (    0.30 ms per token,  3378.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =     356.08 ms /  1127 tokens (    0.32 ms per token,  3165.05 tokens per second)\n",
            "llama_print_timings:        eval time =      39.55 ms /     4 runs   (    9.89 ms per token,   101.15 tokens per second)\n",
            "llama_print_timings:       total time =     411.50 ms /  1131 tokens\n",
            " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:13<00:04,  1.95it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       4.26 ms /    15 runs   (    0.28 ms per token,  3522.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     453.10 ms /  1491 tokens (    0.30 ms per token,  3290.68 tokens per second)\n",
            "llama_print_timings:        eval time =     142.97 ms /    14 runs   (   10.21 ms per token,    97.93 tokens per second)\n",
            "llama_print_timings:       total time =     631.73 ms /  1505 tokens\n",
            " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 26/33 [00:14<00:03,  1.81it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       4.38 ms /    16 runs   (    0.27 ms per token,  3656.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     392.95 ms /  1238 tokens (    0.32 ms per token,  3150.56 tokens per second)\n",
            "llama_print_timings:        eval time =     145.92 ms /    15 runs   (    9.73 ms per token,   102.80 tokens per second)\n",
            "llama_print_timings:       total time =     575.37 ms /  1253 tokens\n",
            " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/33 [00:15<00:03,  1.78it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       1.90 ms /     7 runs   (    0.27 ms per token,  3678.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     461.72 ms /  1505 tokens (    0.31 ms per token,  3259.57 tokens per second)\n",
            "llama_print_timings:        eval time =      58.64 ms /     6 runs   (    9.77 ms per token,   102.32 tokens per second)\n",
            "llama_print_timings:       total time =     538.76 ms /  1511 tokens\n",
            " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:15<00:02,  1.80it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       2.51 ms /     9 runs   (    0.28 ms per token,  3588.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     375.54 ms /  1167 tokens (    0.32 ms per token,  3107.53 tokens per second)\n",
            "llama_print_timings:        eval time =      78.28 ms /     8 runs   (    9.79 ms per token,   102.19 tokens per second)\n",
            "llama_print_timings:       total time =     475.51 ms /  1175 tokens\n",
            " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:16<00:02,  1.87it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       2.17 ms /     8 runs   (    0.27 ms per token,  3695.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     366.01 ms /  1110 tokens (    0.33 ms per token,  3032.66 tokens per second)\n",
            "llama_print_timings:        eval time =      67.36 ms /     7 runs   (    9.62 ms per token,   103.93 tokens per second)\n",
            "llama_print_timings:       total time =     453.52 ms /  1117 tokens\n",
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:16<00:01,  1.95it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       2.46 ms /     9 runs   (    0.27 ms per token,  3661.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     289.87 ms /   961 tokens (    0.30 ms per token,  3315.33 tokens per second)\n",
            "llama_print_timings:        eval time =      78.30 ms /     8 runs   (    9.79 ms per token,   102.18 tokens per second)\n",
            "llama_print_timings:       total time =     389.03 ms /   969 tokens\n",
            " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 31/33 [00:17<00:00,  2.09it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       4.53 ms /    16 runs   (    0.28 ms per token,  3531.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     412.04 ms /  1303 tokens (    0.32 ms per token,  3162.29 tokens per second)\n",
            "llama_print_timings:        eval time =     145.55 ms /    15 runs   (    9.70 ms per token,   103.05 tokens per second)\n",
            "llama_print_timings:       total time =     598.66 ms /  1318 tokens\n",
            " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 32/33 [00:17<00:00,  1.94it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     190.46 ms\n",
            "llama_print_timings:      sample time =       2.47 ms /     9 runs   (    0.27 ms per token,  3649.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =     427.68 ms /  1396 tokens (    0.31 ms per token,  3264.15 tokens per second)\n",
            "llama_print_timings:        eval time =      80.63 ms /     8 runs   (   10.08 ms per token,    99.22 tokens per second)\n",
            "llama_print_timings:       total time =     530.67 ms /  1404 tokens\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:18<00:00,  1.82it/s]\n",
            "2024-03-10 16:27:49,558 - BERTopic - Representation - Completed âœ“\n"
          ]
        }
      ],
      "source": [
        "from bertopic import BERTopic\n",
        "\n",
        "topic_model = BERTopic(\n",
        "\n",
        "  # Sub-models\n",
        "  embedding_model=embedding_model,\n",
        "  umap_model=umap_model,\n",
        "  hdbscan_model=hdbscan_model,\n",
        "  representation_model=representation_model,\n",
        "\n",
        "  # Hyperparameters\n",
        "  top_n_words=10,\n",
        "  verbose=True\n",
        ")\n",
        "\n",
        "# Train model\n",
        "topics, probs = topic_model.fit_transform(docs, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VP3thw16ECx"
      },
      "source": [
        "Now that we are done training our model, let's see what topics were generated:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4Uj8MYhCafmX",
        "outputId": "0d4e64c1-947b-45ac-b951-9cfc4bc2daca"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic</th>\n",
              "      <th>Count</th>\n",
              "      <th>Name</th>\n",
              "      <th>Representation</th>\n",
              "      <th>KeyBERT</th>\n",
              "      <th>LLM</th>\n",
              "      <th>Representative_Docs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>60273</td>\n",
              "      <td>-1_the_of_and_to</td>\n",
              "      <td>[the, of, and, to, in, we, is, for, that, on]</td>\n",
              "      <td>[datasets, models, model, algorithms, learning...</td>\n",
              "      <td>[Machine Learning Representation and Algorithm...</td>\n",
              "      <td>[  Gaussian Mixture Models are one of the most...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>7177</td>\n",
              "      <td>0_policy_learning_the_reinforcement</td>\n",
              "      <td>[policy, learning, the, reinforcement, to, in,...</td>\n",
              "      <td>[learning, reinforcement, dynamics, robot, mod...</td>\n",
              "      <td>[Reinforcement Learning Policies and Imitation...</td>\n",
              "      <td>[  Applying reinforcement learning (RL) method...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>6448</td>\n",
              "      <td>1_the_and_of_to</td>\n",
              "      <td>[the, and, of, to, in, for, data, is, we, with]</td>\n",
              "      <td>[convolutional, mri, imaging, trained, predict...</td>\n",
              "      <td>[Deep Learning in Medical Image Analysis, , , ...</td>\n",
              "      <td>[  Deep learning methods are successfully used...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>6040</td>\n",
              "      <td>2_language_the_and_of</td>\n",
              "      <td>[language, the, and, of, to, in, we, text, on,...</td>\n",
              "      <td>[embeddings, nlp, language, representations, s...</td>\n",
              "      <td>[Language Modeling with Transfer Learning, , ,...</td>\n",
              "      <td>[  Pretrained contextualized text representati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>3496</td>\n",
              "      <td>3_the_to_and_of</td>\n",
              "      <td>[the, to, and, of, we, generative, image, in, ...</td>\n",
              "      <td>[gans, adversarial, gan, generative, models, m...</td>\n",
              "      <td>[Generative Adversarial Networks, , , , , , , ...</td>\n",
              "      <td>[  Generative adversarial networks (GANs) have...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4</td>\n",
              "      <td>2812</td>\n",
              "      <td>4_speech_audio_the_speaker</td>\n",
              "      <td>[speech, audio, the, speaker, to, of, and, in,...</td>\n",
              "      <td>[speech, voice, language, models, neural, mode...</td>\n",
              "      <td>[Speech Separation and Enhancement\\n\\nQ:\\nWhic...</td>\n",
              "      <td>[  Deep learning models are becoming predomina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5</td>\n",
              "      <td>2809</td>\n",
              "      <td>5_privacy_federated_fl_data</td>\n",
              "      <td>[privacy, federated, fl, data, the, learning, ...</td>\n",
              "      <td>[federated, distributed, datasets, model, mode...</td>\n",
              "      <td>[Federated Learning Privacy\\nB:\\nFederated Lea...</td>\n",
              "      <td>[Federated learning allows many devices to col...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6</td>\n",
              "      <td>2584</td>\n",
              "      <td>6_adversarial_attacks_attack_robustness</td>\n",
              "      <td>[adversarial, attacks, attack, robustness, the...</td>\n",
              "      <td>[adversarial, dnns, attacks, models, model, at...</td>\n",
              "      <td>[Adversarial Attacks and Robustness in Deep Ne...</td>\n",
              "      <td>[  Recent studies on the adversarial vulnerabi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7</td>\n",
              "      <td>1933</td>\n",
              "      <td>7_the_of_and_to</td>\n",
              "      <td>[the, of, and, to, in, for, is, equations, neu...</td>\n",
              "      <td>[modeling, dynamics, pdes, models, pde, simula...</td>\n",
              "      <td>[Partial Differential Equations and Deep Learn...</td>\n",
              "      <td>[  In typical machine learning tasks and appli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>1815</td>\n",
              "      <td>8_graph_node_graphs_the</td>\n",
              "      <td>[graph, node, graphs, the, nodes, gnns, of, an...</td>\n",
              "      <td>[graphs, graph, embeddings, networks, embeddin...</td>\n",
              "      <td>[\"Graph Representation Learning\", , , , , , , ...</td>\n",
              "      <td>[  Graph Neural Networks (GNNs) are an effecti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>9</td>\n",
              "      <td>1773</td>\n",
              "      <td>9_matrix_the_of_rank</td>\n",
              "      <td>[matrix, the, of, rank, is, we, in, and, for, ...</td>\n",
              "      <td>[regularization, factorization, matrices, spar...</td>\n",
              "      <td>[\"Low Rank Matrix Factorization, Kernel Ridge ...</td>\n",
              "      <td>[  One approach to improving the running time ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>10</td>\n",
              "      <td>1734</td>\n",
              "      <td>10_regret_bandit_the_algorithm</td>\n",
              "      <td>[regret, bandit, the, algorithm, we, of, arm, ...</td>\n",
              "      <td>[bandits, stochastic, optimization, optimal, a...</td>\n",
              "      <td>[Regret Bound for Bandit Algorithms, , , , , ,...</td>\n",
              "      <td>[  The stochastic multi-armed bandit problem i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>11</td>\n",
              "      <td>1666</td>\n",
              "      <td>11_networks_neural_the_of</td>\n",
              "      <td>[networks, neural, the, of, we, network, deep,...</td>\n",
              "      <td>[dnns, regularization, neural, generalization,...</td>\n",
              "      <td>[Neural Networks - Generalization - Theory - L...</td>\n",
              "      <td>[  Multi-layer feedforward networks have been ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>12</td>\n",
              "      <td>1400</td>\n",
              "      <td>12_traffic_driving_the_and</td>\n",
              "      <td>[traffic, driving, the, and, to, of, in, vehic...</td>\n",
              "      <td>[traffic, networks, trajectories, network, for...</td>\n",
              "      <td>[Intelligent Traffic Prediction Algorithms, , ...</td>\n",
              "      <td>[  Transportation networks are highly complex ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>13</td>\n",
              "      <td>1379</td>\n",
              "      <td>13_user_recommendation_item_recommender</td>\n",
              "      <td>[user, recommendation, item, recommender, the,...</td>\n",
              "      <td>[recommender, embedding, embeddings, recommend...</td>\n",
              "      <td>[Recommendation Systems for Users and Items., ...</td>\n",
              "      <td>[  In recommender systems, cold-start issues a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>14</td>\n",
              "      <td>1323</td>\n",
              "      <td>14_molecular_protein_of_molecules</td>\n",
              "      <td>[molecular, protein, of, molecules, drug, the,...</td>\n",
              "      <td>[molecular, computational, molecules, molecule...</td>\n",
              "      <td>[\"Molecular Property Prediction\", , , , , , , ...</td>\n",
              "      <td>[Accurate and efficient prediction of the mole...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>15</td>\n",
              "      <td>1314</td>\n",
              "      <td>15_gradient_stochastic_convergence_convex</td>\n",
              "      <td>[gradient, stochastic, convergence, convex, sg...</td>\n",
              "      <td>[minimization, stochastic, optimization, gradi...</td>\n",
              "      <td>[Stochastic Optimization Algorithms\\n\\nQ:\\nWha...</td>\n",
              "      <td>[  We consider stochastic optimization of a sm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>16</td>\n",
              "      <td>1259</td>\n",
              "      <td>16_channel_the_to_wireless</td>\n",
              "      <td>[channel, the, to, wireless, and, of, in, netw...</td>\n",
              "      <td>[networks, beamforming, mimo, network, wireles...</td>\n",
              "      <td>[Channel Allocation Algorithms for IoT and Wir...</td>\n",
              "      <td>[  5G beyond is an end-edge-cloud orchestrated...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>17</td>\n",
              "      <td>1043</td>\n",
              "      <td>17_and_hardware_the_pruning</td>\n",
              "      <td>[and, hardware, the, pruning, to, of, neural, ...</td>\n",
              "      <td>[cnns, convolutional, dnns, dnn, computational...</td>\n",
              "      <td>[Neural network pruning and hardware optimizat...</td>\n",
              "      <td>[  With the emergence of a spectrum of high-en...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>18</td>\n",
              "      <td>962</td>\n",
              "      <td>18_domain_target_source_adaptation</td>\n",
              "      <td>[domain, target, source, adaptation, the, lear...</td>\n",
              "      <td>[unsupervised, supervised, domain, learning, m...</td>\n",
              "      <td>[Domain Adaptation in Machine Learning, , , , ...</td>\n",
              "      <td>[  Most visual recognition methods implicitly ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>19</td>\n",
              "      <td>749</td>\n",
              "      <td>19_explanations_explanation_of_to</td>\n",
              "      <td>[explanations, explanation, of, to, the, and, ...</td>\n",
              "      <td>[predictive, explainability, interpretability,...</td>\n",
              "      <td>[Explanation Methods for Black Box Models, , ,...</td>\n",
              "      <td>[  Systems based on artificial intelligence an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>20</td>\n",
              "      <td>747</td>\n",
              "      <td>20_power_energy_the_and</td>\n",
              "      <td>[power, energy, the, and, of, to, electricity,...</td>\n",
              "      <td>[forecasting, prediction, models, renewable, n...</td>\n",
              "      <td>[Smart Grids and Electricity Load Forecasting,...</td>\n",
              "      <td>[  Demand forecasting in power sector has beco...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>21</td>\n",
              "      <td>743</td>\n",
              "      <td>21_quantum_classical_the_of</td>\n",
              "      <td>[quantum, classical, the, of, to, in, we, for,...</td>\n",
              "      <td>[quantum, qubits, hamiltonian, entanglement, q...</td>\n",
              "      <td>[Quantum Machine Learning\\nB:\\nClassical Surro...</td>\n",
              "      <td>[  While quantum architectures are still under...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>22</td>\n",
              "      <td>737</td>\n",
              "      <td>22_continual_forgetting_learning_memory</td>\n",
              "      <td>[continual, forgetting, learning, memory, cata...</td>\n",
              "      <td>[forgetting, learning, incremental, memory, co...</td>\n",
              "      <td>[Continual Learning with Memory\\n\\n### Instruc...</td>\n",
              "      <td>[  Continual/lifelong learning from a non-stat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>23</td>\n",
              "      <td>682</td>\n",
              "      <td>23_the_classification_of_and</td>\n",
              "      <td>[the, classification, of, and, to, is, tree, i...</td>\n",
              "      <td>[classifiers, classifier, prediction, regressi...</td>\n",
              "      <td>[Machine Learning Classifiers, , , , , , , , , ]</td>\n",
              "      <td>[  For many applications, an ensemble of base ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>24</td>\n",
              "      <td>681</td>\n",
              "      <td>24_covid_19_the_and</td>\n",
              "      <td>[covid, 19, the, and, of, pandemic, to, in, fo...</td>\n",
              "      <td>[cov, coronavirus, covid, epidemic, dataset, a...</td>\n",
              "      <td>[\"Covid-19 Diagnosis using CT Images\", , , , ,...</td>\n",
              "      <td>[  Computer-aided diagnosis has become a neces...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>25</td>\n",
              "      <td>665</td>\n",
              "      <td>25_inference_variational_gaussian_posterior</td>\n",
              "      <td>[inference, variational, gaussian, posterior, ...</td>\n",
              "      <td>[bayesian, stochastic, approximations, regress...</td>\n",
              "      <td>[Approximate Bayesian Inference\\nThe above res...</td>\n",
              "      <td>[  We address the problem of continual learnin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>26</td>\n",
              "      <td>639</td>\n",
              "      <td>26_fairness_fair_of_to</td>\n",
              "      <td>[fairness, fair, of, to, in, the, and, that, w...</td>\n",
              "      <td>[fairness, biases, unfairness, bias, accuracy,...</td>\n",
              "      <td>[Fairness in Machine Learning, , , , , , , , , ]</td>\n",
              "      <td>[  Accuracy and fairness are both crucial aspe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>27</td>\n",
              "      <td>622</td>\n",
              "      <td>27_stock_financial_market_the</td>\n",
              "      <td>[stock, financial, market, the, of, and, tradi...</td>\n",
              "      <td>[volatility, predicting, investors, lstm, pred...</td>\n",
              "      <td>[Stock Market Prediction with Deep Learning, ,...</td>\n",
              "      <td>[  Financial markets have a vital role in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>28</td>\n",
              "      <td>599</td>\n",
              "      <td>28_series_time_forecasting_the</td>\n",
              "      <td>[series, time, forecasting, the, of, and, to, ...</td>\n",
              "      <td>[forecasting, prediction, forecasts, multivari...</td>\n",
              "      <td>[Time Series Forecasting Algorithms, , , , , ,...</td>\n",
              "      <td>[  A highly comparative, feature-based approac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>29</td>\n",
              "      <td>557</td>\n",
              "      <td>29_clustering_means_clusters_the</td>\n",
              "      <td>[clustering, means, clusters, the, cluster, of...</td>\n",
              "      <td>[clusterings, clustering, clusters, cluster, a...</td>\n",
              "      <td>[Clustering Algorithms and Techniques, , , , ,...</td>\n",
              "      <td>[  Clustering is an important part of many mod...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>30</td>\n",
              "      <td>525</td>\n",
              "      <td>30_causal_the_of_variables</td>\n",
              "      <td>[causal, the, of, variables, we, and, observat...</td>\n",
              "      <td>[causality, confounders, causal, covariates, b...</td>\n",
              "      <td>[Causal Learning Algorithms\\nThe Brief:\\nThis ...</td>\n",
              "      <td>[  We extend the definition of the marginal ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>31</td>\n",
              "      <td>406</td>\n",
              "      <td>31_code_software_program_of</td>\n",
              "      <td>[code, software, program, of, source, to, the,...</td>\n",
              "      <td>[programming, snippets, prediction, language, ...</td>\n",
              "      <td>[Code Generation and Transformation with Deep ...</td>\n",
              "      <td>[Pre-trained Generative Language models (e.g. ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Topic  Count                                         Name  \\\n",
              "0      -1  60273                             -1_the_of_and_to   \n",
              "1       0   7177          0_policy_learning_the_reinforcement   \n",
              "2       1   6448                              1_the_and_of_to   \n",
              "3       2   6040                        2_language_the_and_of   \n",
              "4       3   3496                              3_the_to_and_of   \n",
              "5       4   2812                   4_speech_audio_the_speaker   \n",
              "6       5   2809                  5_privacy_federated_fl_data   \n",
              "7       6   2584      6_adversarial_attacks_attack_robustness   \n",
              "8       7   1933                              7_the_of_and_to   \n",
              "9       8   1815                      8_graph_node_graphs_the   \n",
              "10      9   1773                         9_matrix_the_of_rank   \n",
              "11     10   1734               10_regret_bandit_the_algorithm   \n",
              "12     11   1666                    11_networks_neural_the_of   \n",
              "13     12   1400                   12_traffic_driving_the_and   \n",
              "14     13   1379      13_user_recommendation_item_recommender   \n",
              "15     14   1323            14_molecular_protein_of_molecules   \n",
              "16     15   1314    15_gradient_stochastic_convergence_convex   \n",
              "17     16   1259                   16_channel_the_to_wireless   \n",
              "18     17   1043                  17_and_hardware_the_pruning   \n",
              "19     18    962           18_domain_target_source_adaptation   \n",
              "20     19    749            19_explanations_explanation_of_to   \n",
              "21     20    747                      20_power_energy_the_and   \n",
              "22     21    743                  21_quantum_classical_the_of   \n",
              "23     22    737      22_continual_forgetting_learning_memory   \n",
              "24     23    682                 23_the_classification_of_and   \n",
              "25     24    681                          24_covid_19_the_and   \n",
              "26     25    665  25_inference_variational_gaussian_posterior   \n",
              "27     26    639                       26_fairness_fair_of_to   \n",
              "28     27    622                27_stock_financial_market_the   \n",
              "29     28    599               28_series_time_forecasting_the   \n",
              "30     29    557             29_clustering_means_clusters_the   \n",
              "31     30    525                   30_causal_the_of_variables   \n",
              "32     31    406                  31_code_software_program_of   \n",
              "\n",
              "                                       Representation  \\\n",
              "0       [the, of, and, to, in, we, is, for, that, on]   \n",
              "1   [policy, learning, the, reinforcement, to, in,...   \n",
              "2     [the, and, of, to, in, for, data, is, we, with]   \n",
              "3   [language, the, and, of, to, in, we, text, on,...   \n",
              "4   [the, to, and, of, we, generative, image, in, ...   \n",
              "5   [speech, audio, the, speaker, to, of, and, in,...   \n",
              "6   [privacy, federated, fl, data, the, learning, ...   \n",
              "7   [adversarial, attacks, attack, robustness, the...   \n",
              "8   [the, of, and, to, in, for, is, equations, neu...   \n",
              "9   [graph, node, graphs, the, nodes, gnns, of, an...   \n",
              "10  [matrix, the, of, rank, is, we, in, and, for, ...   \n",
              "11  [regret, bandit, the, algorithm, we, of, arm, ...   \n",
              "12  [networks, neural, the, of, we, network, deep,...   \n",
              "13  [traffic, driving, the, and, to, of, in, vehic...   \n",
              "14  [user, recommendation, item, recommender, the,...   \n",
              "15  [molecular, protein, of, molecules, drug, the,...   \n",
              "16  [gradient, stochastic, convergence, convex, sg...   \n",
              "17  [channel, the, to, wireless, and, of, in, netw...   \n",
              "18  [and, hardware, the, pruning, to, of, neural, ...   \n",
              "19  [domain, target, source, adaptation, the, lear...   \n",
              "20  [explanations, explanation, of, to, the, and, ...   \n",
              "21  [power, energy, the, and, of, to, electricity,...   \n",
              "22  [quantum, classical, the, of, to, in, we, for,...   \n",
              "23  [continual, forgetting, learning, memory, cata...   \n",
              "24  [the, classification, of, and, to, is, tree, i...   \n",
              "25  [covid, 19, the, and, of, pandemic, to, in, fo...   \n",
              "26  [inference, variational, gaussian, posterior, ...   \n",
              "27  [fairness, fair, of, to, in, the, and, that, w...   \n",
              "28  [stock, financial, market, the, of, and, tradi...   \n",
              "29  [series, time, forecasting, the, of, and, to, ...   \n",
              "30  [clustering, means, clusters, the, cluster, of...   \n",
              "31  [causal, the, of, variables, we, and, observat...   \n",
              "32  [code, software, program, of, source, to, the,...   \n",
              "\n",
              "                                              KeyBERT  \\\n",
              "0   [datasets, models, model, algorithms, learning...   \n",
              "1   [learning, reinforcement, dynamics, robot, mod...   \n",
              "2   [convolutional, mri, imaging, trained, predict...   \n",
              "3   [embeddings, nlp, language, representations, s...   \n",
              "4   [gans, adversarial, gan, generative, models, m...   \n",
              "5   [speech, voice, language, models, neural, mode...   \n",
              "6   [federated, distributed, datasets, model, mode...   \n",
              "7   [adversarial, dnns, attacks, models, model, at...   \n",
              "8   [modeling, dynamics, pdes, models, pde, simula...   \n",
              "9   [graphs, graph, embeddings, networks, embeddin...   \n",
              "10  [regularization, factorization, matrices, spar...   \n",
              "11  [bandits, stochastic, optimization, optimal, a...   \n",
              "12  [dnns, regularization, neural, generalization,...   \n",
              "13  [traffic, networks, trajectories, network, for...   \n",
              "14  [recommender, embedding, embeddings, recommend...   \n",
              "15  [molecular, computational, molecules, molecule...   \n",
              "16  [minimization, stochastic, optimization, gradi...   \n",
              "17  [networks, beamforming, mimo, network, wireles...   \n",
              "18  [cnns, convolutional, dnns, dnn, computational...   \n",
              "19  [unsupervised, supervised, domain, learning, m...   \n",
              "20  [predictive, explainability, interpretability,...   \n",
              "21  [forecasting, prediction, models, renewable, n...   \n",
              "22  [quantum, qubits, hamiltonian, entanglement, q...   \n",
              "23  [forgetting, learning, incremental, memory, co...   \n",
              "24  [classifiers, classifier, prediction, regressi...   \n",
              "25  [cov, coronavirus, covid, epidemic, dataset, a...   \n",
              "26  [bayesian, stochastic, approximations, regress...   \n",
              "27  [fairness, biases, unfairness, bias, accuracy,...   \n",
              "28  [volatility, predicting, investors, lstm, pred...   \n",
              "29  [forecasting, prediction, forecasts, multivari...   \n",
              "30  [clusterings, clustering, clusters, cluster, a...   \n",
              "31  [causality, confounders, causal, covariates, b...   \n",
              "32  [programming, snippets, prediction, language, ...   \n",
              "\n",
              "                                                  LLM  \\\n",
              "0   [Machine Learning Representation and Algorithm...   \n",
              "1   [Reinforcement Learning Policies and Imitation...   \n",
              "2   [Deep Learning in Medical Image Analysis, , , ...   \n",
              "3   [Language Modeling with Transfer Learning, , ,...   \n",
              "4   [Generative Adversarial Networks, , , , , , , ...   \n",
              "5   [Speech Separation and Enhancement\\n\\nQ:\\nWhic...   \n",
              "6   [Federated Learning Privacy\\nB:\\nFederated Lea...   \n",
              "7   [Adversarial Attacks and Robustness in Deep Ne...   \n",
              "8   [Partial Differential Equations and Deep Learn...   \n",
              "9   [\"Graph Representation Learning\", , , , , , , ...   \n",
              "10  [\"Low Rank Matrix Factorization, Kernel Ridge ...   \n",
              "11  [Regret Bound for Bandit Algorithms, , , , , ,...   \n",
              "12  [Neural Networks - Generalization - Theory - L...   \n",
              "13  [Intelligent Traffic Prediction Algorithms, , ...   \n",
              "14  [Recommendation Systems for Users and Items., ...   \n",
              "15  [\"Molecular Property Prediction\", , , , , , , ...   \n",
              "16  [Stochastic Optimization Algorithms\\n\\nQ:\\nWha...   \n",
              "17  [Channel Allocation Algorithms for IoT and Wir...   \n",
              "18  [Neural network pruning and hardware optimizat...   \n",
              "19  [Domain Adaptation in Machine Learning, , , , ...   \n",
              "20  [Explanation Methods for Black Box Models, , ,...   \n",
              "21  [Smart Grids and Electricity Load Forecasting,...   \n",
              "22  [Quantum Machine Learning\\nB:\\nClassical Surro...   \n",
              "23  [Continual Learning with Memory\\n\\n### Instruc...   \n",
              "24   [Machine Learning Classifiers, , , , , , , , , ]   \n",
              "25  [\"Covid-19 Diagnosis using CT Images\", , , , ,...   \n",
              "26  [Approximate Bayesian Inference\\nThe above res...   \n",
              "27   [Fairness in Machine Learning, , , , , , , , , ]   \n",
              "28  [Stock Market Prediction with Deep Learning, ,...   \n",
              "29  [Time Series Forecasting Algorithms, , , , , ,...   \n",
              "30  [Clustering Algorithms and Techniques, , , , ,...   \n",
              "31  [Causal Learning Algorithms\\nThe Brief:\\nThis ...   \n",
              "32  [Code Generation and Transformation with Deep ...   \n",
              "\n",
              "                                  Representative_Docs  \n",
              "0   [  Gaussian Mixture Models are one of the most...  \n",
              "1   [  Applying reinforcement learning (RL) method...  \n",
              "2   [  Deep learning methods are successfully used...  \n",
              "3   [  Pretrained contextualized text representati...  \n",
              "4   [  Generative adversarial networks (GANs) have...  \n",
              "5   [  Deep learning models are becoming predomina...  \n",
              "6   [Federated learning allows many devices to col...  \n",
              "7   [  Recent studies on the adversarial vulnerabi...  \n",
              "8   [  In typical machine learning tasks and appli...  \n",
              "9   [  Graph Neural Networks (GNNs) are an effecti...  \n",
              "10  [  One approach to improving the running time ...  \n",
              "11  [  The stochastic multi-armed bandit problem i...  \n",
              "12  [  Multi-layer feedforward networks have been ...  \n",
              "13  [  Transportation networks are highly complex ...  \n",
              "14  [  In recommender systems, cold-start issues a...  \n",
              "15  [Accurate and efficient prediction of the mole...  \n",
              "16  [  We consider stochastic optimization of a sm...  \n",
              "17  [  5G beyond is an end-edge-cloud orchestrated...  \n",
              "18  [  With the emergence of a spectrum of high-en...  \n",
              "19  [  Most visual recognition methods implicitly ...  \n",
              "20  [  Systems based on artificial intelligence an...  \n",
              "21  [  Demand forecasting in power sector has beco...  \n",
              "22  [  While quantum architectures are still under...  \n",
              "23  [  Continual/lifelong learning from a non-stat...  \n",
              "24  [  For many applications, an ensemble of base ...  \n",
              "25  [  Computer-aided diagnosis has become a neces...  \n",
              "26  [  We address the problem of continual learnin...  \n",
              "27  [  Accuracy and fairness are both crucial aspe...  \n",
              "28  [  Financial markets have a vital role in the ...  \n",
              "29  [  A highly comparative, feature-based approac...  \n",
              "30  [  Clustering is an important part of many mod...  \n",
              "31  [  We extend the definition of the marginal ca...  \n",
              "32  [Pre-trained Generative Language models (e.g. ...  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Show topics\n",
        "topic_model.get_topic_info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCgBCfxv-CFD"
      },
      "source": [
        "# ðŸ“Š Visualization with DataMapPlot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2Vk-52o1WpwR"
      },
      "outputs": [],
      "source": [
        "import PIL\n",
        "import numpy as np\n",
        "import requests\n",
        "\n",
        "# Prepare logo\n",
        "bertopic_logo_response = requests.get(\n",
        "    \"https://raw.githubusercontent.com/MaartenGr/BERTopic/master/images/logo.png\",\n",
        "    stream=True,\n",
        "    headers={'User-Agent': 'My User Agent 1.0'}\n",
        ")\n",
        "bertopic_logo = np.asarray(PIL.Image.open(bertopic_logo_response.raw))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg9rglMro2sZ"
      },
      "source": [
        "We can use the labels created by the LLM and assign them to topics that we have created:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 878
        },
        "id": "Ctg7wEpu9urL",
        "outputId": "fa303c24-0fb7-45ad-e225-05df8de7ee88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<Figure size 1200x1200 with 1 Axes>,\n",
              " <Axes: title={'left': 'Topics labeled with `openhermes-2.5-mistral-7b`'}>)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x1200 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import datamapplot\n",
        "import re\n",
        "\n",
        "# Create a label for each document\n",
        "llm_labels = [re.sub(r'\\W+', ' ', label[0][0].split(\"\\n\")[0].replace('\"', '')) for label in topic_model.get_topics(full=True)[\"LLM\"].values()]\n",
        "llm_labels = [label if label else \"Unlabelled\" for label in llm_labels]\n",
        "all_labels = [llm_labels[topic+topic_model._outliers] if topic != -1 else \"Unlabelled\" for topic in topics]\n",
        "\n",
        "# Run the visualization\n",
        "datamapplot.create_plot(\n",
        "    reduced_embeddings,\n",
        "    all_labels,\n",
        "    label_font_size=11,\n",
        "    title=\"ArXiv - BERTopic\",\n",
        "    sub_title=\"Topics labeled with `openhermes-2.5-mistral-7b`\",\n",
        "    label_wrap_width=20,\n",
        "    use_medoids=True,\n",
        "    logo=bertopic_logo,\n",
        "    logo_width=0.16\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "003f1df5815f4907a0ece85edad574ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0261126af0bf47d490b40ebc8f8f73c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28e9406ec1404eb0bfb3ebba01c5e04f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_80495805c2a448a6a4405d2f223dc95b",
            "value": " 232k/232k [00:00&lt;00:00, 4.91MB/s]"
          }
        },
        "0656dc8d4d4f4b2987e41da798c1cc2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d1c63a7a7574ff08330faf410b38a9b",
              "IPY_MODEL_64371ae184bc42d89017e9d426ce71da",
              "IPY_MODEL_c8cb15a80ab5442b9725bcd3d4df3cca"
            ],
            "layout": "IPY_MODEL_274e55c30b554a7c8a0d3b140c6e164e"
          }
        },
        "0c3b3798b81e4518b37a193c8a2cf8e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0da7331c8f0f446fb916f148beab9877": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e5dd6cd23634bebace06350f7261dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_767239d6be1f4e61812154e9307f8cd4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_929629791d604f08afdee6b7c812c4e6",
            "value": " 986/986 [00:00&lt;00:00, 14.3kB/s]"
          }
        },
        "13d0f64fbd2242df842b5ee24e62c713": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1537d3486fcf4ec683be254e3f9af7f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90ea70019c8842079d7ff919f3af843a",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1eca1748c8c4055a43d97492d078879",
            "value": 349
          }
        },
        "1786b6f50554429e9a05e4afd159eec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef67fa67939e4101bd14109bc86012ee",
              "IPY_MODEL_4f9cd48c6a544edfb76db48c38475a95",
              "IPY_MODEL_a13cfeb6c4cf4a6db46f70615fcbfdbb"
            ],
            "layout": "IPY_MODEL_1c9f9da220244c2bb5cb3b8ea26fefd1"
          }
        },
        "1b0acf777e1e40d99b5c33e0f8e543a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_484449cc5f214722bee84bdaf3e0bb62",
              "IPY_MODEL_da644207a0fe482fa7e7801d146743b9",
              "IPY_MODEL_27816c1794c04a31b850cab640690984"
            ],
            "layout": "IPY_MODEL_da11831b9b64409ebb221c5696d4df00"
          }
        },
        "1c9f9da220244c2bb5cb3b8ea26fefd1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f27a38fceaf435aa129c9105088cad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50a57b619b2a48c4a8eb5305e92edacf",
              "IPY_MODEL_a2886173497d446d8c33718541dd2f86",
              "IPY_MODEL_d51117191e3f464d908bdaf9af40d416"
            ],
            "layout": "IPY_MODEL_ef3c40dc8acf4c7f998af622ee487f32"
          }
        },
        "1ff5a36868a04ee1a2a70520e4004cce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25a509713da94079a3d732b3640b45f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2747796f87d348afa909fe11e7a0672d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "274e55c30b554a7c8a0d3b140c6e164e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27816c1794c04a31b850cab640690984": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99f5f91417b347679eab2084dc3a173c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6f071c1778514eb19cfd7e1c591bad3b",
            "value": " 133M/133M [00:00&lt;00:00, 180MB/s]"
          }
        },
        "28e9406ec1404eb0bfb3ebba01c5e04f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2911473810814cf2a701fb7c664535d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c068a62e89514493b6892902b07588ca",
              "IPY_MODEL_8ed574479d084302903a187f742d37dd",
              "IPY_MODEL_57ff32efde8b46b4b8446f9f8ad3124c"
            ],
            "layout": "IPY_MODEL_3ab6e3c02835479c952c1ff94cf2d11d"
          }
        },
        "29dfb020240b4e2082ebd415e9bebae1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2baa14a4ade84861a04c2cb39626a3f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf29105419e14ab6bb3812c67091db3a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a4229c528f004d89af576a9eb55a4af0",
            "value": " 52.0/52.0 [00:00&lt;00:00, 2.28kB/s]"
          }
        },
        "2caedd07b84a4c2e83948e7d36ffce13": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2def6630a8c64e768e38c0cecf7b4a19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca959e8e38e14764bc1e046ce1b241c1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9c64ba4c52d24c42ac2a1cc3e3e0a77f",
            "value": "modules.json: 100%"
          }
        },
        "31eafc989e3f4355afd8cc39c2a308d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7cddcdb41f8c48d48d9688118a3df1f4",
              "IPY_MODEL_77dc6643ecec446a85b1c10527cc97ed",
              "IPY_MODEL_373af9df368b47a9ab45b05702c23377"
            ],
            "layout": "IPY_MODEL_daf244afa867435ea9c46964d7730c21"
          }
        },
        "32a918340856453489397cd396aa74ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "32b3e320c6394311ba48773db9e9b22b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ecba0505794e4312a8c6eddfd6563058",
              "IPY_MODEL_d44050c3f35842a58b6158aec48b20e1",
              "IPY_MODEL_668d08eef527446ca16ab8e7c41c788b"
            ],
            "layout": "IPY_MODEL_c5fc9a8da64b48c8ad1e1cccbc00b7a7"
          }
        },
        "32c56102732245f7b1c0980e2b32343d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35b4e41692ea44e08648722c0ffeb5ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "373af9df368b47a9ab45b05702c23377": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38e695c7b2c04dff86521c2ae0bfa7cd",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8c348e604699440385a58eedb6320b37",
            "value": " 711k/711k [00:00&lt;00:00, 27.0MB/s]"
          }
        },
        "38497928129048929cf8a4a6fa040f75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38e695c7b2c04dff86521c2ae0bfa7cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39534b0ad5154390959f44ea29dfbe0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ab6e3c02835479c952c1ff94cf2d11d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b609a78031542ec9ad23639bea6fbd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b8bc05023784477ac20e075c1511783": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d375f52b5d84b38825d11bafafcfc9f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dc13a513ab54716ac6652de82c2c6e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d28ee359eca1443ba2e8843a5cc87634",
            "max": 90797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e000ee95b1941d4b85556cc55a7cb7a",
            "value": 90797
          }
        },
        "43796a96b6bc4fa49f793cf10e9753ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51f7538f4fc54c04bf5cf54c0d1db01c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ee0283e32ca45b0aed5ae1baf48cea6",
            "value": 1
          }
        },
        "4537ca1a93ff459ea91a1971febc3240": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47995cace7734f1db0013b2d52b5a33b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "484449cc5f214722bee84bdaf3e0bb62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a581cb88aa744e959667dea384a4d67d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_dd3775f1c6da4690b6d4bb0d4c05faa3",
            "value": "model.safetensors: 100%"
          }
        },
        "4872a46c8ada479ca62ee8a362135399": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4902c16cf7fc41258572e9e77da6e785": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49d7ea3e683c4c1d9bbdec9a0a50def2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdb633688620485e833e894b0690b624",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ef40bb8746e24b0bba4c9b86f0e71366",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "4bda87d74e3c4144965a8378f6ecd55d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5a14432201a4555aeafcab05cde85da",
              "IPY_MODEL_ce8273bae8f44c09aaa6d20ed9733320",
              "IPY_MODEL_0e5dd6cd23634bebace06350f7261dd9"
            ],
            "layout": "IPY_MODEL_4bdd30f0b2064c09a75be73e9f3693f9"
          }
        },
        "4bdd30f0b2064c09a75be73e9f3693f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e075b9251ba4851993ffa2134cfda30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b105bd9d8489494bb2fcfd6dc12e9940",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e420443a8f094a088158c922a067ab92",
            "value": 125
          }
        },
        "4ee0283e32ca45b0aed5ae1baf48cea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f9cd48c6a544edfb76db48c38475a95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a8c442cba3442afaf74dd9e1a867cc9",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b91f4bc6b624f5ab927e1938b2b2e1b",
            "value": 124
          }
        },
        "504f359e12bc4d7abec3432b613b2b57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_896ed32e621449ff8a0bb9ef65fe241f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e7b6b060966b468ca3bda23b744590c5",
            "value": " 366/366 [00:00&lt;00:00, 21.2kB/s]"
          }
        },
        "50a57b619b2a48c4a8eb5305e92edacf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_513b6ef2d1f24fb09b35da7508cf677b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_926f81d57f8c44728f7ab2ce23045a1e",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "513b6ef2d1f24fb09b35da7508cf677b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51b13d2bc9f14949bdae2d926ae94a68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_565feae099e74cbb9f702a5836e672f6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c4d1958113544a5cb5eb8beb3384f0c3",
            "value": "Generating train split: "
          }
        },
        "51f7538f4fc54c04bf5cf54c0d1db01c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "53527a64fdba4ee0a322b32867f473b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53ddd2c0ee5844dc96961c63f7cf357a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53f7e33194f04fab8b16f175c8446cfd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "549cfd8542c947efac340054c6fecdad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "565feae099e74cbb9f702a5836e672f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56b77e38f86a4a81a1e091d8426aeebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57ff32efde8b46b4b8446f9f8ad3124c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c536190d16a94bee9040b3e30e0e7a42",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bf432b718c9e45c1aec79c343a2a961b",
            "value": " 190/190 [00:00&lt;00:00, 10.9kB/s]"
          }
        },
        "59edec96719244ee8844c4c00b586665": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5aa1c93e38f84e1682e0da8916f23570": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b8bc05023784477ac20e075c1511783",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c19f084191a349a48daa49580cbf9a22",
            "value": " 90.8k/90.8k [00:00&lt;00:00, 3.04MB/s]"
          }
        },
        "5e097d4a966a41d497cc7998197a3a1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f81bfbdf539477095bf1d9cd1fb44e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64371ae184bc42d89017e9d426ce71da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2caedd07b84a4c2e83948e7d36ffce13",
            "max": 146951408,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8de0aa4ddfa240e1b55dcb966f02651b",
            "value": 146951408
          }
        },
        "668d08eef527446ca16ab8e7c41c788b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfc7002e8ad0487ca27a002c906f0a91",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_86a3358c8192420cb03bf26f5aa82a55",
            "value": " 1.52k/1.52k [00:00&lt;00:00, 105kB/s]"
          }
        },
        "66d7fcd2e1c147fdafff192c2379d192": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67e7fa0df2d34f78b6545ff9fdcd5eb6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a760553da3a4cf4af57314f70ecca12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_750c0b4ead7b4a4b87f21ea1af774912",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_13d0f64fbd2242df842b5ee24e62c713",
            "value": " 684/684 [00:00&lt;00:00, 38.9kB/s]"
          }
        },
        "6d1c63a7a7574ff08330faf410b38a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d375f52b5d84b38825d11bafafcfc9f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bfd2099a75744919bbabc28db878ecb1",
            "value": "Downloading data: 100%"
          }
        },
        "6f071c1778514eb19cfd7e1c591bad3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74fc148c1fa3428382acbcd43b747472": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "750c0b4ead7b4a4b87f21ea1af774912": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "767239d6be1f4e61812154e9307f8cd4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7747d146a0e44cf69b2c97c4e0a7a6e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77dc6643ecec446a85b1c10527cc97ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b71af597c449404b81f871ed31bf853d",
            "max": 711396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66d7fcd2e1c147fdafff192c2379d192",
            "value": 711396
          }
        },
        "7a8c442cba3442afaf74dd9e1a867cc9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cddcdb41f8c48d48d9688118a3df1f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53f7e33194f04fab8b16f175c8446cfd",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_549cfd8542c947efac340054c6fecdad",
            "value": "tokenizer.json: 100%"
          }
        },
        "7e000ee95b1941d4b85556cc55a7cb7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7eaf5817d3d844cc83f0d22249877c2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e81c7b65f15646db923f2b757663a390",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bc772c27481e4e3fadd74a76008a718f",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "80495805c2a448a6a4405d2f223dc95b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "856d9c2c3ea7412fbf3ff6c846d853c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86844c08bc1c4286a43167a9a50d95ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4902c16cf7fc41258572e9e77da6e785",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e7bd4ae907124c638850fd340c95c9ab",
            "value": " 117592/0 [00:02&lt;00:00, 45493.31 examples/s]"
          }
        },
        "86a3358c8192420cb03bf26f5aa82a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "896ed32e621449ff8a0bb9ef65fe241f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89c5eff824b44a67ba29f8a51b6519d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2def6630a8c64e768e38c0cecf7b4a19",
              "IPY_MODEL_1537d3486fcf4ec683be254e3f9af7f2",
              "IPY_MODEL_9670404c09bc4781aa10fd4e2d06ad2e"
            ],
            "layout": "IPY_MODEL_67e7fa0df2d34f78b6545ff9fdcd5eb6"
          }
        },
        "8a7ee59f41a548808479b4482282d803": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f85952f39f6247f2b308477082723642",
              "IPY_MODEL_97bdf1b1b19147d1932a8057d5f81dd2",
              "IPY_MODEL_6a760553da3a4cf4af57314f70ecca12"
            ],
            "layout": "IPY_MODEL_47995cace7734f1db0013b2d52b5a33b"
          }
        },
        "8bfb23759e14494bb4ab56b92e8c1611": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51b13d2bc9f14949bdae2d926ae94a68",
              "IPY_MODEL_43796a96b6bc4fa49f793cf10e9753ac",
              "IPY_MODEL_86844c08bc1c4286a43167a9a50d95ff"
            ],
            "layout": "IPY_MODEL_2747796f87d348afa909fe11e7a0672d"
          }
        },
        "8c348e604699440385a58eedb6320b37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8de0aa4ddfa240e1b55dcb966f02651b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ed574479d084302903a187f742d37dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf1d7fd7cd774a7082bd131c385771f0",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_909aefbb4913407cbfcca69367bf12c9",
            "value": 190
          }
        },
        "909aefbb4913407cbfcca69367bf12c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90ea70019c8842079d7ff919f3af843a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "926f81d57f8c44728f7ab2ce23045a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "929629791d604f08afdee6b7c812c4e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93442b807f2d406eb9e8253318176a8c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9446d53d57724a4caf06e344ea21df78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59edec96719244ee8844c4c00b586665",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_56b77e38f86a4a81a1e091d8426aeebf",
            "value": " 3675/3675 [06:02&lt;00:00, 29.62it/s]"
          }
        },
        "95aeff88d4454d6997ded27932add286": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9670404c09bc4781aa10fd4e2d06ad2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4b6c986d05c4957885e39f1f93a6355",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b113de801dc24911bec0f2c09ef0540c",
            "value": " 349/349 [00:00&lt;00:00, 20.3kB/s]"
          }
        },
        "97bdf1b1b19147d1932a8057d5f81dd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3278f12f0da4a73bd3589ff9908ba45",
            "max": 684,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7747d146a0e44cf69b2c97c4e0a7a6e2",
            "value": 684
          }
        },
        "990f4fea07194fd5963b040e38033198": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c3b3798b81e4518b37a193c8a2cf8e5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e1c0ac8457bd4dc6ad76a6682c9c9294",
            "value": "README.md: 100%"
          }
        },
        "99d3f153e4b04d4087112ecb5ab36cb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99f5f91417b347679eab2084dc3a173c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a0fc4fa6be34d3fb4773c6ffdef365c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b91f4bc6b624f5ab927e1938b2b2e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c64ba4c52d24c42ac2a1cc3e3e0a77f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f1a759cfa9848dfaab4a4579cd4edca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a13cfeb6c4cf4a6db46f70615fcbfdbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e097d4a966a41d497cc7998197a3a1b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c893c283bd6f4c5094498870881554ab",
            "value": " 124/124 [00:00&lt;00:00, 7.59kB/s]"
          }
        },
        "a2886173497d446d8c33718541dd2f86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29dfb020240b4e2082ebd415e9bebae1",
            "max": 133508397,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4082a051e9040c3a275b9c327255ccc",
            "value": 133508397
          }
        },
        "a4229c528f004d89af576a9eb55a4af0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a581cb88aa744e959667dea384a4d67d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a89dd48f19f74c669de84b78b9158908": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9d90d474012467b8a23c8c59ee4fba6",
              "IPY_MODEL_c2e95cca9f7c40949cc88addf207069a",
              "IPY_MODEL_9446d53d57724a4caf06e344ea21df78"
            ],
            "layout": "IPY_MODEL_0da7331c8f0f446fb916f148beab9877"
          }
        },
        "ad2f32462e0549e6bc86caf9669fef64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adaf28e7e7f44b55a39319aa1911c5af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afa8767a74a243cb8248b05bccc47d1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_856d9c2c3ea7412fbf3ff6c846d853c1",
            "max": 366,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f81bfbdf539477095bf1d9cd1fb44e0",
            "value": 366
          }
        },
        "b105bd9d8489494bb2fcfd6dc12e9940": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b113de801dc24911bec0f2c09ef0540c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4b6c986d05c4957885e39f1f93a6355": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b71af597c449404b81f871ed31bf853d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b788043339374e3caece51aee331fc8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb912639a55846f39ffad8a4b0f3c9bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbe2f12d1a81462bb8cf22be9f0b619c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49d7ea3e683c4c1d9bbdec9a0a50def2",
              "IPY_MODEL_4e075b9251ba4851993ffa2134cfda30",
              "IPY_MODEL_ce368f69663c47a9bc62f42a87a4b9a4"
            ],
            "layout": "IPY_MODEL_53ddd2c0ee5844dc96961c63f7cf357a"
          }
        },
        "bc772c27481e4e3fadd74a76008a718f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcfe91d3a22045a7add3deb099fd641a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bef1768f438044ea98e36913c123d378": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf432b718c9e45c1aec79c343a2a961b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfd2099a75744919bbabc28db878ecb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c068a62e89514493b6892902b07588ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3e0c7959c9d452a92d1f6331577ef0b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_cefba38a83524e25ba11a8afe51d7a4a",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "c19f084191a349a48daa49580cbf9a22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2e95cca9f7c40949cc88addf207069a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_003f1df5815f4907a0ece85edad574ca",
            "max": 3675,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eac4daaeefc944c1b3c90323e4953242",
            "value": 3675
          }
        },
        "c4d1958113544a5cb5eb8beb3384f0c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c536190d16a94bee9040b3e30e0e7a42": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5fc9a8da64b48c8ad1e1cccbc00b7a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c68875f2a5c9423d8ad572e930759826": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3c875bed4e04774a32f9503c63c8e66",
              "IPY_MODEL_f4ec9b1bbf89426fbc515e0d2b291d90",
              "IPY_MODEL_0261126af0bf47d490b40ebc8f8f73c5"
            ],
            "layout": "IPY_MODEL_4872a46c8ada479ca62ee8a362135399"
          }
        },
        "c893c283bd6f4c5094498870881554ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8cb15a80ab5442b9725bcd3d4df3cca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32c56102732245f7b1c0980e2b32343d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_53527a64fdba4ee0a322b32867f473b9",
            "value": " 147M/147M [00:17&lt;00:00, 7.98MB/s]"
          }
        },
        "ca5f02626ce14220af769957b8729fd6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca814d3d1d1e463696a87e6af616c725": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca959e8e38e14764bc1e046ce1b241c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccaae9ff77ce4393baca81c3235e6512": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7eaf5817d3d844cc83f0d22249877c2c",
              "IPY_MODEL_ddea2dbed8d244a08eb34fbdd51fd4ff",
              "IPY_MODEL_2baa14a4ade84861a04c2cb39626a3f8"
            ],
            "layout": "IPY_MODEL_4537ca1a93ff459ea91a1971febc3240"
          }
        },
        "cdb633688620485e833e894b0690b624": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce368f69663c47a9bc62f42a87a4b9a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca814d3d1d1e463696a87e6af616c725",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_38497928129048929cf8a4a6fa040f75",
            "value": " 125/125 [00:00&lt;00:00, 7.48kB/s]"
          }
        },
        "ce8273bae8f44c09aaa6d20ed9733320": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8ab72a750044bcb89138176f97bfb87",
            "max": 986,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32a918340856453489397cd396aa74ef",
            "value": 986
          }
        },
        "cefba38a83524e25ba11a8afe51d7a4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf1d7fd7cd774a7082bd131c385771f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf29105419e14ab6bb3812c67091db3a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d28ee359eca1443ba2e8843a5cc87634": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3c875bed4e04774a32f9503c63c8e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ff5a36868a04ee1a2a70520e4004cce",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f07049851cbd47819466c7f5b9be3db5",
            "value": "vocab.txt: 100%"
          }
        },
        "d44050c3f35842a58b6158aec48b20e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eba5cfcc6796421b906625f898c736a0",
            "max": 1519,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f1a759cfa9848dfaab4a4579cd4edca",
            "value": 1519
          }
        },
        "d51117191e3f464d908bdaf9af40d416": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef4e004652c749609ef7d4f8fb5b38d7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d5e24ec20e544f2fa2bc90355e24bc9e",
            "value": " 134M/134M [00:00&lt;00:00, 185MB/s]"
          }
        },
        "d5e24ec20e544f2fa2bc90355e24bc9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8ab72a750044bcb89138176f97bfb87": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8bf6d6dc49f403bb5c1b7a2eaf9c5ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9d90d474012467b8a23c8c59ee4fba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb912639a55846f39ffad8a4b0f3c9bc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e3e175e11dff4ffc9345fceffdaf4ad0",
            "value": "Batches: 100%"
          }
        },
        "da11831b9b64409ebb221c5696d4df00": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da644207a0fe482fa7e7801d146743b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25a509713da94079a3d732b3640b45f1",
            "max": 133466304,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b788043339374e3caece51aee331fc8e",
            "value": 133466304
          }
        },
        "daf244afa867435ea9c46964d7730c21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db6096a4006548f18a1768e1a7b56ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dcafd9390a4145b2ba60291d992e8a99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_990f4fea07194fd5963b040e38033198",
              "IPY_MODEL_3dc13a513ab54716ac6652de82c2c6e1",
              "IPY_MODEL_5aa1c93e38f84e1682e0da8916f23570"
            ],
            "layout": "IPY_MODEL_93442b807f2d406eb9e8253318176a8c"
          }
        },
        "dd3775f1c6da4690b6d4bb0d4c05faa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddea2dbed8d244a08eb34fbdd51fd4ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95aeff88d4454d6997ded27932add286",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db6096a4006548f18a1768e1a7b56ed0",
            "value": 52
          }
        },
        "dfc7002e8ad0487ca27a002c906f0a91": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1c0ac8457bd4dc6ad76a6682c9c9294": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1eca1748c8c4055a43d97492d078879": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2afa0054bc24ca1a48b214a0558c281": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcfe91d3a22045a7add3deb099fd641a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_99d3f153e4b04d4087112ecb5ab36cb2",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e3278f12f0da4a73bd3589ff9908ba45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3e0c7959c9d452a92d1f6331577ef0b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3e175e11dff4ffc9345fceffdaf4ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e420443a8f094a088158c922a067ab92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e4b9a48b2b634aac89dd82905a96fca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2afa0054bc24ca1a48b214a0558c281",
              "IPY_MODEL_afa8767a74a243cb8248b05bccc47d1c",
              "IPY_MODEL_504f359e12bc4d7abec3432b613b2b57"
            ],
            "layout": "IPY_MODEL_9a0fc4fa6be34d3fb4773c6ffdef365c"
          }
        },
        "e5a14432201a4555aeafcab05cde85da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad2f32462e0549e6bc86caf9669fef64",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3b609a78031542ec9ad23639bea6fbd8",
            "value": "Downloading readme: 100%"
          }
        },
        "e7b6b060966b468ca3bda23b744590c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7bd4ae907124c638850fd340c95c9ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e81c7b65f15646db923f2b757663a390": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eac4daaeefc944c1b3c90323e4953242": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eba5cfcc6796421b906625f898c736a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecba0505794e4312a8c6eddfd6563058": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca5f02626ce14220af769957b8729fd6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_adaf28e7e7f44b55a39319aa1911c5af",
            "value": ".gitattributes: 100%"
          }
        },
        "ef3c40dc8acf4c7f998af622ee487f32": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef40bb8746e24b0bba4c9b86f0e71366": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef4e004652c749609ef7d4f8fb5b38d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef67fa67939e4101bd14109bc86012ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35b4e41692ea44e08648722c0ffeb5ec",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_39534b0ad5154390959f44ea29dfbe0a",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "efd44195239945aaaef40fa4290105df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f07049851cbd47819466c7f5b9be3db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4082a051e9040c3a275b9c327255ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4ec9b1bbf89426fbc515e0d2b291d90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8bf6d6dc49f403bb5c1b7a2eaf9c5ae",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74fc148c1fa3428382acbcd43b747472",
            "value": 231508
          }
        },
        "f85952f39f6247f2b308477082723642": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bef1768f438044ea98e36913c123d378",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_efd44195239945aaaef40fa4290105df",
            "value": "config.json: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
