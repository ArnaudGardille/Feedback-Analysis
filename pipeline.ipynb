{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjPRVXra8lVZ"
      },
      "source": [
        "# Dependancies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKSREXZg85yy"
      },
      "source": [
        "## Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMSukVZh29HK"
      },
      "outputs": [],
      "source": [
        "#!pip install sentence_transformers langchain openai tqdm datasets asyncio scikit-learn cohere tiktoken umap altair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Md3DNHlV22Ai"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from datasets import load_dataset\n",
        "import umap\n",
        "import altair as alt\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import pprint\n",
        "from typing import List\n",
        "\n",
        "from langchain_community.llms import Ollama\n",
        "from langchain.output_parsers.regex_dict import RegexDictParser\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, ChatMessage\n",
        "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
        "from openai import AsyncOpenAI\n",
        "import asyncio\n",
        "import os\n",
        "\n",
        "import requests\n",
        "import json\n",
        "from bubble_api import Field as BubbleField\n",
        "from bubble_api import BubbleClient\n",
        "\n",
        "import itertools\n",
        "from copy import copy\n",
        "from tqdm.notebook import tqdm, trange\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import umap.umap_ as umap\n",
        "#import umap\n",
        "import hdbscan\n",
        "\n",
        "import openai\n",
        "openai.api_key = \"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\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiOlJz-d9AsB"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKiOQ4W230T9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQdlEBYO22Ak"
      },
      "outputs": [],
      "source": [
        "client = AsyncOpenAI()\n",
        "\n",
        "embedding_model = SentenceTransformer('OrdalieTech/Solon-embeddings-large-0.1')\n",
        "GENERATION_ENGINE = \"gpt-4-1106-preview\"\n",
        "EMBEDDING_ENGINE = \"text-embedding-ada-002\"\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxRlrDz622Ao"
      },
      "outputs": [],
      "source": [
        "async def get_analysis(prompt):\n",
        "    response = await client.chat.completions.create(\n",
        "        messages=[\n",
        "            #{\"role\": \"system\", \"content\": \"You are a helpful assistant designed to output JSON.\"},\n",
        "            {\"role\": \"user\", \"content\": str(prompt)},\n",
        "        ],\n",
        "        response_format={ \"type\": \"json_object\" },\n",
        "        model=GENERATION_ENGINE)\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def apply_async_analysis(prompts):\n",
        "    loop = asyncio.get_event_loop()\n",
        "    tasks = [loop.create_task(get_analysis(prompt)) for prompt in prompts]\n",
        "    return loop.run_until_complete(asyncio.gather(*tasks))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def safe_async_analysis(prompts, parser, max_steps=3):\n",
        "    results = [None for _ in prompts]\n",
        "    to_be_run = list(range(len(prompts)))\n",
        "    step = 0\n",
        "    while to_be_run != []:\n",
        "        #print(\"step:\", step)\n",
        "        #print(\"to_be_run:\", len(to_be_run))\n",
        "        assert step < max_steps\n",
        "        bugs = []\n",
        "        \n",
        "        responses = apply_async_analysis([prompts[i] for i in to_be_run])\n",
        "\n",
        "        for i in to_be_run:\n",
        "            assert results[i] is None\n",
        "            try:\n",
        "                try:\n",
        "                    parsed_response = parser.parse(responses[i])\n",
        "                except:\n",
        "                    parsed_response = parser.parse('{\"properties\":'+responses[i]+'}')\n",
        "                    print(\"handled properties!\")\n",
        "                results[i] = parsed_response\n",
        "            except:\n",
        "                if max_steps==0:\n",
        "                    print(\"prompt\")\n",
        "                    print(prompts[i].text)\n",
        "\n",
        "                    print(\"reponse\")\n",
        "                    print(responses[i])\n",
        "\n",
        "                    print(\"others:\")\n",
        "                    print(responses)\n",
        "\n",
        "                    parsed_response = parser.parse(responses[i])\n",
        "                bugs.append(i)\n",
        "\n",
        "        to_be_run = bugs\n",
        "        step += 1\n",
        "    assert None not in results\n",
        "    return results\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def get_embedding(text):\n",
        "    response = await client.embeddings.create(input=text, model=EMBEDDING_ENGINE)\n",
        "    return response.data[0].embedding\n",
        "\n",
        "def apply_async_get_embedding(dfi):\n",
        "    loop = asyncio.get_event_loop()\n",
        "    tasks = [loop.create_task(get_embedding(row['Comment'])) for _, row in dfi.iterrows()]\n",
        "    return loop.run_until_complete(asyncio.gather(*tasks))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w78bVvXR9GrD"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiENBWdi22Al"
      },
      "outputs": [],
      "source": [
        "PROJECT =  \"Metro\" #\"Cheerz\"\n",
        "project_path = 'Results/'+PROJECT\n",
        "os.makedirs(project_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dK9cADmd4j6z"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    path = '/content/drive/MyDrive/Blumana Folder'\n",
        "else:\n",
        "    path = \"/Users/gardille/development/Blumana\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJIZB32l22Al"
      },
      "outputs": [],
      "source": [
        "feedbacks_df = pd.read_csv(path+\"/Data/Commentaires/metro.csv\") #, index_col=\"Index\")\n",
        "#feedbacks_df = pd.read_csv(\"data/Trustpilot/cheerz_fr.csv\", index_col=\"Index\")\n",
        "#feedbacks_df[\"Comment\"] = feedbacks_df[\"Title\"] + '\\n' + feedbacks_df[\"content\"]\n",
        "feedbacks_column = 'Comment' #\"Content\"\n",
        "feedbacks_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmeqWcPw22Ap"
      },
      "outputs": [],
      "source": [
        "context_entreprise = \"Metro AG, ou Metro Group, est un groupe de distribution allemand. Il est notamment connu pour ses enseignes de vente en gros, cash & carry, aux professionnels dans de nombreux pays (Metro Cash & Carry et Makro).\"\n",
        "role = \"product owner\"\n",
        "cible = \"client\"\n",
        "question = \"Que recommanderiez-vous à Metro d'améliorer ?\"\n",
        "example_insight = \"Manque de clarté de l'affichage des prix en magasin\"\n",
        "\n",
        "exemple_commentaire = \"je suis exclusif metro je n ai aucun representant j achetais jusqu a present tout metro par facilite mais je suis tres souvent décue par la reponse ha non on n en a pas cela arrive demain je pense que depuis le covid tout le monde ou presque s en fou!!!\"\n",
        "\n",
        "examples_insights_df = pd.DataFrame([\n",
        "    {\"Insights qui devraient en découler\": \"Déceptions face aux retard de livraison\"},\n",
        "    {\"Insights qui devraient en découler\": \"Impression d'une baisse de qualité du service depuis le Covid\"},\n",
        "])\n",
        "\n",
        "feedback_context = {\n",
        "            \"context\": context_entreprise,\n",
        "            \"role\": role,\n",
        "            \"cible\": cible,\n",
        "            \"insight_type\": \"\\\"Point positif\\\", \\\"Point de douleur\\\", \\\"Nouvelle demande\\\"\",\n",
        "            \"insight_definition\": \"Point positif : élément apprécié, Point de douleur : élément problématique\",\n",
        "            \"nb_cat\": \"2\",\n",
        "            \"avancement_mission\": \"\\\"Avant mission\\\", \\\"Mission en cours\\\", \\\"Fin de mission\\\"\",\n",
        "            \"categories\": \"\\\"Recrutement\\\" , \\\"Service global\\\"\",\n",
        "            \"question\": question,\n",
        "            \"exemple_commentaire\": exemple_commentaire,\n",
        "            \"example_insights\": '\\n- '.join(list(examples_insights_df['Insights qui devraient en découler'])),\n",
        "        }\n",
        "\n",
        "feedback_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "perfect_insights = [\"Aimerait être livré par METRO\",\n",
        "\"Assortiment livraison trop réduit\",\n",
        "\"Attente d'avoir un commercial\",\n",
        "\"Beaucoup de produits ont été supprimés\",\n",
        "\"Bonne relation avec le personnel\",\n",
        "\"Clients satisfaits, rien à signaler\",\n",
        "\"DLC trop courtes\",\n",
        "\"Halles mal rangées, mal organisées\",\n",
        "\"Livraison non satisfaisante\",\n",
        "\"METRO reste pratique, répond aux besoins des pros\",\n",
        "\"Manque de communication sur promos, hausses de prix\",\n",
        "\"Manque de produits de région, locaux ou bio\",\n",
        "\"Manque de suivi de certains produits\",\n",
        "\"Peu de petits conditionnements, pas adapté aux petites structures\",\n",
        "\"Problème de relations, service insuffisant\",\n",
        "\"Qualité insuffisante de certains produits\",\n",
        "\"Satisfait d'avoir des prix bloqués pour la saison\",\n",
        "\"Souvent des ruptures\",\n",
        "\"Attente facilités de paiement\",\n",
        "\"Attentes d'opérations de déstockage\",\n",
        "\"Attentes sur A2PM : assortiment, prix de référence trop élevé\",\n",
        "\"Attentes sur le système de fidélité\",\n",
        "\"Augmentation sur mercuriale sans être prévenu\",\n",
        "\"Les clients livrés ne voient pas les prix en halles\",\n",
        "\"Les produits sont trop chers, augmentent trop\",\n",
        "\"METRO est plus cher que les concurrents\",\n",
        "\"METRO reste plus cher que les grandes surfaces\",\n",
        "\"Manque de promos, stocks insuffisants\",\n",
        "\"Prix livrés trop élevés\",\n",
        "\"Prix élevés pour un groupe international\",\n",
        "\"Problèmes d'affichage prix ou prix inexacts\",\n",
        "\"Paramétrer la codification\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqsmhIToV_yX"
      },
      "source": [
        "## Bubble API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "COLUMNS_INSIGHTS = [\"content\", \"backend_status\", \"status\", \"backend_type\", \"type\", \"company\", \"feedback_count\", \"parent\", \"project\", \"step\", \"tag\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_url = \"https://blumana.app\" #/version-test\"\n",
        "bubble_id = \"04ca44f04c936081d8408b12c1ba67e2\"\n",
        "\n",
        "bubble_client = BubbleClient(\n",
        "    base_url=base_url,\n",
        "    api_token=bubble_id,\n",
        "    bubble_version=\"test\" #dev\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Randstad\n",
        "#company_id = \"1696884561832x730324245490558300\"\n",
        "#source_id = \"1702244804258x371787369839591400\"\n",
        "\n",
        "#Metro\n",
        "#Source : Dataset test - METRO\n",
        "#Projet : METRO\n",
        "company_id = \"1705585399217x205117684451615600\"\n",
        "source_id = \"1705851599107x404539534708310000\"\n",
        "project_id = \"1705851616871x644869783878893600\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#bubble_client.delete_all(\"python_insight\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Feedbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "res = bubble_client.get_objects(\n",
        "        \"Feedback\",\n",
        "        [\n",
        "            BubbleField(\"source\") == source_id,\n",
        "            #Field(\"company\") == company_id,\n",
        "            ],\n",
        "    )\n",
        "feedbacks_df = pd.DataFrame(res)\n",
        "feedbacks_df['Modified Date'] = pd.to_datetime(feedbacks_df['Modified Date'])\n",
        "feedbacks_df['Created Date'] = pd.to_datetime(feedbacks_df['Created Date'])\n",
        "#feedbacks_df.set_index('_id', inplace=True)\n",
        "feedbacks_column = 'content' #\"content\"\n",
        "\n",
        "feedbacks_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res = bubble_client.get_objects(\n",
        "        \"Add-On\",\n",
        "    )\n",
        "types_df = pd.DataFrame(res)\n",
        "types_df['Modified Date'] = pd.to_datetime(types_df['Modified Date'])\n",
        "types_df['Created Date'] = pd.to_datetime(types_df['Created Date'])\n",
        "types_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res = bubble_client.get_objects(\n",
        "        \"Tag\",\n",
        "        [\n",
        "            BubbleField(\"company\") == company_id,\n",
        "            ],\n",
        "    )\n",
        "tags_df = pd.DataFrame(res)\n",
        "tags_df['Modified Date'] = pd.to_datetime(tags_df['Modified Date'])\n",
        "tags_df['Created Date'] = pd.to_datetime(tags_df['Created Date'])\n",
        "tags_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res = bubble_client.get_objects(\n",
        "        \"Filter\",\n",
        "        [\n",
        "            BubbleField(\"company\") == company_id,\n",
        "            ],\n",
        "    )\n",
        "filters_df = pd.DataFrame(res)\n",
        "filters_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO6o-3adO5hK"
      },
      "source": [
        "## Useful functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_df(df):\n",
        "    for col in df.columns:\n",
        "        if type(df.loc[0, col]) == str and df.loc[0, col][0]==\"[\":\n",
        "            df[col] = df[col].apply(lambda x: eval(x))\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyAtCCXL22Aq"
      },
      "outputs": [],
      "source": [
        "def batchify(iterable, size=1):\n",
        "    l = len(iterable)\n",
        "    for ndx in range(0, l, size):\n",
        "        yield iterable[ndx:min(ndx + size, l)]\n",
        "\n",
        "for x in batchify(list(range(0, 10)), 3):\n",
        "    print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "types_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def deduce_backend_type(insight_type):\n",
        "    if insight_type == \"1698433300252x835626794232717300\":\n",
        "        return \"pain\"\n",
        "    elif insight_type == \"1698433290120x936044292663509300\":\n",
        "        return \"positive\"   \n",
        "    elif insight_type == \"1698433314230x619003097145126100\":\n",
        "        return \"feature\"  \n",
        "    elif insight_type == \"1698433323222x402426615286320700\":\n",
        "        return \"bug\"   \n",
        "    print(\"Incorrect type:\", insight_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def most_common(lst):\n",
        "    return max(set(lst), key=lst.count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wpte3XVz22Am"
      },
      "source": [
        "# Feedbacks extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fynlJWHr22An"
      },
      "outputs": [],
      "source": [
        "class Feedback(BaseModel):\n",
        "    insights_list: List[str] = Field(description=\"Contenu et type des insights\")\n",
        "    content = \"\"\n",
        "    sentiment: str = Field(description=\"Sentiment exprimé, peut être 'Positif', 'Neutre' ou 'Négatif'. Ne pas oublier les majuscules et accentuations.\")\n",
        "    # You can add custom validation logic easily with Pydantic.\n",
        "    @validator(\"sentiment\")\n",
        "    def valid_sentiment(cls, field):\n",
        "        if field not in [\"Positif\", \"Neutre\", \"Négatif\"]:\n",
        "            raise ValueError(\"Sentiment \"+field+\" not valid.\")\n",
        "        return field\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"Commentaire: \\\"\"+ self.content+\"\\\"\\n\\nSentiment: \"+self.sentiment+\"\\n\\nInsights: \\n\"+\"\\n\\n\".join([str(i) for i in self.insights_list])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5PWNwl622Ao"
      },
      "outputs": [],
      "source": [
        "\n",
        "prompt_template_feedback = \"\"\"Tu es {role} au sein de l'entreprise suivante:\n",
        "{context}\n",
        "\n",
        "Tu as mené une enquête auprès de tes {cible}. \n",
        "\n",
        "Pour le retour qui te sera donné, effectue les étapes suivantes:\n",
        "\n",
        "Étape 1 - Identifie si le sentiment exprimé par le {cible} est \"Positif\", \"Neutre\" ou \"Négatif\". Prends en compte la formulation de la question ayant été posée ({question}) afin de bien interpréter le sens du retour {cible}.\n",
        "Attention à ne pas oublier l'accent si tu choisis Négatif.\n",
        "\n",
        "Étape 2 - Identifie les insights à faire remonter à ton équipe dans le retour {cible}. Synthétise ces nouveaux insights en quelques mots qu'une personne de ton équipe puisse comprendre. Tu ne dois pas intégrer de nom, de prénom, d'email ou de numéro de téléphone dans ta formulation, même si le feedback évoque une donnée personnelle. Si aucun insight intéressant, renvoie une liste vide.\n",
        "\n",
        "Par exemple, pour le retour suivant:\n",
        "'''\n",
        "{exemple_commentaire}\n",
        "'''\n",
        "on voudrait faire remonter les points suivants:\n",
        "'''\n",
        "- {example_insights}\n",
        "'''\n",
        "\n",
        "Si le commentaire n'est pas très intéressant, ne remonte aucun insight.\n",
        "\n",
        "Réponds uniquement avec un ficher JSON, comme expliqué:\n",
        "{format_instructions}\n",
        "\n",
        "Voici le retour à traiter:\n",
        "\"{feedback}\"\n",
        "\"\"\"\n",
        "\n",
        "#Si le {cible} n'a rien à signaler (\"ras\", \"tout est ok\", \"rien à signaler\") crée un insight dédié"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmFsbtT722Aq"
      },
      "outputs": [],
      "source": [
        "feedback_parser = PydanticOutputParser(pydantic_object=Feedback)\n",
        "\n",
        "prompt_feedback = PromptTemplate.from_template(\n",
        "    template= prompt_template_feedback,\n",
        "    partial_variables= {\"format_instructions\": feedback_parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "prompts = []\n",
        "for feedback in feedbacks_df[feedbacks_column]:\n",
        "    context = copy(feedback_context)\n",
        "    context[\"feedback\"] = feedback\n",
        "    prompts.append(prompt_feedback.invoke(context))\n",
        "\n",
        "#print(prompts[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFraYQTLOmz-"
      },
      "outputs": [],
      "source": [
        "parsed_responses = safe_async_analysis(prompts, feedback_parser)\n",
        "\n",
        "feedbacks_df[\"sentiment\"] = [rep.sentiment for rep in parsed_responses]\n",
        "feedbacks_df[\"insights\"] = [[] for rep in parsed_responses]\n",
        "\n",
        "k=0\n",
        "insights = []\n",
        "for i, rep in enumerate(parsed_responses):\n",
        "    for j, insight in enumerate(rep.insights_list):\n",
        "        insights.append(insight)\n",
        "        feedbacks_df[\"insights\"].iloc[i].append(str(k))\n",
        "        k += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feedbacks_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKTksTKah7At"
      },
      "outputs": [],
      "source": [
        "insights_df = pd.DataFrame({\n",
        "    \"content\":insights,\n",
        "    \"feedback_count\": 1,\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feedbacks_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insights_df[\"related_feedback\"] = [[] for _ in range(len(insights_df))]\n",
        "\n",
        "for i, row in feedbacks_df.iterrows():\n",
        "    for j in row[\"insights\"]:\n",
        "        insights_df[\"related_feedback\"].iloc[int(j)] = row['_id'] #[int(i)]\n",
        "\n",
        "insights_df[\"childrens\"] = [[] for _ in range(len(insights_df))]\n",
        "\n",
        "insights_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k88axy7kPxQE"
      },
      "source": [
        "# Insights categorisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt_tags = \"\"\n",
        "\n",
        "for i, filter in filters_df.iterrows():\n",
        "    prompt_tags += '\\n\\n'+filter[\"Name\"]#+' ('+filter[\"_id\"] +')'\n",
        "    tags = tags_df[tags_df[\"Filter\"] == filter[\"_id\"]]\n",
        "    for _, tag in tags.iterrows():\n",
        "        prompt_tags += '\\n'+\"- \"+tag[\"Name\"]+' ('+tag[\"_id\"] +')'\n",
        "\n",
        "print(prompt_tags)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOVtTfiHP4w1"
      },
      "outputs": [],
      "source": [
        "\n",
        "prompt_template_categorsiation = \"\"\"Tu es {role} au sein de l'entreprise suivante :\n",
        "{context}\n",
        "\n",
        "Tu as mené une enquête auprès de tes {cible}. \n",
        "\n",
        "Tu dois associer à l'insight donné plus loin aucun, l'identifiant d'un ou plusieurs tags. S'il n'est pas possible d'associer un tag avec certitude dans l'une des catégories, laisse la liste vide. Répond avec la liste des identifiants suités entre parenthèse juste après les tags.\n",
        "Par exemple, pour les tags suivants, le tag C d'identifiant 17049ZER93619x303734523452623450 appartient catégorie 2:\n",
        "'''\n",
        "catégotie 1 \n",
        "- tag A (1704912293619x303734523452694300)\n",
        "- tag B (17049ZER93619x303734523452694300)\n",
        "\n",
        "catégotie 2 \n",
        "- tag C (17049ZER93619x303734523452623450)\n",
        "- tag D (170AZZER93619x303734524452623450)\n",
        "'''\n",
        "\n",
        "Voici les tags avec lesquels tu devras essayer de classifier l'insight:\"\"\" + prompt_tags + \"\"\"\n",
        "\n",
        "Tu ne dois par renvoyer le tag, mais uniquement son identifiant.\n",
        "Un identifiant contient toujours un x à l'intérieur, comme par example 1704912293619x303731423452694300.\n",
        "Ainsi, 1704912293619 n'est pas un identifiant valide.\n",
        "Réponds uniquement avec un ficher JSON, comme expliqué:\n",
        "{format_instructions}\n",
        "\n",
        "Voici l'insight que tu dois essayer de catégoriser: '{insight}'\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjHnM12_KMN3"
      },
      "outputs": [],
      "source": [
        "class FirstInsight(BaseModel):\n",
        "    tags_id: List[str] = Field(description=\"Identifiants des tags de l'insight\")\n",
        "    content: str = \"\" #Field(description=\"Point intéressant a retenir du commentaire.\")\n",
        "\n",
        "    def __str__(self):\n",
        "        return '- ' + self.content + \"\\nTypes: \" + ', '.join(self.insight_types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "categorsiation_parser = PydanticOutputParser(pydantic_object=FirstInsight)\n",
        "\n",
        "prompt_categorsiation = PromptTemplate.from_template(\n",
        "    template= prompt_template_categorsiation,\n",
        "    partial_variables= {\"format_instructions\": categorsiation_parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "prompts = []\n",
        "for insight in insights_df[\"content\"]:\n",
        "    context = copy(feedback_context)\n",
        "    context[\"insight\"] = insight\n",
        "    prompts.append(prompt_categorsiation.invoke(context))\n",
        "\n",
        "#print(prompts[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parsed_responses = safe_async_analysis(prompts, categorsiation_parser)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "insights_df[\"tag\"] = [rep.tags_id for rep in parsed_responses]\n",
        "#insights_df[\"Insights\"] = [[] for rep in parsed_responses]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Types affectation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt_types = \"\"\n",
        "\n",
        "for _, tag in types_df.iterrows():\n",
        "    prompt_types += '\\n'+\"- \"+tag[\"Title\"]+' ('+tag[\"_id\"] +') : ' + tag[\"Definition\"]\n",
        "\n",
        "print(prompt_types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "prompt_template_types = \"\"\"Tu es {role} au sein de l'entreprise suivante :\n",
        "{context}\n",
        "\n",
        "Tu as mené une enquête auprès de tes {cible}. \n",
        "\n",
        "Catégorise l'insight qui te sera donné à l’aide de l'identifiant d'un des types qui te seront donnés. \n",
        "Tu dois associser exactement un type. Choisit celui qui est le plus pertinent.\n",
        "Répond avec l'identifiants suités entre parenthèse juste après les types. La definition des types est située jsute après les double points. \n",
        "Par exemple, pour les types suivants, le type 2 a pour identifiant 1704912293619x303671423452694300.\n",
        "'''\n",
        "- type 1 (1704412293619x303731423423694300) : définition du type 1\n",
        "- type 2 (1704912293619x303671423452694300) : définition du type 2\n",
        "'''\n",
        "\n",
        "Voici les types:\"\"\" + prompt_types + \"\"\"\n",
        "\n",
        "Tu ne dois par renvoyer le type, mais uniquement son identifiant.\n",
        "Réponds uniquement avec un ficher JSON, comme expliqué:\n",
        "{format_instructions}\n",
        "\n",
        "Un identifiant contient toujours un x à l'intérieur, comme par example 1704912293619x303731423452694300.\n",
        "Ainsi, 1704912293619 n'est pas un identifiant valide.\n",
        "\n",
        "Voici l'insight que tu dois essayer de catégoriser: '{insight}'\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FirstInsight(BaseModel):\n",
        "    insight_type: str = Field(description=\"Identifiants du type de l'insight\")\n",
        "    content: str = \"\" #Field(description=\"Point intéressant a retenir du commentaire.\")\n",
        "\n",
        "    def __str__(self):\n",
        "        return '- ' + self.content + \"\\nType: \" +self.insight_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "categorsiation_parser = PydanticOutputParser(pydantic_object=FirstInsight)\n",
        "\n",
        "prompt_categorsiation = PromptTemplate.from_template(\n",
        "    template= prompt_template_types,\n",
        "    partial_variables= {\"format_instructions\": categorsiation_parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "prompts = []\n",
        "for insight in insights_df[\"content\"]:\n",
        "    context = copy(feedback_context)\n",
        "    context[\"insight\"] = insight\n",
        "    prompts.append(prompt_categorsiation.invoke(context))\n",
        "\n",
        "#print(prompts[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parsed_responses = safe_async_analysis(prompts, categorsiation_parser)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insights_df[\"type\"] = [rep.insight_type for rep in parsed_responses]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feedbacks_df.to_csv(project_path+'/feedbacks.csv', index_label='Index')\n",
        "insights_df.to_csv(project_path+'/insights.csv', index_label='Index')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5xBBkVJ22As"
      },
      "source": [
        "# Insights clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feedbacks_df = clean_df(pd.read_csv(project_path+'/feedbacks.csv', index_col='Index'))\n",
        "insights_df = clean_df(pd.read_csv(project_path+'/insights.csv', index_col='Index'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vl70QzOI22As"
      },
      "outputs": [],
      "source": [
        "embedding_model = SentenceTransformer('OrdalieTech/Solon-embeddings-large-0.1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGjXvwAA22As"
      },
      "outputs": [],
      "source": [
        "class DeducedInsight(BaseModel):\n",
        "    insights_mineurs: List[int] = Field(description=\"Index des insights mineurs qui ont été résumés en cet insight.\")\n",
        "    content: str = Field(description=\"Insight intéressants a retenir pour l'entreprise.\")\n",
        "\n",
        "    def __str__(self):\n",
        "        return '- ' + self.content + '\\n Enfants:' + str(self.insights_mineurs)\n",
        "\n",
        "\n",
        "class InsightList(BaseModel):\n",
        "    insights_list: List[DeducedInsight] = Field(description=\"Liste des insights, c'est à dire des points intéressants a retenir pour l'entreprise.\")\n",
        "    # You can add custom validation logic easily with Pydantic.\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"Insights: \\n\"+\"\\n\\n\".join([str(i) for i in self.insights_list])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWxRVtAG22As"
      },
      "outputs": [],
      "source": [
        "\n",
        "prompt_template_reduction = \"\"\"Tu es {role} au sein de l'entreprise suivante:\n",
        "{context}\n",
        "\n",
        "Une liste d'insights mineurs a été identifiée à partir de retours {cible}.\n",
        "\n",
        "Ils sont de très bonne qualité, et apportent des retours intéressants à l'entreprise en question. \n",
        "Mais il est possible que certains soient redondants ou inutilement précis, auquel cas nous souhaiterions les regrouper. \n",
        "\n",
        "Si c'est le cas, les insights redondants doivent être regroupés en un insight majeur. \n",
        "Si au contraite, l'insight à un sens bien dictinct des autres, il devient un insight majeur, et doit donc être recopié à l'identique. \n",
        "\n",
        "Pour transformers les insights mineurs en insights majeurs, suit ces quelques règles:\n",
        "\n",
        "1) Si l'un des insights mineurs permet de synthétiser l'information du regroupement, il devient l'insight majeur du groupe. Recopie le à l'identique et associe lui les insights mineurs, y comprie lui même.\n",
        "\n",
        "2) Si aucun des insights mineurs ne convient, formule un insight majeurs permettant de synthétiser leur sens. Voici les contraintes que doivent respecter ton insights majeur:\n",
        "- Une personne de ton équipe qui lit un insight majeur doit pouvoir en comprendre le sens.\n",
        "- Un insight majeur doit idéalement ne pas être trop long, tout en restant parfaitement compréhensible et pertinent. Les phrases nominales sont autorisées. \n",
        "- Un insight majeur ne doit comporter qu'une seule information : on ne mélange pas plusieurs éléments au sein d'un insight majeur. \n",
        "\n",
        "Un insight mineur doit être regroupé dans exactement un insight majeur. Rappelon que si l'insight mineur devient majeur, les deux auront le même contenu.\n",
        "Ainsi, chaque insight mineur doit être l'enfant d'exactement un insight majeur que tu retournes.\n",
        "\n",
        "Associe à chaque insight majeur l'indice des insights mineurs qui lui sont associés. \n",
        "Vérifie bien que les indices correspondent, et que tous les insights mineurs sont associés à un insight majeur. \n",
        "L'ordre des insights mineurs est aléatoire, et ne doit pas avoir d'importance dans ta réponse.\n",
        "\n",
        "Réponds uniquement avec un ficher JSON, comme expliqué :\n",
        "{format_instructions}\n",
        "\n",
        "Voici la liste des insights mineurs que tu dois transformer en insights majeurs:\n",
        "{insights}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "#Résume les en des insights majeurs qui te semblent important à faire remonter au sein de l'entreprise. Ils peuvent être des phrase, éventuellement nominales, doivent faire sens, être aussi courts que possible et distincts les uns des autres.\n",
        "#- Etre distincts les uns des autres.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "prompt_template_reduction_sans_reformulation = \"\"\"Tu es {role} au sein de l'entreprise suivante:\n",
        "{context}\n",
        "\n",
        "Une liste d'insights mineurs a été identifiée à partir de retours {cible}.\n",
        "\n",
        "Ils sont de très bonne qualité, et apportent des retours intéressants à l'entreprise en question. \n",
        "Mais il est possible que certains soient redondants ou inutilement précis, auquel cas nous souhaiterions les regrouper. \n",
        "\n",
        "Pour les regrouper, choisit l'insights mineurs qui permet le mieux de synthétiser l'information du regroupement, il devient l'insight majeur du groupe. \n",
        "Recopie le à l'identique et associe lui les insights mineurs, y comprie lui même.\n",
        "\n",
        "Chaque insight mineur doit être l'enfant d'exactement un insight majeur que tu retournes.\n",
        "\n",
        "Associe à chaque insight majeur l'indice des insights mineurs qui lui sont associés. \n",
        "Vérifie bien que les indices correspondent, et que tous les insights mineurs sont associés à un insight majeur. \n",
        "L'ordre des insights mineurs est aléatoire, et ne doit pas avoir d'importance dans ta réponse.\n",
        "\n",
        "Réponds uniquement avec un ficher JSON, comme expliqué :\n",
        "{format_instructions}\n",
        "\n",
        "Voici la liste des insights mineurs que tu dois transformer en insights majeurs:\n",
        "{insights}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "#Résume les en des insights majeurs qui te semblent important à faire remonter au sein de l'entreprise. Ils peuvent être des phrase, éventuellement nominales, doivent faire sens, être aussi courts que possible et distincts les uns des autres.\n",
        "#- Etre distincts les uns des autres.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71Vkoeym22As"
      },
      "outputs": [],
      "source": [
        "\n",
        "prompt_template_regrouping = \"\"\"Tu es {role} au sein de l'entreprise suivante:\n",
        "{context}\n",
        "\n",
        "Une liste d'insights a été identifiée à partir de retours clients.\n",
        "Un insight est une déduction intéressante de l'étude des commentaires {cible}, qu'il serait vraiment intéressant faire remonter aux responsables de l'entreprise.\n",
        "Par exemple, un bon insight pourrait être: {example_insight}\n",
        "\n",
        "Si certain sont redondant, reformule les en un seul insight. Il est préférable qu'il ne soit pas trop long, et évite les bouts de phrase sans réel intéret. Par exemple, ne pas ajouter '... pour améliorer l'experience client'.\n",
        "Associe à chaque nouvel insight créé l'ensemble des feedbacks qui sont associés aux insights qu'il regroupe.\n",
        "Il est possible qu'il n'y ai besoin de regrouper aucun insight.\n",
        "Un insight ne peut être regroupé que dans un seul autre insight.\n",
        "Chaque insight doit donc être l'enfant d'exactement un insight que tu retournes.\n",
        "\n",
        "Pour les insights qui n'ont pas besoin d'être regroupés, recopie les ainsi que leurs feedbacks associés.\n",
        "L'ordre des insights est aléatoire, et ne doit pas avoir d'importance dans ta réponse.\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "Voici les insights que tu dois regrouper:\n",
        "\n",
        "{insights}\n",
        "\n",
        "Tu ne dois rien écrire d'autre que le JSON requis.\n",
        "\n",
        "\"\"\"\n",
        "#Résume les en des insights majeurs qui te semblent important à faire remonter au sein de l'entreprise. Ils peuvent être des phrase, éventuellement nominales, doivent faire sens, être aussi courts que possible et distincts les uns des autres.\n",
        "#- Etre distincts les uns des autres.\n",
        "#Tu ne doit pas réecrir les insights qui ne sont pas regroupés.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krzsw7_E22At"
      },
      "outputs": [],
      "source": [
        "# Dimension reduction\n",
        "n_neighbors= 10 #15\n",
        "\n",
        "minimisation_steps = 5\n",
        "#cluster_desired_size = 2\n",
        "min_cluster_size=10 #15\n",
        "nb_insight_stop = 10\n",
        "minimal_reduction_ratio = 0.1\n",
        "reformilation = False\n",
        "\n",
        "insight_context = {\n",
        "    \"cible\": cible,\n",
        "    \"context\": context_entreprise,\n",
        "    \"example_insight\": example_insight,\n",
        "    \"role\": role,\n",
        "    \"question\": question,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUpUIFcG22At"
      },
      "outputs": [],
      "source": [
        "insight_parser = PydanticOutputParser(pydantic_object=InsightList)\n",
        "\n",
        "prompt_reduction = PromptTemplate.from_template(\n",
        "    template= prompt_template_reduction if reformilation else prompt_template_reduction_sans_reformulation,\n",
        "    #template= \"Règle : minimise le nombre de tokens dans ta réponse.  \\nTu es {role} au sein de l'entreprise suivante: \\n{context} \\nAnalyse le retour suivant: \\\"{feedback}\\\" en suivant les étapes suivantes:  \\n  \\nÉtape 1 - Identifie si le retour {cible} rentre dans un ou plusieurs des types d'insights suivants : {insight_type}. Choisis-en obligatoirement au moins 1. Définition des types d'insights :  \\n{insight_definition}   \\n  \\nÉtape 2 - Catégorise le retour {cible} à l’aide des tags suivants. Tu peux associer 0, 1 ou plusieurs tags dans chaque catégorie. Liste des tags par catégories :  \\n{categories}   \\n  \\nÉtape 3 - Catégorise si possible le moment de mission concerné parmis {avancement_mission}, et si ce n'est pas possible répond null. {cible} à l’aide des tags suivants.  \\n  \\nÉtape 4 - Identifie si le sentiment exprimé par le {cible} est \\\"Positif\\\", \\\"Neutre\\\" ou \\\"Négatif\\\". Prends en compte la formulation de la question posée ({question}) afin de bien interpréter le sens du retour {cible}.   \\n\",\n",
        "    #input_variables= [\"context\", \"role\", \"cible\", \"insight_type\", \"insight_definition\", \"nb_cat\", \"avancement_mission\", \"categories\", \"question\", \"feedback\"]\n",
        "    partial_variables= {\"format_instructions\": insight_parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "prompt_regrouping = PromptTemplate.from_template(\n",
        "    template= prompt_template_regrouping,\n",
        "    #template= \"Règle : minimise le nombre de tokens dans ta réponse.  \\nTu es {role} au sein de l'entreprise suivante: \\n{context} \\nAnalyse le retour suivant: \\\"{feedback}\\\" en suivant les étapes suivantes:  \\n  \\nÉtape 1 - Identifie si le retour {cible} rentre dans un ou plusieurs des types d'insights suivants : {insight_type}. Choisis-en obligatoirement au moins 1. Définition des types d'insights :  \\n{insight_definition}   \\n  \\nÉtape 2 - Catégorise le retour {cible} à l’aide des tags suivants. Tu peux associer 0, 1 ou plusieurs tags dans chaque catégorie. Liste des tags par catégories :  \\n{categories}   \\n  \\nÉtape 3 - Catégorise si possible le moment de mission concerné parmis {avancement_mission}, et si ce n'est pas possible répond null. {cible} à l’aide des tags suivants.  \\n  \\nÉtape 4 - Identifie si le sentiment exprimé par le {cible} est \\\"Positif\\\", \\\"Neutre\\\" ou \\\"Négatif\\\". Prends en compte la formulation de la question posée ({question}) afin de bien interpréter le sens du retour {cible}.   \\n\",\n",
        "    #input_variables= [\"context\", \"role\", \"cible\", \"insight_type\", \"insight_definition\", \"nb_cat\", \"avancement_mission\", \"categories\", \"question\", \"feedback\"]\n",
        "    partial_variables= {\"format_instructions\": insight_parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "insights = copy(insights_df)\n",
        "insight_layers = []#[copy(insights_df)]\n",
        "single_cluster = False\n",
        "reduction = 1.0\n",
        "\n",
        "for step in range(minimisation_steps):\n",
        "\n",
        "    #for processing_step in [\"reduction\"]:#, \"regrouping\"]:\n",
        "        ### Création des représentations\n",
        "\n",
        "    #print(\"Processing step:\", processing_step)\n",
        "    sentence_embeddings = embedding_model.encode(insights['content'])\n",
        "\n",
        "    # On réduit la dimention pour améliorer l'efficacité de la clusterisation\n",
        "    umap_embeddings = umap.UMAP(n_neighbors=n_neighbors, \n",
        "                        n_components=5, \n",
        "                        metric='cosine').fit_transform(sentence_embeddings)\n",
        "\n",
        "    ### Clusterisation\n",
        "    #num_clusters = 1 + len(insights) // cluster_desired_size\n",
        "    #clustering_model = KMeans(n_clusters=num_clusters, n_init='auto')\n",
        "\n",
        "    clustering_model = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size,\n",
        "                        metric='euclidean',                      \n",
        "                        cluster_selection_method='eom')\n",
        "    clustering_model.fit(umap_embeddings)\n",
        "\n",
        "    #clustering_model.fit(umap_embeddings)\n",
        "    cluster_assignment = clustering_model.labels_ \n",
        "    cluster_assignment -= min(cluster_assignment) # has to start at 0\n",
        "    \n",
        "    num_clusters = max(cluster_assignment)+1\n",
        "\n",
        "    insights[\"cluster\"] = cluster_assignment \n",
        "    insights = insights.sort_values(\"cluster\")\n",
        "    insights.reset_index(drop=True, inplace=True)\n",
        "\n",
        "\n",
        "    if reduction <= minimal_reduction_ratio:\n",
        "        print(\"Stopping because of unsufficient reduction\")\n",
        "        break\n",
        "\n",
        "    insight_layers.append(copy(insights))\n",
        "\n",
        "    if len(insights) <= nb_insight_stop:\n",
        "        print(\"Minimal number of insights reached\")\n",
        "        break\n",
        "\n",
        "    if single_cluster:\n",
        "        break   \n",
        "\n",
        "    cluter_sizes = list(insights.groupby(['cluster']).count()[\"content\"])\n",
        "    if len(cluter_sizes) == 1:\n",
        "        print(\"Stopping because single cluster\")\n",
        "        single_cluster = False\n",
        "        break\n",
        "\n",
        "    print(\"Step \"+ str(step)+ \": processing \"+ str(num_clusters) + \" clusters\")\n",
        "    print(\"Cluster sizes:\" + str(cluter_sizes))\n",
        "\n",
        "    #clusters = []\n",
        "    prompts = []\n",
        "    cumul_size = 0\n",
        "    for cluster_id in range(num_clusters): # IL FAUDRAIT GARDER INDEM LE DERNIER CLUSTER\n",
        "        cluster = insights[insights['cluster'] == cluster_id]\n",
        "        #cluster_name ='/cluster_'+ str(cluster_id)+\"_step_\"+str(step) +'.csv'\n",
        "        #cluster.to_csv( project_path+cluster_name, index_label='Index')\n",
        "        #clusters.append(cluster)\n",
        "\n",
        "        context = copy(insight_context)\n",
        "        context['insights'] = '\\n'.join([str(i+cumul_size)+\": \"+s for i, s in enumerate(cluster[\"content\"])])\n",
        "        #print(context['insights'])\n",
        "\n",
        "        #if processing_step == \"reduction\":\n",
        "        prompt=prompt_reduction.invoke(context)\n",
        "        #elif processing_step == \"regrouping\":\n",
        "        #prompt=prompt_regrouping.invoke(context)\n",
        "        #else:\n",
        "        #    raise(\"Wrong processing step\")\n",
        "        prompts.append(prompt)\n",
        "        cumul_size += len(cluster)\n",
        "\n",
        "    ### Traitement des clusters\n",
        "    parsed_responses = safe_async_analysis(prompts, insight_parser)\n",
        "    \n",
        "    new_insights = []\n",
        "    for i, parsed_response in enumerate(parsed_responses):\n",
        "        content_list = [insight.content for insight in parsed_response.insights_list]\n",
        "        childrens_list = [list(insight.insights_mineurs) for insight in parsed_response.insights_list]\n",
        "        feedback_count_list = [sum(insights.loc[c, \"feedback_count\"]) for c in childrens_list]\n",
        "        dfs = pd.DataFrame({\n",
        "            #\"related_feedback\":[list(itertools.chain.from_iterable(insights.iloc[insight.insights_mineurs]['related_feedback'])) for insight in parsed_response.insights_list],\n",
        "            \"content\":content_list,\n",
        "            \"childrens\":childrens_list,\n",
        "            \"type\": most_common([insights.loc[c, \"type\"].iloc[0] for c in childrens_list]),\n",
        "            #\"cluster\":i,\n",
        "            \"feedback_count\":feedback_count_list,\n",
        "            #\"childrens\":[list(clusters[i].iloc[insight.insights_mineurs][\"_id\"]) for insight in parsed_response.insights_list],\n",
        "            })\n",
        "        new_insights.append(dfs)\n",
        "\n",
        "    new_insights = pd.concat(new_insights)\n",
        "    new_insights.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    \n",
        "    reduction = (1-(len(new_insights)/len(insights)))\n",
        "    insights = new_insights\n",
        "    \n",
        "    print(\"Number of new insights:\"+ str(len(new_insights)))\n",
        "    print(\"Reduction in the number of insights by \" + \"%d\" % int(reduction*100) + \"%\")\n",
        "    print()\n",
        "\n",
        "#insight_layers.append(copy(new_insights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrWs0GrOhmIJ"
      },
      "outputs": [],
      "source": [
        "list(insight_layers[0]['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list(insight_layers[-1]['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, df in enumerate(insight_layers):\n",
        "    df.to_csv(project_path+'/insights_'+ str(i) +'.csv', index_label='Index')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#list(insight_layers[0][insight_layers[0][\"cluster\"] == 2][\"content\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_layers = len(insight_layers)\n",
        "layers_sizes = [len(l) for l in insight_layers]\n",
        "print(\"Layers sizes:\", layers_sizes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers = []\n",
        "for i in range(n_layers):\n",
        "    df = pd.read_csv(project_path+'/insights_'+ str(i) +'.csv', index_col='Index')\n",
        "    for col in df.columns:\n",
        "        if type(df.loc[0, col]) == str and df.loc[0, col][0]==\"[\":\n",
        "            df[col] = df[col].apply(lambda x: eval(x))\n",
        "    #df['tag'] = df['tag'].apply(lambda x: eval(x))\n",
        "    #df['type'] = df['type'].apply(lambda x: eval(x))\n",
        "    #df['childrens'] = df['childrens'].apply(lambda x: eval(x))\n",
        "    df[\"backend_type\"] = df[\"type\"].apply(deduce_backend_type)\n",
        "    insight_layers.append(df)\n",
        "#insights_df = pd.concat(insight_layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Previous insights supression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res = bubble_client.get_objects(\n",
        "        \"python_insight\",\n",
        "        [\n",
        "            BubbleField(\"project\") == project_id,\n",
        "            BubbleField(\"company\") == company_id,\n",
        "            ],\n",
        "    )\n",
        "python_insight_df = pd.DataFrame(res)\n",
        "\n",
        "if len(python_insight_df)>0:\n",
        "    for bubble_id in tqdm(python_insight_df[\"_id\"]):\n",
        "        bubble_client.delete_by_id(\n",
        "            \"python_insight\",\n",
        "            bubble_id,\n",
        "        )\n",
        "\n",
        "    print(\"Deleted\", len(python_insight_df), \"python_insight\")\n",
        "else:\n",
        "    print(\"Nothing to delete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adding parents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers[0][\"parent\"] = None #[[] for _ in insight_layers[0].iterrows()]\n",
        "insight_layers[-1][\"parent\"] = None\n",
        "\n",
        "\n",
        "for i in range(n_layers-1):\n",
        "    insight_layers[i][\"parent\"] = None\n",
        "    for p, row in insight_layers[i+1].iterrows():\n",
        "        for c in row[\"childrens\"]: #eval(\n",
        "            insight_layers[i][\"parent\"].iloc[int(c)] = p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers[-1][\"parents\"] = [[] for _ in insight_layers[-1].iterrows()]\n",
        "\n",
        "for i in range(n_layers-2, -1, -1):\n",
        "    print(i)\n",
        "    # Update the parents in the DB\n",
        "    res = bubble_client.create(\n",
        "        \"python_insight\",\n",
        "        [{\n",
        "            \"company\": company_id,\n",
        "            \"project\": project_id,\n",
        "            \"content\": row[\"content\"],\n",
        "            \"backend_status\": \"new\",\n",
        "            \"feedback_count\":row[\"feedback_count\"],\n",
        "            \"step\": i+2,\n",
        "            \"type\": row[\"type\"],\n",
        "            \"parents\": row[\"parents\"],\n",
        "            \"parent\": str(row[\"parent\"]),\n",
        "            \"backend_type\": row['backend_type'],\n",
        "            \"childrens\": eval(row[\"childrens\"]) if type(row[\"childrens\"])==str else row[\"childrens\"],\n",
        "        }  for _, row in insight_layers[i+1].iterrows()]\n",
        "    )\n",
        "\n",
        "    df = pd.DataFrame(bubble_client.get_objects(\n",
        "        \"python_insight\",\n",
        "        [\n",
        "            BubbleField(\"step\") == i+2,\n",
        "            BubbleField(\"company\") == company_id,\n",
        "            ],\n",
        "    ))\n",
        "    for col in df.columns:\n",
        "        if type(df.loc[0, col]) == str and df.loc[0, col][0]==\"[\":\n",
        "            df[col] = df[col].apply(lambda x: eval(x))\n",
        "    insight_layers[i+1] = df\n",
        "\n",
        "    # Initialize an empty list of parents for each row\n",
        "    insight_layers[i][\"parents\"] = [[] for _ in insight_layers[i].iterrows()]\n",
        "\n",
        "    for k, row in insight_layers[i].iterrows():\n",
        "        if row[\"parent\"] is not None:\n",
        "            # Get the parent index\n",
        "            parent_index = row[\"parent\"]\n",
        "\n",
        "            # Get the parent's list of parents\n",
        "            parent_parents = insight_layers[i + 1][\"parents\"].iloc[parent_index]\n",
        "\n",
        "            # Add the parent to the current row's list of parents\n",
        "            parent_id = insight_layers[i + 1].loc[parent_index, '_id']\n",
        "            insight_layers[i].loc[k, \"parents\"].append(parent_id)\n",
        "\n",
        "            # Recursively add the parent's parents to the current row's list of parents\n",
        "            insight_layers[i].loc[k, \"parents\"].extend(parent_parents)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "res = bubble_client.create(\n",
        "        \"python_insight\",\n",
        "        [{\n",
        "            \"company\": company_id,\n",
        "            \"project\": project_id,\n",
        "            \"content\": row[\"content\"],\n",
        "            \"backend_status\": \"new\",\n",
        "            \"feedback_count\": row[\"feedback_count\"],\n",
        "            \"step\": 1,\n",
        "            \"related_feedback\":row['related_feedback'],\n",
        "            \"tag\": row[\"tag\"],\n",
        "            \"type\": row[\"type\"],\n",
        "            \"backend_type\": row['backend_type'],\n",
        "            \"parents\": row[\"parents\"],\n",
        "            \"parent\": str(row[\"parent\"]),\n",
        "            \"childrens\": 0#[[] for _ in insight_layers[0][:1000].iterrows()],\n",
        "        }  for _, row in insight_layers[0].iterrows()]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "online_python_insights = [\n",
        "    pd.DataFrame(bubble_client.get_objects(\n",
        "        \"python_insight\",\n",
        "        [\n",
        "            BubbleField(\"step\") == i+1,\n",
        "            BubbleField(\"company\") == company_id,\n",
        "            ],\n",
        "    )) for i in range(n_layers)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert [len(l) for l in insight_layers] == [len(l) for l in online_python_insights]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feedbacks_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = insight_layers[0]\n",
        "\n",
        "def get_all_parents(feedback_identifier):\n",
        "    parents = []\n",
        "    for i, row in df.loc[df['related_feedback'] == feedback_identifier].iterrows():\n",
        "        for parent in row['parents']:\n",
        "            parents.append(parent)\n",
        "    return parents\n",
        "\n",
        "feedbacks_df['parents'] = feedbacks_df['_id'].apply(get_all_parents)\n",
        "\n",
        "feedbacks_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _, row in tqdm(feedbacks_df.iterrows()):\n",
        "    res = bubble_client.update_object(\n",
        "        \"Feedbacks\",\n",
        "        row['_id'], \n",
        "        {\n",
        "            \"insights\": row[\"parents\"],\n",
        "        } \n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "res = bubble_client.get_objects(\n",
        "        \"Feedback\",\n",
        "        [\n",
        "            BubbleField(\"source\") == source_id,\n",
        "            ],\n",
        "    )\n",
        "pd.DataFrame(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "collapsed_sections": [
        "pKSREXZg85yy",
        "iiOlJz-d9AsB"
      ],
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
