{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjPRVXra8lVZ"
      },
      "source": [
        "# Dependancies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKSREXZg85yy"
      },
      "source": [
        "## Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMSukVZh29HK"
      },
      "outputs": [],
      "source": [
        "#!pip install sentence_transformers langchain openai tqdm datasets asyncio scikit-learn cohere tiktoken umap altair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Md3DNHlV22Ai"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from datasets import load_dataset\n",
        "import umap\n",
        "import altair as alt\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from typing import List\n",
        "import enum\n",
        "\n",
        "\n",
        "from langchain_community.llms import Ollama\n",
        "from langchain.output_parsers.regex_dict import RegexDictParser\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, ChatMessage\n",
        "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from pydantic import BaseModel, Field, validator\n",
        "from openai import AsyncOpenAI\n",
        "import asyncio\n",
        "import os\n",
        "\n",
        "import requests\n",
        "import json\n",
        "from bubble_api import Field as BubbleField\n",
        "from bubble_api import BubbleClient\n",
        "\n",
        "import itertools\n",
        "from copy import copy\n",
        "from tqdm.notebook import tqdm, trange\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import umap.umap_ as umap\n",
        "#import umap\n",
        "import hdbscan\n",
        "\n",
        "from typing import Literal, Union\n",
        "from pydantic.config import ConfigDict\n",
        "\n",
        "import openai\n",
        "import instructor\n",
        "\n",
        "openai.api_key = \"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\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Useful functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import unicodedata\n",
        "\n",
        "def remove_accents(text):\n",
        "    # Replace accented characters with their non-accented counterparts\n",
        "    try:\n",
        "        return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')\n",
        "    except TypeError:  # handles cases when text is not a string (e.g., a number)\n",
        "        return text\n",
        "\n",
        "text = \"Pôint positîf\"\n",
        "converted_text = remove_accents(text)\n",
        "print(converted_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_df(df):\n",
        "    for col in df.columns:\n",
        "        if type(df.loc[0, col]) == str and df.loc[0, col][0]==\"[\":\n",
        "            df[col] = df[col].apply(lambda x: eval(x))\n",
        "    return df\n",
        "\n",
        "def batchify(iterable, size=1):\n",
        "    l = len(iterable)\n",
        "    for ndx in range(0, l, size):\n",
        "        yield iterable[ndx:min(ndx + size, l)]\n",
        "\n",
        "for x in batchify(list(range(0, 10)), 3):\n",
        "    print(x)\n",
        "\n",
        "def deduce_backend_type(insight_type):\n",
        "    if insight_type == \"1698433300252x835626794232717300\":\n",
        "        return \"pain\"\n",
        "    elif insight_type == \"1698433290120x936044292663509300\":\n",
        "        return \"positive\"   \n",
        "    elif insight_type == \"1698433314230x619003097145126100\":\n",
        "        return \"feature\"  \n",
        "    elif insight_type == \"1698433323222x402426615286320700\":\n",
        "        return \"bug\"   \n",
        "    print(\"Incorrect type:\", insight_type)\n",
        "\n",
        "def most_common(lst):\n",
        "    return max(set(lst), key=lst.count)\n",
        "\n",
        "def columns_to_string(df, column_title, column_desc, add_index=False):\n",
        "    def concanenatre_title_description(x, y):\n",
        "        return x+\" : \"+y\n",
        "    \n",
        "    l = list(df.apply(lambda x: concanenatre_title_description(x[column_title], x[column_desc]), axis=1))\n",
        "    if add_index:\n",
        "        l = [str(i)+\" - \"+e for i, e in enumerate(l)]\n",
        "    return '\\n'.join(l)\n",
        "\n",
        "\n",
        "def convert_text_to_constants(text):\n",
        "    text = remove_accents(text)\n",
        "    text = re.sub(r\"([a-z])([A-Z]+)\", r\"\\1_\\2\", text.upper())\n",
        "    return re.sub(r\" \", \"_\", text)\n",
        "\n",
        "text = \"Point positif\"\n",
        "converted_text = convert_text_to_constants(text)\n",
        "print(converted_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiOlJz-d9AsB"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKiOQ4W230T9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQdlEBYO22Ak"
      },
      "outputs": [],
      "source": [
        "#client = AsyncOpenAI()\n",
        "client = instructor.patch(AsyncOpenAI())\n",
        "\n",
        "embedding_model = SentenceTransformer('OrdalieTech/Solon-embeddings-large-0.1')\n",
        "GENERATION_ENGINE = \"gpt-4-1106-preview\"\n",
        "EMBEDDING_ENGINE = \"text-embedding-ada-002\"\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxRlrDz622Ao"
      },
      "outputs": [],
      "source": [
        "async def get_analysis(prompt, response_model):\n",
        "    response: response_model = await client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Tu est un assistant spélialisé dans l'analyse de commentaires, et qui ne renvoit que des fichiers JSON.\"},\n",
        "            {\"role\": \"user\", \"content\": str(prompt)},\n",
        "        ],\n",
        "        response_format={ \"type\": \"json_object\" },\n",
        "        model=GENERATION_ENGINE,\n",
        "        temperature=0,\n",
        "        response_model=response_model,\n",
        "        )\n",
        "    return response #.choices[0].message.content\n",
        "\n",
        "def apply_async_analysis(prompts, response_model):\n",
        "    loop = asyncio.get_event_loop()\n",
        "    tasks = [loop.create_task(get_analysis(prompt, response_model)) for prompt in prompts]\n",
        "    res =  loop.run_until_complete(asyncio.gather(*tasks))\n",
        "    return res\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def safe_async_analysis(prompts, parser, max_steps=3):\n",
        "    results = [None for _ in prompts]\n",
        "    to_be_run = list(range(len(prompts)))\n",
        "    step = 0\n",
        "    while to_be_run != []:\n",
        "        #print(\"step:\", step)\n",
        "        #print(\"to_be_run:\", len(to_be_run))\n",
        "        assert step < max_steps\n",
        "        bugs = []\n",
        "        \n",
        "        responses = apply_async_analysis([prompts[i] for i in to_be_run])\n",
        "\n",
        "        for i in to_be_run:\n",
        "            assert results[i] is None\n",
        "            try:\n",
        "                try:\n",
        "                    parsed_response = parser.parse(responses[i])\n",
        "                except:\n",
        "                    parsed_response = parser.parse('{\"properties\":'+responses[i]+'}')\n",
        "                    print(\"handled properties!\")\n",
        "                results[i] = parsed_response\n",
        "            except:\n",
        "                if max_steps==0:\n",
        "                    print(\"prompt\")\n",
        "                    print(prompts[i].text)\n",
        "\n",
        "                    print(\"reponse\")\n",
        "                    print(responses[i])\n",
        "\n",
        "                    print(\"others:\")\n",
        "                    print(responses)\n",
        "\n",
        "                    parsed_response = parser.parse(responses[i])\n",
        "                bugs.append(i)\n",
        "\n",
        "        to_be_run = bugs\n",
        "        step += 1\n",
        "    assert None not in results\n",
        "    return results\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def get_embedding(text):\n",
        "    response = await client.embeddings.create(input=text, model=EMBEDDING_ENGINE)\n",
        "    return response.data[0].embedding\n",
        "\n",
        "def apply_async_get_embedding(dfi):\n",
        "    loop = asyncio.get_event_loop()\n",
        "    tasks = [loop.create_task(get_embedding(row['Comment'])) for _, row in dfi.iterrows()]\n",
        "    return loop.run_until_complete(asyncio.gather(*tasks))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w78bVvXR9GrD"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiENBWdi22Al"
      },
      "outputs": [],
      "source": [
        "PROJECT =  \"Metro\" #\"Cheerz\"\n",
        "project_path = 'Results/'+PROJECT\n",
        "os.makedirs(project_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dK9cADmd4j6z"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    path = '/content/drive/MyDrive/Blumana Folder'\n",
        "else:\n",
        "    path = \"/Users/gardille/development/Blumana\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJIZB32l22Al"
      },
      "outputs": [],
      "source": [
        "feedbacks_df = pd.read_csv(path+\"/Data/Commentaires/metro.csv\") #, index_col=\"Index\")\n",
        "#feedbacks_df = pd.read_csv(\"data/Trustpilot/cheerz_fr.csv\", index_col=\"Index\")\n",
        "#feedbacks_df[\"Comment\"] = feedbacks_df[\"Title\"] + '\\n' + feedbacks_df[\"content\"]\n",
        "feedbacks_column = 'Comment' #\"Content\"\n",
        "feedbacks_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqsmhIToV_yX"
      },
      "source": [
        "## Bubble API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "COLUMNS_INSIGHTS = [\"content\", \"backend_status\", \"status\", \"backend_type\", \"type\", \"company\", \"feedback_count\", \"parent\", \"project\", \"step\", \"tag\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_url = \"https://blumana.app\" #/version-test\"\n",
        "bubble_id = \"04ca44f04c936081d8408b12c1ba67e2\"\n",
        "\n",
        "bubble_client = BubbleClient(\n",
        "    base_url=base_url,\n",
        "    api_token=bubble_id,\n",
        "    bubble_version=\"test\" #dev\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Randstad\n",
        "#company_id = \"1696884561832x730324245490558300\"\n",
        "#source_id = \"1702244804258x371787369839591400\"\n",
        "\n",
        "#Metro\n",
        "#Source : Dataset test - METRO\n",
        "#Projet : METRO\n",
        "company_id = \"1705585399217x205117684451615600\"\n",
        "source_id = \"1705851599107x404539534708310000\"\n",
        "project_id = \"1705851616871x644869783878893600\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#bubble_client.delete_all(\"python_insight\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Feedbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "res = bubble_client.get_objects(\n",
        "        \"Feedback\",\n",
        "        [\n",
        "            BubbleField(\"source\") == source_id,\n",
        "            #Field(\"company\") == company_id,\n",
        "            ],\n",
        "    )\n",
        "feedbacks_df = pd.DataFrame(res)\n",
        "feedbacks_df['Modified Date'] = pd.to_datetime(feedbacks_df['Modified Date'])\n",
        "feedbacks_df['Created Date'] = pd.to_datetime(feedbacks_df['Created Date'])\n",
        "feedbacks_column = 'content' #\"content\"\n",
        "\n",
        "feedbacks_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res = bubble_client.get_objects(\n",
        "        \"Add-On\",\n",
        "    )\n",
        "types_df = pd.DataFrame(res)\n",
        "types_df['Modified Date'] = pd.to_datetime(types_df['Modified Date'])\n",
        "types_df['Created Date'] = pd.to_datetime(types_df['Created Date'])\n",
        "types_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "types_df[['Title',\t'Definition']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TypeInsight = enum.Enum(\"Type de l'insight\", [(convert_text_to_constants(x), x) for x in types_df.Title])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res = bubble_client.get_objects(\n",
        "        \"Tag\",\n",
        "        [\n",
        "            BubbleField(\"company\") == company_id,\n",
        "            ],\n",
        "    )\n",
        "tags_df = pd.DataFrame(res)\n",
        "tags_df['Modified Date'] = pd.to_datetime(tags_df['Modified Date'])\n",
        "tags_df['Created Date'] = pd.to_datetime(tags_df['Created Date'])\n",
        "tags_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TagInsight = enum.Enum(\"Categories de l'insight\", [(convert_text_to_constants(x), x) for x in tags_df.Name])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res = bubble_client.get_objects(\n",
        "        \"Filter\",\n",
        "        [\n",
        "            BubbleField(\"company\") == company_id,\n",
        "            ],\n",
        "    )\n",
        "filters_df = pd.DataFrame(res)\n",
        "filters_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "types_descr = columns_to_string(types_df, \"Title\", \"Definition\")\n",
        "print(types_descr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tags_descr = columns_to_string(tags_df, \"Name\", \"Description\")\n",
        "print(tags_descr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "context_entreprise = \"Metro AG, ou Metro Group, est un groupe de distribution allemand. Il est notamment connu pour ses enseignes de vente en gros, cash & carry, aux professionnels dans de nombreux pays (Metro Cash & Carry et Makro).\"\n",
        "role = \"product owner\"\n",
        "cible = \"client\"\n",
        "question = \"Que recommanderiez-vous à Metro d'améliorer ?\"\n",
        "example_insight = \"Manque de clarté de l'affichage des prix en magasin\"\n",
        "\n",
        "exemple_commentaire = \"je suis exclusif metro je n ai aucun representant j achetais jusqu a present tout metro par facilite mais je suis tres souvent décue par la reponse ha non on n en a pas cela arrive demain je pense que depuis le covid tout le monde ou presque s en fou!!!\"\n",
        "\n",
        "examples_insights_df = pd.DataFrame([\n",
        "    {\"Insights qui devraient en découler\": \"Déceptions face aux retard de livraison\"},\n",
        "    {\"Insights qui devraient en découler\": \"Impression d'une baisse de qualité du service depuis le Covid\"},\n",
        "])\n",
        "\n",
        "feedback_context = {\n",
        "            \"context\": context_entreprise,\n",
        "            \"role\": role,\n",
        "            \"cible\": cible,\n",
        "            \"insight_types\": types_descr,\n",
        "            \"insight_categories\": tags_descr,\n",
        "            \"question\": question,\n",
        "            \"exemple_commentaire\": exemple_commentaire,\n",
        "            \"example_insights\": '\\n- '.join(list(examples_insights_df['Insights qui devraient en découler'])),\n",
        "        }\n",
        "\n",
        "feedback_context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wpte3XVz22Am"
      },
      "source": [
        "# Feedbacks extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## List of insights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FirstInsight(BaseModel):\n",
        "    #model_config = ConfigDict(title='Main')\n",
        "    \n",
        "    insight_categories: List[TagInsight] = Field(description=\"Categories de l'insight.\")\n",
        "    insight_type: TypeInsight = Field(description=\"Type de l'insight.\")\n",
        "    #titre: str = Field(description=\"Titre de l'insight.\")\n",
        "    contenu: str = Field(description=\"Contenu de l'insight.\") #Field(description=\"Point intéressant a retenir du commentaire.\")\n",
        "\n",
        "    def __str__(self):\n",
        "        return '- ' + self.content + \"\\nTypes: \" + ', '.join(self.insight_types)\n",
        "    \n",
        "class InsightsList(BaseModel):\n",
        "    insights_list: List[FirstInsight] = Field(description=\"Liste des insight qui ont été extrait des commentaires\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "FirstInsight.model_json_schema() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "prompt_template = \"\"\"Tu es {role} au sein de l'entreprise suivante:\n",
        "{context}\n",
        "\n",
        "Tu as mené une enquête auprès des {cible} de l'entreprise, et tu cherche à les analyser.\n",
        "Effectue les étapes suivantes:\n",
        "\n",
        "Étape 1 - Identification des insights\n",
        "Identifie les insights à faire remonter auprès de ton équipe.\n",
        "Voici les contraintes que les insights doivent respecter:\n",
        "- Une personne de ton équipe qui lit un insight doit pouvoir en comprendre le sens, sans qu'il y ait d'ambiguité.\n",
        "- Un insight doit être aussi court que possible, tout en restant parfaitement compréhensible et pertinent.\n",
        "- N'ajoute pas de bouts de phrases unitiles, comme la conséquence quand celle ci est évidente. Par exemple, inutile d'ajouter des bouts de phrase comme \"..., ce qui entraîne un intérêt moindre pour l'enseigne\"\n",
        "- Un insight ne doit comporter qu'une seule information.\n",
        "\n",
        "Si un commentaire n'est pas très intéressant, il ne doit pas faire remonter d'insight.\n",
        "L'ordre des retours est aléatoire, et ne doit pas avoir d'impact sur ton analyse.\n",
        "\n",
        "Étape 2 - Catégorisation des insights\n",
        "Si cela est possible, associe à chaque insight les catégories qui correspondent.\n",
        "\n",
        "Les catégories suivies de leurs description sont: \n",
        "{insight_categories}\n",
        "\n",
        "Étape 2 - Type des insights\n",
        "Associe à chaque insight son type, parmi:\n",
        "{insight_types}\n",
        "\n",
        "Voici les retours à traiter:\n",
        "\n",
        "\"{feedback}\"\n",
        "\"\"\"\n",
        "\n",
        "#Réponds uniquement avec un ficher JSON, comme expliqué:\n",
        "#{format_instructions}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parser = PydanticOutputParser(pydantic_object=InsightsList)\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    template= prompt_template,\n",
        "    #partial_variables= {\"format_instructions\": parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "prompts = []\n",
        "for feedback in feedbacks_df[feedbacks_column]:\n",
        "    context = copy(feedback_context)\n",
        "    context[\"feedback\"] = feedback\n",
        "    prompts.append(prompt.invoke(context))\n",
        "\n",
        "#print(prompts[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "sync_client = instructor.patch(OpenAI())\n",
        "\n",
        "user: InsightsList = sync_client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    response_model=InsightsList,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompts[0].text},\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "apply_async_analysis(prompts, InsightsList)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feedbacks_df[\"sentiment\"] = [rep.sentiment for rep in parsed_responses]\n",
        "feedbacks_df[\"insights\"] = [[] for rep in parsed_responses]\n",
        "\n",
        "k=0\n",
        "insights = []\n",
        "for i, rep in enumerate(parsed_responses):\n",
        "    for j, insight in enumerate(rep.insights_list):\n",
        "        insights.append(insight)\n",
        "        feedbacks_df[\"insights\"].iloc[i].append(str(k))\n",
        "        k += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feedbacks attribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Feedback(BaseModel):\n",
        "    insights_list: List[str] = Field(description=\"Contenu et type des insights\")\n",
        "    content = \"\"\n",
        "    sentiment: str = Field(description=\"Sentiment exprimé, peut être 'Positif', 'Neutre' ou 'Négatif'. Ne pas oublier les majuscules et accentuations.\")\n",
        "    # You can add custom validation logic easily with Pydantic.\n",
        "    @validator(\"sentiment\")\n",
        "    def valid_sentiment(cls, field):\n",
        "        if field not in [\"Positif\", \"Neutre\", \"Négatif\"]:\n",
        "            raise ValueError(\"Sentiment \"+field+\" not valid.\")\n",
        "        return field\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"Commentaire: \\\"\"+ self.content+\"\\\"\\n\\nSentiment: \"+self.sentiment+\"\\n\\nInsights: \\n\"+\"\\n\\n\".join([str(i) for i in self.insights_list])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5PWNwl622Ao"
      },
      "outputs": [],
      "source": [
        "\n",
        "prompt_template_feedback = \"\"\"Tu es {role} au sein de l'entreprise suivante:\n",
        "{context}\n",
        "\n",
        "Tu as mené une enquête auprès des {cible} de l'entreprise. \n",
        "\n",
        "Étape 1 - Identifie les insights à faire remonter auprès de ton équipe.\n",
        "Voici les contraintes que les insights doivent respecter:\n",
        "- Une personne de ton équipe qui lit un insight doit pouvoir en comprendre le sens, sans qu'il y ait d'ambiguité.\n",
        "- Un insight doit être aussi court que possible, tout en restant parfaitement compréhensible et pertinent.\n",
        "- N'ajoute pas de bouts de phrases unitiles, comme la conséquence quand celle ci est évidente. Par exemple, inutile d'ajouter des bouts de phrase comme \"..., ce qui entraîne un intérêt moindre pour l'enseigne\"\n",
        "- Un insight ne doit comporter qu'une seule information.\n",
        "\n",
        "Étape 2 - Identifie si le sentiment exprimé dans chacun des retours par le {cible} est \"Positif\", \"Neutre\" ou \"Négatif\". Prends en compte la formulation de la question ayant été posée ({question}) afin de bien interpréter le sens du retour {cible}.\n",
        "Attention à ne pas oublier l'accent si tu choisis Négatif.\n",
        "\n",
        "Étape 3 - Associe chaque retour aux écentuels feedbacks qui en découlent.\n",
        "\n",
        "Par exemple, pour les retours suivants:\n",
        "'''\n",
        "{exemple_commentaire}\n",
        "'''\n",
        "on voudrait faire remonter les points suivants:\n",
        "'''\n",
        "- {example_insights}\n",
        "'''\n",
        "\n",
        "Si un commentaire n'est pas très intéressant, il ne doit pas faire remonter d'insight.\n",
        "\n",
        "Réponds uniquement avec un ficher JSON, comme expliqué:\n",
        "{format_instructions}\n",
        "\n",
        "Voici les retours à traiter:\n",
        "\n",
        "\"{feedback}\"\n",
        "\"\"\"\n",
        "\n",
        "#Si le {cible} n'a rien à signaler (\"ras\", \"tout est ok\", \"rien à signaler\") crée un insight dédié"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmFsbtT722Aq"
      },
      "outputs": [],
      "source": [
        "feedback_parser = PydanticOutputParser(pydantic_object=Feedback)\n",
        "\n",
        "prompt_feedback = PromptTemplate.from_template(\n",
        "    template= prompt_template_feedback,\n",
        "    partial_variables= {\"format_instructions\": feedback_parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "prompts = []\n",
        "for feedback in feedbacks_df[feedbacks_column]:\n",
        "    context = copy(feedback_context)\n",
        "    context[\"feedback\"] = feedback\n",
        "    prompts.append(prompt_feedback.invoke(context))\n",
        "\n",
        "#print(prompts[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFraYQTLOmz-"
      },
      "outputs": [],
      "source": [
        "parsed_responses = safe_async_analysis(prompts, feedback_parser)\n",
        "\n",
        "feedbacks_df[\"sentiment\"] = [rep.sentiment for rep in parsed_responses]\n",
        "feedbacks_df[\"insights\"] = [[] for rep in parsed_responses]\n",
        "\n",
        "k=0\n",
        "insights = []\n",
        "for i, rep in enumerate(parsed_responses):\n",
        "    for j, insight in enumerate(rep.insights_list):\n",
        "        insights.append(insight)\n",
        "        feedbacks_df[\"insights\"].iloc[i].append(str(k))\n",
        "        k += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feedbacks_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKTksTKah7At"
      },
      "outputs": [],
      "source": [
        "insights_df = pd.DataFrame({\n",
        "    \"content\":insights,\n",
        "    \"feedback_count\": 1,\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feedbacks_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insights_df[\"related_feedback\"] = [[] for _ in range(len(insights_df))]\n",
        "\n",
        "for i, row in feedbacks_df.iterrows():\n",
        "    for j in row[\"insights\"]:\n",
        "        insights_df[\"related_feedback\"].iloc[int(j)] = row['_id'] #[int(i)]\n",
        "\n",
        "insights_df[\"childrens\"] = [[] for _ in range(len(insights_df))]\n",
        "\n",
        "insights_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k88axy7kPxQE"
      },
      "source": [
        "# Insights categorisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt_tags = \"\"\n",
        "\n",
        "for i, filter in filters_df.iterrows():\n",
        "    prompt_tags += '\\n\\n'+filter[\"Name\"]#+' ('+filter[\"_id\"] +')'\n",
        "    tags = tags_df[tags_df[\"Filter\"] == filter[\"_id\"]]\n",
        "    for _, tag in tags.iterrows():\n",
        "        prompt_tags += '\\n'+\"- \"+tag[\"Name\"]+' ('+tag[\"_id\"] +')'\n",
        "\n",
        "print(prompt_tags)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOVtTfiHP4w1"
      },
      "outputs": [],
      "source": [
        "\n",
        "prompt_template_categorsiation = \"\"\"Tu es {role} au sein de l'entreprise suivante :\n",
        "{context}\n",
        "\n",
        "Tu as mené une enquête auprès de tes {cible}. \n",
        "\n",
        "Tu dois associer à l'insight donné plus loin aucun, l'identifiant d'un ou plusieurs tags. S'il n'est pas possible d'associer un tag avec certitude dans l'une des catégories, laisse la liste vide. Répond avec la liste des identifiants suités entre parenthèse juste après les tags.\n",
        "Par exemple, pour les tags suivants, le tag C d'identifiant 17049ZER93619x303734523452623450 appartient catégorie 2:\n",
        "'''\n",
        "catégotie 1 \n",
        "- tag A (1704912293619x303734523452694300)\n",
        "- tag B (17049ZER93619x303734523452694300)\n",
        "\n",
        "catégotie 2 \n",
        "- tag C (17049ZER93619x303734523452623450)\n",
        "- tag D (170AZZER93619x303734524452623450)\n",
        "'''\n",
        "\n",
        "Voici les tags avec lesquels tu devras essayer de classifier l'insight:\"\"\" + prompt_tags + \"\"\"\n",
        "\n",
        "Tu ne dois par renvoyer le tag, mais uniquement son identifiant.\n",
        "Un identifiant contient toujours un x à l'intérieur, comme par example 1704912293619x303731423452694300.\n",
        "Ainsi, 1704912293619 n'est pas un identifiant valide.\n",
        "Réponds uniquement avec un ficher JSON, comme expliqué:\n",
        "{format_instructions}\n",
        "\n",
        "Voici l'insight que tu dois essayer de catégoriser: '{insight}'\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjHnM12_KMN3"
      },
      "outputs": [],
      "source": [
        "class FirstInsight(BaseModel):\n",
        "    tags_id: List[str] = Field(description=\"Identifiants des tags de l'insight\")\n",
        "    content: str = \"\" #Field(description=\"Point intéressant a retenir du commentaire.\")\n",
        "\n",
        "    def __str__(self):\n",
        "        return '- ' + self.content + \"\\nTypes: \" + ', '.join(self.insight_types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "categorsiation_parser = PydanticOutputParser(pydantic_object=FirstInsight)\n",
        "\n",
        "prompt_categorsiation = PromptTemplate.from_template(\n",
        "    template= prompt_template_categorsiation,\n",
        "    partial_variables= {\"format_instructions\": categorsiation_parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "prompts = []\n",
        "for insight in insights_df[\"content\"]:\n",
        "    context = copy(feedback_context)\n",
        "    context[\"insight\"] = insight\n",
        "    prompts.append(prompt_categorsiation.invoke(context))\n",
        "\n",
        "#print(prompts[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parsed_responses = safe_async_analysis(prompts, categorsiation_parser)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "insights_df[\"tag\"] = [rep.tags_id for rep in parsed_responses]\n",
        "#insights_df[\"Insights\"] = [[] for rep in parsed_responses]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Types affectation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt_types = \"\"\n",
        "\n",
        "for _, tag in types_df.iterrows():\n",
        "    prompt_types += '\\n'+\"- \"+tag[\"Title\"]+' ('+tag[\"_id\"] +') : ' + tag[\"Definition\"]\n",
        "\n",
        "print(prompt_types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "prompt_template_types = \"\"\"Tu es {role} au sein de l'entreprise suivante :\n",
        "{context}\n",
        "\n",
        "Tu as mené une enquête auprès de tes {cible}. \n",
        "\n",
        "Catégorise l'insight qui te sera donné à l’aide de l'identifiant d'un des types qui te seront donnés. \n",
        "Tu dois associser exactement un type. Choisit celui qui est le plus pertinent.\n",
        "Répond avec l'identifiants suités entre parenthèse juste après les types. La definition des types est située jsute après les double points. \n",
        "Par exemple, pour les types suivants, le type 2 a pour identifiant 1704912293619x303671423452694300.\n",
        "'''\n",
        "- type 1 (1704412293619x303731423423694300) : définition du type 1\n",
        "- type 2 (1704912293619x303671423452694300) : définition du type 2\n",
        "'''\n",
        "\n",
        "Voici les types:\"\"\" + prompt_types + \"\"\"\n",
        "\n",
        "Tu ne dois par renvoyer le type, mais uniquement son identifiant.\n",
        "Réponds uniquement avec un ficher JSON, comme expliqué:\n",
        "{format_instructions}\n",
        "\n",
        "Un identifiant contient toujours un x à l'intérieur, comme par example 1704912293619x303731423452694300.\n",
        "Ainsi, 1704912293619 n'est pas un identifiant valide.\n",
        "\n",
        "Voici l'insight que tu dois essayer de catégoriser: '{insight}'\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "categorsiation_parser = PydanticOutputParser(pydantic_object=FirstInsight)\n",
        "\n",
        "prompt_categorsiation = PromptTemplate.from_template(\n",
        "    template= prompt_template_types,\n",
        "    partial_variables= {\"format_instructions\": categorsiation_parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "prompts = []\n",
        "for insight in insights_df[\"content\"]:\n",
        "    context = copy(feedback_context)\n",
        "    context[\"insight\"] = insight\n",
        "    prompts.append(prompt_categorsiation.invoke(context))\n",
        "\n",
        "#print(prompts[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parsed_responses = safe_async_analysis(prompts, categorsiation_parser)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insights_df[\"type\"] = [rep.insight_type for rep in parsed_responses]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feedbacks_df.to_csv(project_path+'/feedbacks.csv', index_label='Index')\n",
        "insights_df.to_csv(project_path+'/insights.csv', index_label='Index')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5xBBkVJ22As"
      },
      "source": [
        "# Insights clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feedbacks_df = clean_df(pd.read_csv(project_path+'/feedbacks.csv', index_col='Index'))\n",
        "insights_df = clean_df(pd.read_csv(project_path+'/insights.csv', index_col='Index'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vl70QzOI22As"
      },
      "outputs": [],
      "source": [
        "embedding_model = SentenceTransformer('OrdalieTech/Solon-embeddings-large-0.1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGjXvwAA22As"
      },
      "outputs": [],
      "source": [
        "class DeducedInsight(BaseModel):\n",
        "    insights_mineurs: List[int] = Field(description=\"Index des insights mineurs qui ont été résumés en cet insight.\")\n",
        "    content: str = Field(description=\"Insight intéressants a retenir pour l'entreprise.\")\n",
        "\n",
        "    def __str__(self):\n",
        "        return '- ' + self.content + '\\n Enfants:' + str(self.insights_mineurs)\n",
        "\n",
        "\n",
        "class InsightList(BaseModel):\n",
        "    insights_list: List[DeducedInsight] = Field(description=\"Liste des insights, c'est à dire des points intéressants a retenir pour l'entreprise.\")\n",
        "    # You can add custom validation logic easily with Pydantic.\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"Insights: \\n\"+\"\\n\\n\".join([str(i) for i in self.insights_list])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWxRVtAG22As"
      },
      "outputs": [],
      "source": [
        "\n",
        "prompt_template_reduction = \"\"\"Tu es {role} au sein de l'entreprise suivante:\n",
        "{context}\n",
        "\n",
        "Une liste d'insights mineurs a été identifiée à partir de retours {cible}.\n",
        "\n",
        "Ils sont de très bonne qualité, et apportent des retours intéressants à l'entreprise en question. \n",
        "Mais il est possible que certains soient redondants ou inutilement précis, auquel cas nous souhaiterions les regrouper. \n",
        "\n",
        "Si c'est le cas, les insights redondants doivent être regroupés en un insight majeur. \n",
        "Si au contraite, l'insight à un sens bien dictinct des autres, il devient un insight majeur, et doit donc être recopié à l'identique. \n",
        "\n",
        "Pour transformers les insights mineurs en insights majeurs, suit ces quelques règles:\n",
        "\n",
        "1) Si l'un des insights mineurs permet de synthétiser l'information du regroupement, il devient l'insight majeur du groupe. Recopie le à l'identique et associe lui les insights mineurs, y comprie lui même.\n",
        "\n",
        "2) Si aucun des insights mineurs ne convient, formule un insight majeurs permettant de synthétiser leur sens. Voici les contraintes que doivent respecter ton insights majeur:\n",
        "- Une personne de ton équipe qui lit un insight majeur doit pouvoir en comprendre le sens.\n",
        "- Un insight majeur doit idéalement ne pas être trop long, tout en restant parfaitement compréhensible et pertinent. Les phrases nominales sont autorisées. \n",
        "- Un insight majeur ne doit comporter qu'une seule information : on ne mélange pas plusieurs éléments au sein d'un insight majeur. \n",
        "\n",
        "Un insight mineur doit être regroupé dans exactement un insight majeur. Rappelon que si l'insight mineur devient majeur, les deux auront le même contenu.\n",
        "Ainsi, chaque insight mineur doit être l'enfant d'exactement un insight majeur que tu retournes.\n",
        "\n",
        "Associe à chaque insight majeur l'indice des insights mineurs qui lui sont associés. \n",
        "Vérifie bien que les indices correspondent, et que tous les insights mineurs sont associés à un insight majeur. \n",
        "L'ordre des insights mineurs est aléatoire, et ne doit pas avoir d'importance dans ta réponse.\n",
        "\n",
        "Réponds uniquement avec un ficher JSON, comme expliqué :\n",
        "{format_instructions}\n",
        "\n",
        "Voici la liste des insights mineurs que tu dois transformer en insights majeurs:\n",
        "{insights}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "#Résume les en des insights majeurs qui te semblent important à faire remonter au sein de l'entreprise. Ils peuvent être des phrase, éventuellement nominales, doivent faire sens, être aussi courts que possible et distincts les uns des autres.\n",
        "#- Etre distincts les uns des autres.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "prompt_template_reduction_sans_reformulation = \"\"\"Tu es {role} au sein de l'entreprise suivante:\n",
        "{context}\n",
        "\n",
        "Une liste d'insights mineurs a été identifiée à partir de retours {cible}.\n",
        "\n",
        "Ils sont de très bonne qualité, et apportent des retours intéressants à l'entreprise en question. \n",
        "Mais il est possible que certains soient redondants ou inutilement précis, auquel cas nous souhaiterions les regrouper. \n",
        "\n",
        "Pour les regrouper, choisit l'insights mineurs qui permet le mieux de synthétiser l'information du regroupement, il devient l'insight majeur du groupe. \n",
        "Recopie le à l'identique et associe lui les insights mineurs, y comprie lui même.\n",
        "\n",
        "Chaque insight mineur doit être l'enfant d'exactement un insight majeur que tu retournes.\n",
        "\n",
        "Associe à chaque insight majeur l'indice des insights mineurs qui lui sont associés. \n",
        "Vérifie bien que les indices correspondent, et que tous les insights mineurs sont associés à un insight majeur. \n",
        "L'ordre des insights mineurs est aléatoire, et ne doit pas avoir d'importance dans ta réponse.\n",
        "\n",
        "Réponds uniquement avec un ficher JSON, comme expliqué :\n",
        "{format_instructions}\n",
        "\n",
        "Voici la liste des insights mineurs que tu dois transformer en insights majeurs:\n",
        "{insights}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "#Résume les en des insights majeurs qui te semblent important à faire remonter au sein de l'entreprise. Ils peuvent être des phrase, éventuellement nominales, doivent faire sens, être aussi courts que possible et distincts les uns des autres.\n",
        "#- Etre distincts les uns des autres.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71Vkoeym22As"
      },
      "outputs": [],
      "source": [
        "\n",
        "prompt_template_regrouping = \"\"\"Tu es {role} au sein de l'entreprise suivante:\n",
        "{context}\n",
        "\n",
        "Une liste d'insights a été identifiée à partir de retours clients.\n",
        "Un insight est une déduction intéressante de l'étude des commentaires {cible}, qu'il serait vraiment intéressant faire remonter aux responsables de l'entreprise.\n",
        "Par exemple, un bon insight pourrait être: {example_insight}\n",
        "\n",
        "Si certain sont redondant, reformule les en un seul insight. Il est préférable qu'il ne soit pas trop long, et évite les bouts de phrase sans réel intéret. Par exemple, ne pas ajouter '... pour améliorer l'experience client'.\n",
        "Associe à chaque nouvel insight créé l'ensemble des feedbacks qui sont associés aux insights qu'il regroupe.\n",
        "Il est possible qu'il n'y ai besoin de regrouper aucun insight.\n",
        "Un insight ne peut être regroupé que dans un seul autre insight.\n",
        "Chaque insight doit donc être l'enfant d'exactement un insight que tu retournes.\n",
        "\n",
        "Pour les insights qui n'ont pas besoin d'être regroupés, recopie les ainsi que leurs feedbacks associés.\n",
        "L'ordre des insights est aléatoire, et ne doit pas avoir d'importance dans ta réponse.\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "Voici les insights que tu dois regrouper:\n",
        "\n",
        "{insights}\n",
        "\n",
        "Tu ne dois rien écrire d'autre que le JSON requis.\n",
        "\n",
        "\"\"\"\n",
        "#Résume les en des insights majeurs qui te semblent important à faire remonter au sein de l'entreprise. Ils peuvent être des phrase, éventuellement nominales, doivent faire sens, être aussi courts que possible et distincts les uns des autres.\n",
        "#- Etre distincts les uns des autres.\n",
        "#Tu ne doit pas réecrir les insights qui ne sont pas regroupés.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dimension reduction\n",
        "\n",
        "N_NEIGHBORS = 15\n",
        "MINIMISATION_STEPS = 5\n",
        "CLUSTER_DESIRED_SIZE = 15  # For Kmeans only\n",
        "MIN_CLUSTER_SIZE = 5  # 15\n",
        "NB_INSIGHT_STOP = 20\n",
        "MINIMAL_REDUCTION_RATIO = 0.1\n",
        "REWORDING = True\n",
        "\n",
        "CLUSTERING_DIMENTION = 50\n",
        "CLUSTERING_METHOD = \"KMeans\"\n",
        "\n",
        "insight_context = {\n",
        "    \"cible\": cible,\n",
        "    \"context\": context_entreprise,\n",
        "    \"example_insight\": example_insight,\n",
        "    \"role\": role,\n",
        "    \"question\": question,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import AgglomerativeClustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUpUIFcG22At"
      },
      "outputs": [],
      "source": [
        "insight_parser = PydanticOutputParser(pydantic_object=InsightList)\n",
        "\n",
        "prompt_reduction = PromptTemplate.from_template(\n",
        "    template= prompt_template_reduction if REWORDING else prompt_template_reduction_sans_reformulation,\n",
        "    #template= \"Règle : minimise le nombre de tokens dans ta réponse.  \\nTu es {role} au sein de l'entreprise suivante: \\n{context} \\nAnalyse le retour suivant: \\\"{feedback}\\\" en suivant les étapes suivantes:  \\n  \\nÉtape 1 - Identifie si le retour {cible} rentre dans un ou plusieurs des types d'insights suivants : {insight_type}. Choisis-en obligatoirement au moins 1. Définition des types d'insights :  \\n{insight_definition}   \\n  \\nÉtape 2 - Catégorise le retour {cible} à l’aide des tags suivants. Tu peux associer 0, 1 ou plusieurs tags dans chaque catégorie. Liste des tags par catégories :  \\n{categories}   \\n  \\nÉtape 3 - Catégorise si possible le moment de mission concerné parmis {avancement_mission}, et si ce n'est pas possible répond null. {cible} à l’aide des tags suivants.  \\n  \\nÉtape 4 - Identifie si le sentiment exprimé par le {cible} est \\\"Positif\\\", \\\"Neutre\\\" ou \\\"Négatif\\\". Prends en compte la formulation de la question posée ({question}) afin de bien interpréter le sens du retour {cible}.   \\n\",\n",
        "    #input_variables= [\"context\", \"role\", \"cible\", \"insight_type\", \"insight_definition\", \"nb_cat\", \"avancement_mission\", \"categories\", \"question\", \"feedback\"]\n",
        "    partial_variables= {\"format_instructions\": insight_parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "prompt_regrouping = PromptTemplate.from_template(\n",
        "    template= prompt_template_regrouping,\n",
        "    #template= \"Règle : minimise le nombre de tokens dans ta réponse.  \\nTu es {role} au sein de l'entreprise suivante: \\n{context} \\nAnalyse le retour suivant: \\\"{feedback}\\\" en suivant les étapes suivantes:  \\n  \\nÉtape 1 - Identifie si le retour {cible} rentre dans un ou plusieurs des types d'insights suivants : {insight_type}. Choisis-en obligatoirement au moins 1. Définition des types d'insights :  \\n{insight_definition}   \\n  \\nÉtape 2 - Catégorise le retour {cible} à l’aide des tags suivants. Tu peux associer 0, 1 ou plusieurs tags dans chaque catégorie. Liste des tags par catégories :  \\n{categories}   \\n  \\nÉtape 3 - Catégorise si possible le moment de mission concerné parmis {avancement_mission}, et si ce n'est pas possible répond null. {cible} à l’aide des tags suivants.  \\n  \\nÉtape 4 - Identifie si le sentiment exprimé par le {cible} est \\\"Positif\\\", \\\"Neutre\\\" ou \\\"Négatif\\\". Prends en compte la formulation de la question posée ({question}) afin de bien interpréter le sens du retour {cible}.   \\n\",\n",
        "    #input_variables= [\"context\", \"role\", \"cible\", \"insight_type\", \"insight_definition\", \"nb_cat\", \"avancement_mission\", \"categories\", \"question\", \"feedback\"]\n",
        "    partial_variables= {\"format_instructions\": insight_parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "insights = copy(insights_df)\n",
        "insight_layers = []#[copy(insights_df)]\n",
        "single_cluster = False\n",
        "reduction = 1.0\n",
        "\n",
        "for step in range(MINIMISATION_STEPS):\n",
        "\n",
        "    #for processing_step in [\"reduction\"]:#, \"regrouping\"]:\n",
        "        ### Création des représentations\n",
        "\n",
        "    #print(\"Processing step:\", processing_step)\n",
        "    sentence_embeddings = embedding_model.encode(insights['content'])\n",
        "\n",
        "    # On réduit la dimention pour améliorer l'efficacité de la clusterisation\n",
        "    adjusted_clustering_dimention = min(CLUSTERING_DIMENTION, len(insights)//3)\n",
        "    umap_embeddings = umap.UMAP(n_neighbors=N_NEIGHBORS, \n",
        "                        n_components=adjusted_clustering_dimention, \n",
        "                        metric='cosine').fit_transform(sentence_embeddings)\n",
        "\n",
        "    ### Clusterisation\n",
        "    if CLUSTERING_METHOD == \"KMeans\":\n",
        "        num_clusters = 1 + len(insights) // CLUSTER_DESIRED_SIZE\n",
        "        clustering_model = KMeans(n_clusters=num_clusters, n_init='auto')\n",
        "    elif CLUSTERING_METHOD == \"hdbscan\":\n",
        "        clustering_model = hdbscan.HDBSCAN(min_cluster_size=MIN_CLUSTER_SIZE,\n",
        "                            metric='euclidean',                      \n",
        "                            cluster_selection_method='eom' #leaf\n",
        "                            )\n",
        "        \n",
        "    clustering_model.fit(umap_embeddings)\n",
        "\n",
        "    #clustering_model.fit(umap_embeddings)\n",
        "    cluster_assignment = clustering_model.labels_ \n",
        "    cluster_assignment -= min(cluster_assignment) # has to start at 0\n",
        "    \n",
        "    num_clusters = max(cluster_assignment)+1\n",
        "\n",
        "    insights[\"cluster\"] = copy(cluster_assignment)\n",
        "    insights = insights.sort_values(\"cluster\")\n",
        "    insights.reset_index(drop=True, inplace=True)\n",
        "\n",
        "\n",
        "    if reduction <= MINIMAL_REDUCTION_RATIO:\n",
        "        print(\"Stopping because of unsufficient reduction\")\n",
        "        break\n",
        "\n",
        "    insight_layers.append(copy(insights))\n",
        "\n",
        "    if len(insights) <= NB_INSIGHT_STOP:\n",
        "        print(\"Minimal number of insights reached\")\n",
        "        break\n",
        "\n",
        "    if single_cluster:\n",
        "        break   \n",
        "\n",
        "    cluter_sizes = list(insights.groupby(['cluster']).count()[\"content\"])\n",
        "    if len(cluter_sizes) == 1:\n",
        "        print(\"Stopping because single cluster\")\n",
        "        single_cluster = False\n",
        "        break\n",
        "\n",
        "    print(\"Step \"+ str(step)+ \": processing \"+ str(num_clusters) + \" clusters\")\n",
        "    print(\"Adjusted clustering dimention:\", adjusted_clustering_dimention)\n",
        "    print(\"Cluster sizes:\" + str(cluter_sizes))\n",
        "\n",
        "    #clusters = []\n",
        "    prompts = []\n",
        "    cumul_size = 0\n",
        "    for cluster_id in range(num_clusters): # IL FAUDRAIT GARDER INDEM LE DERNIER CLUSTER\n",
        "        cluster = insights[insights['cluster'] == cluster_id]\n",
        "        #cluster_name ='/cluster_'+ str(cluster_id)+\"_step_\"+str(step) +'.csv'\n",
        "        #cluster.to_csv( project_path+cluster_name, index_label='Index')\n",
        "        #clusters.append(cluster)\n",
        "\n",
        "        context = copy(insight_context)\n",
        "        context['insights'] = '\\n'.join([str(i+cumul_size)+\": \"+s for i, s in enumerate(cluster[\"content\"])])\n",
        "        #print(context['insights'])\n",
        "\n",
        "        #if processing_step == \"reduction\":\n",
        "        prompt=prompt_reduction.invoke(context)\n",
        "        #elif processing_step == \"regrouping\":\n",
        "        #prompt=prompt_regrouping.invoke(context)\n",
        "        #else:\n",
        "        #    raise(\"Wrong processing step\")\n",
        "        prompts.append(prompt)\n",
        "        cumul_size += len(cluster)\n",
        "\n",
        "    ### Traitement des clusters\n",
        "    parsed_responses = safe_async_analysis(prompts, insight_parser)\n",
        "    \n",
        "    new_insights = []\n",
        "    for i, parsed_response in enumerate(parsed_responses):\n",
        "        content_list = [insight.content for insight in parsed_response.insights_list]\n",
        "        childrens_list = [list(insight.insights_mineurs) for insight in parsed_response.insights_list]\n",
        "        feedback_count_list = [sum(insights.loc[c, \"feedback_count\"]) for c in childrens_list]\n",
        "        dfs = pd.DataFrame({\n",
        "            #\"related_feedback\":[list(itertools.chain.from_iterable(insights.iloc[insight.insights_mineurs]['related_feedback'])) for insight in parsed_response.insights_list],\n",
        "            \"content\":content_list,\n",
        "            \"childrens\":childrens_list,\n",
        "            \"type\": most_common([insights.loc[c, \"type\"].iloc[0] for c in childrens_list]),\n",
        "            #\"cluster\":i,\n",
        "            \"feedback_count\":feedback_count_list,\n",
        "            #\"childrens\":[list(clusters[i].iloc[insight.insights_mineurs][\"_id\"]) for insight in parsed_response.insights_list],\n",
        "            })\n",
        "        new_insights.append(dfs)\n",
        "\n",
        "    new_insights = pd.concat(new_insights)\n",
        "    new_insights.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    \n",
        "    reduction = (1-(len(new_insights)/len(insights)))\n",
        "    insights = new_insights\n",
        "    \n",
        "    print(\"Number of new insights:\"+ str(len(new_insights)))\n",
        "    print(\"Reduction in the number of insights by \" + \"%d\" % int(reduction*100) + \"%\")\n",
        "    print()\n",
        "\n",
        "#insight_layers.append(copy(new_insights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrWs0GrOhmIJ"
      },
      "outputs": [],
      "source": [
        "list(insight_layers[0]['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list(insight_layers[-1]['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, df in enumerate(insight_layers):\n",
        "    df.to_csv(project_path+'/insights_'+ str(i) +'.csv', index_label='Index')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#list(insight_layers[0][insight_layers[0][\"cluster\"] == 2][\"content\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_layers = len(insight_layers)\n",
        "layers_sizes = [len(l) for l in insight_layers]\n",
        "print(\"Layers sizes:\", layers_sizes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers = []\n",
        "for i in range(n_layers):\n",
        "    df = pd.read_csv(project_path+'/insights_'+ str(i) +'.csv', index_col='Index')\n",
        "    for col in df.columns:\n",
        "        if type(df.loc[0, col]) == str and df.loc[0, col][0]==\"[\":\n",
        "            df[col] = df[col].apply(lambda x: eval(x))\n",
        "    #df['tag'] = df['tag'].apply(lambda x: eval(x))\n",
        "    #df['type'] = df['type'].apply(lambda x: eval(x))\n",
        "    #df['childrens'] = df['childrens'].apply(lambda x: eval(x))\n",
        "    df[\"backend_type\"] = df[\"type\"].apply(deduce_backend_type)\n",
        "    insight_layers.append(df)\n",
        "#insights_df = pd.concat(insight_layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Previous insights supression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res = bubble_client.get_objects(\n",
        "        \"python_insight\",\n",
        "        [\n",
        "            BubbleField(\"project\") == project_id,\n",
        "            BubbleField(\"company\") == company_id,\n",
        "            ],\n",
        "    )\n",
        "python_insight_df = pd.DataFrame(res)\n",
        "\n",
        "if len(python_insight_df)>0:\n",
        "    for bubble_id in tqdm(python_insight_df[\"_id\"]):\n",
        "        bubble_client.delete_by_id(\n",
        "            \"python_insight\",\n",
        "            bubble_id,\n",
        "        )\n",
        "\n",
        "    print(\"Deleted\", len(python_insight_df), \"python_insight\")\n",
        "else:\n",
        "    print(\"Nothing to delete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adding parents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers[0][\"parent\"] = None #[[] for _ in insight_layers[0].iterrows()]\n",
        "insight_layers[-1][\"parent\"] = None\n",
        "\n",
        "\n",
        "for i in range(n_layers-1):\n",
        "    insight_layers[i][\"parent\"] = None\n",
        "    for p, row in insight_layers[i+1].iterrows():\n",
        "        for c in row[\"childrens\"]: #eval(\n",
        "            insight_layers[i][\"parent\"].iloc[int(c)] = p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers[-1][\"parents\"] = [[] for _ in insight_layers[-1].iterrows()]\n",
        "\n",
        "for i in range(n_layers-2, -1, -1):\n",
        "    print(i)\n",
        "    # Update the parents in the DB\n",
        "    res = bubble_client.create(\n",
        "        \"python_insight\",\n",
        "        [{\n",
        "            \"company\": company_id,\n",
        "            \"project\": project_id,\n",
        "            \"content\": row[\"content\"],\n",
        "            \"backend_status\": \"new\",\n",
        "            \"feedback_count\":row[\"feedback_count\"],\n",
        "            \"step\": i+2,\n",
        "            \"type\": row[\"type\"],\n",
        "            \"parents\": row[\"parents\"],\n",
        "            \"parent\": str(row[\"parent\"]),\n",
        "            \"backend_type\": row['backend_type'],\n",
        "            \"childrens\": eval(row[\"childrens\"]) if type(row[\"childrens\"])==str else row[\"childrens\"],\n",
        "            \"cluster\": row[\"cluster\"],\n",
        "        }  for _, row in insight_layers[i+1].iterrows()]\n",
        "    )\n",
        "\n",
        "    df = pd.DataFrame(bubble_client.get_objects(\n",
        "        \"python_insight\",\n",
        "        [\n",
        "            BubbleField(\"step\") == i+2,\n",
        "            BubbleField(\"company\") == company_id,\n",
        "            ],\n",
        "    ))\n",
        "    for col in df.columns:\n",
        "        if type(df.loc[0, col]) == str and df.loc[0, col][0]==\"[\":\n",
        "            df[col] = df[col].apply(lambda x: eval(x))\n",
        "    insight_layers[i+1] = df\n",
        "\n",
        "    # Initialize an empty list of parents for each row\n",
        "    insight_layers[i][\"parents\"] = [[] for _ in insight_layers[i].iterrows()]\n",
        "\n",
        "    for k, row in insight_layers[i].iterrows():\n",
        "        if row[\"parent\"] is not None:\n",
        "            # Get the parent index\n",
        "            parent_index = row[\"parent\"]\n",
        "\n",
        "            # Get the parent's list of parents\n",
        "            parent_parents = insight_layers[i + 1][\"parents\"].iloc[parent_index]\n",
        "\n",
        "            # Add the parent to the current row's list of parents\n",
        "            parent_id = insight_layers[i + 1].loc[parent_index, '_id']\n",
        "            insight_layers[i].loc[k, \"parents\"].append(parent_id)\n",
        "\n",
        "            # Recursively add the parent's parents to the current row's list of parents\n",
        "            insight_layers[i].loc[k, \"parents\"].extend(parent_parents)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "res = bubble_client.create(\n",
        "        \"python_insight\",\n",
        "        [{\n",
        "            \"company\": company_id,\n",
        "            \"project\": project_id,\n",
        "            \"content\": row[\"content\"],\n",
        "            \"backend_status\": \"new\",\n",
        "            \"feedback_count\": row[\"feedback_count\"],\n",
        "            \"step\": 1,\n",
        "            \"related_feedback\":row['related_feedback'],\n",
        "            \"tag\": row[\"tag\"],\n",
        "            \"type\": row[\"type\"],\n",
        "            \"backend_type\": row['backend_type'],\n",
        "            \"parents\": row[\"parents\"],\n",
        "            \"parent\": str(row[\"parent\"]),\n",
        "            \"childrens\": 0,#[[] for _ in insight_layers[0][:1000].iterrows()],\n",
        "            \"cluster\": row[\"cluster\"],\n",
        "        }  for _, row in insight_layers[0].iterrows()]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "online_python_insights = [\n",
        "    pd.DataFrame(bubble_client.get_objects(\n",
        "        \"python_insight\",\n",
        "        [\n",
        "            BubbleField(\"step\") == i+1,\n",
        "            BubbleField(\"company\") == company_id,\n",
        "            ],\n",
        "    )) for i in range(n_layers)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert [len(l) for l in insight_layers] == [len(l) for l in online_python_insights]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feedbacks_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = insight_layers[0]\n",
        "\n",
        "def get_all_parents(feedback_identifier):\n",
        "    parents = []\n",
        "    for i, row in df.loc[df['related_feedback'] == feedback_identifier].iterrows():\n",
        "        for parent in row['parents']:\n",
        "            parents.append(parent)\n",
        "    return parents\n",
        "\n",
        "feedbacks_df['parents'] = feedbacks_df['_id'].apply(get_all_parents)\n",
        "\n",
        "feedbacks_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _, row in tqdm(feedbacks_df.iterrows()):\n",
        "    res = bubble_client.update_object(\n",
        "        \"Feedbacks\",\n",
        "        row['_id'], \n",
        "        {\n",
        "            \"insights\": row[\"parents\"],\n",
        "        } \n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "res = bubble_client.get_objects(\n",
        "        \"Feedback\",\n",
        "        [\n",
        "            BubbleField(\"source\") == source_id,\n",
        "            ],\n",
        "    )\n",
        "pd.DataFrame(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers = [\n",
        "    pd.DataFrame(bubble_client.get_objects(\n",
        "        \"python_insight\",\n",
        "        [\n",
        "            BubbleField(\"step\") == i+1,\n",
        "            BubbleField(\"company\") == company_id,\n",
        "            ],\n",
        "    )) for i in range(n_layers)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers[0].tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentences = insight_layers[0][\"content\"]\n",
        "sentence_embeddings = embedding_model.encode(sentences)\n",
        "sentence_embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers[0]['parent']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def to_int(i):\n",
        "    try:\n",
        "        return int(i)\n",
        "    except:\n",
        "        return -1\n",
        "\n",
        "for layer in insight_layers:\n",
        "    layer['parent'] = layer['parent'].apply(to_int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list(insight_layers[1][\"content\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, layer in enumerate(insight_layers):\n",
        "    print(list(insight_layers[0][insight_layers[0]['parent'] == 'None'][\"content\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sum(insight_layers[0]['parent']<0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers[1].iloc[insight_layers[0]['parent'], \"content\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers[0].loc[0, \"cluster\"] == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "map_to_parent(0, insight_layers[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers[1].loc[0, 'parent']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@Insight Plot the archive {display-mode: \"form\"}\n",
        "\n",
        "# UMAP reduces the dimensions from 1024 to 2 dimensions that we can plot\n",
        "reducer = umap.UMAP(n_neighbors=15)\n",
        "umap_embeds = reducer.fit_transform(sentence_embeddings)\n",
        "\n",
        "def map_to_parent(i, parents_df):\n",
        "    try:\n",
        "        return parents_df.loc[i, 'content']\n",
        "    except:\n",
        "        return \"\"\n",
        "    \n",
        "# Prepare the data to plot and interactive visualization\n",
        "# using Altair\n",
        "df_explore = pd.DataFrame(data={\n",
        "    'content': insight_layers[0]['content'], \n",
        "    'parent': insight_layers[0]['parent'].apply(lambda x: map_to_parent(x, insight_layers[1])),\n",
        "    'cluster': insight_layers[0]['cluster'].astype(str),\n",
        "    })\n",
        "df_explore['x'] = umap_embeds[:,0]\n",
        "df_explore['y'] = umap_embeds[:,1]\n",
        "df_explore\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Plot\n",
        "chart = alt.Chart(df_explore).mark_circle(size=60).encode(\n",
        "    x=#'x',\n",
        "    alt.X('x',\n",
        "        scale=alt.Scale(zero=False)\n",
        "    ),\n",
        "    y=\n",
        "    alt.Y('y',\n",
        "        scale=alt.Scale(zero=False)\n",
        "    ),\n",
        "    color='cluster',\n",
        "    tooltip=['content', \"parent\"]\n",
        ").properties(\n",
        "    width=700,\n",
        "    height=400\n",
        ")\n",
        "chart.interactive()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def td_idf(documents)\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vectors = vectorizer.fit_transform(documents)\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    dense = vectors.todense()\n",
        "    denselist = dense.tolist()\n",
        "    df = pd.DataFrame(denselist, columns=feature_names)\n",
        "    df = df[df.columns.difference(stopwords.words('french'))]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = td_idf(feedbacks_df['content'])\n",
        "#print('\\n'.join(df.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#print('\\n'.join(df.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def get_top_two_columns(row):\n",
        "    top_two_indexes = row.nlargest(5).index.tolist()\n",
        "    return top_two_indexes\n",
        "\n",
        "top_two_columns_df = df.apply(get_top_two_columns, axis=1)\n",
        "\n",
        "print(top_two_columns_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#print('\\n'.join(insights_df['content']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "collapsed_sections": [
        "pKSREXZg85yy",
        "iiOlJz-d9AsB"
      ],
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
