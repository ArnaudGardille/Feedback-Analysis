{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjPRVXra8lVZ"
      },
      "source": [
        "# Dependancies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKSREXZg85yy"
      },
      "source": [
        "## Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "zMSukVZh29HK"
      },
      "outputs": [],
      "source": [
        "#!pip install sentence_transformers langchain openai tqdm datasets asyncio scikit-learn cohere tiktoken umap altair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "Md3DNHlV22Ai"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from datasets import load_dataset\n",
        "import umap\n",
        "import altair as alt\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from typing import List\n",
        "import enum\n",
        "\n",
        "from langchain_community.llms import Ollama\n",
        "from langchain.output_parsers.regex_dict import RegexDictParser\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, ChatMessage\n",
        "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from pydantic import BaseModel, Field, validator\n",
        "from openai import AsyncOpenAI\n",
        "import asyncio\n",
        "import os\n",
        "\n",
        "import requests\n",
        "import json\n",
        "from bubble_api import Field as BubbleField\n",
        "from bubble_api import BubbleClient\n",
        "\n",
        "import itertools\n",
        "from copy import copy\n",
        "from tqdm.notebook import tqdm, trange\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import umap.umap_ as umap\n",
        "#import umap\n",
        "import hdbscan\n",
        "\n",
        "from typing import Literal, Union\n",
        "from pydantic.config import ConfigDict\n",
        "\n",
        "import openai\n",
        "import instructor\n",
        "\n",
        "openai.api_key = \"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\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {},
      "outputs": [],
      "source": [
        "MAX_RETRIES = 0\n",
        "TEMPERATURE = 0.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Useful functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Point positif\n"
          ]
        }
      ],
      "source": [
        "import unicodedata\n",
        "\n",
        "def remove_accents(text):\n",
        "    # Replace accented characters with their non-accented counterparts\n",
        "    try:\n",
        "        return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')\n",
        "    except TypeError:  # handles cases when text is not a string (e.g., a number)\n",
        "        return text\n",
        "\n",
        "text = \"Pôint positîf\"\n",
        "converted_text = remove_accents(text)\n",
        "print(converted_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1, 2]\n",
            "[3, 4, 5]\n",
            "[6, 7, 8]\n",
            "[9]\n",
            "POINT_POSITIF\n"
          ]
        }
      ],
      "source": [
        "def clean_df(df):\n",
        "    for col in df.columns:\n",
        "        if type(df.loc[0, col]) == str and df.loc[0, col][0]==\"[\":\n",
        "            df[col] = df[col].apply(lambda x: eval(x))\n",
        "    return df\n",
        "\n",
        "def batchify(iterable, size=1):\n",
        "    l = len(iterable)\n",
        "    for ndx in range(0, l, size):\n",
        "        yield iterable[ndx:min(ndx + size, l)]\n",
        "\n",
        "for x in batchify(list(range(0, 10)), 3):\n",
        "    print(x)\n",
        "\n",
        "def deduce_backend_type(insight_type):\n",
        "    if insight_type == \"1698433300252x835626794232717300\":\n",
        "        return \"pain\"\n",
        "    elif insight_type == \"1698433290120x936044292663509300\":\n",
        "        return \"positive\"   \n",
        "    elif insight_type == \"1698433314230x619003097145126100\":\n",
        "        return \"feature\"  \n",
        "    elif insight_type == \"1698433323222x402426615286320700\":\n",
        "        return \"bug\"   \n",
        "    print(\"Incorrect type:\", insight_type)\n",
        "\n",
        "def most_common(lst):\n",
        "    return max(set(lst), key=lst.count)\n",
        "\n",
        "def columns_to_string(df, column_title, column_desc, add_index=False):\n",
        "    def concanenatre_title_description(x, y):\n",
        "        return x+\" : \"+y\n",
        "    \n",
        "    l = list(df.apply(lambda x: concanenatre_title_description(x[column_title], x[column_desc]), axis=1))\n",
        "    if add_index:\n",
        "        l = [str(i)+\" - \"+e for i, e in enumerate(l)]\n",
        "    return '\\n'.join(l)\n",
        "\n",
        "\n",
        "def convert_text_to_constants(text):\n",
        "    text = remove_accents(text)\n",
        "    text = re.sub(r\"([a-z])([A-Z]+)\", r\"\\1_\\2\", text.upper())\n",
        "    return re.sub(r\" \", \"_\", text)\n",
        "\n",
        "text = \"Point positif\"\n",
        "converted_text = convert_text_to_constants(text)\n",
        "print(converted_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [],
      "source": [
        "def enum_to_str(e):\n",
        "    if type(e) is str:\n",
        "        return e\n",
        "    if issubclass(type(e), enum.Enum):\n",
        "        return e.value\n",
        "    if type(e) is list:\n",
        "        return [enum_to_str(x) for x in e]\n",
        "    if type(e) is dict:\n",
        "        return {k:enum_to_str(v) for (k,v) in e.items()}\n",
        "    if issubclass(type(e), BaseModel):\n",
        "        return enum_to_str(e.dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiOlJz-d9AsB"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "sKiOQ4W230T9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "KQdlEBYO22Ak"
      },
      "outputs": [],
      "source": [
        "#client = AsyncOpenAI()\n",
        "client = instructor.patch(AsyncOpenAI())\n",
        "\n",
        "embedding_model = SentenceTransformer('OrdalieTech/Solon-embeddings-large-0.1')\n",
        "GENERATION_ENGINE = \"gpt-4-1106-preview\"\n",
        "EMBEDDING_ENGINE = \"text-embedding-ada-002\"\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {
        "id": "QxRlrDz622Ao"
      },
      "outputs": [],
      "source": [
        "async def get_analysis(prompt, response_model):\n",
        "    response: response_model = await client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Tu est un assistant spélialisé dans l'analyse de commentaires, et qui ne renvoit que des fichiers JSON.\"},\n",
        "            {\"role\": \"user\", \"content\": str(prompt)},\n",
        "        ],\n",
        "        response_format={ \"type\": \"json_object\" },\n",
        "        model=GENERATION_ENGINE,\n",
        "        temperature=TEMPERATURE,\n",
        "        max_retries=MAX_RETRIES,\n",
        "        response_model=response_model,\n",
        "        )\n",
        "    return response #.choices[0].message.content\n",
        "\n",
        "def apply_async_analysis(prompts, response_model):\n",
        "    if type(response_model) is not list:\n",
        "        response_models = [response_model for _ in prompts]\n",
        "    loop = asyncio.get_event_loop()\n",
        "    tasks = [loop.create_task(get_analysis(prompt, response_model)) for (prompt, response_model) in zip(prompts, response_models)]\n",
        "    res =  loop.run_until_complete(asyncio.gather(*tasks))\n",
        "    return res\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [],
      "source": [
        "def safe_async_analysis(prompts, parser, max_steps=3):\n",
        "    results = [None for _ in prompts]\n",
        "    to_be_run = list(range(len(prompts)))\n",
        "    step = 0\n",
        "    while to_be_run != []:\n",
        "        #print(\"step:\", step)\n",
        "        #print(\"to_be_run:\", len(to_be_run))\n",
        "        assert step < max_steps\n",
        "        bugs = []\n",
        "        \n",
        "        responses = apply_async_analysis([prompts[i] for i in to_be_run])\n",
        "\n",
        "        for i in to_be_run:\n",
        "            assert results[i] is None\n",
        "            try:\n",
        "                try:\n",
        "                    parsed_response = parser.parse(responses[i])\n",
        "                except:\n",
        "                    parsed_response = parser.parse('{\"properties\":'+responses[i]+'}')\n",
        "                    print(\"handled properties!\")\n",
        "                results[i] = parsed_response\n",
        "            except:\n",
        "                if max_steps==0:\n",
        "                    print(\"prompt\")\n",
        "                    print(prompts[i].text)\n",
        "\n",
        "                    print(\"reponse\")\n",
        "                    print(responses[i])\n",
        "\n",
        "                    print(\"others:\")\n",
        "                    print(responses)\n",
        "\n",
        "                    parsed_response = parser.parse(responses[i])\n",
        "                bugs.append(i)\n",
        "\n",
        "        to_be_run = bugs\n",
        "        step += 1\n",
        "    assert None not in results\n",
        "    return results\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def get_embedding(text):\n",
        "    response = await client.embeddings.create(input=text, model=EMBEDDING_ENGINE)\n",
        "    return response.data[0].embedding\n",
        "\n",
        "def apply_async_get_embedding(dfi):\n",
        "    loop = asyncio.get_event_loop()\n",
        "    tasks = [loop.create_task(get_embedding(row['Comment'])) for _, row in dfi.iterrows()]\n",
        "    return loop.run_until_complete(asyncio.gather(*tasks))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w78bVvXR9GrD"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "uiENBWdi22Al"
      },
      "outputs": [],
      "source": [
        "PROJECT =  \"Metro\" #\"Cheerz\"\n",
        "project_path = 'Results/'+PROJECT\n",
        "os.makedirs(project_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "dK9cADmd4j6z"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    path = '/content/drive/MyDrive/Blumana Folder'\n",
        "else:\n",
        "    path = \"/Users/gardille/development/Blumana\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "YJIZB32l22Al"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Trop de ruptures , de produits arrêtés du jour...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Je n'ai pas grand chose à dire sur les prix pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Metro augmente ses prix à vu deuil, pour la li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rupture de produit tout type de produit \\n ( s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Gros soucis du côté stationnement pour les véh...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Comment\n",
              "0  Trop de ruptures , de produits arrêtés du jour...\n",
              "1  Je n'ai pas grand chose à dire sur les prix pa...\n",
              "2  Metro augmente ses prix à vu deuil, pour la li...\n",
              "3  Rupture de produit tout type de produit \\n ( s...\n",
              "4  Gros soucis du côté stationnement pour les véh..."
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feedbacks_df = pd.read_csv(path+\"/Data/Commentaires/metro.csv\") #, index_col=\"Index\")\n",
        "#feedbacks_df = pd.read_csv(\"data/Trustpilot/cheerz_fr.csv\", index_col=\"Index\")\n",
        "#feedbacks_df[\"Comment\"] = feedbacks_df[\"Title\"] + '\\n' + feedbacks_df[\"content\"]\n",
        "feedbacks_column = 'Comment' #\"Content\"\n",
        "feedbacks_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqsmhIToV_yX"
      },
      "source": [
        "## Bubble API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [],
      "source": [
        "COLUMNS_INSIGHTS = [\"content\", \"backend_status\", \"status\", \"backend_type\", \"type\", \"company\", \"feedback_count\", \"parent\", \"project\", \"step\", \"tag\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_url = \"https://blumana.app\" #/version-test\"\n",
        "bubble_id = \"04ca44f04c936081d8408b12c1ba67e2\"\n",
        "\n",
        "bubble_client = BubbleClient(\n",
        "    base_url=base_url,\n",
        "    api_token=bubble_id,\n",
        "    bubble_version=\"test\" #dev\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Randstad\n",
        "#company_id = \"1696884561832x730324245490558300\"\n",
        "#source_id = \"1702244804258x371787369839591400\"\n",
        "\n",
        "#Metro\n",
        "#Source : Dataset test - METRO\n",
        "#Projet : METRO\n",
        "company_id = \"1705585399217x205117684451615600\"\n",
        "source_id = \"1705851599107x404539534708310000\"\n",
        "project_id = \"1705851616871x644869783878893600\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [],
      "source": [
        "#bubble_client.delete_all(\"python_insight\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Feedbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modified Date</th>\n",
              "      <th>Created Date</th>\n",
              "      <th>Created By</th>\n",
              "      <th>content</th>\n",
              "      <th>company</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Analyzed?</th>\n",
              "      <th>source</th>\n",
              "      <th>character_number</th>\n",
              "      <th>insights</th>\n",
              "      <th>_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2024-01-26 15:44:56.054000+00:00</td>\n",
              "      <td>2024-01-21 15:40:00.025000+00:00</td>\n",
              "      <td>1705847494855x437900943146650500</td>\n",
              "      <td>livrer TOUT les produits disponibles en magasi...</td>\n",
              "      <td>1705585399217x205117684451615600</td>\n",
              "      <td>Positif</td>\n",
              "      <td>False</td>\n",
              "      <td>1705851599107x404539534708310000</td>\n",
              "      <td>95</td>\n",
              "      <td>[1706283885834x852473847338076800, 17062838843...</td>\n",
              "      <td>1705851599759x115801332943705310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2024-01-26 15:44:56.728000+00:00</td>\n",
              "      <td>2024-01-21 15:39:59.800000+00:00</td>\n",
              "      <td>1705847494855x437900943146650500</td>\n",
              "      <td>Votre offer internet devient « ridicule ». Ell...</td>\n",
              "      <td>1705585399217x205117684451615600</td>\n",
              "      <td>Négatif</td>\n",
              "      <td>False</td>\n",
              "      <td>1705851599107x404539534708310000</td>\n",
              "      <td>486</td>\n",
              "      <td>[1706283885563x302893551310678300, 17062838842...</td>\n",
              "      <td>1705851599759x118530353766926000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2024-01-26 15:44:57.373000+00:00</td>\n",
              "      <td>2024-01-21 15:39:59.898000+00:00</td>\n",
              "      <td>1705847494855x437900943146650500</td>\n",
              "      <td>Le rangement est bordélique une vache ne retro...</td>\n",
              "      <td>1705585399217x205117684451615600</td>\n",
              "      <td>Négatif</td>\n",
              "      <td>False</td>\n",
              "      <td>1705851599107x404539534708310000</td>\n",
              "      <td>66</td>\n",
              "      <td>[1706283885852x576671576530028300, 17062838842...</td>\n",
              "      <td>1705851599759x119429130200745520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2024-01-25 13:15:45.483000+00:00</td>\n",
              "      <td>2024-01-21 15:40:00.012000+00:00</td>\n",
              "      <td>1705847494855x437900943146650500</td>\n",
              "      <td>Je profite ailleurs d'opération de destockage,...</td>\n",
              "      <td>1705585399217x205117684451615600</td>\n",
              "      <td>Positif</td>\n",
              "      <td>False</td>\n",
              "      <td>1705851599107x404539534708310000</td>\n",
              "      <td>63</td>\n",
              "      <td>[]</td>\n",
              "      <td>1705851599759x120869695273613470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2024-01-26 15:44:58.300000+00:00</td>\n",
              "      <td>2024-01-21 15:39:59.800000+00:00</td>\n",
              "      <td>1705847494855x437900943146650500</td>\n",
              "      <td>il est dommage de ne plus recevoir les promoti...</td>\n",
              "      <td>1705585399217x205117684451615600</td>\n",
              "      <td>Négatif</td>\n",
              "      <td>False</td>\n",
              "      <td>1705851599107x404539534708310000</td>\n",
              "      <td>78</td>\n",
              "      <td>[1706283885714x509937248958346050, 17062838843...</td>\n",
              "      <td>1705851599759x123910318505263460</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Modified Date                     Created Date  \\\n",
              "0 2024-01-26 15:44:56.054000+00:00 2024-01-21 15:40:00.025000+00:00   \n",
              "1 2024-01-26 15:44:56.728000+00:00 2024-01-21 15:39:59.800000+00:00   \n",
              "2 2024-01-26 15:44:57.373000+00:00 2024-01-21 15:39:59.898000+00:00   \n",
              "3 2024-01-25 13:15:45.483000+00:00 2024-01-21 15:40:00.012000+00:00   \n",
              "4 2024-01-26 15:44:58.300000+00:00 2024-01-21 15:39:59.800000+00:00   \n",
              "\n",
              "                         Created By  \\\n",
              "0  1705847494855x437900943146650500   \n",
              "1  1705847494855x437900943146650500   \n",
              "2  1705847494855x437900943146650500   \n",
              "3  1705847494855x437900943146650500   \n",
              "4  1705847494855x437900943146650500   \n",
              "\n",
              "                                             content  \\\n",
              "0  livrer TOUT les produits disponibles en magasi...   \n",
              "1  Votre offer internet devient « ridicule ». Ell...   \n",
              "2  Le rangement est bordélique une vache ne retro...   \n",
              "3  Je profite ailleurs d'opération de destockage,...   \n",
              "4  il est dommage de ne plus recevoir les promoti...   \n",
              "\n",
              "                            company sentiment  Analyzed?  \\\n",
              "0  1705585399217x205117684451615600   Positif      False   \n",
              "1  1705585399217x205117684451615600   Négatif      False   \n",
              "2  1705585399217x205117684451615600   Négatif      False   \n",
              "3  1705585399217x205117684451615600   Positif      False   \n",
              "4  1705585399217x205117684451615600   Négatif      False   \n",
              "\n",
              "                             source  character_number  \\\n",
              "0  1705851599107x404539534708310000                95   \n",
              "1  1705851599107x404539534708310000               486   \n",
              "2  1705851599107x404539534708310000                66   \n",
              "3  1705851599107x404539534708310000                63   \n",
              "4  1705851599107x404539534708310000                78   \n",
              "\n",
              "                                            insights  \\\n",
              "0  [1706283885834x852473847338076800, 17062838843...   \n",
              "1  [1706283885563x302893551310678300, 17062838842...   \n",
              "2  [1706283885852x576671576530028300, 17062838842...   \n",
              "3                                                 []   \n",
              "4  [1706283885714x509937248958346050, 17062838843...   \n",
              "\n",
              "                                _id  \n",
              "0  1705851599759x115801332943705310  \n",
              "1  1705851599759x118530353766926000  \n",
              "2  1705851599759x119429130200745520  \n",
              "3  1705851599759x120869695273613470  \n",
              "4  1705851599759x123910318505263460  "
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "res = bubble_client.get_objects(\n",
        "        \"Feedback\",\n",
        "        [\n",
        "            BubbleField(\"source\") == source_id,\n",
        "            #Field(\"company\") == company_id,\n",
        "            ],\n",
        "    )\n",
        "feedbacks_df = pd.DataFrame(res)\n",
        "feedbacks_df['Modified Date'] = pd.to_datetime(feedbacks_df['Modified Date'])\n",
        "feedbacks_df['Created Date'] = pd.to_datetime(feedbacks_df['Created Date'])\n",
        "feedbacks_column = 'content' #\"content\"\n",
        "\n",
        "feedbacks_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modified Date</th>\n",
              "      <th>Created Date</th>\n",
              "      <th>Created By</th>\n",
              "      <th>Title</th>\n",
              "      <th>Definition</th>\n",
              "      <th>_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-11-29 20:08:33.257000+00:00</td>\n",
              "      <td>2023-10-27 19:01:30.120000+00:00</td>\n",
              "      <td>admin_user_sifter-63385_test</td>\n",
              "      <td>Point positif</td>\n",
              "      <td>Élément apprécié par le client ou l'utilisateur</td>\n",
              "      <td>1698433290120x936044292663509300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2023-11-29 20:08:18.542000+00:00</td>\n",
              "      <td>2023-10-27 19:01:40.253000+00:00</td>\n",
              "      <td>admin_user_sifter-63385_test</td>\n",
              "      <td>Point de douleur</td>\n",
              "      <td>Problème qui gène ou ennuie le client ou l'uti...</td>\n",
              "      <td>1698433300252x835626794232717300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2023-11-29 20:07:58.192000+00:00</td>\n",
              "      <td>2023-10-27 19:01:54.230000+00:00</td>\n",
              "      <td>admin_user_sifter-63385_test</td>\n",
              "      <td>Nouvelle demande</td>\n",
              "      <td>Suggestion d'évolution faite par le client ou ...</td>\n",
              "      <td>1698433314230x619003097145126100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2023-10-27 19:04:56.574000+00:00</td>\n",
              "      <td>2023-10-27 19:02:03.222000+00:00</td>\n",
              "      <td>admin_user_sifter-63385_test</td>\n",
              "      <td>Bug</td>\n",
              "      <td>Anomalie de fonctionnement de l'application dé...</td>\n",
              "      <td>1698433323222x402426615286320700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Modified Date                     Created Date  \\\n",
              "0 2023-11-29 20:08:33.257000+00:00 2023-10-27 19:01:30.120000+00:00   \n",
              "1 2023-11-29 20:08:18.542000+00:00 2023-10-27 19:01:40.253000+00:00   \n",
              "2 2023-11-29 20:07:58.192000+00:00 2023-10-27 19:01:54.230000+00:00   \n",
              "3 2023-10-27 19:04:56.574000+00:00 2023-10-27 19:02:03.222000+00:00   \n",
              "\n",
              "                     Created By             Title  \\\n",
              "0  admin_user_sifter-63385_test     Point positif   \n",
              "1  admin_user_sifter-63385_test  Point de douleur   \n",
              "2  admin_user_sifter-63385_test  Nouvelle demande   \n",
              "3  admin_user_sifter-63385_test               Bug   \n",
              "\n",
              "                                          Definition  \\\n",
              "0    Élément apprécié par le client ou l'utilisateur   \n",
              "1  Problème qui gène ou ennuie le client ou l'uti...   \n",
              "2  Suggestion d'évolution faite par le client ou ...   \n",
              "3  Anomalie de fonctionnement de l'application dé...   \n",
              "\n",
              "                                _id  \n",
              "0  1698433290120x936044292663509300  \n",
              "1  1698433300252x835626794232717300  \n",
              "2  1698433314230x619003097145126100  \n",
              "3  1698433323222x402426615286320700  "
            ]
          },
          "execution_count": 138,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res = bubble_client.get_objects(\n",
        "        \"Add-On\",\n",
        "    )\n",
        "types_df = pd.DataFrame(res)\n",
        "types_df['Modified Date'] = pd.to_datetime(types_df['Modified Date'])\n",
        "types_df['Created Date'] = pd.to_datetime(types_df['Created Date'])\n",
        "types_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Definition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Point positif</td>\n",
              "      <td>Élément apprécié par le client ou l'utilisateur</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Point de douleur</td>\n",
              "      <td>Problème qui gène ou ennuie le client ou l'uti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nouvelle demande</td>\n",
              "      <td>Suggestion d'évolution faite par le client ou ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bug</td>\n",
              "      <td>Anomalie de fonctionnement de l'application dé...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Title                                         Definition\n",
              "0     Point positif    Élément apprécié par le client ou l'utilisateur\n",
              "1  Point de douleur  Problème qui gène ou ennuie le client ou l'uti...\n",
              "2  Nouvelle demande  Suggestion d'évolution faite par le client ou ...\n",
              "3               Bug  Anomalie de fonctionnement de l'application dé..."
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "types_df[['Title',\t'Definition']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {},
      "outputs": [],
      "source": [
        "TypeInsight = enum.Enum(\"Type de l'insight\", [(convert_text_to_constants(x), x) for x in types_df.Title])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Created Date</th>\n",
              "      <th>Created By</th>\n",
              "      <th>Modified Date</th>\n",
              "      <th>Description</th>\n",
              "      <th>Name</th>\n",
              "      <th>Company</th>\n",
              "      <th>Projects</th>\n",
              "      <th>Filter</th>\n",
              "      <th>_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2024-01-21 14:40:54.587000+00:00</td>\n",
              "      <td>admin_user_sifter-63385_test</td>\n",
              "      <td>2024-01-21 14:40:54.589000+00:00</td>\n",
              "      <td>Concerne les retours liés à un achat effectué ...</td>\n",
              "      <td>Magasin</td>\n",
              "      <td>1705585399217x205117684451615600</td>\n",
              "      <td>[]</td>\n",
              "      <td>1705847852729x742507764532722400</td>\n",
              "      <td>1705848054587x622458924372477600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2024-01-21 14:41:22.881000+00:00</td>\n",
              "      <td>admin_user_sifter-63385_test</td>\n",
              "      <td>2024-01-21 14:42:43.769000+00:00</td>\n",
              "      <td>Concerne les retours liés à un achat effectué ...</td>\n",
              "      <td>Livraison</td>\n",
              "      <td>1705585399217x205117684451615600</td>\n",
              "      <td>[]</td>\n",
              "      <td>1705847852729x742507764532722400</td>\n",
              "      <td>1705848082881x454792214332598400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2024-01-21 14:41:58.874000+00:00</td>\n",
              "      <td>admin_user_sifter-63385_test</td>\n",
              "      <td>2024-01-21 14:42:32.586000+00:00</td>\n",
              "      <td>Cette catégorie inclut les avis relatifs à la ...</td>\n",
              "      <td>Disponibilité des produits</td>\n",
              "      <td>1705585399217x205117684451615600</td>\n",
              "      <td>[]</td>\n",
              "      <td>1705847838457x608321687289097300</td>\n",
              "      <td>1705848118874x455206967781607300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2024-01-21 14:43:43.473000+00:00</td>\n",
              "      <td>admin_user_sifter-63385_test</td>\n",
              "      <td>2024-01-21 14:43:43.474000+00:00</td>\n",
              "      <td>Catégorie regroupant les avis concernant les p...</td>\n",
              "      <td>Politique de prix</td>\n",
              "      <td>1705585399217x205117684451615600</td>\n",
              "      <td>[]</td>\n",
              "      <td>1705847838457x608321687289097300</td>\n",
              "      <td>1705848223473x225401328908415580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2024-01-21 14:44:10.225000+00:00</td>\n",
              "      <td>admin_user_sifter-63385_test</td>\n",
              "      <td>2024-01-21 14:44:10.226000+00:00</td>\n",
              "      <td>Avis portant sur la qualité, la fraîcheur ou l...</td>\n",
              "      <td>Qualité des produits</td>\n",
              "      <td>1705585399217x205117684451615600</td>\n",
              "      <td>[]</td>\n",
              "      <td>1705847838457x608321687289097300</td>\n",
              "      <td>1705848250225x478538894601366000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      Created Date                    Created By  \\\n",
              "0 2024-01-21 14:40:54.587000+00:00  admin_user_sifter-63385_test   \n",
              "1 2024-01-21 14:41:22.881000+00:00  admin_user_sifter-63385_test   \n",
              "2 2024-01-21 14:41:58.874000+00:00  admin_user_sifter-63385_test   \n",
              "3 2024-01-21 14:43:43.473000+00:00  admin_user_sifter-63385_test   \n",
              "4 2024-01-21 14:44:10.225000+00:00  admin_user_sifter-63385_test   \n",
              "\n",
              "                     Modified Date  \\\n",
              "0 2024-01-21 14:40:54.589000+00:00   \n",
              "1 2024-01-21 14:42:43.769000+00:00   \n",
              "2 2024-01-21 14:42:32.586000+00:00   \n",
              "3 2024-01-21 14:43:43.474000+00:00   \n",
              "4 2024-01-21 14:44:10.226000+00:00   \n",
              "\n",
              "                                         Description  \\\n",
              "0  Concerne les retours liés à un achat effectué ...   \n",
              "1  Concerne les retours liés à un achat effectué ...   \n",
              "2  Cette catégorie inclut les avis relatifs à la ...   \n",
              "3  Catégorie regroupant les avis concernant les p...   \n",
              "4  Avis portant sur la qualité, la fraîcheur ou l...   \n",
              "\n",
              "                         Name                           Company Projects  \\\n",
              "0                     Magasin  1705585399217x205117684451615600       []   \n",
              "1                   Livraison  1705585399217x205117684451615600       []   \n",
              "2  Disponibilité des produits  1705585399217x205117684451615600       []   \n",
              "3           Politique de prix  1705585399217x205117684451615600       []   \n",
              "4        Qualité des produits  1705585399217x205117684451615600       []   \n",
              "\n",
              "                             Filter                               _id  \n",
              "0  1705847852729x742507764532722400  1705848054587x622458924372477600  \n",
              "1  1705847852729x742507764532722400  1705848082881x454792214332598400  \n",
              "2  1705847838457x608321687289097300  1705848118874x455206967781607300  \n",
              "3  1705847838457x608321687289097300  1705848223473x225401328908415580  \n",
              "4  1705847838457x608321687289097300  1705848250225x478538894601366000  "
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res = bubble_client.get_objects(\n",
        "        \"Tag\",\n",
        "        [\n",
        "            BubbleField(\"company\") == company_id,\n",
        "            ],\n",
        "    )\n",
        "tags_df = pd.DataFrame(res)\n",
        "tags_df['Modified Date'] = pd.to_datetime(tags_df['Modified Date'])\n",
        "tags_df['Created Date'] = pd.to_datetime(tags_df['Created Date'])\n",
        "tags_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [],
      "source": [
        "TagInsight = enum.Enum(\"Categories de l'insight\", [(convert_text_to_constants(x), x) for x in tags_df.Name])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modified Date</th>\n",
              "      <th>Created Date</th>\n",
              "      <th>Created By</th>\n",
              "      <th>Company</th>\n",
              "      <th>Name</th>\n",
              "      <th>Projects</th>\n",
              "      <th>_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2024-01-22T07:16:16.180Z</td>\n",
              "      <td>2024-01-21T14:37:18.457Z</td>\n",
              "      <td>admin_user_sifter-63385_test</td>\n",
              "      <td>1705585399217x205117684451615600</td>\n",
              "      <td>Thématiques</td>\n",
              "      <td>[1705851616871x644869783878893600]</td>\n",
              "      <td>1705847838457x608321687289097300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2024-01-22T07:16:23.551Z</td>\n",
              "      <td>2024-01-21T14:37:32.729Z</td>\n",
              "      <td>admin_user_sifter-63385_test</td>\n",
              "      <td>1705585399217x205117684451615600</td>\n",
              "      <td>Mode d'achat</td>\n",
              "      <td>[1705851616871x644869783878893600]</td>\n",
              "      <td>1705847852729x742507764532722400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Modified Date              Created Date  \\\n",
              "0  2024-01-22T07:16:16.180Z  2024-01-21T14:37:18.457Z   \n",
              "1  2024-01-22T07:16:23.551Z  2024-01-21T14:37:32.729Z   \n",
              "\n",
              "                     Created By                           Company  \\\n",
              "0  admin_user_sifter-63385_test  1705585399217x205117684451615600   \n",
              "1  admin_user_sifter-63385_test  1705585399217x205117684451615600   \n",
              "\n",
              "           Name                            Projects  \\\n",
              "0   Thématiques  [1705851616871x644869783878893600]   \n",
              "1  Mode d'achat  [1705851616871x644869783878893600]   \n",
              "\n",
              "                                _id  \n",
              "0  1705847838457x608321687289097300  \n",
              "1  1705847852729x742507764532722400  "
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res = bubble_client.get_objects(\n",
        "        \"Filter\",\n",
        "        [\n",
        "            BubbleField(\"company\") == company_id,\n",
        "            ],\n",
        "    )\n",
        "filters_df = pd.DataFrame(res)\n",
        "filters_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Point positif : Élément apprécié par le client ou l'utilisateur\n",
            "Point de douleur : Problème qui gène ou ennuie le client ou l'utilisateur\n",
            "Nouvelle demande : Suggestion d'évolution faite par le client ou l'utilisateur\n",
            "Bug : Anomalie de fonctionnement de l'application détectée par l'utilisateur\n"
          ]
        }
      ],
      "source": [
        "types_descr = columns_to_string(types_df, \"Title\", \"Definition\")\n",
        "print(types_descr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Magasin : Concerne les retours liés à un achat effectué en magasin\n",
            "Livraison : Concerne les retours liés à un achat effectué en livraison\n",
            "Disponibilité des produits : Cette catégorie inclut les avis relatifs à la disponibilité (ou à l'indisponibilité) des produits, peu importe le mode d'achat. Cela comprend les ruptures de stock et les problèmes de réapprovisionnement.\n",
            "Politique de prix : Catégorie regroupant les avis concernant les prix des produits, les augmentations de tarifs, ou les politiques tarifaires en général.\n",
            "Qualité des produits : Avis portant sur la qualité, la fraîcheur ou la satisfaction globale concernant les produits achetés, que ce soit en magasin ou via livraison.\n",
            "Expérience d'achat : Cette catégorie englobe les retours d'expérience liés directement à l'acte d'achat, comme l'accueil en magasin, la facilité de navigation en ligne pour les commandes, ou la facilité de stationnement au point de vente.\n",
            "Service client : Commentaires relatifs à l'interaction avec le personnel du service client, incluant l'efficacité du service, la réactivité et la qualité de l'assistance fournie.\n"
          ]
        }
      ],
      "source": [
        "tags_descr = columns_to_string(tags_df, \"Name\", \"Description\")\n",
        "print(tags_descr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context': 'Metro AG, ou Metro Group, est un groupe de distribution allemand. Il est notamment connu pour ses enseignes de vente en gros, cash & carry, aux professionnels dans de nombreux pays (Metro Cash & Carry et Makro).',\n",
              " 'role': 'product owner',\n",
              " 'cible': 'client',\n",
              " 'insight_types': \"Point positif : Élément apprécié par le client ou l'utilisateur\\nPoint de douleur : Problème qui gène ou ennuie le client ou l'utilisateur\\nNouvelle demande : Suggestion d'évolution faite par le client ou l'utilisateur\\nBug : Anomalie de fonctionnement de l'application détectée par l'utilisateur\",\n",
              " 'insight_categories': \"Magasin : Concerne les retours liés à un achat effectué en magasin\\nLivraison : Concerne les retours liés à un achat effectué en livraison\\nDisponibilité des produits : Cette catégorie inclut les avis relatifs à la disponibilité (ou à l'indisponibilité) des produits, peu importe le mode d'achat. Cela comprend les ruptures de stock et les problèmes de réapprovisionnement.\\nPolitique de prix : Catégorie regroupant les avis concernant les prix des produits, les augmentations de tarifs, ou les politiques tarifaires en général.\\nQualité des produits : Avis portant sur la qualité, la fraîcheur ou la satisfaction globale concernant les produits achetés, que ce soit en magasin ou via livraison.\\nExpérience d'achat : Cette catégorie englobe les retours d'expérience liés directement à l'acte d'achat, comme l'accueil en magasin, la facilité de navigation en ligne pour les commandes, ou la facilité de stationnement au point de vente.\\nService client : Commentaires relatifs à l'interaction avec le personnel du service client, incluant l'efficacité du service, la réactivité et la qualité de l'assistance fournie.\",\n",
              " 'question': \"Que recommanderiez-vous à Metro d'améliorer ?\",\n",
              " 'exemple_commentaire': 'je suis exclusif metro je n ai aucun representant j achetais jusqu a present tout metro par facilite mais je suis tres souvent décue par la reponse ha non on n en a pas cela arrive demain je pense que depuis le covid tout le monde ou presque s en fou!!!',\n",
              " 'example_insights': \"Déceptions face aux retards de livraison\\n- Impression d'une baisse de qualité du service depuis le Covid\"}"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "context_entreprise = \"Metro AG, ou Metro Group, est un groupe de distribution allemand. Il est notamment connu pour ses enseignes de vente en gros, cash & carry, aux professionnels dans de nombreux pays (Metro Cash & Carry et Makro).\"\n",
        "role = \"product owner\"\n",
        "cible = \"client\"\n",
        "question = \"Que recommanderiez-vous à Metro d'améliorer ?\"\n",
        "example_insight = \"Manque de clarté de l'affichage des prix en magasin\"\n",
        "\n",
        "exemple_commentaire = \"je suis exclusif metro je n ai aucun representant j achetais jusqu a present tout metro par facilite mais je suis tres souvent décue par la reponse ha non on n en a pas cela arrive demain je pense que depuis le covid tout le monde ou presque s en fou!!!\"\n",
        "\n",
        "examples_insights_df = pd.DataFrame([\n",
        "    {\"Insights qui devraient en découler\": \"Déceptions face aux retards de livraison\"},\n",
        "    {\"Insights qui devraient en découler\": \"Impression d'une baisse de qualité du service depuis le Covid\"},\n",
        "])\n",
        "\n",
        "feedback_context = {\n",
        "            \"context\": context_entreprise,\n",
        "            \"role\": role,\n",
        "            \"cible\": cible,\n",
        "            \"insight_types\": types_descr,\n",
        "            \"insight_categories\": tags_descr,\n",
        "            \"question\": question,\n",
        "            \"exemple_commentaire\": exemple_commentaire,\n",
        "            \"example_insights\": '\\n- '.join(list(examples_insights_df['Insights qui devraient en découler'])),\n",
        "        }\n",
        "\n",
        "feedback_context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Insights extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FirstInsight(BaseModel):\n",
        "    #model_config = ConfigDict(title='Main')\n",
        "    \n",
        "    insight_categories: List[TagInsight] = Field(description=\"Categories de l'insight.\")\n",
        "    insight_type: TypeInsight = Field(description=\"Type de l'insight.\")\n",
        "    #titre: str = Field(description=\"Titre de l'insight.\")\n",
        "    contenu: str = Field(description=\"Contenu de l'insight.\") #Field(description=\"Point intéressant a retenir du commentaire.\")\n",
        "\n",
        "    def __str__(self):\n",
        "        return '- ' + self.content + \"\\nTypes: \" + ', '.join(self.insight_types)\n",
        "    \n",
        "class InsightsList(BaseModel):\n",
        "    insights_list: List[FirstInsight] = Field(description=\"Liste des insight qui ont été extrait des commentaires\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {},
      "outputs": [],
      "source": [
        "#FirstInsight.model_json_schema() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt_insights = PromptTemplate.from_template(\"\"\"\n",
        "Tu es {role} au sein de l'entreprise suivante:\n",
        "{context}\n",
        "\n",
        "Tu as mené une enquête auprès des {cible} de l'entreprise, et tu cherche à les analyser.\n",
        "Effectue les étapes suivantes:\n",
        "\n",
        "Étape 1 - Identification des insights\n",
        "Identifie les insights à faire remonter auprès de ton équipe.\n",
        "Voici les contraintes que les insights doivent respecter:\n",
        "- Une personne de ton équipe qui lit un insight doit pouvoir en comprendre le sens, sans qu'il y ait d'ambiguité.\n",
        "- Un insight doit être aussi court que possible, tout en restant parfaitement compréhensible et pertinent.\n",
        "- N'ajoute pas de bouts de phrases unitiles, comme la conséquence quand celle ci est évidente. Par exemple, inutile d'ajouter des bouts de phrase comme \"..., ce qui entraîne un intérêt moindre pour l'enseigne\"\n",
        "- Un insight ne doit comporter qu'une seule information.\n",
        "\n",
        "Si un commentaire n'est pas très intéressant, il ne doit pas faire remonter d'insight.\n",
        "L'ordre des retours est aléatoire, et ne doit pas avoir d'impact sur ton analyse.\n",
        "\n",
        "Étape 2 - Catégorisation des insights\n",
        "Si cela est possible, associe à chaque insight les catégories qui correspondent.\n",
        "Il est possible que l'insight ne soit associé à aucune catégorie.\n",
        "\n",
        "Étape 3 - Type des insights\n",
        "Associe à chaque insight son type.\n",
        "\n",
        "\"{feedbacks}\"\n",
        "\"\"\")\n",
        "\n",
        "#Les catégories suivies de leurs description sont: \n",
        "#{insight_categories}\n",
        "#, parmi:{insight_types}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompts = []\n",
        "BATCH_SIZE = 30\n",
        "\n",
        "for batch_df in batchify(feedbacks_df, size=BATCH_SIZE):\n",
        "    context = copy(feedback_context)\n",
        "    context[\"feedbacks\"] = \"- \"+\"\\n- \".join(batch_df['content'])\n",
        "    #context[\"insights\"] = \"- \"+\"\\n- \".join(batch_df['content'])\n",
        "    prompts.append(prompt_insights.invoke(context))\n",
        "\n",
        "responses = apply_async_analysis(prompts, InsightsList)\n",
        "list_batch_insights_df = [pd.DataFrame(enum_to_str(response.insights_list)) for response in responses]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 211,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(list_batch_insights_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Accociate newly created insights to feedbacks "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "prompt_feedback = PromptTemplate.from_template(\"\"\"\n",
        "Tu es {role} au sein de l'entreprise suivante:\n",
        "{context}\n",
        "\n",
        "Tu as mené une enquête auprès des {cible} de l'entreprise. \n",
        "Tu as récupérés des commentaires, et en a extrait des insights.\n",
        "                                               \n",
        "Pour chacun des insights qui te sera donné, effectue les étapes suivantes:\n",
        "\n",
        "Étape 1 - Identifie si le sentiment exprimé dans chacun des retours par le {cible} est \"Positif\", \"Neutre\" ou \"Négatif\". Prends en compte la formulation de la question ayant été posée ({question}) afin de bien interpréter le sens du retour {cible}.\n",
        "\n",
        "Étape 2 - Associe chaque retour aux éventuels insights qui en découlent.\n",
        "Un insight doit nécessairement est associé à au moins un retour. Un retour peut n'être associé à aucun insight.\n",
        "\n",
        "Voici les retours à traiter:\n",
        "\n",
        "'''\n",
        "{feedbacks}\n",
        "'''\n",
        "                                            \n",
        "                                               \n",
        "Retourne dans l'ordre les informations traitées sur les retours.\n",
        "\"\"\")\n",
        "\n",
        "#Et les insights qui en ont été extrait:                                              \n",
        "#'''\n",
        "#{insights}\n",
        "#'''\n",
        "#Par exemple, pour les retours suivants:\n",
        "#'''\n",
        "#{exemple_commentaire}\n",
        "#'''\n",
        "#on voudrait faire remonter les points suivants:\n",
        "#'''\n",
        "#- {example_insights}\n",
        "#'''\n",
        "#Si le {cible} n'a rien à signaler (\"ras\", \"tout est ok\", \"rien à signaler\") crée un insight dédié"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Sentiment(str, enum.Enum):\n",
        "    POSITIF = \"Positif\"\n",
        "    NEUTRE = \"Neutre\"\n",
        "    NEGATIF = \"Négatif\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "InsightsList(insights_list=[FirstInsight(insight_categories=[<Categories de l'insight.LIVRAISON: 'Livraison'>, <Categories de l'insight.POLITIQUE_DE_PRIX: 'Politique de prix'>], insight_type=<Type de l'insight.POINT_DE_DOULEUR: 'Point de douleur'>, contenu='Les prix sur internet ne correspondent pas aux prix en magasin, empêchant la comparaison et la transparence des coûts de livraison.'), FirstInsight(insight_categories=[<Categories de l'insight.MAGASIN: 'Magasin'>], insight_type=<Type de l'insight.POINT_DE_DOULEUR: 'Point de douleur'>, contenu=\"L'organisation des produits en magasin est désordonnée.\"), FirstInsight(insight_categories=[<Categories de l'insight.EXPERIENCE_D'ACHAT: \"Expérience d'achat\">], insight_type=<Type de l'insight.POINT_POSITIF: 'Point positif'>, contenu=\"Les opérations de déstockage chez d'autres fournisseurs sont appréciées.\"), FirstInsight(insight_categories=[<Categories de l'insight.EXPERIENCE_D'ACHAT: \"Expérience d'achat\">], insight_type=<Type de l'insight.POINT_DE_DOULEUR: 'Point de douleur'>, contenu='La suppression des promotions sous forme papier ou digitale est regrettée.'), FirstInsight(insight_categories=[<Categories de l'insight.POLITIQUE_DE_PRIX: 'Politique de prix'>], insight_type=<Type de l'insight.POINT_DE_DOULEUR: 'Point de douleur'>, contenu='Les prix chez Metro sont parfois plus élevés que dans les grandes surfaces, même pour des produits identiques.'), FirstInsight(insight_categories=[<Categories de l'insight.QUALITE_DES_PRODUITS: 'Qualité des produits'>], insight_type=<Type de l'insight.POINT_DE_DOULEUR: 'Point de douleur'>, contenu='La qualité et la variété des produits proposés, notamment pendant les fêtes, ont diminué.'), FirstInsight(insight_categories=[<Categories de l'insight.SERVICE_CLIENT: 'Service client'>], insight_type=<Type de l'insight.POINT_DE_DOULEUR: 'Point de douleur'>, contenu=\"Le service client est jugé insuffisant, surtout lors d'achats en grande quantité.\"), FirstInsight(insight_categories=[<Categories de l'insight.POLITIQUE_DE_PRIX: 'Politique de prix'>], insight_type=<Type de l'insight.POINT_DE_DOULEUR: 'Point de douleur'>, contenu='Les prix sont jugés trop élevés même avec le système dégressif, et la concurrence est plus compétitive.'), FirstInsight(insight_categories=[<Categories de l'insight.LIVRAISON: 'Livraison'>], insight_type=<Type de l'insight.POINT_DE_DOULEUR: 'Point de douleur'>, contenu='La gestion des livraisons et des avoirs est à améliorer.'), FirstInsight(insight_categories=[<Categories de l'insight.POLITIQUE_DE_PRIX: 'Politique de prix'>], insight_type=<Type de l'insight.POINT_DE_DOULEUR: 'Point de douleur'>, contenu='Les promotions sont insuffisantes pour les petites quantités achetées.'), FirstInsight(insight_categories=[<Categories de l'insight.EXPERIENCE_D'ACHAT: \"Expérience d'achat\">], insight_type=<Type de l'insight.NOUVELLE_DEMANDE: 'Nouvelle demande'>, contenu=\"Mise en place d'un système de points de fidélité suggérée.\"), FirstInsight(insight_categories=[<Categories de l'insight.LIVRAISON: 'Livraison'>, <Categories de l'insight.DISPONIBILITE_DES_PRODUITS: 'Disponibilité des produits'>], insight_type=<Type de l'insight.POINT_DE_DOULEUR: 'Point de douleur'>, contenu=\"L'assortiment de produits disponibles en livraison a été réduit, impactant négativement les commandes.\"), FirstInsight(insight_categories=[<Categories de l'insight.QUALITE_DES_PRODUITS: 'Qualité des produits'>, <Categories de l'insight.POLITIQUE_DE_PRIX: 'Politique de prix'>], insight_type=<Type de l'insight.POINT_DE_DOULEUR: 'Point de douleur'>, contenu='La qualité et la fraîcheur des produits sont inconstantes et les prix sont plus élevés que dans les supermarchés.'), FirstInsight(insight_categories=[<Categories de l'insight.SERVICE_CLIENT: 'Service client'>], insight_type=<Type de l'insight.POINT_DE_DOULEUR: 'Point de douleur'>, contenu='Le nouveau directeur de Metro Caen est critiqué pour son manque de courtoisie.'), FirstInsight(insight_categories=[<Categories de l'insight.POLITIQUE_DE_PRIX: 'Politique de prix'>], insight_type=<Type de l'insight.POINT_DE_DOULEUR: 'Point de douleur'>, contenu=\"Certains produits sont moins chers en grande surface qu'à Metro.\"), FirstInsight(insight_categories=[<Categories de l'insight.SERVICE_CLIENT: 'Service client'>], insight_type=<Type de l'insight.NOUVELLE_DEMANDE: 'Nouvelle demande'>, contenu='Les clients souhaitent des visites commerciales pour négocier des tarifs sur une gamme de produits utilisée.'), FirstInsight(insight_categories=[<Categories de l'insight.MAGASIN: 'Magasin'>, <Categories de l'insight.POLITIQUE_DE_PRIX: 'Politique de prix'>], insight_type=<Type de l'insight.POINT_DE_DOULEUR: 'Point de douleur'>, contenu=\"Manque d'étiquetage des prix en magasin, qui sont jugés trop élevés.\"), FirstInsight(insight_categories=[<Categories de l'insight.EXPERIENCE_D'ACHAT: \"Expérience d'achat\">], insight_type=<Type de l'insight.POINT_DE_DOULEUR: 'Point de douleur'>, contenu='Augmentation des tarifs sans préavis.'), FirstInsight(insight_categories=[<Categories de l'insight.SERVICE_CLIENT: 'Service client'>], insight_type=<Type de l'insight.POINT_DE_DOULEUR: 'Point de douleur'>, contenu='Les retours clients ne semblent pas pris en compte, et certains chefs de rayon sont jugés indifférents.'), FirstInsight(insight_categories=[<Categories de l'insight.POLITIQUE_DE_PRIX: 'Politique de prix'>], insight_type=<Type de l'insight.POINT_DE_DOULEUR: 'Point de douleur'>, contenu='Les prix augmentent rapidement.'), FirstInsight(insight_categories=[<Categories de l'insight.MAGASIN: 'Magasin'>], insight_type=<Type de l'insight.POINT_DE_DOULEUR: 'Point de douleur'>, contenu=\"Les articles manquent souvent d'étiquetage de prix.\"), FirstInsight(insight_categories=[<Categories de l'insight.EXPERIENCE_D'ACHAT: \"Expérience d'achat\">], insight_type=<Type de l'insight.NOUVELLE_DEMANDE: 'Nouvelle demande'>, contenu='Les clients souhaitent plus de promotions.'), FirstInsight(insight_categories=[<Categories de l'insight.POLITIQUE_DE_PRIX: 'Politique de prix'>], insight_type=<Type de l'insight.POINT_DE_DOULEUR: 'Point de douleur'>, contenu='Les augmentations de prix ne sont pas toujours communiquées.'), FirstInsight(insight_categories=[<Categories de l'insight.EXPERIENCE_D'ACHAT: \"Expérience d'achat\">], insight_type=<Type de l'insight.NOUVELLE_DEMANDE: 'Nouvelle demande'>, contenu='Les clients demandent une meilleure visibilité des prix TTC pour faciliter la comparaison.')])"
            ]
          },
          "execution_count": 214,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_insights_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'InsightsList' object has no attribute 'index'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[213], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m classes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_insights_df, batch_feedbacks_df \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(responses, batchify(feedbacks_df, size\u001b[38;5;241m=\u001b[39mBATCH_SIZE)):\n\u001b[0;32m----> 4\u001b[0m     InsightsEnum \u001b[38;5;241m=\u001b[39m enum\u001b[38;5;241m.\u001b[39mEnum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInsight associé\u001b[39m\u001b[38;5;124m\"\u001b[39m, [(x, i) \u001b[38;5;28;01mfor\u001b[39;00m i, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(batch_insights_df\u001b[38;5;241m.\u001b[39mindex, batch_insights_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontenu\u001b[39m\u001b[38;5;124m\"\u001b[39m])])\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFeedback\u001b[39;00m(BaseModel):\n\u001b[1;32m      7\u001b[0m         insights_list: List[InsightsEnum] \u001b[38;5;241m=\u001b[39m Field(description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInsights associés à ce retour\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/blumana_env/lib/python3.11/site-packages/pydantic/main.py:761\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[0;32m--> 761\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'InsightsList' object has no attribute 'index'"
          ]
        }
      ],
      "source": [
        "prompts = []\n",
        "classes = []\n",
        "for batch_insights_df, batch_feedbacks_df in zip(responses, batchify(feedbacks_df, size=BATCH_SIZE)):\n",
        "    InsightsEnum = enum.Enum(\"Insight associé\", [(x, i) for i, x in zip(batch_insights_df.index, batch_insights_df[\"contenu\"])])\n",
        "    \n",
        "    class Feedback(BaseModel):\n",
        "        insights_list: List[InsightsEnum] = Field(description=\"Insights associés à ce retour\")\n",
        "        sentiment: Sentiment = Field(description=\"Sentiment exprimé\")\n",
        "    classes.append(Feedback)\n",
        "\n",
        "    context = copy(feedback_context)\n",
        "    context[\"feedbacks\"] = \"- \"+\"\\n- \".join(batch_df['content'])\n",
        "    prompts.append(prompt_feedback.invoke(context))\n",
        "\n",
        "responses = apply_async_analysis(prompts, classes)\n",
        "\n",
        "list_batch_feedbacks_df = [pd.DataFrame(enum_to_str(response)) for response in responses]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "l = [response.insights_list for response in responses]\n",
        "l = list(itertools.chain.from_iterable(l))\n",
        "insights_df = pd.DataFrame(enum_to_str(l))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Livrer tous les produits disponibles en magasin, y compris les bouteilles d'alcool à l'unité.\n",
            "- L'offre internet est insuffisante et oblige à se rendre en magasin ou à commander ailleurs.\n",
            "- Le rangement en magasin est désorganisé.\n",
            "- Les opérations de déstockage chez d'autres fournisseurs sont très intéressantes.\n",
            "- Les promotions ne sont plus communiquées sous forme papier ou digitale.\n",
            "- Les prix chez Metro sont parfois plus élevés qu'en grande surface, même pour des produits identiques.\n",
            "- Les entrées chaudes et les propositions traiteurs pour les fêtes de fin d'année ne sont plus proposées.\n",
            "- Le service client ne facilite pas le chargement des achats en grande quantité.\n",
            "- Les prix sont trop élevés même avec le système dégressif et la concurrence est plus compétitive.\n",
            "- La gestion des livraisons et des avoirs est à améliorer.\n",
            "- Il n'y a pas assez de promotions pour les petites quantités achetées.\n",
            "- Mettre en place un système de points de fidélité.\n",
            "- L'assortiment en livraison a été réduit, ce qui diminue les commandes.\n",
            "- La qualité et la fraîcheur des produits sont inconstantes.\n",
            "- Le nouveau directeur de Metro Caen ne salue pas les clients.\n",
            "- Certains produits sont moins chers en grande surface qu'à Metro.\n",
            "- Un commercial devrait visiter les clients pour négocier des tarifs sur une gamme de produits.\n",
            "- Manque d'étiquettes sur de nombreux produits et les prix sont trop élevés.\n",
            "- Augmentation des tarifs sans préavis.\n",
            "- Les avis des clients ne semblent pas pris en compte.\n",
            "- Les prix augmentent très rapidement.\n",
            "- Les prix peuvent augmenter sans que les clients en soient informés.\n",
            "- Afficher les prix TTC pour une meilleure lisibilité et comparaison.\n",
            "- Les tarifs préférentiels sur certains produits comme le lait et le fromage râpé ont disparu.\n",
            "- Produits de très mauvaise qualité chez le fournisseur fourni resto, absence de réponse à des réclamations.\n",
            "- Variété des lots insuffisante.\n",
            "- Prix non adaptés pour les petits volumes, risque de perte de clientèle.\n",
            "- Augmentation fréquente des prix.\n",
            "- Manque de suivi pour les produits intéressants.\n",
            "- Différence de prix significative avec les fournisseurs locaux.\n",
            "- Promotions non disponibles en quantité suffisante.\n",
            "- Satisfaction concernant la coopération et les prix négociés pour les livraisons hebdomadaires.\n",
            "- Disparition de nombreux produits.\n",
            "- Conditions de paiement non flexibles pour les micro entreprises, attente de promotions pour des prix compétitifs.\n",
            "- Qualité variable des produits, certains essentiels et de meilleure qualité que la concurrence.\n",
            "- Manque de promotions et de références en livraison à domicile.\n",
            "- Augmentation constante des prix, fruits et légumes particulièrement chers.\n",
            "- Approvisionnement insuffisant, manque régulier de produits.\n",
            "- Prix élevés pour les commerçants.\n",
            "- Fréquentes ruptures de stock.\n",
            "- Prix du sucre significativement plus élevé qu'en grande surface.\n",
            "- Prix en rayon non affichés pour certains produits, entraînant une perte de temps et d'achats.\n",
            "- Absence de confitures de gamme moyenne, produits d'entretien rarement en promotion.\n",
            "- Incohérence entre les prix affichés et ceux en caisse.\n",
            "- Préférence pour le début de semaine pour les promotions, en adéquation avec les jours d'achat.\n",
            "- Manque de petits conditionnements, nécessitant des achats dans plusieurs magasins.\n",
            "- Prix parfois 3 à 4 fois plus élevés que chez les concurrents.\n",
            "- Demande d'affichage correct des prix en rayons.\n",
            "- Déception due à une fermeture inattendue pour inventaire, manque de communication.\n",
            "- Refus de reprise de matériel inutilisé, principe jugé décevant.\n"
          ]
        }
      ],
      "source": [
        "print(\"- \"+\"\\n- \".join(insights_df['contenu']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feedbacks attribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RangeIndex(start=0, stop=4, step=1)"
            ]
          },
          "execution_count": 179,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(\"Demande de livraison des bouteilles d'alcool à l'unité et pas seulement au carton.\",\n",
              "  0),\n",
              " ('Difficulté à comparer les prix en ligne avec ceux en magasin.', 1),\n",
              " (\"Impossibilité de connaître le prix en magasin lors d'une commande en livraison.\",\n",
              "  2),\n",
              " ('Obligation de se rendre en magasin ou ailleurs pour compléter les commandes.',\n",
              "  3)]"
            ]
          },
          "execution_count": 181,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "insights_enum = enum.Enum(\"Insight associé\", [(x, i) for i, x in zip(batch_insights_df.index, batch_insights_df[\"contenu\"])])\n",
        "[(e.name, e.value) for e in insights_enum]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5PWNwl622Ao"
      },
      "outputs": [],
      "source": [
        "\n",
        "prompt_template_feedback = \"\"\"Tu es {role} au sein de l'entreprise suivante:\n",
        "{context}\n",
        "\n",
        "Tu as mené une enquête auprès des {cible} de l'entreprise. \n",
        "\n",
        "Étape 1 - Identifie les insights à faire remonter auprès de ton équipe.\n",
        "Voici les contraintes que les insights doivent respecter:\n",
        "- Une personne de ton équipe qui lit un insight doit pouvoir en comprendre le sens, sans qu'il y ait d'ambiguité.\n",
        "- Un insight doit être aussi court que possible, tout en restant parfaitement compréhensible et pertinent.\n",
        "- N'ajoute pas de bouts de phrases unitiles, comme la conséquence quand celle ci est évidente. Par exemple, inutile d'ajouter des bouts de phrase comme \"..., ce qui entraîne un intérêt moindre pour l'enseigne\"\n",
        "- Un insight ne doit comporter qu'une seule information.\n",
        "\n",
        "Étape 2 - Identifie si le sentiment exprimé dans chacun des retours par le {cible} est \"Positif\", \"Neutre\" ou \"Négatif\". Prends en compte la formulation de la question ayant été posée ({question}) afin de bien interpréter le sens du retour {cible}.\n",
        "Attention à ne pas oublier l'accent si tu choisis Négatif.\n",
        "\n",
        "Étape 3 - Associe chaque retour aux écentuels feedbacks qui en découlent.\n",
        "\n",
        "Par exemple, pour les retours suivants:\n",
        "'''\n",
        "{exemple_commentaire}\n",
        "'''\n",
        "on voudrait faire remonter les points suivants:\n",
        "'''\n",
        "- {example_insights}\n",
        "'''\n",
        "\n",
        "Si un commentaire n'est pas très intéressant, il ne doit pas faire remonter d'insight.\n",
        "\n",
        "Réponds uniquement avec un ficher JSON, comme expliqué:\n",
        "{format_instructions}\n",
        "\n",
        "Voici les retours à traiter:\n",
        "\n",
        "\"{feedback}\"\n",
        "\"\"\"\n",
        "\n",
        "#Si le {cible} n'a rien à signaler (\"ras\", \"tout est ok\", \"rien à signaler\") crée un insight dédié"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmFsbtT722Aq"
      },
      "outputs": [],
      "source": [
        "feedback_parser = PydanticOutputParser(pydantic_object=Feedback)\n",
        "\n",
        "prompt_feedback = PromptTemplate.from_template(\n",
        "    template= prompt_template_feedback,\n",
        "    partial_variables= {\"format_instructions\": feedback_parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "prompts = []\n",
        "for feedback in feedbacks_df[feedbacks_column]:\n",
        "    context = copy(feedback_context)\n",
        "    context[\"feedback\"] = feedback\n",
        "    prompts.append(prompt_feedback.invoke(context))\n",
        "\n",
        "#print(prompts[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFraYQTLOmz-"
      },
      "outputs": [],
      "source": [
        "parsed_responses = safe_async_analysis(prompts, feedback_parser)\n",
        "\n",
        "feedbacks_df[\"sentiment\"] = [rep.sentiment for rep in parsed_responses]\n",
        "feedbacks_df[\"insights\"] = [[] for rep in parsed_responses]\n",
        "\n",
        "k=0\n",
        "insights = []\n",
        "for i, rep in enumerate(parsed_responses):\n",
        "    for j, insight in enumerate(rep.insights_list):\n",
        "        insights.append(insight)\n",
        "        feedbacks_df[\"insights\"].iloc[i].append(str(k))\n",
        "        k += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feedbacks_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKTksTKah7At"
      },
      "outputs": [],
      "source": [
        "insights_df = pd.DataFrame({\n",
        "    \"content\":insights,\n",
        "    \"feedback_count\": 1,\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feedbacks_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insights_df[\"related_feedback\"] = [[] for _ in range(len(insights_df))]\n",
        "\n",
        "for i, row in feedbacks_df.iterrows():\n",
        "    for j in row[\"insights\"]:\n",
        "        insights_df[\"related_feedback\"].iloc[int(j)] = row['_id'] #[int(i)]\n",
        "\n",
        "insights_df[\"childrens\"] = [[] for _ in range(len(insights_df))]\n",
        "\n",
        "insights_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k88axy7kPxQE"
      },
      "source": [
        "# Insights categorisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Thématiques\n",
            "- Disponibilité des produits (1705848118874x455206967781607300)\n",
            "- Politique de prix (1705848223473x225401328908415580)\n",
            "- Qualité des produits (1705848250225x478538894601366000)\n",
            "- Expérience d'achat (1705848274056x125824383936905310)\n",
            "- Service client (1705848302697x426707208945675400)\n",
            "\n",
            "Mode d'achat\n",
            "- Magasin (1705848054587x622458924372477600)\n",
            "- Livraison (1705848082881x454792214332598400)\n"
          ]
        }
      ],
      "source": [
        "prompt_tags = \"\"\n",
        "\n",
        "for i, filter in filters_df.iterrows():\n",
        "    prompt_tags += '\\n\\n'+filter[\"Name\"]#+' ('+filter[\"_id\"] +')'\n",
        "    tags = tags_df[tags_df[\"Filter\"] == filter[\"_id\"]]\n",
        "    for _, tag in tags.iterrows():\n",
        "        prompt_tags += '\\n'+\"- \"+tag[\"Name\"]+' ('+tag[\"_id\"] +')'\n",
        "\n",
        "print(prompt_tags)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "id": "aOVtTfiHP4w1"
      },
      "outputs": [],
      "source": [
        "\n",
        "prompt_template_categorsiation = \"\"\"Tu es {role} au sein de l'entreprise suivante :\n",
        "{context}\n",
        "\n",
        "Tu as mené une enquête auprès de tes {cible}. \n",
        "\n",
        "Tu dois associer à l'insight donné plus loin aucun, l'identifiant d'un ou plusieurs tags. S'il n'est pas possible d'associer un tag avec certitude dans l'une des catégories, laisse la liste vide. Répond avec la liste des identifiants suités entre parenthèse juste après les tags.\n",
        "Par exemple, pour les tags suivants, le tag C d'identifiant 17049ZER93619x303734523452623450 appartient catégorie 2:\n",
        "'''\n",
        "catégotie 1 \n",
        "- tag A (1704912293619x303734523452694300)\n",
        "- tag B (17049ZER93619x303734523452694300)\n",
        "\n",
        "catégotie 2 \n",
        "- tag C (17049ZER93619x303734523452623450)\n",
        "- tag D (170AZZER93619x303734524452623450)\n",
        "'''\n",
        "\n",
        "Voici les tags avec lesquels tu devras essayer de classifier l'insight:\"\"\" + prompt_tags + \"\"\"\n",
        "\n",
        "Tu ne dois par renvoyer le tag, mais uniquement son identifiant.\n",
        "Un identifiant contient toujours un x à l'intérieur, comme par example 1704912293619x303731423452694300.\n",
        "Ainsi, 1704912293619 n'est pas un identifiant valide.\n",
        "Réponds uniquement avec un ficher JSON, comme expliqué:\n",
        "{format_instructions}\n",
        "\n",
        "Voici l'insight que tu dois essayer de catégoriser: '{insight}'\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "id": "hjHnM12_KMN3"
      },
      "outputs": [],
      "source": [
        "class FirstInsight(BaseModel):\n",
        "    tags_id: List[str] = Field(description=\"Identifiants des tags de l'insight\")\n",
        "    content: str = \"\" #Field(description=\"Point intéressant a retenir du commentaire.\")\n",
        "\n",
        "    def __str__(self):\n",
        "        return '- ' + self.content + \"\\nTypes: \" + ', '.join(self.insight_types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'content'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m~/opt/anaconda3/envs/blumana_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'content'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[208], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m prompt_categorsiation \u001b[38;5;241m=\u001b[39m PromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\n\u001b[1;32m      4\u001b[0m     template\u001b[38;5;241m=\u001b[39m prompt_template_categorsiation,\n\u001b[1;32m      5\u001b[0m     partial_variables\u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_instructions\u001b[39m\u001b[38;5;124m\"\u001b[39m: categorsiation_parser\u001b[38;5;241m.\u001b[39mget_format_instructions()},\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m prompts \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m insight \u001b[38;5;129;01min\u001b[39;00m insights_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     10\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy(feedback_context)\n\u001b[1;32m     11\u001b[0m     context[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minsight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m insight\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/blumana_env/lib/python3.11/site-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/blumana_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3807\u001b[0m     ):\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'content'"
          ]
        }
      ],
      "source": [
        "categorsiation_parser = PydanticOutputParser(pydantic_object=FirstInsight)\n",
        "\n",
        "prompt_categorsiation = PromptTemplate.from_template(\n",
        "    template= prompt_template_categorsiation,\n",
        "    partial_variables= {\"format_instructions\": categorsiation_parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "prompts = []\n",
        "for insight in insights_df[\"content\"]:\n",
        "    context = copy(feedback_context)\n",
        "    context[\"insight\"] = insight\n",
        "    prompts.append(prompt_categorsiation.invoke(context))\n",
        "\n",
        "#print(prompts[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parsed_responses = safe_async_analysis(prompts, categorsiation_parser)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "insights_df[\"tag\"] = [rep.tags_id for rep in parsed_responses]\n",
        "#insights_df[\"Insights\"] = [[] for rep in parsed_responses]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Types affectation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt_types = \"\"\n",
        "\n",
        "for _, tag in types_df.iterrows():\n",
        "    prompt_types += '\\n'+\"- \"+tag[\"Title\"]+' ('+tag[\"_id\"] +') : ' + tag[\"Definition\"]\n",
        "\n",
        "print(prompt_types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "prompt_template_types = \"\"\"Tu es {role} au sein de l'entreprise suivante :\n",
        "{context}\n",
        "\n",
        "Tu as mené une enquête auprès de tes {cible}. \n",
        "\n",
        "Catégorise l'insight qui te sera donné à l’aide de l'identifiant d'un des types qui te seront donnés. \n",
        "Tu dois associser exactement un type. Choisit celui qui est le plus pertinent.\n",
        "Répond avec l'identifiants suités entre parenthèse juste après les types. La definition des types est située jsute après les double points. \n",
        "Par exemple, pour les types suivants, le type 2 a pour identifiant 1704912293619x303671423452694300.\n",
        "'''\n",
        "- type 1 (1704412293619x303731423423694300) : définition du type 1\n",
        "- type 2 (1704912293619x303671423452694300) : définition du type 2\n",
        "'''\n",
        "\n",
        "Voici les types:\"\"\" + prompt_types + \"\"\"\n",
        "\n",
        "Tu ne dois par renvoyer le type, mais uniquement son identifiant.\n",
        "Réponds uniquement avec un ficher JSON, comme expliqué:\n",
        "{format_instructions}\n",
        "\n",
        "Un identifiant contient toujours un x à l'intérieur, comme par example 1704912293619x303731423452694300.\n",
        "Ainsi, 1704912293619 n'est pas un identifiant valide.\n",
        "\n",
        "Voici l'insight que tu dois essayer de catégoriser: '{insight}'\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "categorsiation_parser = PydanticOutputParser(pydantic_object=FirstInsight)\n",
        "\n",
        "prompt_categorsiation = PromptTemplate.from_template(\n",
        "    template= prompt_template_types,\n",
        "    partial_variables= {\"format_instructions\": categorsiation_parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "prompts = []\n",
        "for insight in insights_df[\"content\"]:\n",
        "    context = copy(feedback_context)\n",
        "    context[\"insight\"] = insight\n",
        "    prompts.append(prompt_categorsiation.invoke(context))\n",
        "\n",
        "#print(prompts[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parsed_responses = safe_async_analysis(prompts, categorsiation_parser)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insights_df[\"type\"] = [rep.insight_type for rep in parsed_responses]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feedbacks_df.to_csv(project_path+'/feedbacks.csv', index_label='Index')\n",
        "insights_df.to_csv(project_path+'/insights.csv', index_label='Index')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5xBBkVJ22As"
      },
      "source": [
        "# Insights clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feedbacks_df = clean_df(pd.read_csv(project_path+'/feedbacks.csv', index_col='Index'))\n",
        "insights_df = clean_df(pd.read_csv(project_path+'/insights.csv', index_col='Index'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vl70QzOI22As"
      },
      "outputs": [],
      "source": [
        "embedding_model = SentenceTransformer('OrdalieTech/Solon-embeddings-large-0.1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGjXvwAA22As"
      },
      "outputs": [],
      "source": [
        "class DeducedInsight(BaseModel):\n",
        "    insights_mineurs: List[int] = Field(description=\"Index des insights mineurs qui ont été résumés en cet insight.\")\n",
        "    content: str = Field(description=\"Insight intéressants a retenir pour l'entreprise.\")\n",
        "\n",
        "    def __str__(self):\n",
        "        return '- ' + self.content + '\\n Enfants:' + str(self.insights_mineurs)\n",
        "\n",
        "\n",
        "class InsightList(BaseModel):\n",
        "    insights_list: List[DeducedInsight] = Field(description=\"Liste des insights, c'est à dire des points intéressants a retenir pour l'entreprise.\")\n",
        "    # You can add custom validation logic easily with Pydantic.\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"Insights: \\n\"+\"\\n\\n\".join([str(i) for i in self.insights_list])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWxRVtAG22As"
      },
      "outputs": [],
      "source": [
        "\n",
        "prompt_template_reduction = \"\"\"Tu es {role} au sein de l'entreprise suivante:\n",
        "{context}\n",
        "\n",
        "Une liste d'insights mineurs a été identifiée à partir de retours {cible}.\n",
        "\n",
        "Ils sont de très bonne qualité, et apportent des retours intéressants à l'entreprise en question. \n",
        "Mais il est possible que certains soient redondants ou inutilement précis, auquel cas nous souhaiterions les regrouper. \n",
        "\n",
        "Si c'est le cas, les insights redondants doivent être regroupés en un insight majeur. \n",
        "Si au contraite, l'insight à un sens bien dictinct des autres, il devient un insight majeur, et doit donc être recopié à l'identique. \n",
        "\n",
        "Pour transformers les insights mineurs en insights majeurs, suit ces quelques règles:\n",
        "\n",
        "1) Si l'un des insights mineurs permet de synthétiser l'information du regroupement, il devient l'insight majeur du groupe. Recopie le à l'identique et associe lui les insights mineurs, y comprie lui même.\n",
        "\n",
        "2) Si aucun des insights mineurs ne convient, formule un insight majeurs permettant de synthétiser leur sens. Voici les contraintes que doivent respecter ton insights majeur:\n",
        "- Une personne de ton équipe qui lit un insight majeur doit pouvoir en comprendre le sens.\n",
        "- Un insight majeur doit idéalement ne pas être trop long, tout en restant parfaitement compréhensible et pertinent. Les phrases nominales sont autorisées. \n",
        "- Un insight majeur ne doit comporter qu'une seule information : on ne mélange pas plusieurs éléments au sein d'un insight majeur. \n",
        "\n",
        "Un insight mineur doit être regroupé dans exactement un insight majeur. Rappelon que si l'insight mineur devient majeur, les deux auront le même contenu.\n",
        "Ainsi, chaque insight mineur doit être l'enfant d'exactement un insight majeur que tu retournes.\n",
        "\n",
        "Associe à chaque insight majeur l'indice des insights mineurs qui lui sont associés. \n",
        "Vérifie bien que les indices correspondent, et que tous les insights mineurs sont associés à un insight majeur. \n",
        "L'ordre des insights mineurs est aléatoire, et ne doit pas avoir d'importance dans ta réponse.\n",
        "\n",
        "Réponds uniquement avec un ficher JSON, comme expliqué :\n",
        "{format_instructions}\n",
        "\n",
        "Voici la liste des insights mineurs que tu dois transformer en insights majeurs:\n",
        "{insights}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "#Résume les en des insights majeurs qui te semblent important à faire remonter au sein de l'entreprise. Ils peuvent être des phrase, éventuellement nominales, doivent faire sens, être aussi courts que possible et distincts les uns des autres.\n",
        "#- Etre distincts les uns des autres.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "prompt_template_reduction_sans_reformulation = \"\"\"Tu es {role} au sein de l'entreprise suivante:\n",
        "{context}\n",
        "\n",
        "Une liste d'insights mineurs a été identifiée à partir de retours {cible}.\n",
        "\n",
        "Ils sont de très bonne qualité, et apportent des retours intéressants à l'entreprise en question. \n",
        "Mais il est possible que certains soient redondants ou inutilement précis, auquel cas nous souhaiterions les regrouper. \n",
        "\n",
        "Pour les regrouper, choisit l'insights mineurs qui permet le mieux de synthétiser l'information du regroupement, il devient l'insight majeur du groupe. \n",
        "Recopie le à l'identique et associe lui les insights mineurs, y comprie lui même.\n",
        "\n",
        "Chaque insight mineur doit être l'enfant d'exactement un insight majeur que tu retournes.\n",
        "\n",
        "Associe à chaque insight majeur l'indice des insights mineurs qui lui sont associés. \n",
        "Vérifie bien que les indices correspondent, et que tous les insights mineurs sont associés à un insight majeur. \n",
        "L'ordre des insights mineurs est aléatoire, et ne doit pas avoir d'importance dans ta réponse.\n",
        "\n",
        "Réponds uniquement avec un ficher JSON, comme expliqué :\n",
        "{format_instructions}\n",
        "\n",
        "Voici la liste des insights mineurs que tu dois transformer en insights majeurs:\n",
        "{insights}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "#Résume les en des insights majeurs qui te semblent important à faire remonter au sein de l'entreprise. Ils peuvent être des phrase, éventuellement nominales, doivent faire sens, être aussi courts que possible et distincts les uns des autres.\n",
        "#- Etre distincts les uns des autres.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71Vkoeym22As"
      },
      "outputs": [],
      "source": [
        "\n",
        "prompt_template_regrouping = \"\"\"Tu es {role} au sein de l'entreprise suivante:\n",
        "{context}\n",
        "\n",
        "Une liste d'insights a été identifiée à partir de retours clients.\n",
        "Un insight est une déduction intéressante de l'étude des commentaires {cible}, qu'il serait vraiment intéressant faire remonter aux responsables de l'entreprise.\n",
        "Par exemple, un bon insight pourrait être: {example_insight}\n",
        "\n",
        "Si certain sont redondant, reformule les en un seul insight. Il est préférable qu'il ne soit pas trop long, et évite les bouts de phrase sans réel intéret. Par exemple, ne pas ajouter '... pour améliorer l'experience client'.\n",
        "Associe à chaque nouvel insight créé l'ensemble des feedbacks qui sont associés aux insights qu'il regroupe.\n",
        "Il est possible qu'il n'y ai besoin de regrouper aucun insight.\n",
        "Un insight ne peut être regroupé que dans un seul autre insight.\n",
        "Chaque insight doit donc être l'enfant d'exactement un insight que tu retournes.\n",
        "\n",
        "Pour les insights qui n'ont pas besoin d'être regroupés, recopie les ainsi que leurs feedbacks associés.\n",
        "L'ordre des insights est aléatoire, et ne doit pas avoir d'importance dans ta réponse.\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "Voici les insights que tu dois regrouper:\n",
        "\n",
        "{insights}\n",
        "\n",
        "Tu ne dois rien écrire d'autre que le JSON requis.\n",
        "\n",
        "\"\"\"\n",
        "#Résume les en des insights majeurs qui te semblent important à faire remonter au sein de l'entreprise. Ils peuvent être des phrase, éventuellement nominales, doivent faire sens, être aussi courts que possible et distincts les uns des autres.\n",
        "#- Etre distincts les uns des autres.\n",
        "#Tu ne doit pas réecrir les insights qui ne sont pas regroupés.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dimension reduction\n",
        "\n",
        "N_NEIGHBORS = 15\n",
        "MINIMISATION_STEPS = 5\n",
        "CLUSTER_DESIRED_SIZE = 15  # For Kmeans only\n",
        "MIN_CLUSTER_SIZE = 5  # 15\n",
        "NB_INSIGHT_STOP = 20\n",
        "MINIMAL_REDUCTION_RATIO = 0.1\n",
        "REWORDING = True\n",
        "\n",
        "CLUSTERING_DIMENTION = 50\n",
        "CLUSTERING_METHOD = \"KMeans\"\n",
        "\n",
        "insight_context = {\n",
        "    \"cible\": cible,\n",
        "    \"context\": context_entreprise,\n",
        "    \"example_insight\": example_insight,\n",
        "    \"role\": role,\n",
        "    \"question\": question,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import AgglomerativeClustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUpUIFcG22At"
      },
      "outputs": [],
      "source": [
        "insight_parser = PydanticOutputParser(pydantic_object=InsightList)\n",
        "\n",
        "prompt_reduction = PromptTemplate.from_template(\n",
        "    template= prompt_template_reduction if REWORDING else prompt_template_reduction_sans_reformulation,\n",
        "    #template= \"Règle : minimise le nombre de tokens dans ta réponse.  \\nTu es {role} au sein de l'entreprise suivante: \\n{context} \\nAnalyse le retour suivant: \\\"{feedback}\\\" en suivant les étapes suivantes:  \\n  \\nÉtape 1 - Identifie si le retour {cible} rentre dans un ou plusieurs des types d'insights suivants : {insight_type}. Choisis-en obligatoirement au moins 1. Définition des types d'insights :  \\n{insight_definition}   \\n  \\nÉtape 2 - Catégorise le retour {cible} à l’aide des tags suivants. Tu peux associer 0, 1 ou plusieurs tags dans chaque catégorie. Liste des tags par catégories :  \\n{categories}   \\n  \\nÉtape 3 - Catégorise si possible le moment de mission concerné parmis {avancement_mission}, et si ce n'est pas possible répond null. {cible} à l’aide des tags suivants.  \\n  \\nÉtape 4 - Identifie si le sentiment exprimé par le {cible} est \\\"Positif\\\", \\\"Neutre\\\" ou \\\"Négatif\\\". Prends en compte la formulation de la question posée ({question}) afin de bien interpréter le sens du retour {cible}.   \\n\",\n",
        "    #input_variables= [\"context\", \"role\", \"cible\", \"insight_type\", \"insight_definition\", \"nb_cat\", \"avancement_mission\", \"categories\", \"question\", \"feedback\"]\n",
        "    partial_variables= {\"format_instructions\": insight_parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "prompt_regrouping = PromptTemplate.from_template(\n",
        "    template= prompt_template_regrouping,\n",
        "    #template= \"Règle : minimise le nombre de tokens dans ta réponse.  \\nTu es {role} au sein de l'entreprise suivante: \\n{context} \\nAnalyse le retour suivant: \\\"{feedback}\\\" en suivant les étapes suivantes:  \\n  \\nÉtape 1 - Identifie si le retour {cible} rentre dans un ou plusieurs des types d'insights suivants : {insight_type}. Choisis-en obligatoirement au moins 1. Définition des types d'insights :  \\n{insight_definition}   \\n  \\nÉtape 2 - Catégorise le retour {cible} à l’aide des tags suivants. Tu peux associer 0, 1 ou plusieurs tags dans chaque catégorie. Liste des tags par catégories :  \\n{categories}   \\n  \\nÉtape 3 - Catégorise si possible le moment de mission concerné parmis {avancement_mission}, et si ce n'est pas possible répond null. {cible} à l’aide des tags suivants.  \\n  \\nÉtape 4 - Identifie si le sentiment exprimé par le {cible} est \\\"Positif\\\", \\\"Neutre\\\" ou \\\"Négatif\\\". Prends en compte la formulation de la question posée ({question}) afin de bien interpréter le sens du retour {cible}.   \\n\",\n",
        "    #input_variables= [\"context\", \"role\", \"cible\", \"insight_type\", \"insight_definition\", \"nb_cat\", \"avancement_mission\", \"categories\", \"question\", \"feedback\"]\n",
        "    partial_variables= {\"format_instructions\": insight_parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "insights = copy(insights_df)\n",
        "insight_layers = []#[copy(insights_df)]\n",
        "single_cluster = False\n",
        "reduction = 1.0\n",
        "\n",
        "for step in range(MINIMISATION_STEPS):\n",
        "\n",
        "    #for processing_step in [\"reduction\"]:#, \"regrouping\"]:\n",
        "        ### Création des représentations\n",
        "\n",
        "    #print(\"Processing step:\", processing_step)\n",
        "    sentence_embeddings = embedding_model.encode(insights['content'])\n",
        "\n",
        "    # On réduit la dimention pour améliorer l'efficacité de la clusterisation\n",
        "    adjusted_clustering_dimention = min(CLUSTERING_DIMENTION, len(insights)//3)\n",
        "    umap_embeddings = umap.UMAP(n_neighbors=N_NEIGHBORS, \n",
        "                        n_components=adjusted_clustering_dimention, \n",
        "                        metric='cosine').fit_transform(sentence_embeddings)\n",
        "\n",
        "    ### Clusterisation\n",
        "    if CLUSTERING_METHOD == \"KMeans\":\n",
        "        num_clusters = 1 + len(insights) // CLUSTER_DESIRED_SIZE\n",
        "        clustering_model = KMeans(n_clusters=num_clusters, n_init='auto')\n",
        "    elif CLUSTERING_METHOD == \"hdbscan\":\n",
        "        clustering_model = hdbscan.HDBSCAN(min_cluster_size=MIN_CLUSTER_SIZE,\n",
        "                            metric='euclidean',                      \n",
        "                            cluster_selection_method='eom' #leaf\n",
        "                            )\n",
        "        \n",
        "    clustering_model.fit(umap_embeddings)\n",
        "\n",
        "    #clustering_model.fit(umap_embeddings)\n",
        "    cluster_assignment = clustering_model.labels_ \n",
        "    cluster_assignment -= min(cluster_assignment) # has to start at 0\n",
        "    \n",
        "    num_clusters = max(cluster_assignment)+1\n",
        "\n",
        "    insights[\"cluster\"] = copy(cluster_assignment)\n",
        "    insights = insights.sort_values(\"cluster\")\n",
        "    insights.reset_index(drop=True, inplace=True)\n",
        "\n",
        "\n",
        "    if reduction <= MINIMAL_REDUCTION_RATIO:\n",
        "        print(\"Stopping because of unsufficient reduction\")\n",
        "        break\n",
        "\n",
        "    insight_layers.append(copy(insights))\n",
        "\n",
        "    if len(insights) <= NB_INSIGHT_STOP:\n",
        "        print(\"Minimal number of insights reached\")\n",
        "        break\n",
        "\n",
        "    if single_cluster:\n",
        "        break   \n",
        "\n",
        "    cluter_sizes = list(insights.groupby(['cluster']).count()[\"content\"])\n",
        "    if len(cluter_sizes) == 1:\n",
        "        print(\"Stopping because single cluster\")\n",
        "        single_cluster = False\n",
        "        break\n",
        "\n",
        "    print(\"Step \"+ str(step)+ \": processing \"+ str(num_clusters) + \" clusters\")\n",
        "    print(\"Adjusted clustering dimention:\", adjusted_clustering_dimention)\n",
        "    print(\"Cluster sizes:\" + str(cluter_sizes))\n",
        "\n",
        "    #clusters = []\n",
        "    prompts = []\n",
        "    cumul_size = 0\n",
        "    for cluster_id in range(num_clusters): # IL FAUDRAIT GARDER INDEM LE DERNIER CLUSTER\n",
        "        cluster = insights[insights['cluster'] == cluster_id]\n",
        "        #cluster_name ='/cluster_'+ str(cluster_id)+\"_step_\"+str(step) +'.csv'\n",
        "        #cluster.to_csv( project_path+cluster_name, index_label='Index')\n",
        "        #clusters.append(cluster)\n",
        "\n",
        "        context = copy(insight_context)\n",
        "        context['insights'] = '\\n'.join([str(i+cumul_size)+\": \"+s for i, s in enumerate(cluster[\"content\"])])\n",
        "        #print(context['insights'])\n",
        "\n",
        "        #if processing_step == \"reduction\":\n",
        "        prompt=prompt_reduction.invoke(context)\n",
        "        #elif processing_step == \"regrouping\":\n",
        "        #prompt=prompt_regrouping.invoke(context)\n",
        "        #else:\n",
        "        #    raise(\"Wrong processing step\")\n",
        "        prompts.append(prompt)\n",
        "        cumul_size += len(cluster)\n",
        "\n",
        "    ### Traitement des clusters\n",
        "    parsed_responses = safe_async_analysis(prompts, insight_parser)\n",
        "    \n",
        "    new_insights = []\n",
        "    for i, parsed_response in enumerate(parsed_responses):\n",
        "        content_list = [insight.content for insight in parsed_response.insights_list]\n",
        "        childrens_list = [list(insight.insights_mineurs) for insight in parsed_response.insights_list]\n",
        "        feedback_count_list = [sum(insights.loc[c, \"feedback_count\"]) for c in childrens_list]\n",
        "        dfs = pd.DataFrame({\n",
        "            #\"related_feedback\":[list(itertools.chain.from_iterable(insights.iloc[insight.insights_mineurs]['related_feedback'])) for insight in parsed_response.insights_list],\n",
        "            \"content\":content_list,\n",
        "            \"childrens\":childrens_list,\n",
        "            \"type\": most_common([insights.loc[c, \"type\"].iloc[0] for c in childrens_list]),\n",
        "            #\"cluster\":i,\n",
        "            \"feedback_count\":feedback_count_list,\n",
        "            #\"childrens\":[list(clusters[i].iloc[insight.insights_mineurs][\"_id\"]) for insight in parsed_response.insights_list],\n",
        "            })\n",
        "        new_insights.append(dfs)\n",
        "\n",
        "    new_insights = pd.concat(new_insights)\n",
        "    new_insights.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    \n",
        "    reduction = (1-(len(new_insights)/len(insights)))\n",
        "    insights = new_insights\n",
        "    \n",
        "    print(\"Number of new insights:\"+ str(len(new_insights)))\n",
        "    print(\"Reduction in the number of insights by \" + \"%d\" % int(reduction*100) + \"%\")\n",
        "    print()\n",
        "\n",
        "#insight_layers.append(copy(new_insights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrWs0GrOhmIJ"
      },
      "outputs": [],
      "source": [
        "list(insight_layers[0]['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list(insight_layers[-1]['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, df in enumerate(insight_layers):\n",
        "    df.to_csv(project_path+'/insights_'+ str(i) +'.csv', index_label='Index')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#list(insight_layers[0][insight_layers[0][\"cluster\"] == 2][\"content\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_layers = len(insight_layers)\n",
        "layers_sizes = [len(l) for l in insight_layers]\n",
        "print(\"Layers sizes:\", layers_sizes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers = []\n",
        "for i in range(n_layers):\n",
        "    df = pd.read_csv(project_path+'/insights_'+ str(i) +'.csv', index_col='Index')\n",
        "    for col in df.columns:\n",
        "        if type(df.loc[0, col]) == str and df.loc[0, col][0]==\"[\":\n",
        "            df[col] = df[col].apply(lambda x: eval(x))\n",
        "    #df['tag'] = df['tag'].apply(lambda x: eval(x))\n",
        "    #df['type'] = df['type'].apply(lambda x: eval(x))\n",
        "    #df['childrens'] = df['childrens'].apply(lambda x: eval(x))\n",
        "    df[\"backend_type\"] = df[\"type\"].apply(deduce_backend_type)\n",
        "    insight_layers.append(df)\n",
        "#insights_df = pd.concat(insight_layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Previous insights supression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res = bubble_client.get_objects(\n",
        "        \"python_insight\",\n",
        "        [\n",
        "            BubbleField(\"project\") == project_id,\n",
        "            BubbleField(\"company\") == company_id,\n",
        "            ],\n",
        "    )\n",
        "python_insight_df = pd.DataFrame(res)\n",
        "\n",
        "if len(python_insight_df)>0:\n",
        "    for bubble_id in tqdm(python_insight_df[\"_id\"]):\n",
        "        bubble_client.delete_by_id(\n",
        "            \"python_insight\",\n",
        "            bubble_id,\n",
        "        )\n",
        "\n",
        "    print(\"Deleted\", len(python_insight_df), \"python_insight\")\n",
        "else:\n",
        "    print(\"Nothing to delete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adding parents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers[0][\"parent\"] = None #[[] for _ in insight_layers[0].iterrows()]\n",
        "insight_layers[-1][\"parent\"] = None\n",
        "\n",
        "\n",
        "for i in range(n_layers-1):\n",
        "    insight_layers[i][\"parent\"] = None\n",
        "    for p, row in insight_layers[i+1].iterrows():\n",
        "        for c in row[\"childrens\"]: #eval(\n",
        "            insight_layers[i][\"parent\"].iloc[int(c)] = p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers[-1][\"parents\"] = [[] for _ in insight_layers[-1].iterrows()]\n",
        "\n",
        "for i in range(n_layers-2, -1, -1):\n",
        "    print(i)\n",
        "    # Update the parents in the DB\n",
        "    res = bubble_client.create(\n",
        "        \"python_insight\",\n",
        "        [{\n",
        "            \"company\": company_id,\n",
        "            \"project\": project_id,\n",
        "            \"content\": row[\"content\"],\n",
        "            \"backend_status\": \"new\",\n",
        "            \"feedback_count\":row[\"feedback_count\"],\n",
        "            \"step\": i+2,\n",
        "            \"type\": row[\"type\"],\n",
        "            \"parents\": row[\"parents\"],\n",
        "            \"parent\": str(row[\"parent\"]),\n",
        "            \"backend_type\": row['backend_type'],\n",
        "            \"childrens\": eval(row[\"childrens\"]) if type(row[\"childrens\"])==str else row[\"childrens\"],\n",
        "            \"cluster\": row[\"cluster\"],\n",
        "        }  for _, row in insight_layers[i+1].iterrows()]\n",
        "    )\n",
        "\n",
        "    df = pd.DataFrame(bubble_client.get_objects(\n",
        "        \"python_insight\",\n",
        "        [\n",
        "            BubbleField(\"step\") == i+2,\n",
        "            BubbleField(\"company\") == company_id,\n",
        "            ],\n",
        "    ))\n",
        "    for col in df.columns:\n",
        "        if type(df.loc[0, col]) == str and df.loc[0, col][0]==\"[\":\n",
        "            df[col] = df[col].apply(lambda x: eval(x))\n",
        "    insight_layers[i+1] = df\n",
        "\n",
        "    # Initialize an empty list of parents for each row\n",
        "    insight_layers[i][\"parents\"] = [[] for _ in insight_layers[i].iterrows()]\n",
        "\n",
        "    for k, row in insight_layers[i].iterrows():\n",
        "        if row[\"parent\"] is not None:\n",
        "            # Get the parent index\n",
        "            parent_index = row[\"parent\"]\n",
        "\n",
        "            # Get the parent's list of parents\n",
        "            parent_parents = insight_layers[i + 1][\"parents\"].iloc[parent_index]\n",
        "\n",
        "            # Add the parent to the current row's list of parents\n",
        "            parent_id = insight_layers[i + 1].loc[parent_index, '_id']\n",
        "            insight_layers[i].loc[k, \"parents\"].append(parent_id)\n",
        "\n",
        "            # Recursively add the parent's parents to the current row's list of parents\n",
        "            insight_layers[i].loc[k, \"parents\"].extend(parent_parents)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "res = bubble_client.create(\n",
        "        \"python_insight\",\n",
        "        [{\n",
        "            \"company\": company_id,\n",
        "            \"project\": project_id,\n",
        "            \"content\": row[\"content\"],\n",
        "            \"backend_status\": \"new\",\n",
        "            \"feedback_count\": row[\"feedback_count\"],\n",
        "            \"step\": 1,\n",
        "            \"related_feedback\":row['related_feedback'],\n",
        "            \"tag\": row[\"tag\"],\n",
        "            \"type\": row[\"type\"],\n",
        "            \"backend_type\": row['backend_type'],\n",
        "            \"parents\": row[\"parents\"],\n",
        "            \"parent\": str(row[\"parent\"]),\n",
        "            \"childrens\": 0,#[[] for _ in insight_layers[0][:1000].iterrows()],\n",
        "            \"cluster\": row[\"cluster\"],\n",
        "        }  for _, row in insight_layers[0].iterrows()]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "online_python_insights = [\n",
        "    pd.DataFrame(bubble_client.get_objects(\n",
        "        \"python_insight\",\n",
        "        [\n",
        "            BubbleField(\"step\") == i+1,\n",
        "            BubbleField(\"company\") == company_id,\n",
        "            ],\n",
        "    )) for i in range(n_layers)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert [len(l) for l in insight_layers] == [len(l) for l in online_python_insights]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feedbacks_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = insight_layers[0]\n",
        "\n",
        "def get_all_parents(feedback_identifier):\n",
        "    parents = []\n",
        "    for i, row in df.loc[df['related_feedback'] == feedback_identifier].iterrows():\n",
        "        for parent in row['parents']:\n",
        "            parents.append(parent)\n",
        "    return parents\n",
        "\n",
        "feedbacks_df['parents'] = feedbacks_df['_id'].apply(get_all_parents)\n",
        "\n",
        "feedbacks_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _, row in tqdm(feedbacks_df.iterrows()):\n",
        "    res = bubble_client.update_object(\n",
        "        \"Feedbacks\",\n",
        "        row['_id'], \n",
        "        {\n",
        "            \"insights\": row[\"parents\"],\n",
        "        } \n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "res = bubble_client.get_objects(\n",
        "        \"Feedback\",\n",
        "        [\n",
        "            BubbleField(\"source\") == source_id,\n",
        "            ],\n",
        "    )\n",
        "pd.DataFrame(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers = [\n",
        "    pd.DataFrame(bubble_client.get_objects(\n",
        "        \"python_insight\",\n",
        "        [\n",
        "            BubbleField(\"step\") == i+1,\n",
        "            BubbleField(\"company\") == company_id,\n",
        "            ],\n",
        "    )) for i in range(n_layers)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers[0].tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentences = insight_layers[0][\"content\"]\n",
        "sentence_embeddings = embedding_model.encode(sentences)\n",
        "sentence_embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers[0]['parent']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def to_int(i):\n",
        "    try:\n",
        "        return int(i)\n",
        "    except:\n",
        "        return -1\n",
        "\n",
        "for layer in insight_layers:\n",
        "    layer['parent'] = layer['parent'].apply(to_int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list(insight_layers[1][\"content\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, layer in enumerate(insight_layers):\n",
        "    print(list(insight_layers[0][insight_layers[0]['parent'] == 'None'][\"content\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sum(insight_layers[0]['parent']<0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers[1].iloc[insight_layers[0]['parent'], \"content\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers[0].loc[0, \"cluster\"] == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "map_to_parent(0, insight_layers[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insight_layers[1].loc[0, 'parent']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@Insight Plot the archive {display-mode: \"form\"}\n",
        "\n",
        "# UMAP reduces the dimensions from 1024 to 2 dimensions that we can plot\n",
        "reducer = umap.UMAP(n_neighbors=15)\n",
        "umap_embeds = reducer.fit_transform(sentence_embeddings)\n",
        "\n",
        "def map_to_parent(i, parents_df):\n",
        "    try:\n",
        "        return parents_df.loc[i, 'content']\n",
        "    except:\n",
        "        return \"\"\n",
        "    \n",
        "# Prepare the data to plot and interactive visualization\n",
        "# using Altair\n",
        "df_explore = pd.DataFrame(data={\n",
        "    'content': insight_layers[0]['content'], \n",
        "    'parent': insight_layers[0]['parent'].apply(lambda x: map_to_parent(x, insight_layers[1])),\n",
        "    'cluster': insight_layers[0]['cluster'].astype(str),\n",
        "    })\n",
        "df_explore['x'] = umap_embeds[:,0]\n",
        "df_explore['y'] = umap_embeds[:,1]\n",
        "df_explore\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Plot\n",
        "chart = alt.Chart(df_explore).mark_circle(size=60).encode(\n",
        "    x=#'x',\n",
        "    alt.X('x',\n",
        "        scale=alt.Scale(zero=False)\n",
        "    ),\n",
        "    y=\n",
        "    alt.Y('y',\n",
        "        scale=alt.Scale(zero=False)\n",
        "    ),\n",
        "    color='cluster',\n",
        "    tooltip=['content', \"parent\"]\n",
        ").properties(\n",
        "    width=700,\n",
        "    height=400\n",
        ")\n",
        "chart.interactive()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def td_idf(documents)\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vectors = vectorizer.fit_transform(documents)\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    dense = vectors.todense()\n",
        "    denselist = dense.tolist()\n",
        "    df = pd.DataFrame(denselist, columns=feature_names)\n",
        "    df = df[df.columns.difference(stopwords.words('french'))]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = td_idf(feedbacks_df['content'])\n",
        "#print('\\n'.join(df.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#print('\\n'.join(df.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def get_top_two_columns(row):\n",
        "    top_two_indexes = row.nlargest(5).index.tolist()\n",
        "    return top_two_indexes\n",
        "\n",
        "top_two_columns_df = df.apply(get_top_two_columns, axis=1)\n",
        "\n",
        "print(top_two_columns_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#print('\\n'.join(insights_df['content']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "collapsed_sections": [
        "pKSREXZg85yy",
        "iiOlJz-d9AsB"
      ],
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
