{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjPRVXra8lVZ"
   },
   "source": [
    "# Dependancies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKSREXZg85yy"
   },
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zMSukVZh29HK"
   },
   "outputs": [],
   "source": [
    "#!pip install sentence_transformers langchain openai tqdm datasets asyncio scikit-learn cohere tiktoken umap altair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Md3DNHlV22Ai"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset\n",
    "import umap\n",
    "import altair as alt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List\n",
    "import enum\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.output_parsers.regex_dict import RegexDictParser\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, ChatMessage\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from pydantic import BaseModel, Field, validator, create_model\n",
    "from openai import AsyncOpenAI, OpenAI\n",
    "#import asyncio\n",
    "import os\n",
    "\n",
    "import requests\n",
    "\n",
    "from pydantic import BaseModel, ValidationInfo, model_validator\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import umap.umap_ as umap\n",
    "#import umap\n",
    "import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.bubble import *\n",
    "from src.models import *\n",
    "from src.utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_path = \"Prompts/fr/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqsmhIToV_yX"
   },
   "source": [
    "## Bubble API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedbacks_df = get(\"Feedback\", max_objects=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_df = get(\"Type\", constraints=[])\n",
    "categories_df = get(\"Category\")\n",
    "original_subcategories_df = get(\"SubCategory\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_infos = bubble_client.get(\n",
    "    \"Company\",\n",
    "    bubble_id=COMPANY_ID,\n",
    ")\n",
    "project_infos = bubble_client.get(\n",
    "    \"Project\",\n",
    "    bubble_id=PROJECT_ID,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TypeInsight = enum.Enum(\"Type de l'insight\", [(convert_text_to_constants(x), x) for x in types_df.Name])\n",
    "TypeInsight(\"Point positif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TypeInsight.POINT_POSITIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TypeInsight = enum.Enum(\"Type de l'insight\", [(convert_text_to_constants(x), x) for x in types_df.Name])\n",
    "CategoryInsight = enum.Enum(\"Categories de l'insight\", [(convert_text_to_constants(x), x) for x in categories_df.Name])\n",
    "dict_SubCategoriesInsight = {\n",
    "    row[\"Name\"]:enum.Enum(\"Categories de l'insight\", [(convert_text_to_constants(x), x) for x in original_subcategories_df[original_subcategories_df[\"Parent_category\"] == row[\"_id\"]].Name])\n",
    "    for _,row in categories_df.iterrows()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = categories_df.copy()\n",
    "df['Parent_category'] = df['_id'].astype(str)\n",
    "original_subcategories_df['Parent_category'] = original_subcategories_df['Parent_category'].astype(str)\n",
    "df = pd.merge(original_subcategories_df, df, on=[\"Parent_category\", \"Company\"])\n",
    "df = df[[\"Name_x\", \"Name_y\", \"Company\", \"Description\", \"_id_x\", \"_id_y\"]]\n",
    "df.columns = [\"Name\", \"Category\",  \"Company\", \"Description\", \"_id\", \"Category_id\"]\n",
    "subcategories_df = df\n",
    "subcategories_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SubCategoriyInsight = enum.Enum(\"Categories de l'insight\", [(row[\"Category\"]+\" : \"+row[\"Name\"], convert_text_to_constants(row[\"Category\"]+\" : \"+row[\"Name\"])) for _, row in subcategories_df.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_descr = columns_to_string(types_df, \"Name\", \"Description\")\n",
    "print(types_descr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_descr = columns_to_string(subcategories_df, \"Name\", \"Description\")\n",
    "print(tags_descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example_insight = \"Manque de clarté de l'affichage des prix en magasin\"\n",
    "#exemple_commentaire = \"je suis exclusif metro je n ai aucun representant j achetais jusqu a present tout metro par facilite mais je suis tres souvent décue par la reponse ha non on n en a pas cela arrive demain je pense que depuis le covid tout le monde ou presque s en fou!!!\"\n",
    "#examples_insights_df = pd.DataFrame([\n",
    "#    {\"Insights qui devraient en découler\": \"Déceptions face aux retards de livraison\"},\n",
    "#    {\"Insights qui devraient en découler\": \"Impression d'une baisse de qualité du service depuis le Covid\"},\n",
    "#])\n",
    "\n",
    "feedback_context = {\n",
    "            \"entreprise\": company_infos[\"Name\"],\n",
    "            \"context\": company_infos['Context'],\n",
    "            \"role\": company_infos['Role'],\n",
    "            \"cible\": project_infos['Target'],\n",
    "            \"insight_types\": types_descr,\n",
    "            \"insight_categories\": tags_descr,\n",
    "            #\"question\": project_infos['Study_question'],\n",
    "            #\"exemple_commentaire\": exemple_commentaire,\n",
    "            #\"example_insights\": '\\n- '.join(list(examples_insights_df['Insights qui devraient en découler'])),\n",
    "        }\n",
    "\n",
    "feedback_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Insights extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aspects and Insights creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FeedbackIndex = enum.Enum(\"Indice du retour associé\", [(str(i), i) for i in range(BATCH_SIZE)])\n",
    "\n",
    "class SousCategorie(BaseModel):\n",
    "    indice: int = Field(description=\"Indice de la sous-catégorie. Doit être un entier.\")\n",
    "    nom: str = Field(description=\"Nom de la sous-catégorie.\")\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.nom + ' ('+str(self.indice)+')'\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def validate_ids(self, info: ValidationInfo):\n",
    "        context = info.context\n",
    "        if context:\n",
    "            tags: List[SousCategorie] = context.get(\"sous_categories\")\n",
    "            assert self.indice in {\n",
    "                tag.indice for tag in tags\n",
    "            }, f\"sous_categories ID {self.indice} not found in context\"\n",
    "            assert self.nom in {\n",
    "                tag.nom for tag in tags\n",
    "            }, f\"sous_categories name {self.nom} not found in context\"\n",
    "        return self\n",
    "    \n",
    "class SousCategorieAvecDescription(SousCategorie):\n",
    "    categorie : str\n",
    "    description: str\n",
    "\n",
    "\n",
    "class Aspect(BaseModel):\n",
    "    sous_categorie : SousCategorie = Field(description=\"Sous-catégorie concernée.\")\n",
    "    note_satisfaction : int = Field(description=\"Note de satisfaction du client concernant cette sous-catégorie, de 1 (pas content) à 5 (très content).\")\n",
    "    explication: str = Field(description=\"Eventuelle explication du ressenti du client, si celle-ci parait importante à faire remonter au sein de l'entreprise. Doit être aussi claire et concise que possible.\") #Field(description=\"Point intéressant a retenir du commentaire.\")\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        return '\\n' + str(self.sous_categorie) + '\\nSatisfaction: ' + str(self.note_satisfaction) + \"/5\\nExplication: \" + self.explication\n",
    "    \n",
    "    @model_validator(mode=\"after\")\n",
    "    def validate_ids(self, info: ValidationInfo):\n",
    "        assert (0 <= self.note_satisfaction) and (self.note_satisfaction <= 5)\n",
    "        return self\n",
    "\n",
    "class ListAspects(BaseModel):\n",
    "    list_aspects: List[Aspect] = Field(description=\"Liste des différents aspects évoqués dans le feedback.\")\n",
    "\n",
    "    def __str__(self):\n",
    "        return '\\n'.join([str(x) for x in self.list_aspects])\n",
    "    \n",
    "\n",
    "class AspectsRequest(BaseModel):\n",
    "    texts: List[str]\n",
    "    sous_categories: List[SousCategorieAvecDescription]\n",
    "\n",
    "\n",
    "class AspectsResponse(BaseModel):\n",
    "    texts: List[str]\n",
    "    predictions: List[Aspect]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sous_categories = [SousCategorieAvecDescription(indice=i, nom=row[\"Category\"] + \" : \" + row[\"Name\"], categorie=row[\"Category\"], description=row[\"Description\"]) for i ,row in  subcategories_df.iterrows()]\n",
    "sous_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(prompts_path+'prompt_aspects.txt') as f:\n",
    "    prompt_aspects = PromptTemplate.from_template(f.read())\n",
    "\n",
    "print(prompt_aspects.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\", \".join([f\"`{tag}`\" for tag in sous_categories])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_single_request(prompt: str, sous_categories: List[SousCategorie]) -> Aspect:\n",
    "    allowed_tags = [(tag.indice, tag.nom) for tag in sous_categories]\n",
    "    allowed_tags_str = \", \".join([f\"`{tag}`\" for tag in allowed_tags])\n",
    "\n",
    "    return client.chat.completions.create(\n",
    "        model=\"mixtral\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"Tu es {feedback_context['role']} au sein de l'entreprise {feedback_context['entreprise']}. Voici un bref rappel sur cette entreprise: \\n'{feedback_context['context']}'\\n\\En tant que  {feedback_context['role']}, tu est spécialisé dans l'analyse de commentaire.\"\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Voici les sous-catégories: {allowed_tags_str}\",\n",
    "            },\n",
    "        ], \n",
    "        response_model=ListAspects,  # Minimizes the hallucination of tags that are not in the allowed tags.\n",
    "        validation_context={\"sous_categories\": sous_categories},\n",
    "    )\n",
    "\n",
    "def tag_request(request: AspectsRequest) -> AspectsResponse:\n",
    "    predictions = [tag_single_request(text, request.tags) for text in request.texts]\n",
    "    \n",
    "    return AspectsResponse(\n",
    "        texts=request.texts,\n",
    "        predictions=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feedback =\"J'ai commandé une paire de chaussures sur votre site. Le site était facile à utiliser mais j'ai galéré à trouver ma taille. La livraison a été super rapide, mais les chaussures étaient trop petites. J'ai contacté le service client pour les renvoyer et ils m'ont dit que je devais payer les frais de retour. Du coup, j'ai décidé de les garder et de les donner à ma sœur. Elles sont bien mais un peu trop serrées pour moi.\"\n",
    "feedback =\"I ordered a pair of shoes on your site. The site was easy to use but I had a hard time finding my size. The delivery was super fast, but the shoes were too small. I contacted the customer service to return them and they told me I had to pay the return shipping. So I decided to keep them and give them to my sister. They are good but a little too tight for me.\"\n",
    "prompt = prompt_aspects.invoke({\"feedback\": feedback})\n",
    "response = tag_single_request(prompt.text, sous_categories=sous_categories)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feedback =\"J'ai commandé une paire de chaussures sur votre site. Le site était facile à utiliser mais j'ai galéré à trouver ma taille. La livraison a été super rapide, mais les chaussures étaient trop petites. J'ai contacté le service client pour les renvoyer et ils m'ont dit que je devais payer les frais de retour. Du coup, j'ai décidé de les garder et de les donner à ma sœur. Elles sont bien mais un peu trop serrées pour moi.\"\n",
    "feedback =\"I ordered a pair of shoes on your site. The site was easy to use but I had a hard time finding my size. The delivery was super fast, but the shoes were too small. I contacted the customer service to return them and they told me I had to pay the return shipping. So I decided to keep them and give them to my sister. They are good but a little too tight for me.\"\n",
    "prompt = prompt_aspects.invoke({\"feedback\": feedback})\n",
    "response = tag_single_request(prompt.text, sous_categories=sous_categories)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feedback =\"J'ai commandé une paire de chaussures sur votre site. Le site était facile à utiliser mais j'ai galéré à trouver ma taille. La livraison a été super rapide, mais les chaussures étaient trop petites. J'ai contacté le service client pour les renvoyer et ils m'ont dit que je devais payer les frais de retour. Du coup, j'ai décidé de les garder et de les donner à ma sœur. Elles sont bien mais un peu trop serrées pour moi.\"\n",
    "feedback = feedbacks_df.loc[0, \"Content\"]\n",
    "prompt = prompt_aspects.invoke({\"feedback\": feedback})\n",
    "response = tag_single_request(prompt.text, sous_categories=sous_categories)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedbacks_df.loc[0, \"Content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "for i, feedback in tqdm(feedbacks_df.iterrows()):\n",
    "    prompt = prompt_aspects.invoke({\"feedback\": feedback['Content']})\n",
    "    response = tag_single_request(prompt.text, sous_categories=sous_categories)\n",
    "    responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, feedback in tqdm(feedbacks_df.iterrows()):\n",
    "    results = bubble_client.create(\n",
    "        \"Aspect\",\n",
    "        [{\n",
    "            \"Company\": COMPANY_ID,\n",
    "            \"Project\": PROJECT_ID,\n",
    "            \"Category\": subcategories_df.loc[aspect.sous_categorie.indice, \"Category_id\"],\n",
    "            \"Consequence\": \"\",\n",
    "            \"Explanation\": aspect.explication,\n",
    "            \"Rating\": aspect.note_satisfaction,\n",
    "            \"Sub_category\": subcategories_df.loc[aspect.sous_categorie.indice, \"_id\"],\n",
    "            \"Associated_feedback\": feedback[\"_id\"],\n",
    "            }  for aspect in responses[i].list_aspects]\n",
    "        )\n",
    "\n",
    "    bubble_client.update_object(bubble_type=\"Feedback\", bubble_id=feedback[\"_id\"], fields={\"Aspects\": [res['id'] for res in results]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(prompts_path+'prompt_insights_creation.txt') as f:\n",
    "    prompt_insights = PromptTemplate.from_template(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = []\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "for batch_df in batchify(feedbacks_df, size=BATCH_SIZE):\n",
    "    context = deepcopy(feedback_context)\n",
    "    context[\"feedbacks\"] = '\\n\\n'.join([str(i)+\" : \"+x for i, x in zip(batch_df.index, batch_df[\"Content\"])])  \n",
    "    #\"- \"+\"\\n- \".join(batch_df['content'])\n",
    "    #context[\"insights\"] = \"- \"+\"\\n- \".join(batch_df['content'])\n",
    "    prompts.append(prompt_insights.invoke(context))\n",
    "\n",
    "print(len(prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompts[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = apply_analysis(prompts, InsightsList, bar=True)\n",
    "list_batch_insights_df = [pd.DataFrame(enum_to_str(response.insights_list)) for response in responses]\n",
    "\n",
    "print(len(list_batch_insights_df), \"batch have been processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses[0].insights_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(df) for df in list_batch_insights_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_batch_insights_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(list_batch_insights_df[0]['contenu'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accociate newly created insights to feedbacks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(prompts_path+'prompt_feedbacks.txt') as f:\n",
    "    prompt_feedbacks = PromptTemplate.from_template(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment(str, enum.Enum):\n",
    "    POSITIF = \"Positif\"\n",
    "    NEUTRE = \"Neutre\"\n",
    "    NEGATIF = \"Négatif\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InsightsIndex = enum.Enum(\"Indice de l'insight associé\", [(str(i), i) for i in range(BATCH_SIZE)])\n",
    "\n",
    "class Feedback(BaseModel):\n",
    "        insights_list: List[InsightsIndex] = Field(description=\"Indices des insights associés à ce retour\")\n",
    "        sentiment: Sentiment = Field(description=\"Sentiment exprimé\")\n",
    "\n",
    "class FeedbackInfosList(BaseModel):\n",
    "        feedbacks_list: List[Feedback] = Field(description=\"Liste des informations associées aux feedbacks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = []\n",
    "for batch_insights_df, batch_feedbacks_df in zip(list_batch_insights_df, batchify(feedbacks_df, size=BATCH_SIZE)):\n",
    "    #InsightsEnum = enum.Enum(\"Insight associé\", [(convert_text_to_constants(x), i) for i, x in zip(batch_insights_df.index, batch_insights_df[\"content\"])])\n",
    "\n",
    "    context = deepcopy(feedback_context)\n",
    "    #context[\"feedbacks\"] = \"- \"+\"\\n- \".join(batch_feedbacks_df['content'])\n",
    "    context[\"feedbacks\"] = '\\n'.join([str(i)+\" : \"+x for i, x in zip(batch_insights_df.index, batch_feedbacks_df[\"content\"])])  \n",
    "    context[\"insights\"] = '\\n'.join([str(i)+\" : \"+x for i, x in zip(batch_insights_df.index, batch_insights_df[\"contenu\"])])\n",
    "    prompts.append(prompt_feedbacks.invoke(context))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompts[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "responses = apply_async_analysis(prompts, FeedbackInfosList)\n",
    "\n",
    "list_enriched_feedbacks_df = [pd.DataFrame(enum_to_str(response.feedbacks_list)) for response in responses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(df) for df in list_enriched_feedbacks_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pd.concat(list_enriched_feedbacks_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_insights_df, batch_index_feedbacks, enriched_feedbacks_df in zip(list_batch_insights_df, batchify(feedbacks_df.index, size=BATCH_SIZE), list_enriched_feedbacks_df):\n",
    "    feedbacks_df.loc[batch_index_feedbacks, 'sentiment'] = enriched_feedbacks_df['sentiment']\n",
    "    feedbacks_df.loc[batch_index_feedbacks, 'insights_index'] = enriched_feedbacks_df['insights_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_insights_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_batch_feedbacks_df = [pd.DataFrame(enum_to_str(response.feedbacks_list)) for response in responses]\n",
    "list_batch_feedbacks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedbacks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_batch_feedbacks_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_batch_insights_df[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in batchify(feedbacks_df, size=BATCH_SIZE)][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(df) for df in list_batch_feedbacks_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l = [response.feedbacks_list for response in responses]\n",
    "l = list(itertools.chain.from_iterable(l))\n",
    "feedbacks_infos_df = pd.DataFrame(enum_to_str(l))\n",
    "feedbacks_infos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedbacks_infos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedbacks_infos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedbacks_df['sentiment'] = feedbacks_infos_df['sentiment']\n",
    "feedbacks_df['insights_list'] = feedbacks_infos_df['insights_list']\n",
    "feedbacks_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedbacks attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insights_enum = enum.Enum(\"Insight associé\", [(convert_text_to_constants(x), i) for i, x in zip(batch_insights_df.index, batch_insights_df[\"content\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(prompts_path+'prompt_feedbacks.txt') as f:\n",
    "    prompt_feedbacks = PromptTemplate.from_template(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rmFsbtT722Aq"
   },
   "outputs": [],
   "source": [
    "feedback_parser = PydanticOutputParser(pydantic_object=Feedback)\n",
    "\n",
    "prompt_feedback = PromptTemplate.from_template(\n",
    "    template= prompt_template_feedback,\n",
    "    partial_variables= {\"format_instructions\": feedback_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "prompts = []\n",
    "for feedback in feedbacks_df[feedbacks_column]:\n",
    "    context = deepcopy(feedback_context)\n",
    "    context[\"feedback\"] = feedback\n",
    "    prompts.append(prompt_feedback.invoke(context))\n",
    "\n",
    "#print(prompts[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jFraYQTLOmz-"
   },
   "outputs": [],
   "source": [
    "parsed_responses = safe_async_analysis(prompts, feedback_parser)\n",
    "\n",
    "feedbacks_df[\"sentiment\"] = [rep.sentiment for rep in parsed_responses]\n",
    "feedbacks_df[\"insights\"] = [[] for rep in parsed_responses]\n",
    "\n",
    "k=0\n",
    "insights = []\n",
    "for i, rep in enumerate(parsed_responses):\n",
    "    for j, insight in enumerate(rep.insights_list):\n",
    "        insights.append(insight)\n",
    "        feedbacks_df[\"insights\"].iloc[i].append(str(k))\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedbacks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hKTksTKah7At"
   },
   "outputs": [],
   "source": [
    "insights_df = pd.DataFrame({\n",
    "    \"content\":insights,\n",
    "    \"feedback_count\": 1,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedbacks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insights_df[\"related_feedback\"] = [[] for _ in range(len(insights_df))]\n",
    "\n",
    "for i, row in feedbacks_df.iterrows():\n",
    "    for j in row[\"insights\"]:\n",
    "        insights_df[\"related_feedback\"].iloc[int(j)] = row['_id'] #[int(i)]\n",
    "\n",
    "insights_df[\"childrens\"] = [[] for _ in range(len(insights_df))]\n",
    "\n",
    "insights_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k88axy7kPxQE"
   },
   "source": [
    "# Insights categorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i, filter in filters_df.iterrows():\n",
    "    prompt_tags += '\\n\\n'+filter[\"Name\"]#+' ('+filter[\"_id\"] +')'\n",
    "    tags = tags_df[tags_df[\"Filter\"] == filter[\"_id\"]]\n",
    "    for _, tag in tags.iterrows():\n",
    "        prompt_tags += '\\n'+\"- \"+tag[\"Name\"]+' ('+tag[\"_id\"] +')'\n",
    "\n",
    "print(prompt_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(prompts_path+'prompt_categorsiation.txt') as f:\n",
    "    prompt_categorsiation = PromptTemplate.from_template(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hjHnM12_KMN3"
   },
   "outputs": [],
   "source": [
    "class FirstInsight(BaseModel):\n",
    "    tags_id: List[str] = Field(description=\"Identifiants des tags de l'insight\")\n",
    "    content: str = \"\" #Field(description=\"Point intéressant a retenir du commentaire.\")\n",
    "\n",
    "    def __str__(self):\n",
    "        return '- ' + self.content + \"\\nTypes: \" + ', '.join(self.insight_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorsiation_parser = PydanticOutputParser(pydantic_object=FirstInsight)\n",
    "\n",
    "prompt_categorsiation = PromptTemplate.from_template(\n",
    "    template= prompt_template_categorsiation,\n",
    "    partial_variables= {\"format_instructions\": categorsiation_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "prompts = []\n",
    "for insight in insights_df[\"content\"]:\n",
    "    context = deepcopy(feedback_context)\n",
    "    context[\"insight\"] = insight\n",
    "    prompts.append(prompt_categorsiation.invoke(context))\n",
    "\n",
    "#print(prompts[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_responses = safe_async_analysis(prompts, categorsiation_parser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "insights_df[\"tag\"] = [rep.tags_id for rep in parsed_responses]\n",
    "#insights_df[\"Insights\"] = [[] for rep in parsed_responses]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types affectation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_types = \"\"\n",
    "\n",
    "for _, tag in types_df.iterrows():\n",
    "    prompt_types += '\\n'+\"- \"+tag[\"Title\"]+' ('+tag[\"_id\"] +') : ' + tag[\"Definition\"]\n",
    "\n",
    "print(prompt_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorsiation_parser = PydanticOutputParser(pydantic_object=FirstInsight)\n",
    "\n",
    "prompt_categorsiation = PromptTemplate.from_template(\n",
    "    template= prompt_template_types,\n",
    "    partial_variables= {\"format_instructions\": categorsiation_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "prompts = []\n",
    "for insight in insights_df[\"content\"]:\n",
    "    context = deepcopy(feedback_context)\n",
    "    context[\"insight\"] = insight\n",
    "    prompts.append(prompt_categorsiation.invoke(context))\n",
    "\n",
    "#print(prompts[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_responses = safe_async_analysis(prompts, categorsiation_parser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insights_df[\"type\"] = [rep.insight_type for rep in parsed_responses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedbacks_df.to_csv(project_path+'/feedbacks.csv', index_label='Index')\n",
    "insights_df.to_csv(project_path+'/insights.csv', index_label='Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insight_layers = [\n",
    "    pd.DataFrame(bubble_client.get_objects(\n",
    "        \"python_insight\",\n",
    "        [\n",
    "            BubbleField(\"step\") == i+1,\n",
    "            BubbleField(\"company\") == company_id,\n",
    "            ],\n",
    "    )) for i in range(n_layers)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insight_layers[0].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = insight_layers[0][\"content\"]\n",
    "sentence_embeddings = embedding_model.encode(sentences)\n",
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insight_layers[0]['parent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insight_layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_int(i):\n",
    "    try:\n",
    "        return int(i)\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "for layer in insight_layers:\n",
    "    layer['parent'] = layer['parent'].apply(to_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(insight_layers[1][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(insight_layers):\n",
    "    print(list(insight_layers[0][insight_layers[0]['parent'] == 'None'][\"content\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(insight_layers[0]['parent']<0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insight_layers[1].iloc[insight_layers[0]['parent'], \"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insight_layers[0].loc[0, \"cluster\"] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_to_parent(0, insight_layers[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insight_layers[1].loc[0, 'parent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@Insight Plot the archive {display-mode: \"form\"}\n",
    "\n",
    "# UMAP reduces the dimensions from 1024 to 2 dimensions that we can plot\n",
    "reducer = umap.UMAP(n_neighbors=15)\n",
    "umap_embeds = reducer.fit_transform(sentence_embeddings)\n",
    "\n",
    "def map_to_parent(i, parents_df):\n",
    "    try:\n",
    "        return parents_df.loc[i, 'content']\n",
    "    except:\n",
    "        return \"\"\n",
    "    \n",
    "# Prepare the data to plot and interactive visualization\n",
    "# using Altair\n",
    "df_explore = pd.DataFrame(data={\n",
    "    'content': insight_layers[0]['content'], \n",
    "    'parent': insight_layers[0]['parent'].apply(lambda x: map_to_parent(x, insight_layers[1])),\n",
    "    'cluster': insight_layers[0]['cluster'].astype(str),\n",
    "    })\n",
    "df_explore['x'] = umap_embeds[:,0]\n",
    "df_explore['y'] = umap_embeds[:,1]\n",
    "df_explore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot\n",
    "chart = alt.Chart(df_explore).mark_circle(size=60).encode(\n",
    "    x=#'x',\n",
    "    alt.X('x',\n",
    "        scale=alt.Scale(zero=False)\n",
    "    ),\n",
    "    y=\n",
    "    alt.Y('y',\n",
    "        scale=alt.Scale(zero=False)\n",
    "    ),\n",
    "    color='cluster',\n",
    "    tooltip=['content', \"parent\"]\n",
    ").properties(\n",
    "    width=700,\n",
    "    height=400\n",
    ")\n",
    "chart.interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def td_idf(documents)\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform(documents)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    dense = vectors.todense()\n",
    "    denselist = dense.tolist()\n",
    "    df = pd.DataFrame(denselist, columns=feature_names)\n",
    "    df = df[df.columns.difference(stopwords.words('french'))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = td_idf(feedbacks_df['content'])\n",
    "#print('\\n'.join(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('\\n'.join(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_top_two_columns(row):\n",
    "    top_two_indexes = row.nlargest(5).index.tolist()\n",
    "    return top_two_indexes\n",
    "\n",
    "top_two_columns_df = df.apply(get_top_two_columns, axis=1)\n",
    "\n",
    "print(top_two_columns_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('\\n'.join(insights_df['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "cell_execution_strategy": "setup",
   "collapsed_sections": [
    "pKSREXZg85yy",
    "iiOlJz-d9AsB"
   ],
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
